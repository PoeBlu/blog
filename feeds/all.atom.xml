<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jason Antman's Blog</title><link href="http://blog.jasonantman.com/" rel="alternate"></link><link href="http://blog.jasonantman.com/feeds/all.atom.xml" rel="self"></link><id>http://blog.jasonantman.com/</id><updated>2014-03-01T14:14:00-05:00</updated><entry><title>Blog Moved from Self-hosted WordPress to Pelican on GitHub Pages</title><link href="http://blog.jasonantman.com/2014/03/blog-moved-from-self-hosted-wordpress-to-pelican-on-github-pages/" rel="alternate"></link><updated>2014-03-01T14:14:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-03-01:2014/03/blog-moved-from-self-hosted-wordpress-to-pelican-on-github-pages/</id><summary type="html">&lt;p&gt;I just finally finished my migration from self-hosted WordPress to &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt;, a Python-based
static site generator, hosted on &lt;a href="http://pages.github.com/"&gt;GitHub Pages&lt;/a&gt;. It&amp;#8217;s not only easier and free, but also the
first step in my plan to migrate off of my &lt;a href="http://linode.com"&gt;Linode&lt;/a&gt; &lt;span class="caps"&gt;VM&lt;/span&gt; and onto a mix of &lt;span class="caps"&gt;EC2&lt;/span&gt; and free&amp;nbsp;services.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m sure this post will be &lt;a href="/2009/02/wordpress-installation-finished/"&gt;around in five years&lt;/a&gt; when there&amp;#8217;s a smarter way
to do all this, but until then&amp;#8230;&amp;nbsp;yay!&lt;/p&gt;
&lt;p&gt;I hit a number of bumps during the migration, mainly around &lt;a href="/2014/02/converting-wordpress-posts-to-pelican-markdown/"&gt;Migrating &lt;span class="caps"&gt;HTML&lt;/span&gt; posts from WordPress to Markdown in Pelican&lt;/a&gt;
and migrating &lt;a href="/2014/03/wordpress-to-pelican-with-disqus-comments/"&gt;WordPress comments to Disqus&lt;/a&gt;, but in the end everything
seems to be working. Hopefully someone will find this and save a few hours or days of work if they try the same&amp;nbsp;thing.&lt;/p&gt;
&lt;p&gt;Post-go-live I still had some issues - Disqus was displaying an&amp;nbsp;error:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We were unable to load Disqus. If you are a moderator please see our troubleshooting&amp;nbsp;guide.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;on all posts created after the WordPress migration, and FeedBurner rejected my attempts to change the &lt;span class="caps"&gt;RSS&lt;/span&gt; feed &lt;span class="caps"&gt;URL&lt;/span&gt; to
its new value (though I&amp;#8217;m pretty sure that&amp;#8217;s because I neglected to drop the &lt;span class="caps"&gt;TTL&lt;/span&gt; on the &lt;span class="caps"&gt;DNS&lt;/span&gt; record, and I can&amp;#8217;t
find a way to tell Feedburner to purge it from&amp;nbsp;cache).&lt;/p&gt;</summary><category term="blog"></category><category term="wordpress"></category><category term="pelican"></category><category term="github"></category></entry><entry><title>Wordpress to Pelican with Disqus comments</title><link href="http://blog.jasonantman.com/2014/03/wordpress-to-pelican-with-disqus-comments/" rel="alternate"></link><updated>2014-03-01T09:09:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-03-01:2014/03/wordpress-to-pelican-with-disqus-comments/</id><summary type="html">&lt;p&gt;This is the second part of my WordPress to &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt; conversion saga.
In the &lt;a href="/2014/03/converting-wordpress-posts-to-pelican-markdown/"&gt;last post&lt;/a&gt; I ran through some
of the issues that I faced when converting the posts themselves, setting up my theme and settings,
etc. In this post, I&amp;#8217;ll discuss the saga of moving from WordPress comments to Disqus&amp;nbsp;comments.&lt;/p&gt;
&lt;p&gt;Be sure to read &lt;strong&gt;all&lt;/strong&gt; of this before trying it yourself, as I had some serious problems with my
first&amp;nbsp;attempt.&lt;/p&gt;
&lt;h2 id="initial-import-to-disqus"&gt;Initial Import to&amp;nbsp;Disqus&lt;/h2&gt;
&lt;p&gt;Initially, I installed the Disqus WordPress plugin as instructed in
&lt;a href="http://help.disqus.com/customer/portal/articles/466255-importing-comments-from-wordpress"&gt;Disqus&amp;#8217; Import from WordPress documentation&lt;/a&gt;.
The automatic import imported three of 134 comments, and froze there,
even though the status said it was 100% complete. I emailed Disqus&amp;#8217; support,
and was told that this meant the import failed (even though there was no explicit
notification, their admin &lt;span class="caps"&gt;UI&lt;/span&gt; said the import was successful) and I had to manually
import my comments. I did this, as instructed in the same docs, by disabling all
plugins except for Disqus and generating an &lt;span class="caps"&gt;XML&lt;/span&gt; export from WordPress, then re-enabling
the plugins, and uploading the export to Disqus. This time, I ended up with all 134
comments in Disqus, so I assumed that all went&amp;nbsp;well.&lt;/p&gt;
&lt;h2 id="previewing-comments-in-pelican"&gt;Previewing Comments in&amp;nbsp;Pelican&lt;/h2&gt;
&lt;p&gt;I added my Disqus &lt;code&gt;shortname&lt;/code&gt; to the &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; field in &lt;code&gt;pelicanconf.py&lt;/code&gt; and
re-built. I ended up having an issue with &lt;code&gt;SITE_URL&lt;/code&gt; being set incorrectly for some testing
that I did, so that killed 10 minutes. I rebuilt locally with &lt;code&gt;SITE_URL&lt;/code&gt; not defined, and
then used &lt;code&gt;fab serve&lt;/code&gt; to serve locally. I was using my
&lt;a href="/2014/01/planning-migration-from-wordpress-to-static-site/"&gt;Planning Migration from Wordpress to Static Site&lt;/a&gt;
post to test, as it was both the most recent post, and had a five comments in WordPress, which imported
correctly into Disqus and were visible both in the Disqus moderation tool and on the now-Disqus-powered
WordPress&amp;nbsp;blog.&lt;/p&gt;
&lt;p&gt;Once I rebuilt with &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; set and served locally with SimpleHTTPServer (&lt;code&gt;fab serve&lt;/code&gt;),
I checked the post and saw only a &amp;#8220;We were unable to load Disqus&amp;#8221; message below the post. It contained
a &lt;a href="http://help.disqus.com/customer/portal/articles/472007-i-m-receiving-the-message-%22we-were-unable-to-load-disqus-%22"&gt;link to their help article for that problem&lt;/a&gt;,
which pointed me at a domain mismatch/different origin problem. As indicated on that page,
I went to Settings -&amp;gt; Advanced in the Disqus admin, found the &amp;#8220;Trusted Domains&amp;#8221; box, and added
both my test domain (newblog.jasonantman.com - pointing at GitHub pages until I was ready to
shut WordPress down and actually move the live site) and &amp;#8220;localhost&amp;#8221; for testing, and&amp;nbsp;saved.&lt;/p&gt;
&lt;p&gt;I refreshed the page I was looking at, and now could see the Disqus commenting below my post,
but it wasn&amp;#8217;t showing any of the comments&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Disqus commenting with no comments" src="/GFX/disqus_wrong_url.png" /&gt;&lt;/p&gt;
&lt;p&gt;I pulled up the source of the page, and saw in the Disqus javascript just below the post&amp;nbsp;content:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_shortname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;jasonantman&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// required: replace example with your forum shortname&lt;/span&gt;
            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_identifier&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;planning-migration-from-wordpress-to-static-site&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;../../../2014/01/planning-migration-from-wordpress-to-static-site/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Everything looked &lt;span class="caps"&gt;OK&lt;/span&gt; to me except for &lt;code&gt;disqus_url&lt;/code&gt;, which I&amp;#8217;d seen mention of on the
&lt;a href="http://help.disqus.com/customer/portal/articles/472007-i-m-receiving-the-message-%22we-were-unable-to-load-disqus-%22"&gt;help page&lt;/a&gt;
I&amp;#8217;d just been looking at. Sure enough, it indicated that the &lt;code&gt;disqus_url&lt;/code&gt; var must be
an absolute &lt;span class="caps"&gt;URL&lt;/span&gt; to the post, not a relative path. I assume this was because I&amp;#8217;d generated
the content without having &lt;code&gt;SITE_URL&lt;/code&gt; set, so I hand-edited the generated page to change this
to the correct &lt;span class="caps"&gt;URL&lt;/span&gt;, http://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/,
and tested again. Unfortunately, still zero&amp;nbsp;comments.&lt;/p&gt;
&lt;h2 id="wordpress-disqus-plugin-permalinks"&gt;WordPress Disqus Plugin&amp;nbsp;Permalinks&lt;/h2&gt;
&lt;p&gt;Fearing the worst, I pulled up the same post on my now-Disqus-powered WordPress blog,
and took a peek at the source. The javascript over there revealed a&amp;nbsp;problem:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_identifier&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;1546 http://blog.jasonantman.com/?p=1546&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_container_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;disqus_thread&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_domain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;disqus.com&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_shortname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;jasonantman&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Planning Migration from WordPress to Static Site&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While the &lt;span class="caps"&gt;URL&lt;/span&gt; is correct, the Disqus WordPress plugin uses the WordPress
post &lt;span class="caps"&gt;ID&lt;/span&gt; and permalink for the &amp;#8220;identifier&amp;#8221;, but the Pelican plugin uses the slug.
That&amp;#8217;s a problem, as my Pelican site will have the same URLs, but the WordPress
post-&lt;span class="caps"&gt;ID&lt;/span&gt;-based permalinks are gone (since it&amp;#8217;s a static site, and there&amp;#8217;s no easy
way of replicating things that are query param based). The WordPress post IDs
are thrown out by Pelican, so there&amp;#8217;s no way to connect the&amp;nbsp;two.&lt;/p&gt;
&lt;p&gt;Even worse, I remembered that Disqus&amp;#8217;
&lt;a href="http://help.disqus.com/customer/portal/articles/466255-importing-comments-from-wordpress"&gt;Importing Comments from WordPress help page&lt;/a&gt;
clearly&amp;nbsp;stated:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Imported comments can&amp;#8217;t be permanently deleted. Consider following our &lt;a href="http://help.disqus.com/customer/portal/articles/1053796-best-practices-for-staging-development-and-preview-sites"&gt;guidelines for development sites&lt;/a&gt; to make sure the data you&amp;#8217;re importing is correct. You can &lt;a href="http://disqus.com/register"&gt;register a new forum&lt;/a&gt; if you have imported the wrong&amp;nbsp;comments.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="solution-to-permalink-issue"&gt;Solution to Permalink&amp;nbsp;Issue&lt;/h2&gt;
&lt;p&gt;Not seeing any way around it, I figured it was time to &amp;#8220;bite the bullet&amp;#8221;. I disabled the Disqus plugin
in WordPress and then installed and activated the
&lt;a href="http://wordpress.org/extend/plugins/code-freeze/"&gt;WordPress Code Freeze Plugin&lt;/a&gt;
to disable comments. (&lt;em&gt;Note&lt;/em&gt; ironically, this plugin also uses JavaScript to disable your ability to
deactivate plugins, including itself. So before you activate it, copy the &amp;#8220;Activate&amp;#8221; link and save it
somewhere; changing &lt;code&gt;action=activate&lt;/code&gt; to &lt;code&gt;action=deactivate&lt;/code&gt; will let you get rid of it if you&amp;nbsp;want).&lt;/p&gt;
&lt;p&gt;Disqus has some documentation on &lt;a href="http://help.disqus.com/customer/portal/articles/1104797-importing-exporting"&gt;Importing and Exporting&lt;/a&gt;
which includes &lt;a href="http://help.disqus.com/customer/portal/articles/472150"&gt;Custom &lt;span class="caps"&gt;XML&lt;/span&gt; Imports&lt;/a&gt; based on the
WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export format. So, I figured that I just had to decide that WordPress commenting would be
turned off, and do a point-in-time migration to Disqus (maybe circling back to hack the Disqus &lt;span class="caps"&gt;WP&lt;/span&gt; plugin
to keep comments working there for the time&amp;nbsp;being).&lt;/p&gt;
&lt;p&gt;Before anything else, I decided to actually set up a test forum/site in Disqus like they suggested.
I updated the &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; in &lt;code&gt;pelicanconf.py&lt;/code&gt;, and then started in on the &lt;span class="caps"&gt;XML&lt;/span&gt; munging. The
&lt;a href="http://help.disqus.com/customer/portal/articles/472150"&gt;Custom &lt;span class="caps"&gt;XML&lt;/span&gt; Imports&lt;/a&gt; documentation implies
that the import engine recognizes a &lt;code&gt;dsq:thread_identifier&lt;/code&gt; &lt;span class="caps"&gt;XML&lt;/span&gt; element that holds the thread identifier,
but that element wasn&amp;#8217;t present in my WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export. It appeared that Disqus was concatenating the
&lt;code&gt;wp:post_id&lt;/code&gt; and &lt;code&gt;guid&lt;/code&gt; fields (with a space in between) to come up with the&amp;nbsp;identifier.&lt;/p&gt;
&lt;p&gt;So, I wrote a script (&lt;a href="https://github.com/jantman/blog/blob/master/dev/wp-move/wp_comment_xml_munge.py"&gt;wp_comment_xml_munge.py&lt;/a&gt;)
using &lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt; that adds the &lt;code&gt;dsq:&lt;/code&gt; namespace to the WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export (unfortunately using
string replacement and a temp file, due to a &lt;a href="https://bugs.launchpad.net/lxml/+bug/555602"&gt;bug in lxml&lt;/a&gt;)
and then adds the &lt;code&gt;dsq:thread_identifier&lt;/code&gt; tag to each post item, setting its value to the same
string as &lt;code&gt;wp:post_name&lt;/code&gt;, the &lt;span class="caps"&gt;URL&lt;/span&gt; slug (and post identifier in&amp;nbsp;Pelican).&lt;/p&gt;
&lt;p&gt;I imported the &lt;span class="caps"&gt;XML&lt;/span&gt; written by the script into my test forum in Disqus and rebuilt the Pelican content.
Magically, the first time I looked, the comments were&amp;nbsp;there.&lt;/p&gt;
&lt;p&gt;Now, time to see if I could get the same effect with the existing Disqus&amp;nbsp;site/forum:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In the Disqus moderation interface, delete all comments. You&amp;#8217;ll have to do this in batches of 10, as that&amp;#8217;s
   how they&amp;#8217;re paged in the interface. The comments don&amp;#8217;t seem to be permanently deleted, but do show as&amp;nbsp;&amp;#8220;deleted&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Go to &lt;a href="http://import.disqus.com"&gt;import.disqus.com&lt;/a&gt; and select your &amp;#8220;forum&amp;#8221; (site). You should see your existing
   (previous) import, as 100% complete, with the correct count of threads and comments. Do another import with the
   &lt;code&gt;_disqus.xml&lt;/code&gt; munged &lt;span class="caps"&gt;XML&lt;/span&gt;&amp;nbsp;export.&lt;/li&gt;
&lt;li&gt;Comments should now be linked to the correct post in&amp;nbsp;Pelican.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, Pelican seemed to be working, but WordPress was still left with only the old internal commenting,
and that was disabled by the Code Freeze plugin. I probably could have manually patched the Disqus plugin to
reflect the new thread identifiers, but instead, I chose to just push forward with the switch from WordPress to&amp;nbsp;Pelican.&lt;/p&gt;
&lt;p&gt;That only took a few hours, and I&amp;#8217;m happy to say that I&amp;#8217;m now up and running with a Pelican blog, hosted for free
by GitHub&amp;nbsp;Pages.&lt;/p&gt;</summary><category term="wordpress"></category><category term="pelican"></category><category term="blog"></category><category term="disqus"></category><category term="comments"></category></entry><entry><title>Converting WordPress Posts to Pelican MarkDown</title><link href="http://blog.jasonantman.com/2014/02/converting-wordpress-posts-to-pelican-markdown/" rel="alternate"></link><updated>2014-02-28T22:21:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-02-28:2014/02/converting-wordpress-posts-to-pelican-markdown/</id><summary type="html">&lt;p&gt;A few weeks ago, I
&lt;a href="/2014/01/planning-migration-from-wordpress-to-static-site/"&gt;posted&lt;/a&gt; about my
plans to convert my self-hosted WordPress blog to a static site using a static
blog generator. Since then, I&amp;#8217;ve decided to stop working on my exhaustive
&lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AnHh-ye5DNiNdF9DWkJrT2kzSkNsNVp6cjMzLXJ6VEE&amp;amp;usp=sharing"&gt;static blog generator comparison spreadsheet&lt;/a&gt;
and just try &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt; - mainly because it&amp;#8217;s written in
Python which is my current strongest language, comes highly recommended, seems
to have most of the features I want, and seems to be easily&amp;nbsp;extensible.&lt;/p&gt;
&lt;p&gt;So, I walked through the documentation for the latest version (3.3.0), started
a &lt;a href="https://github.com/jantman/blog"&gt;GitHub repo&lt;/a&gt;, and tweaked a bunch of
settings. The repo is public, so if you want to take a look behind the scenes,
see my &lt;a href="https://github.com/jantman/blog/blob/master/fabfile.py"&gt;fabfile&lt;/a&gt;,
etc. feel&amp;nbsp;free. &lt;/p&gt;
&lt;h2 id="initial-wordpress-import-attempt"&gt;Initial WordPress Import&amp;nbsp;Attempt&lt;/h2&gt;
&lt;p&gt;I used the WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; Export tool, as instructed in the &lt;a href="http://docs.getpelican.com/en/latest/importer.html"&gt;Pelican Importer documentation&lt;/a&gt;.
At first, I attempted to do a more-or-less default import from WordPress using
the &lt;code&gt;pelican-import&lt;/code&gt; tool, which writes rST, and then build the blog. What I
ended up with was thousands of errors complaining about &amp;#8220;Inline interpreted
text or phrase reference start-string without end-string&amp;#8221;, &amp;#8220;Explicit markup
ends without a blank line; unexpected uninden&amp;#8221;, &amp;#8220;malformed hyperlink target&amp;#8221;,
&amp;#8220;Unknown target name&amp;#8221; on all of my links, and a bevy of other Docutils
errors. It was so utterly awful that I gave&amp;nbsp;up.&lt;/p&gt;
&lt;h2 id="wordpress-import-as-markdown"&gt;WordPress Import as&amp;nbsp;MarkDown&lt;/h2&gt;
&lt;p&gt;Next I tried importing as MarkDown instead of rST,&amp;nbsp;using:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;pelican-import --markup markdown --wpfile -o content/ --dir-page jasonantman039sblog.wordpress.2014-01-11.xml
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That built without errors, and the posts looked somewhat right out of the
box, without any of the previous thousands of errors. And the links looked
mostly right - even the captions for images. Though I&amp;#8217;m working at a Python
shop and writing a lot of Python these days, my knowledge of MarkDown is still
much better than rST, so this is fine for me. (I even wrote a &lt;code&gt;fab post&lt;/code&gt; task
that prompts for a title, generates all of the post metadata, writes it to the
right file, and opens up an editor on&amp;nbsp;it.)&lt;/p&gt;
&lt;p&gt;The first problem was that the import script gave me one &amp;#8220;content&amp;#8221; directory
with 346 &amp;#8220;.md&amp;#8221; files in it - not exactly easy to work with. Luckily the
metadata was right, so a quick little
&lt;a href="https://github.com/jantman/blog/blob/master/move_wordpress.sh"&gt;bash script&lt;/a&gt;
moved the posts into a &lt;span class="caps"&gt;YYYY&lt;/span&gt;/&lt;span class="caps"&gt;MM&lt;/span&gt; directory&amp;nbsp;hierarchy.&lt;/p&gt;
&lt;h2 id="obvious-problems-with-imported-posts"&gt;Obvious Problems with Imported&amp;nbsp;Posts&lt;/h2&gt;
&lt;p&gt;After getting the MarkDown import working, and the posts moved to the proper
paths, I was still having some&amp;nbsp;issues&amp;#8230;&lt;/p&gt;
&lt;h3 id="syntax-hilighting-gone"&gt;Syntax Hilighting&amp;nbsp;Gone&lt;/h3&gt;
&lt;p&gt;In WordPress, I was using the
&lt;a href="http://wordpress.org/extend/plugins/wp-syntax/"&gt;&lt;span class="caps"&gt;WP&lt;/span&gt;-Syntax&lt;/a&gt; plugin to perform
syntax hilighting via &lt;a href="http://qbnz.com/highlighter/"&gt;GeSHi&lt;/a&gt;. The plugin uses
pre tags with a &lt;code&gt;lang=&lt;/code&gt; attribute to specify the language,&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&amp;lt;pre lang=&amp;quot;bash&amp;quot;&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, these translated to some really ugly MarkDown fenced blocks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;~~~~ {lang=&amp;quot;bash&amp;quot;}
cp /boot/efi/EFI/fedora/grub.cfg /boot/efi/EFI/fedora/grub.cfg.bak
echo &amp;#39;GRUB_DISABLE_OS_PROBER=&amp;quot;true&amp;quot;&amp;#39; &amp;gt;&amp;gt; /etc/default/grub
grub2-mkconfig &amp;gt; /boot/efi/EFI/fedora/grub.cfg
~~~~
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;that seem to be just a bit off from what MarkDown/Pygments can handle. The
places where I just used bare &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; blocks translated&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;http://blog.gastove.com/2013-09-17_enabling_line_numbers_for_pygments.html&lt;/p&gt;
&lt;p&gt;Fixed this by using fenced blocks with the &amp;#8216;lang=&amp;#8217; stuff removed, and in class
syntax like the MarkDown docs suggest. Some four-tab-indents with
:::identifier&amp;nbsp;work.&lt;/p&gt;
&lt;h3 id="broken-links"&gt;Broken&amp;nbsp;Links&lt;/h3&gt;
&lt;p&gt;It seems that something in the conversion process introduced line wraps (could
it really be Pandoc itself???) Unfortunately, this wreaks havoc with any
explicit reference links
that use long (long enough to break across lines) titles, depending on where
they are in the line. It seems that in some places they end up breaking
differently in the link in the text and in the link definition, which MarkDown misses, and
then renders broken links and plain text of the link table at the bottom of
the page. Manually removing the line breaks and any extraneous spaces seems to
fix&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;So, yes, Pandoc was doing this because of the &lt;code&gt;--reference-links&lt;/code&gt; parameter
that &lt;code&gt;pelican-import&lt;/code&gt; was calling it with. There was an
&lt;a href="https://github.com/getpelican/pelican/issues/348"&gt;issue&lt;/a&gt; and
&lt;a href="https://github.com/getpelican/pelican/pull/642"&gt;pull request&lt;/a&gt; to fix this,
but when I started with Pelican the last release was 3.3.0 (4 months ago) and
the &lt;span class="caps"&gt;PR&lt;/span&gt; was merged after that. So, if you&amp;#8217;re having the same problem and the
latest release of Pelican is still 3.3.0, you might as well just apply
&lt;a href="https://github.com/getpelican/pelican/commit/83e4d35b44a422ee8d4b077f505970d03e555f45"&gt;the patch&lt;/a&gt;
yourself - it&amp;#8217;s just a very simple removal of a parameter in
&lt;code&gt;pelican_import.py&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="overall-results"&gt;Overall&amp;nbsp;Results&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m quite happy with the overall results. I also spent a &lt;em&gt;lot&lt;/em&gt; of time manually fixing
markup issues that didn&amp;#8217;t translate well through Pandoc, but I suppose that&amp;#8217;s to be
expected given that many of my older blog posts had &lt;span class="caps"&gt;HTML&lt;/span&gt;&amp;nbsp;issues.&lt;/p&gt;</summary><category term="pelican"></category><category term="wordpress"></category><category term="blog"></category><category term="markdown"></category></entry><entry><title>Planning Migration from WordPress to Static Site</title><link href="http://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/" rel="alternate"></link><updated>2014-01-01T15:15:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2014-01-01:2014/01/planning-migration-from-wordpress-to-static-site/</id><summary type="html">&lt;p&gt;Right now, this blog, my email, and a whole bunch of other services are
hosted on a &lt;a href="http://linode.com"&gt;Linode&lt;/a&gt; Xen &lt;span class="caps"&gt;VM&lt;/span&gt;. I don&amp;#8217;t really keep up
to date with administration and upgrades the way I used to, and
honestly, I&amp;#8217;d rather spend my time working on other things (like
actually writing all of the blog posts that I&amp;#8217;ve been planning to. The
first thing I&amp;#8217;ve identified for migration is this blog itself. It&amp;#8217;s
currently on WordPress and, frankly, I don&amp;#8217;t either need nor like it.
But there are some features I like. I&amp;#8217;d like to end up with a static
site generator, hosted from either S3 or GitHub Pages. I know that means
I&amp;#8217;ll lost comments (unless I move to a third-party, &lt;span class="caps"&gt;JS&lt;/span&gt;-based comment
system like &lt;a href="http://disqus.com/"&gt;Disqus&lt;/a&gt;, which means I&amp;#8217;ll lose
&lt;em&gt;control&lt;/em&gt; over my comments) but I suppose I can live with that. What I
really want is something simple, static, cheap or free (that I&amp;#8217;ll likely
put behind a small ec2 instance running nginx for&amp;nbsp;redirects/rewrites).&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m still in the planning phase, and trying to come up with a
feature-by-feature comparison of my options. I&amp;#8217;ll likely post that when
I finally have it done (at the moment it&amp;#8217;s in a very rough &lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AnHh-ye5DNiNdF9DWkJrT2kzSkNsNVp6cjMzLXJ6VEE&amp;amp;usp=sharing"&gt;Google Docs
spreadsheet&lt;/a&gt;).
I&amp;#8217;m trying to round up my static site generator options and see which
ones will do most, if not all, of what I want (though I still haven&amp;#8217;t
discounted using hosted wordpress if it comes down to it). Here are the
features I currently &amp;#8220;use&amp;#8221; (have) on my WordPress&amp;nbsp;blog:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User-defined permalinks to&amp;nbsp;posts&lt;/li&gt;
&lt;li&gt;Overall &lt;span class="caps"&gt;RSS&lt;/span&gt; feed of blog (currently powered by FeedBurner) and of&amp;nbsp;comments)&lt;/li&gt;
&lt;li&gt;Categories (a post can be in multiple&amp;nbsp;categories)&lt;/li&gt;
&lt;li&gt;Tags&lt;/li&gt;
&lt;li&gt;Category and Tag&amp;nbsp;pages&lt;/li&gt;
&lt;li&gt;per-Category and per-Tag feeds&amp;nbsp;(&lt;span class="caps"&gt;RSS&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;Tag cloud &amp;#8220;widget&amp;#8221; in&amp;nbsp;sidebar&lt;/li&gt;
&lt;li&gt;Themes. I actually like my current &lt;span class="caps"&gt;WP&lt;/span&gt;&amp;nbsp;theme&amp;#8230;&lt;/li&gt;
&lt;li&gt;Visitor statistics (currently self-hosted
    &lt;a href="http://piwik.org/"&gt;Piwik&lt;/a&gt;, formerly Google&amp;nbsp;Analytics)&lt;/li&gt;
&lt;li&gt;Post publishing via cron&amp;#8217;ed script (&lt;em&gt;see below&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Draft/Pending status (i.e. let me save a partial post, and let me
    save a complete post but mark it &amp;#8220;pending&amp;#8221; so I can just publish it&amp;nbsp;later)&lt;/li&gt;
&lt;li&gt;Commenting (this will probably be the big sticking&amp;nbsp;point)&lt;/li&gt;
&lt;li&gt;Syntax&amp;nbsp;hilighting&lt;/li&gt;
&lt;li&gt;As &amp;#8220;weird&amp;#8221; as this is, I write all my posts in raw &lt;span class="caps"&gt;HTML&lt;/span&gt;, and am
    perfectly happy doing&amp;nbsp;that.&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Subscribe via Email&amp;#8221; FeedBurner&amp;nbsp;widget&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;XML&lt;/span&gt;&amp;nbsp;Sitemap&lt;/li&gt;
&lt;li&gt;Twitter&amp;nbsp;box/widget&lt;/li&gt;
&lt;li&gt;Pingbacks (not that these are really useful for anything other than
    spam these&amp;nbsp;days)&lt;/li&gt;
&lt;li&gt;Automatic or manual post excerpts for feeds,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;Remote publishing via &lt;span class="caps"&gt;XML&lt;/span&gt;-&lt;span class="caps"&gt;RPC&lt;/span&gt;/Android app (not that I&amp;#8217;ve used it
    more than once or&amp;nbsp;twice)&lt;/li&gt;
&lt;li&gt;Advertising - I currently use Google AdSense on my blog. The revenue
    from my tiny hit count isn&amp;#8217;t enough to offset the cost of a Linode,
    but if I moved to a much less expensive hosting service, it might be
    worth considering (you can&amp;#8217;t run ads on the free hosted WordPress,
    and I doubt you can on GitHub Pages&amp;nbsp;either).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I should be updating this post when I do some more research and have a
comparison of the&amp;nbsp;options.&lt;/p&gt;
&lt;p&gt;Note on &amp;#8220;Post publishing via cron&amp;#8217;ed script&amp;#8221; - sometimes I sit down and
write half a dozen or so blog posts at a time. But I don&amp;#8217;t want them all
to show up immediately, and spam the few people who still use &lt;span class="caps"&gt;RSS&lt;/span&gt;
readers after the death of Google Reader. So I set the posts to
&amp;#8220;Pending&amp;#8221; status, and I have a cron&amp;#8217;ed script that runs every weekday
morning and publishes the one oldest &amp;#8220;pending&amp;#8221; post. Who knows if this
actually does any good or&amp;nbsp;not&amp;#8230;&lt;/p&gt;</summary><category term="blog"></category><category term="jekyll"></category><category term="pelican"></category><category term="python"></category><category term="static site"></category><category term="wordpress"></category></entry><entry><title>Testing GPG Key Passphrases</title><link href="http://blog.jasonantman.com/2013/08/testing-gpg-key-passphrases/" rel="alternate"></link><updated>2013-08-26T06:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-08-26:2013/08/testing-gpg-key-passphrases/</id><summary type="html">&lt;p&gt;So hypothetically, you have a &lt;span class="caps"&gt;GPG&lt;/span&gt; public/private keypair (from a backup
or old computer), but you don&amp;#8217;t remember the passphrase. Here&amp;#8217;s a
relatively simple way to find it from a number of possible options. This
&lt;em&gt;requires&lt;/em&gt; that you have a computer secure enough to store the possible
options in a text file. I&amp;#8217;d recommend storing that file on a
ramdisk/tmpfs, and using a temporary &lt;span class="caps"&gt;VM&lt;/span&gt; for this, which you&amp;#8217;ll wipe away
when you&amp;#8217;re&amp;nbsp;done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preparation:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You have an appropriately secure place to do this with &lt;span class="caps"&gt;GPG&lt;/span&gt;
    installed, and a safe place to store a text file of sample
    passphrases (i.e. a&amp;nbsp;ramdisk).&lt;/li&gt;
&lt;li&gt;Copy your backed up public and private keys to &lt;code&gt;~/.gnupg&lt;/code&gt; on that
    host. Let&amp;#8217;s assume they&amp;#8217;re called &lt;code&gt;TestUser_public.key&lt;/code&gt; and
    &lt;code&gt;TestUser_private.key&lt;/code&gt;. We&amp;#8217;re assuming that you &lt;span class="caps"&gt;KNOW&lt;/span&gt;, &lt;span class="caps"&gt;BEYOND&lt;/span&gt; A &lt;span class="caps"&gt;DOUBT&lt;/span&gt;
    that these are your keys (i.e. you got them from a secure offline
    backup medium, you&amp;#8217;ve verified against a printed key fingerprint,
    you&amp;#8217;ve verified the fingerprints against a
    &lt;a href="http://pgp.mit.edu/"&gt;keyserver&lt;/a&gt; that you know is authoritative for
    your keys,&amp;nbsp;etc.).&lt;/li&gt;
&lt;li&gt;First, we import the public and private keys to&amp;nbsp;&lt;span class="caps"&gt;GPG&lt;/span&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~$&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; .gnupg
&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --import TestUser_public.key 
&lt;span class="go"&gt;gpg: keyring `/home/testuser/.gnupg/secring.gpg` created&lt;/span&gt;
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: public key &amp;quot;Test User (Test User) &amp;quot; imported&lt;/span&gt;
&lt;span class="go"&gt;gpg: Total number processed: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:               imported: 1  (&lt;span class="caps"&gt;RSA&lt;/span&gt;: 1)&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --allow-secret-key-import --import TestUser_secret.key 
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: secret key imported&lt;/span&gt;
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: &amp;quot;Test User (Test User) &amp;quot; not changed&lt;/span&gt;
&lt;span class="go"&gt;gpg: Total number processed: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:              unchanged: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:       secret keys read: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:   secret keys imported: 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Check that the keys are&amp;nbsp;there:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --list-keys
&lt;span class="go"&gt;/home/testuser/.gnupg/pubring.gpg&lt;/span&gt;
&lt;span class="go"&gt;--------------------------------&lt;/span&gt;
&lt;span class="go"&gt;pub   2048R/&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; 2013-08-24&lt;/span&gt;
&lt;span class="go"&gt;uid                  Test User (Test User) &lt;/span&gt;
&lt;span class="go"&gt;sub   2048R/&lt;span class="caps"&gt;40D9F35E&lt;/span&gt; 2013-08-24&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --list-secret-keys
&lt;span class="go"&gt;/home/testuser/.gnupg/secring.gpg&lt;/span&gt;
&lt;span class="go"&gt;--------------------------------&lt;/span&gt;
&lt;span class="go"&gt;sec   2048R/&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; 2013-08-24&lt;/span&gt;
&lt;span class="go"&gt;uid                  Test User (Test User) &lt;/span&gt;
&lt;span class="go"&gt;ssb   2048R/&lt;span class="caps"&gt;40D9F35E&lt;/span&gt; 2013-08-24&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Note the fingerprint of the key which is, in this case, &lt;code&gt;17AD8D3D&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Testing&amp;nbsp;Passphrases:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Now that we have the keys imported, we&amp;#8217;re ready to test some
    passphrases. Enter your passphrases, one per line, in a text file.
    We&amp;#8217;re assuming that we&amp;#8217;re working on a totally secured host
    (ideally, a &lt;span class="caps"&gt;VM&lt;/span&gt; running on a standalone, non-networked machine) that
    will be destroyed when we&amp;#8217;re done. For added security, I&amp;#8217;d put this
    file on a ramdisk. In this example, the actual passphrase for the
    key is &amp;#8220;test&amp;#8221;. Here&amp;#8217;s our text&amp;nbsp;file:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; cat /tmp/passphrases 
&lt;span class="go"&gt;bad&lt;/span&gt;
&lt;span class="go"&gt;notgood&lt;/span&gt;
&lt;span class="go"&gt;notright&lt;/span&gt;
&lt;span class="go"&gt;test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Next, create a test data file to try to&amp;nbsp;sign/encrypt:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;test input&amp;quot;&lt;/span&gt; &amp;gt; /tmp/test.in
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Now we run the actual test (see below for more&amp;nbsp;information&amp;#8230;)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; &lt;span class="k"&gt;for &lt;/span&gt;p in &lt;span class="sb"&gt;`&lt;/span&gt;cat /tmp/passphrases&lt;span class="sb"&gt;`&lt;/span&gt;; &lt;span class="k"&gt;do &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$p&amp;quot;&lt;/span&gt; | gpg -q --sign --local-user &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; --passphrase-fd 0 --output /dev/null --yes /tmp/test.in &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: $p&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;break&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;; &lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0    &lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0    &lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0    &lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0    &lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: test&lt;/span&gt;
&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;And there we have it, the working passphrase. I&amp;#8217;m sure there&amp;#8217;s a
    more efficient way to do this, and probably a more secure way, but
    I&amp;#8217;m not trying to brute-force someone&amp;#8217;s &lt;span class="caps"&gt;GPG&lt;/span&gt; key, I&amp;#8217;m trying to
    remember which one of my (many, many) passwords I used for a &lt;span class="caps"&gt;GPG&lt;/span&gt; key
    that I generated a decade&amp;nbsp;ago.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The actual command that we ran, rewritten with some linebreaks for
legibility,&amp;nbsp;is:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;for &lt;/span&gt;p in &lt;span class="sb"&gt;`&lt;/span&gt;cat /tmp/passphrases&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$p&amp;quot;&lt;/span&gt; | gpg -q --sign --local-user &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; --passphrase-fd 0 --output /dev/null --yes /tmp/test.in &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: $p&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;break&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This loops over each line in the passphrases file (each passphrase that
we want to try), and for each one, echoes the password and pipes it to
&lt;span class="caps"&gt;STDIN&lt;/span&gt; of &lt;code&gt;gpg&lt;/code&gt;, which tries to sign /tmp/test.in (sending the output
to /dev/null) using the key with &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;code&gt;17AD8D3D&lt;/code&gt; (from #5 in the
Preparation steps above) and a password provided on &lt;span class="caps"&gt;STDIN&lt;/span&gt;. If the &lt;span class="caps"&gt;GPG&lt;/span&gt;
command succeeds, we echo the passphrase and stop looping through the
passphrases&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;I hope I wouldn&amp;#8217;t have to say this for anyone who&amp;#8217;s reading my blog, but
this information (as easy as it is to be figured out), is not to be used
for unethical&amp;nbsp;purposes.&lt;/p&gt;</summary><category term="encryption"></category><category term="gnupg"></category><category term="gpg"></category><category term="key"></category><category term="passphrase"></category><category term="pgp"></category></entry><entry><title>Quick Tip: Timestamping bash history</title><link href="http://blog.jasonantman.com/2013/06/quick-tip-timestamping-bash-history/" rel="alternate"></link><updated>2013-06-11T07:09:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-11:2013/06/quick-tip-timestamping-bash-history/</id><summary type="html">&lt;p&gt;Here&amp;#8217;s a tiny little snippet that I have in my &lt;code&gt;.bashrc&lt;/code&gt; which really
comes in handy when trying to figure out what I did on a system when.
One of the first things I do when (eek) building out or working on a
one-off machine (or setting up a new laptop/desktop, as I am right now)
is set this in bashrc for my user and root, so I can go back and
document the setup process with a little more ease and sanity. Just add
this (it&amp;#8217;s just a &lt;a href="http://linux.die.net/man/3/strftime"&gt;strftime (3)&lt;/a&gt;
format string &lt;a href="http://www.gnu.org/software/bash/manual/bashref.html#index-HISTTIMEFORMAT"&gt;according to the
docs&lt;/a&gt;,
so adjust as desired) to &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;HISTTIMEFORMAT&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;%F %T &amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and bash will store commented-out integer timestamps before each line in
&lt;code&gt;.bash_history&lt;/code&gt; like&amp;nbsp;so:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt;1370950005
&lt;span class="go"&gt;less .bashrc&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950017
&lt;span class="go"&gt;history &lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950279
&lt;span class="go"&gt;tail -30 .bash_history &lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950293
&lt;span class="go"&gt;exit&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;the output of &lt;code&gt;history&lt;/code&gt; now uses the specified time&amp;nbsp;format:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt; 997  2013-06-11 07:26:45 less .bashrc
 998  2013-06-11 07:26:57 history 
 999  2013-06-11 07:31:19 tail -30 .bash_history 
1000  2013-06-11 07:31:33 exit
&lt;/pre&gt;&lt;/div&gt;</summary><category term="bash"></category><category term="history"></category><category term="shell"></category><category term="timestamp"></category></entry><entry><title>Python script to check a list of URLs for return code, and final return code if redirected</title><link href="http://blog.jasonantman.com/2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/" rel="alternate"></link><updated>2013-06-10T06:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-10:2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/</id><summary type="html">&lt;p&gt;Every once in a while I need to add a bunch of redirects in Apache.
Here&amp;#8217;s a handy, dead simple Python script which takes a list of URLs on
&lt;span class="caps"&gt;STDIN&lt;/span&gt;, and for each one prints out either the response code, or, if the
response is a redirect, the response code of what is redirected to.
Pretty useful when you&amp;#8217;ve just added a bunch of redirects and want to
make sure none of them&amp;nbsp;404.&lt;/p&gt;
&lt;p&gt;The latest source of this script lives at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/check_url_list.py"&gt;https://github.com/jantman/misc-scripts/blob/master/check_url_list.py&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Script to check a list of URLs (passed on stdin) for response code, and for response code of the final path in a series of redirects.&lt;/span&gt;
&lt;span class="sd"&gt;Outputs (to stdout) a list of count of a given &lt;span class="caps"&gt;URL&lt;/span&gt;, response code, and if redirected, the final &lt;span class="caps"&gt;URL&lt;/span&gt; and its response code&lt;/span&gt;

&lt;span class="sd"&gt;Optionally, with verbose flag, report on all &lt;span class="caps"&gt;URL&lt;/span&gt; checks on &lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;

&lt;span class="sd"&gt;Copyright 2013 Jason Antman  all rights reserved&lt;/span&gt;
&lt;span class="sd"&gt;This script is distributed under the terms of the GPLv3, as per the&lt;/span&gt;
&lt;span class="sd"&gt;&lt;span class="caps"&gt;LICENSE&lt;/span&gt; file in this repository.&lt;/span&gt;

&lt;span class="sd"&gt;The canonical version of this script can be found at:&lt;/span&gt;

&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_url_nofollow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcode&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;+ checking &lt;span class="caps"&gt;URL&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;get_url_nofollow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;++ &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="http"></category><category term="python"></category><category term="redirect"></category><category term="urllib"></category></entry><entry><title>Modern (0.10.x+) NodeJS RPMs on CentOS/REHL 5 and 6</title><link href="http://blog.jasonantman.com/2013/06/modern-0-10-x-nodejs-rpms-on-centosrehl-5-and-6/" rel="alternate"></link><updated>2013-06-06T20:47:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-06:2013/06/modern-0-10-x-nodejs-rpms-on-centosrehl-5-and-6/</id><summary type="html">&lt;p&gt;I posted back in January about &lt;a href="/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt; Spec Files for nodejs 0.9.5 and v8
on CentOS
6&lt;/a&gt;. In
that post I also said that I was unable to get recent NodeJS to build on
CentOS 5 because of a long chain of dependencies including node-gyp, v8,
http-parser, glibc, etc. I said I couldn&amp;#8217;t get it to build. Well, I have
good news for both distro&amp;nbsp;versions.&lt;/p&gt;
&lt;p&gt;On the CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; 6 side, thanks to a lot of work by &lt;span class="caps"&gt;T. C.
&lt;/span&gt;Hollingsworth and others, NodeJS 0.10.5 is currently in the official
&lt;a href="http://fedoraproject.org/wiki/EPEL"&gt;&lt;span class="caps"&gt;EPEL&lt;/span&gt;&lt;/a&gt; repositories. They seem to be
keeping the packages pretty current, but if you need newer, you can
always grab the SRPMs from &lt;span class="caps"&gt;EPEL&lt;/span&gt; and build the newer versions. This is
great, because it means I no longer need to maintain the spec files and
do my own builds. I don&amp;#8217;t think I really did anything to help get this
package in &lt;span class="caps"&gt;EPEL&lt;/span&gt;, other than ping a few people and comment on a few&amp;nbsp;tickets.&lt;/p&gt;
&lt;p&gt;For CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; 5, I finally have packages, but they&amp;#8217;re not exactly
pretty. The dependency solving issues still stand; they&amp;#8217;re rooted at the
dependency of node-gyp which requires the v8 C++ JavaScript library, and
is required to compile shared object addons. The best solution that I
(and a few others) could find is simply not to build node-gyp, and not
to have support for addons or package any addons; we just have the
binaries that NodeJS&amp;#8217;s Makefile creates, and everything else is
interpreted. A &lt;a href="https://twitter.com/toxigenicpoem"&gt;coworker&lt;/a&gt; found
&lt;a href="https://github.com/kazuhisya/nodejs-rpm"&gt;https://github.com/kazuhisya/nodejs-rpm&lt;/a&gt;
which contains a configure patch and specfile for a dead-simple CentOS
5/6 &lt;span class="caps"&gt;RPM&lt;/span&gt; of NodeJS 0.10.9, which essentially just uses &lt;span class="caps"&gt;EPEL&lt;/span&gt;&amp;#8217;s python26
packages to power the NodeJS build process, configures and uses the
Makefile&amp;#8217;s &lt;code&gt;make binary&lt;/code&gt; command to spit out a NodeJS binary tarball,
and then packages that. That whole process way out of line from the
&lt;a href="http://fedoraproject.org/wiki/Packaging:Guidelines"&gt;Fedora Packaging
Guidelines&lt;/a&gt;, and
also only dumps out nodejs, nodejs-binary and nodejs-debuginfo packages,
so I also can&amp;#8217;t just substitute in a different package name in my puppet
manifests (which install nodejs, nodejs-devel and npm packages). So I
&lt;a href="https://github.com/jantman/nodejs-rpm-centos5"&gt;forked that repository&lt;/a&gt;
and made some changes to the specfile: I gave the package name a prefix
(&amp;#8220;cmgd_&amp;#8221;, since that&amp;#8217;s where I work these days) and some warnings in
the description, to make it abundantly clear that these packages are
very far from what you find in &lt;span class="caps"&gt;EPEL&lt;/span&gt; and other repositories, and broke
npm and the devel files out into their own subpackages. Hopefully this
spec file will be of use to someone else who also has the unfortunate
need of supporting recent NodeJS on CentOS 5. If there&amp;#8217;s enough
interest, I&amp;#8217;ll consider building the packages and putting them in a
repository&amp;nbsp;somewhere.&lt;/p&gt;
&lt;p&gt;You can see the NodeJS 0.10.9 on CentOS 5 spec file, a patch, and the
READMEs at
&lt;a href="https://github.com/jantman/nodejs-rpm-centos5"&gt;https://github.com/jantman/nodejs-rpm-centos5&lt;/a&gt;.
Patches and/or pull requests are greatly appreciated, especially from
anyone who wants to make the spec file more Fedora guidelines&amp;nbsp;compliant.&lt;/p&gt;</summary><category term="build"></category><category term="centos"></category><category term="EPEL"></category><category term="node"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="redhat"></category><category term="RHEL"></category><category term="rpm"></category><category term="specfile"></category></entry><entry><title>Script to easily rebuild a SRPM</title><link href="http://blog.jasonantman.com/2013/05/script-to-easily-rebuild-a-srpm/" rel="alternate"></link><updated>2013-05-28T10:26:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-28:2013/05/script-to-easily-rebuild-a-srpm/</id><summary type="html">&lt;p&gt;Between &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 and 6 the default &lt;span class="caps"&gt;RPM&lt;/span&gt; compression format was
changed to xz. As such, trying to build a recent Fedora or Cent6 &lt;span class="caps"&gt;SRPM&lt;/span&gt; on
Cent5 will error out with a message like
&lt;code&gt;error: unpacking of archive failed on file foo;51a4c2a5: cpio: MD5 sum mismatch&lt;/code&gt;
because tar on CentOS 5 doesn&amp;#8217;t support&amp;nbsp;xz.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a quick and dirty little script to use &lt;code&gt;rpm2cpio&lt;/code&gt; to rebuild a
&lt;span class="caps"&gt;SRPM&lt;/span&gt; using the host&amp;#8217;s native &lt;span class="caps"&gt;RPM&lt;/span&gt; compression. The latest version will
live at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/rebuild_srpm.sh"&gt;https://github.com/jantman/misc-scripts/blob/master/rebuild_srpm.sh&lt;/a&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;
&lt;span class="c"&gt;# Script to rebuild a &lt;span class="caps"&gt;SRPM&lt;/span&gt; 1:1, useful when you want to build a &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 6&lt;/span&gt;
&lt;span class="c"&gt;# &lt;span class="caps"&gt;SRPM&lt;/span&gt; on a &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 system that doesn&amp;#39;t support newer compression (cpio: &lt;span class="caps"&gt;MD5&lt;/span&gt; sum mismatch)&lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;
&lt;span class="c"&gt;# by Jason Antman &lt;/span&gt;
&lt;span class="c"&gt;# The latest version of this script will always live at:&lt;/span&gt;
&lt;span class="c"&gt;# &lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-h&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--help&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: rebuild_srpm.sh  &amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; ! -e &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: &lt;span class="caps"&gt;SRPM&lt;/span&gt; file not found: $1&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; ! which rpmbuild &amp;amp;&amp;gt; /dev/null
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rpmbuild could not be found. please install. (sudo yum install rpm-build)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; ! which rpm2cpio &amp;amp;&amp;gt; /dev/null
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rpm2cpio could not be found. please install. (sudo yum install rpm)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;dirname &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;basename &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;mktemp -d&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;STARTPWD&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Rebuilding $&lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;

&lt;span class="c"&gt;# copy srpm into tempdir&lt;/span&gt;
cp &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;

&lt;span class="nb"&gt;pushd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt; &amp;amp;&amp;gt;/dev/null

&lt;span class="c"&gt;# setup local build dir structure&lt;/span&gt;
mkdir -p rpm rpm/&lt;span class="caps"&gt;BUILD&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt; rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt; rpm/&lt;span class="caps"&gt;SPECS&lt;/span&gt; rpm/&lt;span class="caps"&gt;SRPMS&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/athlon rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/i&lt;span class="se"&gt;\[&lt;/span&gt;3456&lt;span class="se"&gt;\]&lt;/span&gt;86 rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/i386 rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/noarch rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/x86_64

&lt;span class="c"&gt;# setup rpmmacros file&lt;/span&gt;
cat /dev/null &amp;gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/.rpmmacros
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%_topdir        $&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;/rpm&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.rpmmacros

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Extracting &lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;pushd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt;/ &amp;amp;&amp;gt;/dev/null
rpm2cpio &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt; | cpio -idmv &amp;amp;&amp;gt;/dev/null
&lt;span class="nb"&gt;popd&lt;/span&gt; &amp;amp;&amp;gt;/dev/null

&lt;span class="c"&gt;# build the &lt;span class="caps"&gt;SRPM&lt;/span&gt; from the spec and sources&lt;/span&gt;
&lt;span class="c"&gt;# we&amp;#39;re just building a &lt;span class="caps"&gt;SRPM&lt;/span&gt; so we can ignore dependencies&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Rebuilding &lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;NEW_SRPM&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;rpmbuild -bs --nodeps --macros&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/.rpmmacros &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt;/*.spec | grep &lt;span class="s2"&gt;&amp;quot;^Wrote: &amp;quot;&lt;/span&gt; | awk &lt;span class="s1"&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Copying to $&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&amp;quot;&lt;/span&gt;
cp &lt;span class="nv"&gt;$NEW_SRPM&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;/

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Wrote file to $&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;/`basename $NEW_SRPM`&amp;quot;&lt;/span&gt;

&lt;span class="c"&gt;# cleanup&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;STARTPWD&lt;/span&gt;&lt;/span&gt;
rm -Rf &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="lzma"></category><category term="packaging"></category><category term="rpm"></category><category term="rpm2cpio"></category><category term="rpmbuild"></category><category term="srpm"></category><category term="xz"></category></entry><entry><title>Git Cheat Sheet</title><link href="http://blog.jasonantman.com/2013/05/git-cheat-sheet/" rel="alternate"></link><updated>2013-05-14T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-14:2013/05/git-cheat-sheet/</id><summary type="html">&lt;p&gt;I use &lt;a href="http://git-scm.com/"&gt;git&lt;/a&gt; quite a bit these days, both with an
internal server at work and with a bunch of my projects and random code
that now live on &lt;a href="https://github.com/jantman/"&gt;my github account&lt;/a&gt;. The
transition from &lt;span class="caps"&gt;SVN&lt;/span&gt; hasn&amp;#8217;t always been easy. Here&amp;#8217;s a quick cheat sheet
of some of the things that I usually&amp;nbsp;forget.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Show diff of the last&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git diff HEAD^..HEAD
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Roll back to version xyz of a specific file &lt;em&gt;(where xyz is a &lt;span class="caps"&gt;SHA1&lt;/span&gt;
    commit ref)&lt;/em&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout xyz path/to/file
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Undo any &lt;em&gt;unstaged&lt;/em&gt; changes to your&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -f
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Undo any staged and working directory&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git reset --hard
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update submodules after cloning a&amp;nbsp;repository:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git submodule update --init
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebase on current master to pull in new&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebase on current master, but for files that changed, take our
    version &lt;em&gt;(for some reason, a plain rebase seems to sometimes show
    conflicts on files that haven&amp;#8217;t changed in ages on master)&lt;/em&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase -s recursive -Xtheirs master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete a local&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git branch -d BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete a remote branch from&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin --delete BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Roll back your branch to the same state as the branch in&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git reset --hard origin/BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Revert a specific&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git revert COMMIT_HASH
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Track an upstream branch (i.e. in a project you&amp;nbsp;forked):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add --track master upstream https://github.com/user/project.git
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pull in upstream&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout master &amp;amp;&amp;amp; git fetch upstream &amp;amp;&amp;amp; git merge upstream/master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Merge &amp;#8220;stuff&amp;#8221; from someone else&amp;#8217;s fork into&amp;nbsp;yours:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add other-guys-repo URL_TO_REPO
git fetch other-guys-repo
git checkout my_new_branch
git merge other-guys-repo/master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prune local branches that have been deleted in the remote&amp;nbsp;(origin):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote prune origin
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;</summary><category term="git"></category></entry><entry><title>Search for a small-scale but automated RPM build system</title><link href="http://blog.jasonantman.com/2013/05/search-for-a-small-scale-but-automated-rpm-build-system/" rel="alternate"></link><updated>2013-05-13T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-13:2013/05/search-for-a-small-scale-but-automated-rpm-build-system/</id><summary type="html">&lt;p&gt;&lt;strong&gt;This post is part of a series of older draft posts from a few months
ago that I&amp;#8217;m just getting around to publishing. Unfortunately, I have
yet to find a build system that meets my requirements (see the last&amp;nbsp;paragraph).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At work, we have a handful - currently a really small number - of &lt;span class="caps"&gt;RPM&lt;/span&gt;
packages that we need to build and deploy internally for our CentOS
server infrastructure. A number of them are just pulled down from
specific third-party repositories and rebuilt to have the vendor set as
us, and some are internally patched or developed software. We run
websites, and on the product side, we&amp;#8217;re a
Python/&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; shop (in fact, probably
one of the largest Django apps out there). We don&amp;#8217;t deploy our Django
apps via &lt;span class="caps"&gt;RPM&lt;/span&gt;, so building and distributing RPMs is definitely not one of
our core competencies. In fact, we really only want to do it when we&amp;#8217;re
testing/deploying a new distro, or when an upstream package is&amp;nbsp;updated.&lt;/p&gt;
&lt;p&gt;Last week I pulled a ticket to deploy &lt;a href="http://nodejs.org/"&gt;node.js&lt;/a&gt; to
one of our build hosts, and we&amp;#8217;ve got a few things in the pipeline that
also rely on it. I found the
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module on Github that&amp;#8217;s supposed to install it on &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS, but it
pulls packages from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;,
and the newest version of nodejs there is 0.6.18, which is quite old. I
can&amp;#8217;t find any actively maintained sources of newer nodejs packages for
&lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS (yeah, I know, that&amp;#8217;s one down side to the
distributions&amp;#8230;). However, I did find that nodejs 0.9.5 is being &lt;a href="http://koji.fedoraproject.org/koji/packageinfo?packageID=15154"&gt;built
for Fedora 18/19 in the Fedora build
system&lt;/a&gt;,
is already in the Fedora 18 Testing and Fedora Rawhide repos, but is
failing its &lt;span class="caps"&gt;EL6&lt;/span&gt; builds in their system. The decision I&amp;#8217;ve come to is to
use the puppetlabs-nodejs module to install it, but try and rebuild the
Fedora 18 RPMs under CentOS 5 and&amp;nbsp;6.&lt;/p&gt;
&lt;p&gt;So that&amp;#8217;s the background. Now, my current task: to search for an &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system for my current job. My core requirements, in no specific
order,&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be relatively easy and quick to use for people who have a specfile
    or &lt;span class="caps"&gt;SRPM&lt;/span&gt; and want to be able to &amp;#8220;ensure =&gt; present&amp;#8221; the finished &lt;span class="caps"&gt;RPM&lt;/span&gt;
    on a system. i.e., require as little per-package configuration as&amp;nbsp;possible.&lt;/li&gt;
&lt;li&gt;Be able to handle rebuilding &amp;#8220;all&amp;#8221; of our RPMs when we roll out a
    new distro version. Doesn&amp;#8217;t necessarily need to be automatic, but
    should be relatively&amp;nbsp;simple.&lt;/li&gt;
&lt;li&gt;Ideally, not need to be running constantly - i.e. something that
    will cope well with build hosts being VMs that are shut down when
    they&amp;#8217;re not&amp;nbsp;needed.&lt;/li&gt;
&lt;li&gt;Handle automatically putting successfully built packages into a
    repository, ideally with some sort of (manual) promotion process
    from staging to&amp;nbsp;stable.&lt;/li&gt;
&lt;li&gt;Have minimal external (infrastructure) dependencies that we can&amp;#8217;t
    satisfy with existing&amp;nbsp;systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the first step was to research existing &lt;span class="caps"&gt;RPM&lt;/span&gt; build systems and how
others do this. Here&amp;#8217;s a list of what I could find online, though most
of these are from distributions and software vendors/projects, not
end-user companies that are only building for internal&amp;nbsp;use.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://fedorahosted.org/koji/wiki"&gt;Koji&lt;/a&gt; is the build system used
    by &lt;a href="http://fedoraproject.org/wiki/Koji"&gt;Fedora&lt;/a&gt; and RedHat. It&amp;#8217;s
    about as full-featured as any can be, and I&amp;#8217;m familiar with it from
    my time at &lt;a href="http://koji.rutgers.edu/koji/"&gt;Rutgers University&lt;/a&gt;, as
    it&amp;#8217;s used to maintain their CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; packages. It&amp;#8217;s based largely
    on Mock. However, &lt;a href="http://fedoraproject.org/wiki/Koji/ServerHowTo"&gt;setting up the build
    server&lt;/a&gt; is no
    trivial task; there are few installations outside of Fedora/RedHat,
    and it relies on either Kerberos or an &lt;span class="caps"&gt;SSL&lt;/span&gt; &lt;span class="caps"&gt;CA&lt;/span&gt; infrastructure to
    authenticate machines and clients. So, it&amp;#8217;s designed for too large a
    scale and too much infrastructure for&amp;nbsp;me.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux has a &lt;a href="https://www.pld-linux.org/developingpld/builderscript"&gt;builder
    script&lt;/a&gt; that
    seems to automate &lt;code&gt;rpmbuild&lt;/code&gt; as well as fetching sources and
    resolving/building dependencies. I haven&amp;#8217;t looked at the script yet,
    but apparently it&amp;#8217;s in &lt;span class="caps"&gt;PLD&lt;/span&gt;&amp;#8217;s &amp;#8220;rpm-build-tools&amp;#8221;&amp;nbsp;package.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux also has a &lt;span class="caps"&gt;CVS&lt;/span&gt; repository for something called
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new"&gt;pld-builder.new&lt;/a&gt;.
    The
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/README?rev=1.5"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;
    and
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/ARCHITECTURE?rev=1.6"&gt;&lt;span class="caps"&gt;ARCHITECTURE&lt;/span&gt;&lt;/a&gt;
    files make it sound like a relatively simple mainly-Python system
    that builds &lt;span class="caps"&gt;SRPMS&lt;/span&gt; and binary packages when requested, and most
    importantly, seems like a simple system that uses little more than
    shared filesystem access for communication and&amp;nbsp;coordination.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;ALT&lt;/span&gt; Linux has &lt;a href="http://en.altlinux.org/Sisyphus"&gt;Sisyphus&lt;/a&gt;, which
    combines repository management and web interface tools, package
    building and testing tools, and&amp;nbsp;more.&lt;/li&gt;
&lt;li&gt;The Dries &lt;span class="caps"&gt;RPM&lt;/span&gt; repository uses (or at least used&amp;#8230; my reference is
    quite old) &lt;a href="http://dries.ulyssis.org/rpm/pydar2/index.html"&gt;pydar2&lt;/a&gt;,
    &amp;#8220;a distributed client/server program which allows you to build
    multiple spec files on multiple distribution/architecture
    combinations automatically.&amp;#8221; That sounds like it could be what I
    need, but the last update says that it isn&amp;#8217;t finished yet, and that
    was in &lt;strong&gt;2005&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Mandriva Linux has pretty extensive information on their build
    system &lt;a href="http://wiki.mandriva.com/en/Category:Build_System"&gt;on their
    wiki&lt;/a&gt; and a
    &lt;a href="http://wiki.mandriva.com/en/Development/Packaging/BuildSystem/Theory"&gt;build system theory
    page&lt;/a&gt;,
    but it seems to be largely a hodgepodge of shell scripts and
    cronjobs, and is likely not a candidate for use by anyone other than
    its&amp;nbsp;designers.&lt;/li&gt;
&lt;li&gt;Argeo provides the &lt;a href="https://www.argeo.org/wiki/SLC"&gt;&lt;span class="caps"&gt;SLC&lt;/span&gt; framework&lt;/a&gt;
    which has a &amp;#8220;&lt;span class="caps"&gt;RPM&lt;/span&gt; Factory&amp;#8221; component, but I can&amp;#8217;t seem to find much
    more than a wiki page, and can&amp;#8217;t tell if it&amp;#8217;s a build automation
    system or just handles mocking packages and putting them in a repo
    on a single&amp;nbsp;host.&lt;/li&gt;
&lt;li&gt;Dag Wieers&amp;#8217; repositories use (or used) a set of python scripts
    called &lt;a href="http://dag.wieers.com/home-made/dar/"&gt;&lt;span class="caps"&gt;DAR&lt;/span&gt;, &amp;#8220;Dynamic Apt Repository
    builder&amp;#8221;&lt;/a&gt;. They&amp;#8217;re on
    &lt;a href="https://github.com/dagwieers/dar"&gt;github&lt;/a&gt; but are listed as &amp;#8220;old&amp;#8221;
    and haven&amp;#8217;t been updated in at least 2 years. The features sound
    quite interesting, and though it&amp;#8217;s based on the Apt repo format, it
    might provide some good ideas for implementing a similar&amp;nbsp;system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Update four months later:&lt;/strong&gt; I&amp;#8217;ve yet to find a build system that meets
my requirements above. For the moment I&amp;#8217;m only managing \~20 packages,
so my &amp;#8220;build system&amp;#8221; is a single shell script that reads in some
environment variables and runs through using
&lt;a href="http://fedoraproject.org/wiki/Projects/Mock"&gt;mock&lt;/a&gt; to build them in the
correct order (including pushing the finished RPMs back into the local
repository that mock reads from) and then pushing the finished packages
to our internal repository. Maybe when I have some spare time, I&amp;#8217;ll
consider a project to either make a slightly better (but simple) &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system based on Python, or get our
&lt;a href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; install to handle this for&amp;nbsp;me.&lt;/p&gt;</summary><category term="build"></category><category term="linux"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="repository"></category><category term="rpm"></category><category term="rpmbuild"></category><category term="software"></category><category term="sysadmin"></category><category term="yum"></category></entry><entry><title>Environment Variable Substitution in Apache httpd Configs</title><link href="http://blog.jasonantman.com/2013/05/environment-variable-substitution-in-apache-httpd-configs/" rel="alternate"></link><updated>2013-05-11T12:01:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-11:2013/05/environment-variable-substitution-in-apache-httpd-configs/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been configuring Apache httpd for over a decade, from a single
personal web server to web farms running thousands of vhosts. In most of
the &amp;#8220;real&amp;#8221; environments I&amp;#8217;ve worked in, we&amp;#8217;ve had some variation of
production, stage/test/&lt;span class="caps"&gt;QA&lt;/span&gt; and development hosts; and usually some method
of managing configurations between them, whether it&amp;#8217;s source control or
generating them from template. And in all of these environments, there
has invariably been drift between the configurations in the various
environments, whether it&amp;#8217;s because of poor tools to maintain a unified
configuration or many of those emergency redirect requests that make it
into production but are never backported. This is made all the worse
because everywhere I&amp;#8217;ve worked, the real difference between what
production and other environments &lt;em&gt;should&lt;/em&gt; be is really just a string
replacement in Apache configurations - &lt;code&gt;/prod/&lt;/code&gt; to &lt;code&gt;/test/&lt;/code&gt; or
&lt;code&gt;www.example.com&lt;/code&gt; to &lt;code&gt;www.dev.example.com&lt;/code&gt; or something along those&amp;nbsp;lines.&lt;/p&gt;
&lt;p&gt;Well a few days ago I was having a discussion with some co-workers that
dovetailed into this topic, and when I started some research, I found
(&lt;em&gt;finally after using httpd for years&lt;/em&gt;) that the &lt;a href="http://httpd.apache.org/docs/2.2/configuring.html#syntax"&gt;Apache httpd 2.2
configuration file syntax
documentation&lt;/a&gt;
states that httpd supports environment variable interpolation anywhere
in the config files (and &lt;a href="http://httpd.apache.org/docs/2.4/configuring.html#syntax"&gt;httpd
2.4&lt;/a&gt; supports
it with Defines as&amp;nbsp;well).&lt;/p&gt;
&lt;p&gt;Yup, that&amp;#8217;s right. All those different Apache configs I&amp;#8217;ve worked with
for years that define separate vhosts, document roots, rewrite targets,
ServerAliases, etc. for &lt;code&gt;www.example.com&lt;/code&gt; and &lt;code&gt;www.qa.example.com&lt;/code&gt; and
&lt;code&gt;www.dev.example.com&lt;/code&gt; really only had to be
&lt;code&gt;www.${ENV_URL_PART}example.com&lt;/code&gt;, and set &lt;code&gt;ENV_URL_PART&lt;/code&gt; in the init
script or sysconfig file. (Of course this all assumes that you have your
different environments served by different httpd instances, which you
do, of&amp;nbsp;course&amp;#8230;)&lt;/p&gt;
&lt;p&gt;For me, this is a very big deal. It means that finally, instead of
maintaining separate sets of configs for different environments which
are (theoretically, except for those emergencies) kept identical by
hand, or updating templates and then re-generating each environment&amp;#8217;s
configs, we can finally follow the same
commit/merge/promotion-between-environments workflow that we use for
other production code and Puppet configuration. It also means that those
pesky little rewrites and other minor tweaks will make it all the way
back to development&amp;nbsp;environments.&lt;/p&gt;
&lt;p&gt;So, here&amp;#8217;s a little example of how this would work in reality. Let&amp;#8217;s
assume that we have 3 main environments, &lt;code&gt;prod&lt;/code&gt;, &lt;code&gt;qa&lt;/code&gt; and &lt;code&gt;dev&lt;/code&gt; (though
this should work for N environments) and that domains are prefixed with
&amp;#8220;qa.&amp;#8221; or &amp;#8220;dev.&amp;#8221; for the respective internal environments. We set
environment variables before httpd is started, on a per-host basis,
depending on what environment that host is in. On RedHat based systems,
we&amp;#8217;d add the variables to &lt;code&gt;/etc/sysconfig/httpd&lt;/code&gt; for&amp;nbsp;production:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;HTTPD_ENV_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;prod&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;HTTPD_ENV_URL_PART&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;or for&amp;nbsp;&lt;span class="caps"&gt;QA&lt;/span&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;HTTPD_ENV_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;qa&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;HTTPD_ENV_URL_PART&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;qa.&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Those variables will now be available to httpd within the configurations
(and also to any applications or scripts that have access to the web
server&amp;#8217;s environment&amp;nbsp;variables).&lt;/p&gt;
&lt;p&gt;Now let&amp;#8217;s look at an example vhost configuration file that uses the
environment&amp;nbsp;variables:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;ServerName&lt;/span&gt; example.com
&lt;span class="nb"&gt;ServerAlias&lt;/span&gt; www.example.com
&lt;span class="c"&gt;# Aliases including proper environment name&lt;/span&gt;
&lt;span class="nb"&gt;ServerAlias&lt;/span&gt; www.${HTTPD_ENV_NAME}.example.com ${HTTPD_ENV_NAME}.example.com

&lt;span class="nb"&gt;ErrorLog&lt;/span&gt; &lt;span class="sx"&gt;/var/log/httpd/example.com-error_log&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; &lt;span class="sx"&gt;/var/log/httpd/example.com-access_log&lt;/span&gt; combined

&lt;span class="nb"&gt;DocumentRoot&lt;/span&gt; &lt;span class="sx"&gt;/sites/example.com/&lt;/span&gt;${HTTPD_ENV_NAME}/

&lt;span class="c"&gt;# Environment-specific configuration, if we absolutely need it:&lt;/span&gt;
&lt;span class="nb"&gt;Include&lt;/span&gt; &lt;span class="sx"&gt;/etc/httpd/sites/&lt;/span&gt;${HTTPD_ENV_NAME}/env.conf


&lt;span class="nb"&gt;RewriteEngine&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt;
&lt;span class="nb"&gt;RewriteRule&lt;/span&gt; &lt;span class="sx"&gt;/foobar/.&lt;/span&gt;* http://www.${HTTPD_ENV_URL_PART}example.com/baz/ [R=302,L]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Every instance of &lt;code&gt;${HTTPD_ENV_NAME}&lt;/code&gt; will be replaced with the value
set in the sysconfig file, and likewise with every instance of
&lt;code&gt;${HTTPD_ENV_URL_PART}&lt;/code&gt;. This way, we can have one set of configurations
and use our normal source control branch/promotion process to both test
and promote changes through the environments along with application
code, and ensure that any straight-to-production emergency changes
(everyone has customer-ordered rewrites like that, right?) make it back
to development and&amp;nbsp;qa.&lt;/p&gt;
&lt;p&gt;One caveat is that, if the environment variable is not defined, the
&lt;code&gt;${VAR_NAME}&lt;/code&gt; will be left as a literal string in the configuration
file. There doesn&amp;#8217;t seem to be any way to protect against this in httpd
2.2, other than making sure the variables are set before the server
starts (and maybe setting logical default values, like an empty string,
in your init script which should be overridden by the sysconfig&amp;nbsp;file).&lt;/p&gt;
&lt;p&gt;If you&amp;#8217;re running httpd 2.4+, you can turn on
&lt;a href="http://httpd.apache.org/docs/2.4/mod/mod_info.html"&gt;mod_info&lt;/a&gt; and
browse to &lt;code&gt;http://servername/server-info?config&lt;/code&gt; to dump the current
configuration, which will show the variable&amp;nbsp;substitution.&lt;/p&gt;</summary><category term="apache"></category><category term="environment"></category><category term="httpd"></category><category term="variable"></category></entry><entry><title>RPM Spec Files for nodejs 0.9.5 and v8 on CentOS 6</title><link href="http://blog.jasonantman.com/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/" rel="alternate"></link><updated>2013-01-31T14:13:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-01-31:2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/</id><summary type="html">&lt;p&gt;The latest version of nodejs that I could find as an &lt;span class="caps"&gt;RPM&lt;/span&gt; for CentOS was
0.6.16, from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;.
That&amp;#8217;s the one that puppetlabs currently uses in their
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module. There is, however, a nodejs 0.9.5 &lt;span class="caps"&gt;RPM&lt;/span&gt; in the Fedora Rawhide (19)
repository. Below are some patches to that specfile, and the specfile
for its v8 dependency, to get them to build on CentOS 6. You can also
find the full specfiles on my &lt;a href="https://github.com/jantman/specfiles"&gt;github specfile
repository&lt;/a&gt;. I had originally
wanted to get them built on CentOS 5 as well, but after following the
dependency tree from nodejs to http-parser to gyp, and then finding
issues in the gyp source that are incompatible with CentOS 5&amp;#8217;s python
2.4, I gave up on that&amp;nbsp;target.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nodejs.spec&lt;/strong&gt;, diff from Fedora Rawhide nodejs-0.9.5-9.fc18.src.rpm,
buildID=377755 (&lt;a href="https://raw.github.com/jantman/specfiles/master/nodejs.spec"&gt;full
specfile&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff --git a/nodejs.spec b/nodejs.spec&lt;/span&gt;
&lt;span class="gh"&gt;index 050ed86..86c0f4b 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/nodejs.spec&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/nodejs.spec&lt;/span&gt;
&lt;span class="gu"&gt;@@ -1,6 +1,6 @@&lt;/span&gt;
 Name: nodejs
 Version: 0.9.5
&lt;span class="gd"&gt;-Release: 9%{?dist}&lt;/span&gt;
&lt;span class="gi"&gt;+Release: 10%{?dist}&lt;/span&gt;
 Summary: JavaScript runtime
 License: &lt;span class="caps"&gt;MIT&lt;/span&gt; and &lt;span class="caps"&gt;ASL&lt;/span&gt; 2.0 and &lt;span class="caps"&gt;ISC&lt;/span&gt; and &lt;span class="caps"&gt;BSD&lt;/span&gt;
 Group: Development/Languages
&lt;span class="gu"&gt;@@ -25,7 +25,7 @@ Source6: nodejs-fixdep&lt;/span&gt;
 BuildRequires: v8-devel &amp;gt;= %{v8_ge}
 BuildRequires: http-parser-devel &amp;gt;= 2.0
 BuildRequires: libuv-devel
&lt;span class="gd"&gt;-BuildRequires: c-ares-devel&lt;/span&gt;
&lt;span class="gi"&gt;+BuildRequires: c-ares-devel &amp;gt;= 1.9.0&lt;/span&gt;
 BuildRequires: zlib-devel
 # Node.js requires some features from openssl 1.0.1 for &lt;span class="caps"&gt;SPDY&lt;/span&gt; support
 BuildRequires: openssl-devel &amp;gt;= 1:1.0.1
&lt;span class="gu"&gt;@@ -165,9 +165,13 @@ cp -p common.gypi %{buildroot}%{_datadir}/node&lt;/span&gt;

 %files docs
 %{_defaultdocdir}/%{name}-docs-%{version}
&lt;span class="gd"&gt;-%doc &lt;span class="caps"&gt;LICENSE&lt;/span&gt;&lt;/span&gt;

 %changelog
&lt;span class="gi"&gt;+* Thu Jan 31 2013 Jason Antman  - 0.9.5-10&lt;/span&gt;
&lt;span class="gi"&gt;+- specify build requirement of c-ares-devel &amp;gt;= 1.9.0&lt;/span&gt;
&lt;span class="gi"&gt;+- specify build requirement of libuv-devel 0.9.4&lt;/span&gt;
&lt;span class="gi"&gt;+- remove duplicate %doc &lt;span class="caps"&gt;LICENSE&lt;/span&gt; that was causing cpio &amp;#39;Bad magic&amp;#39; error on CentOS6&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
 * Sat Jan 12 2013 &lt;span class="caps"&gt;T.C.&lt;/span&gt; Hollingsworth  - 0.9.5-9
 - fix brown paper bag bug in requires generation script
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;v8.spec&lt;/strong&gt;, diff from Fedora Rawhide 3.13.7.5-2 (&lt;a href="https://raw.github.com/jantman/specfiles/master/v8.spec"&gt;full
specfile&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gd"&gt;--- v8.spec.orig       2013-01-26 16:03:18.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ v8.spec     2013-01-31 09:04:51.068029459 -0500&lt;/span&gt;
&lt;span class="gu"&gt;@@ -21,9 +21,11 @@&lt;/span&gt;

 # %%global svnver 20110721svn8716

&lt;span class="gi"&gt;+%{!?python_sitelib: %define python_sitelib %(%{__python} -c &amp;quot;import distutils.sysconfig as d; print d.get_python_lib()&amp;quot;)}&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
 Name:          v8
 Version:       %{somajor}.%{sominor}.%{sobuild}.%{sotiny}
&lt;span class="gd"&gt;-Release:       2%{?dist}&lt;/span&gt;
&lt;span class="gi"&gt;+Release:       5%{?dist}&lt;/span&gt;
 Epoch:         1
 Summary:       JavaScript Engine
 Group:         System Environment/Libraries
&lt;span class="gu"&gt;@@ -32,7 +34,7 @@&lt;/span&gt;
 Source0:       http://commondatastorage.googleapis.com/chromium-browser-official/v8-%{version}.tar.bz2
 BuildRoot:     %{_tmppath}/%{name}-%{version}-%{release}-root-%(%{__id_u} -n)
 ExclusiveArch: %{ix86} x86_64 %{arm}
&lt;span class="gd"&gt;-BuildRequires: scons, readline-devel, libicu-devel&lt;/span&gt;
&lt;span class="gi"&gt;+BuildRequires: scons, readline-devel, libicu-devel, ncurses-devel&lt;/span&gt;

 %description
 V8 is Google&amp;#39;s open source JavaScript engine. V8 is written in C++ and is used 
&lt;span class="gu"&gt;@@ -51,8 +53,13 @@&lt;/span&gt;
 %setup -q -n %{name}-%{version}

 # -fno-strict-aliasing is needed with gcc 4.4 to get past some ugly code
&lt;span class="gd"&gt;-PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -Wno-error=strict-overflow -Wno-error=unused-local-typedefs -Wno-unused-but-set-variable\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
&lt;span class="gi"&gt;+%if 0%{?el5}&lt;/span&gt;
&lt;span class="gi"&gt;+PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -lncurses\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
&lt;span class="gi"&gt;+sed -i &amp;quot;s|&amp;#39;-O3&amp;#39;,|$PARSED_OPT_FLAGS,|g&amp;quot; SConstruct&lt;/span&gt;
&lt;span class="gi"&gt;+%else&lt;/span&gt;
&lt;span class="gi"&gt;+PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -Wno-error=strict-overflow -Wno-unused-but-set-variable\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
 sed -i &amp;quot;s|&amp;#39;-O3&amp;#39;,|$PARSED_OPT_FLAGS,|g&amp;quot; SConstruct
&lt;span class="gi"&gt;+%endif&lt;/span&gt;

 # clear spurious executable bits
 find . \( -name \*.cc -o -name \*.h -o -name \*.py \) -a -executable   
&lt;span class="gu"&gt;@@ -198,6 +205,17 @@&lt;/span&gt;
 %{python_sitelib}/j*.py*

 %changelog
&lt;span class="gi"&gt;+* Thu Jan 31 2013 Jason Antman  - 1:3.13.7.5-5&lt;/span&gt;
&lt;span class="gi"&gt;+- remove -Werror=unused-local-typedefs on cent6&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+* Wed Jan 30 2013 Jason Antman  - 1:3.13.7.5-4&lt;/span&gt;
&lt;span class="gi"&gt;+- define python_sitelib if it isn&amp;#39;t already (CentOS 5)&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+* Wed Jan 30 2013 Jason Antman  - 1:3.13.7.5-3&lt;/span&gt;
&lt;span class="gi"&gt;+- pull 3.13.7.5-2 &lt;span class="caps"&gt;SRPM&lt;/span&gt; from Fedora 19 Koji most recent build&lt;/span&gt;
&lt;span class="gi"&gt;+- add ncurses-devel BuildRequires&lt;/span&gt;
&lt;span class="gi"&gt;+- modify PARSED_OPT_FLAGS to work with g++ 4.1.2 on CentOS 5&lt;/span&gt;
&lt;span class="gi"&gt;+ &lt;/span&gt;
 * Sat Jan 26 2013 &lt;span class="caps"&gt;T.C.&lt;/span&gt; Hollingsworth  - 1:3.13.7.5-2
 - rebuild for icu-50
 - ignore new &lt;span class="caps"&gt;GCC&lt;/span&gt; 4.8 warning
&lt;/pre&gt;&lt;/div&gt;</summary><category term="build"></category><category term="centos"></category><category term="node"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="redhat"></category><category term="RHEL"></category><category term="rpm"></category><category term="specfile"></category></entry><entry><title>Fedora Linux and OSX Dual Boot on Mid-2010 (6,2) 15” MacBook Pro Laptop</title><link href="http://blog.jasonantman.com/2013/01/fedora-linux-and-osx-dual-boot-on-mid-2010-62-15-macbook-pro-laptop/" rel="alternate"></link><updated>2013-01-21T12:13:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-01-21:2013/01/fedora-linux-and-osx-dual-boot-on-mid-2010-62-15-macbook-pro-laptop/</id><summary type="html">&lt;p&gt;As part of the transition from a contractor to a full-time employee of
&lt;a href="http://www.cmgdigital.com"&gt;Cox Media Group Digital &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Strategy&lt;/a&gt; (check
out our &lt;a href="https://github.com/cmgdigital"&gt;github&lt;/a&gt;), I&amp;#8217;ve been issued a
&lt;a href="http://support.apple.com/kb/SP582"&gt;Mid-2010 (6,2)&lt;/a&gt; 15&amp;#8221; &lt;a href="http://en.wikipedia.org/wiki/Macbook_pro#Technical_specifications_2"&gt;MacBook
Pro&lt;/a&gt;
laptop, to replace my current &lt;a href="http://support.apple.com/kb/SP11"&gt;Early-2008
(3,1)&lt;/a&gt; MacPro desktop. The desktop is
currently running &lt;a href="http://fedoraproject.org/"&gt;Fedora&lt;/a&gt; 17, dual-boot with
with Mac &lt;span class="caps"&gt;OS&lt;/span&gt; X (left in place for firmware updates and emergencies) using
the &lt;a href="http://www.rodsbooks.com/refind/index.html"&gt;rEFInd boot manager&lt;/a&gt; to
choose between the two OSes. It took me two days to get this working
right on my desktop, but it had been my plan to duplicate this setup on
my laptop. I found a lot of conflicting information online, but I
decided to give it a&amp;nbsp;try.&lt;/p&gt;
&lt;p&gt;Well, I have Fedora 18 and &lt;span class="caps"&gt;OS&lt;/span&gt; X 10.8 dual-booting on the laptop, but not
as planned. After a day and a half of research, troubleshooting and
re-installs, here&amp;#8217;s what I found to actually work, in the hope that
nobody else will go through the ordeal I went through. Following that
are some notes about the new Fedora 18 installer (Anaconda 18),
especially important for anyone who&amp;#8217;s used Linux for a while. To those
who are new to Linux, don&amp;#8217;t be dissuaded by the above. Most of the
frustration I experienced is because I&amp;#8217;ve been using Linux for a
relatively long time (about 10 years), had my own ideas about exactly
how I wanted things setup (which are decidedly &lt;em&gt;not&lt;/em&gt; supported by
Fedora), and had some assumptions about the installation process based
on earlier&amp;nbsp;versions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to get it&amp;nbsp;working:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Forget about rEFInd. This had been the original advice from &lt;a href="http://mjg59.dreamwidth.org/"&gt;Matthew
Garrett&lt;/a&gt;,
&lt;a href="https://twitter.com/mjg59"&gt;@mjg59&lt;/a&gt;, kernel coder, contributor to the
Anaconda project, and all-around authority on booting Linux on &lt;span class="caps"&gt;EFI&lt;/span&gt;/&lt;span class="caps"&gt;UEFI&lt;/span&gt;
hardware. My advice, and the method that worked for&amp;nbsp;me:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shrink your Mac partitions and leave as much free space as you want
    for Fedora. using the Disk Utility tool in &lt;span class="caps"&gt;OS&lt;/span&gt; X (I also created an
    &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;VFAT&lt;/span&gt; partition that both OSes can read/write&amp;nbsp;to).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://fedoraproject.org/en/get-fedora"&gt;Download Fedora 18&lt;/a&gt; 64-bit
    &lt;span class="caps"&gt;DVD&lt;/span&gt; image, I chose the &lt;span class="caps"&gt;KDE&lt;/span&gt; version. Verify the sha256 sum if you
    want (they don&amp;#8217;t have a readily visible link to the checksum file.
    Copy the download link, paste it into your address bar and remove
    the filename. You should get a directory index that includes a
    &lt;code&gt;-CHECKSUM&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Per the Installation Guide&amp;#8217;s &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/Making_USB_Media-UNIX_Linux.html"&gt;Making Fedora &lt;span class="caps"&gt;USB&lt;/span&gt; Media
    page&lt;/a&gt;,
    use &lt;code&gt;liveusb-creator&lt;/code&gt; to setup the installation image on the &lt;span class="caps"&gt;USB&lt;/span&gt;
    flash drive (I needed to start it with the &lt;code&gt;--reset-mbr&lt;/code&gt; option).
    You can also use other tools (dd if you&amp;#8217;re not on a Fedora-based
    distro), or a &lt;span class="caps"&gt;DVD&lt;/span&gt;, but this is the method I&amp;nbsp;chose.&lt;/li&gt;
&lt;li&gt;Due to a &lt;a href="https://fedorahosted.org/liveusb-creator/ticket/810"&gt;bug in
    liveusb-creator&lt;/a&gt;,
    you may need to manually edit &lt;code&gt;/EFI/boot/grub.cfg&lt;/code&gt; on the created
    &lt;span class="caps"&gt;USB&lt;/span&gt; stick if grub gives you a file not found error. If that happens,
    please see my bug report above for the action to take (in short, you
    need to mount the &lt;span class="caps"&gt;USB&lt;/span&gt; stick, &lt;code&gt;chmod u+w /EFI/boot/grub.cfg&lt;/code&gt; then
    edit that file and replace every occurrence of &amp;#8220;isolinux&amp;#8221; with
    &amp;#8220;syslinux&amp;#8221; and every occurrence of
    &amp;#8220;root=live:&lt;span class="caps"&gt;LABEL&lt;/span&gt;=Fedora-18-x86_64-Live-&lt;span class="caps"&gt;KDE&lt;/span&gt;.iso&amp;#8221; with&amp;nbsp;&amp;#8220;root=live:&lt;span class="caps"&gt;LABEL&lt;/span&gt;=&lt;span class="caps"&gt;LIVE&lt;/span&gt;&amp;#8221;).&lt;/li&gt;
&lt;li&gt;Boot the &lt;span class="caps"&gt;USB&lt;/span&gt; drive (use the alt key when you turn on the laptop to
    select the &lt;span class="caps"&gt;USB&lt;/span&gt; drive) and just install Fedora normally, letting it
    do its thing. Select a boot disk and let it put &lt;span class="caps"&gt;GRUB2&lt;/span&gt; on the &lt;span class="caps"&gt;EFI&lt;/span&gt;&amp;nbsp;partition.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When you boot, it will boot to &lt;span class="caps"&gt;GRUB&lt;/span&gt;. There will be some options for Mac
&lt;span class="caps"&gt;OS&lt;/span&gt; there, but they don&amp;#8217;t work (more on that below). If you want to boot
Mac, hold down the alt/option key when you power on the laptop, which
will bring you to the boot disk selector and you can pick the Mac disk.
I know it&amp;#8217;s not pretty or ideal, but it&amp;#8217;s the best option right&amp;nbsp;now.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Making it&amp;nbsp;Better:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;GRUB2&lt;/span&gt; tries to automatically detect other OSes and configure them in the
boot loader (this is done through &lt;code&gt;/etc/grub.d/30_os-prober&lt;/code&gt;, commonly
just referred to as &lt;code&gt;os-prober&lt;/code&gt;). It tries to boot Mac directly through
the xnu_kernel64 module, which not only isn&amp;#8217;t installed on the boot
partition by default, but just doesn&amp;#8217;t work with at least Mountain Lion
(10.8). So getting &lt;span class="caps"&gt;GRUB&lt;/span&gt; to boot Mac means either having the bugs in the
xnu module fixed, or figuring out how to setup a chainloader to boot
from &lt;span class="caps"&gt;GRUB&lt;/span&gt; to Mac. The latter is probably the method I&amp;#8217;ll investigate,
but for now, since I rarely use Mac, I&amp;#8217;m happy having to use the alt key
at boot to get there. To remove the annoying, broken Mac &lt;span class="caps"&gt;OS&lt;/span&gt; options from
the grub screen, run the following commands as root (they assume you
have your &lt;span class="caps"&gt;EFI&lt;/span&gt; partition mounted at &lt;code&gt;/boot/efi&lt;/code&gt; which I believe Fedora
should do by&amp;nbsp;default:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;cp /boot/efi/EFI/fedora/grub.cfg /boot/efi/EFI/fedora/grub.cfg.bak
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;GRUB_DISABLE_OS_PROBER=&amp;quot;true&amp;quot;&amp;#39;&lt;/span&gt; &amp;gt;&amp;gt; /etc/default/grub
grub2-mkconfig &amp;gt; /boot/efi/&lt;span class="caps"&gt;EFI&lt;/span&gt;/fedora/grub.cfg
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Thoughts on the Fedora 18 Anaconda&amp;nbsp;Installer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I found a couple of issues with the new Anaconda 18 installer that were
either unweildy or confusing for someone who&amp;#8217;s been installing Linux for
a long time. Overall, the new installer is very nice. It has a clean,
even elegant &lt;span class="caps"&gt;UI&lt;/span&gt;, a relatively nice flow from start to completion, and is
certainly beginner-friendly. It has fewer options than any Linux
installer I&amp;#8217;ve ever used before - not even options for package
selection, firewall or SELinux configuration, etc. - but I guess this is
in line with the goal of making Fedora a desktop &lt;span class="caps"&gt;OS&lt;/span&gt; for the masses. I
would have appreciated an &amp;#8220;advanced mode&amp;#8221; installer that was more like
Fedora 17 (or even much older versions), but I guess I&amp;#8217;m an edge case,
at least in the Fedora community. However, I did find two things
especially difficult, both related to the fact that my laptop has two
main drives (a &lt;span class="caps"&gt;500GB&lt;/span&gt; hard drive and a &lt;span class="caps"&gt;120GB&lt;/span&gt;&amp;nbsp;&lt;span class="caps"&gt;SSD&lt;/span&gt;):&lt;/p&gt;
&lt;p&gt;First, the installer prompted me to select a &amp;#8220;boot disk&amp;#8221;. I guess I
should have read the installation guide, but I assumed that nomenclature
translated to either &amp;#8220;which disk should the automatic partitiioning put
yout &lt;code&gt;/boot&lt;/code&gt; partition on&amp;#8221; or &amp;#8220;which disk should I set the bootable flag
on in the partition table&amp;#8221;. In fact, it means &amp;#8220;which disk should I put
&lt;span class="caps"&gt;GRUB&lt;/span&gt; on the &lt;span class="caps"&gt;EFI&lt;/span&gt; partition of&amp;#8221;. I installed, rebooted, and was shocked -
and somewhat distressed - to boot directly to &lt;span class="caps"&gt;GRUB2&lt;/span&gt; instead of the
rEFInd installation I had setup. The installer didn&amp;#8217;t have any of the
previously-customary &amp;#8220;warning: this will overwrite your &lt;span class="caps"&gt;MBR&lt;/span&gt;/&lt;span class="caps"&gt;EFI&lt;/span&gt; boot
partition&amp;#8221; notices, so I felt safe letting it continue. It turned out
that this was the way I ended up going, and it also turns out that
there&amp;#8217;s a bug in Anaconda that makes it fail installation if you tell it
not to write a bootloader to disk (though it&amp;#8217;s patched by one line of
Python code). But I was deeply distressed that - contrary to the
experience of every, admittedly more complicated, Linux installer I&amp;#8217;d
used before - the Fedora 18 installer overwrote my &lt;span class="caps"&gt;EFI&lt;/span&gt; bootloader
(analogous to overwriting the &lt;span class="caps"&gt;MBR&lt;/span&gt; on a &lt;span class="caps"&gt;BIOS&lt;/span&gt; boot machine) without ever
warning me or asking for a&amp;nbsp;confirmation.&lt;/p&gt;
&lt;p&gt;Secondly, the partitioning tool is clearly designed for only one
destination disk. The overview screen lists configured partitions by
label and mount point, but not by physical device, so figuring out which
partitions are on which physical disks takes a click on each and every
partition to view that information in the detail panel. When you create
a new partition, it&amp;#8217;s automatically put in a &lt;span class="caps"&gt;LVM&lt;/span&gt; volume group spanning
all disks. Changing the target of the automatically created volume group
requires a few clicks, as does changing the physical disks backing any
new volume groups. To assign a newly created partition to a specific
disk, you have to click on an unlabeled &amp;#8220;tool&amp;#8221; icon under the list of
partitions, far away from the information on the partition in question.
It&amp;#8217;s a nice interface for someone who clicks the &amp;#8220;partition
automatically&amp;#8221; button, or who just knows they want to add &amp;#8220;an extra
partition&amp;#8221;, but for anyone who has a specific layout in mind (like
having &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/boot&lt;/code&gt; and &lt;code&gt;/var&lt;/code&gt;, specifically sized, on the &lt;span class="caps"&gt;SSD&lt;/span&gt; and
&lt;code&gt;/home&lt;/code&gt; on the rotating disk) it takes about 4-5 more clicks and dialogs
to add a partition than the last Fedora installer did. Mainly, it&amp;#8217;s
lacking any sort of Advanced Mode for partitioning that allows the user
to quickly and accurately layout a more complex partitioning&amp;nbsp;scheme.&lt;/p&gt;
&lt;p&gt;Below are some screenshots from the Fedora 17 and Fedora 18 Installation
Guides, which contrast both the overview of all partitions and the
individual partition&amp;nbsp;settings:&lt;/p&gt;
&lt;p&gt;Fedora 18 Overview, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/s1-diskpartitioning-x86.html"&gt;9.13. Creating a Custom Partition
Layout&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://www.dedoimedo.com/images/computers_years/2013_1/fedora-18-installer-configure-partitions.jpg" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 17 Overview, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/s1-diskpartitioning-x86.html"&gt;9.14. Creating a Custom Layout or Modifying
the Default
Layout&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/images/diskpartitioning/ddmain.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 18 Partition Creation/Editing, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/Create_LVM-x86.html"&gt;9.13.3. Create &lt;span class="caps"&gt;LVM&lt;/span&gt; Logical
Volume&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/images/diskpartitioning/lvm-pv.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 17 Partition Creation/Editing, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/Adding_Partitions-x86.html"&gt;9.14.2. Adding
Partitions&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/images/diskpartitioning/part-add.png" /&gt;&lt;/p&gt;</summary><category term="bootloader"></category><category term="efi"></category><category term="fedora"></category><category term="gpt"></category><category term="grub"></category><category term="installation"></category><category term="laptop"></category><category term="mac"></category><category term="macbook"></category><category term="os x"></category></entry><entry><title>Fedora Init Script Specification Summary</title><link href="http://blog.jasonantman.com/2013/01/fedora-init-script-specification-summary/" rel="alternate"></link><updated>2013-01-03T11:30:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-01-03:2013/01/fedora-init-script-specification-summary/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been deploying some new software lately (specifically
&lt;a href="https://github.com/marisaseal/selenesse"&gt;selenesse&lt;/a&gt;, which combines
&lt;a href="http://seleniumhq.org/"&gt;Selenium&lt;/a&gt; and &lt;a href="http://fitnesse.org/"&gt;fitnesse&lt;/a&gt;,
&lt;a href="http://en.wikipedia.org/wiki/Xvfb"&gt;xvfb&lt;/a&gt;). None of these seem to come
with init scripts to run as daemons, and the quality of the few
Fedora/RedHat/CentOS init scripts I was able to find was quite poor. The
Fedora project has a &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript"&gt;Specification for SysV-style Init Scripts in their
Packaging wiki&lt;/a&gt;,
which specifies what a Fedora/RedHat/CentOS init script should look
like, in excruciating detail. What follows is an overview of the more
important points, which I&amp;#8217;m using to develop or modify the scripts I&amp;#8217;m
currently working&amp;nbsp;on.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scripts must be put in &lt;code&gt;/etc/rc.d/init.d&lt;/code&gt;, not in the &lt;code&gt;/etc/init.d&lt;/code&gt;
    symlink. They should have 0755&amp;nbsp;permissions.&lt;/li&gt;
&lt;li&gt;Scripts must have a Fedora-style &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Chkconfig_Header"&gt;chkconfig
    header&lt;/a&gt;
    (&amp;#8220;chkconfig:&amp;#8221;, &amp;#8220;description:&amp;#8221; lines), and may have an &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#LSB_Header"&gt;&lt;span class="caps"&gt;LSB&lt;/span&gt;-style
    header&lt;/a&gt;
    (&lt;span class="caps"&gt;BEGIN&lt;/span&gt; &lt;span class="caps"&gt;INIT&lt;/span&gt; &lt;span class="caps"&gt;INFO&lt;/span&gt;/&lt;span class="caps"&gt;END&lt;/span&gt; &lt;span class="caps"&gt;INIT&lt;/span&gt; &lt;span class="caps"&gt;INFO&lt;/span&gt;). See &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Initscript_template"&gt;Initscript
    template&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Scripts &lt;strong&gt;must&lt;/strong&gt; make use of a lockfile in &lt;code&gt;/var/lock/subsys/&lt;/code&gt;, and
    the name of the lockfile must be the same as the name of the init
    script. (There is a technical reason for this relating to how sysv
    init terminates daemons at shutdown). The lockfile should be touched
    when the daemon successfully starts, and removed when it
    successfully&amp;nbsp;stops.&lt;/li&gt;
&lt;li&gt;Init scripts should not depend on any environment variables set
    outside the script. They should operate gracefully with an
    empty/uninitialized environment (or only &lt;span class="caps"&gt;LANG&lt;/span&gt; and &lt;span class="caps"&gt;TERM&lt;/span&gt; set and a &lt;span class="caps"&gt;CWD&lt;/span&gt;
    of &lt;code&gt;/&lt;/code&gt;, as enforced by &lt;code&gt;service(8)&lt;/code&gt;, or with a full environment if
    they are called directly by a&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Required_Actions"&gt;Required&amp;nbsp;actions&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all of the following actions are required, and have specific&amp;nbsp;definitions:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;start&lt;/strong&gt;: starts the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;stop&lt;/strong&gt;: stops the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;restart&lt;/strong&gt;: stop and restart the service if the service is
    already running, otherwise just start the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;condrestart (and try-restart)&lt;/strong&gt;: restart the service if the
    service is already running, if not, do&amp;nbsp;nothing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;reload&lt;/strong&gt;: reload the configuration of the service without
    actually stopping and restarting the service (if the service
    does not support this, do&amp;nbsp;nothing)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;force-reload&lt;/strong&gt;: reload the configuration of the service and
    restart it so that it takes&amp;nbsp;effect&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;status&lt;/strong&gt;: print the current status of the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;usage&lt;/strong&gt;: by default, if the initscript is run without any
    action, it should list a &amp;#8220;usage message&amp;#8221; that has all actions
    (intended for&amp;nbsp;use)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are specified exit codes for &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Exit_Codes_for_the_Status_Action"&gt;status
    actions&lt;/a&gt;
    and &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Exit_Codes_for_non-Status_Actions"&gt;non-status
    actions&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;They must &amp;#8220;behave sensibly&amp;#8221;. I&amp;#8217;ve found this to be one of the
    biggest problems with homegrown init scripts. If &lt;code&gt;servicename start&lt;/code&gt;
    is called while the service is already running, it should simply
    exit 0. Likewise if the service is already stopped. Init scripts
    &lt;strong&gt;must not kill unrelated processes&lt;/strong&gt;. I don&amp;#8217;t know how many times
    I&amp;#8217;ve seen scripts that kill every java or python process on a&amp;nbsp;machine.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I intend to use this as a quick checklist when developing or evaluating
init scripts for RedHat/Fedora based systems. In my experience, the
biggest problems with most init scripts revolve around poor handling of
&lt;span class="caps"&gt;PID&lt;/span&gt; files and lockfiles,&amp;nbsp;mainly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Killing processes other than the one that the script started (i.e.
    killing all java or python processes), usually because the &lt;span class="caps"&gt;PID&lt;/span&gt; isn&amp;#8217;t
    tracked at&amp;nbsp;start&lt;/li&gt;
&lt;li&gt;Starting a second instance of the subsystem because lockfiles aren&amp;#8217;t
    used, or the status function is&amp;nbsp;broken.&lt;/li&gt;
&lt;li&gt;improper exit&amp;nbsp;codes&lt;/li&gt;
&lt;li&gt;either explicitly relying on environment variables (and therefore
    breaking when called through &lt;code&gt;service(8)&lt;/code&gt;), or conversely, not
    cleaning/resetting environment variables that are used by dependent
    code or&amp;nbsp;processes.&lt;/li&gt;
&lt;/ul&gt;</summary><category term="centos"></category><category term="fedora"></category><category term="init"></category><category term="redhat"></category><category term="startup"></category></entry><entry><title>Random Links for Wednesday, October 24th</title><link href="http://blog.jasonantman.com/2012/10/random-links-for-wednesday-october-24th/" rel="alternate"></link><updated>2012-10-24T12:01:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-24:2012/10/random-links-for-wednesday-october-24th/</id><summary type="html">&lt;p&gt;Some random interesting links from Slashdot for&amp;nbsp;today:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://news.slashdot.org/story/12/10/23/2038220/the-greatest-battle-of-the-personal-computing-revolution-lies-ahead"&gt;The Greatest Battle of the Personal Computing Revolution Lies Ahead
    -
    Slashdot&lt;/a&gt;.
    A bit of a rant, but makes some good points that are close to my
    heart, and unfortunately far from the thoughts of many&amp;nbsp;non-techies.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tos-dr.info/"&gt;Terms of Service; Didn&amp;#8217;t Read&lt;/a&gt; - an
    interesting&amp;nbsp;project&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yro.slashdot.org/story/12/10/21/208206/how-patent-trolls-harm-the-economy"&gt;How Patent Trolls Harm the Economy -
    Slashdot&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;another issue close to my&amp;nbsp;heart&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.datacenterknowledge.com/archives/2012/10/17/how-google-cools-its-armada-of-servers/"&gt;How Google Cools Its Armada of Servers » Data Center&amp;nbsp;Knowledge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.google.com/about/datacenters/gallery/#/"&gt;Data centers – Google Data
    centers&lt;/a&gt; - A
    photo tour of Google data centers, by Google, along with a &lt;a href="https://plus.google.com/+google/posts/Gk8ScjPX23n"&gt;Google+
    post&lt;/a&gt; about the
    architecture photographer who did this&amp;nbsp;work.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tech.slashdot.org/story/12/10/22/0518231/darpa-funds-a-300-software-defined-radio-for-hackers"&gt;&lt;span class="caps"&gt;DARPA&lt;/span&gt; Funds a $300 Software-Defined Radio For Hackers -
    Slashdot&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;way&amp;nbsp;cool.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://map.honeynet.org/"&gt;Honeynet Map&lt;/a&gt; - &amp;#8220;realtime&amp;#8221; map of
    cybersecurity incidents, from the Honeynet&amp;nbsp;Project.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://science.slashdot.org/story/12/10/17/1741225/malware-is-rampant-on-medical-devices-in-hospitals"&gt;Malware Is &amp;#8216;Rampant&amp;#8217; On Medical Devices In Hospitals -
    Slashdot&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a bit scary, but unfortunately not that hard to guess. I&amp;#8217;ve seen
(probably unpatched) Windows 2000 workstations on hospital&amp;nbsp;networks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;To top off the scary posts: &lt;a href="http://news.slashdot.org/story/12/10/17/0325236/researcher-reverse-engineers-pacemaker-transmitter-to-deliver-deadly-shocks"&gt;Researcher Reverse-Engineers Pacemaker
    Transmitter To Deliver Deadly Shocks -&amp;nbsp;Slashdot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="appliancization"></category><category term="cooling"></category><category term="datacenter"></category><category term="google"></category><category term="healthcare"></category><category term="legal"></category><category term="links"></category><category term="malware"></category><category term="pacemaker"></category><category term="patents"></category><category term="radio"></category><category term="SDR"></category><category term="security"></category></entry><entry><title>Readable Nagios Log Timestamps</title><link href="http://blog.jasonantman.com/2012/10/readable-nagios-log-timestamps/" rel="alternate"></link><updated>2012-10-17T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-17:2012/10/readable-nagios-log-timestamps/</id><summary type="html">&lt;p&gt;If you&amp;#8217;re like me and most humans, the Nagios logfile timestamp (a unix
timestamp) isn&amp;#8217;t terribly useful when trying to grep through the logs
and correlate&amp;nbsp;events:  &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; head -2 nagios.log
&lt;span class="go"&gt;[1350360000] &lt;span class="caps"&gt;LOG&lt;/span&gt; &lt;span class="caps"&gt;ROTATION&lt;/span&gt;: &lt;span class="caps"&gt;DAILY&lt;/span&gt;&lt;/span&gt;
&lt;span class="go"&gt;[1350360000] &lt;span class="caps"&gt;LOG&lt;/span&gt; &lt;span class="caps"&gt;VERSION&lt;/span&gt;: 2.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&amp;#8217;s a nifty Perl one-liner that you can pipe your logs&amp;nbsp;through:  &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="n"&gt;perl&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;pe&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;s/(\\d+)/localtime($1)/e&amp;#39;&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to get nicer output&amp;nbsp;like:  &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# head -2 nagios.log&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Tue&lt;/span&gt; &lt;span class="n"&gt;Oct&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;LOG&lt;/span&gt;&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;ROTATION&lt;/span&gt;:&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;DAILY&lt;/span&gt;&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Tue&lt;/span&gt; &lt;span class="n"&gt;Oct&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;LOG&lt;/span&gt;&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;VERSION&lt;/span&gt;:&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="icinga"></category><category term="Nagios"></category><category term="perl"></category><category term="timestamp"></category></entry><entry><title>Custom Tombstone and Road Sign Pictures</title><link href="http://blog.jasonantman.com/2012/10/custom-tombstone-and-road-sign-pictures/" rel="alternate"></link><updated>2012-10-16T07:02:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-16:2012/10/custom-tombstone-and-road-sign-pictures/</id><summary type="html">&lt;p&gt;On the lighter side, I found a few web sites by &lt;a href="http://www.pixbytom.com/"&gt;Tom
Blackwell&lt;/a&gt; that do some fun stuff with text
overlays on images. seems like a nice little tool for those
end-of-project powerpoints, or to send out the monthly &amp;#8220;most rolled-back
commits&amp;#8221;&amp;nbsp;medal&amp;#8230;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.tombstonebuilder.com/index.php"&gt;Custom Tombstone&amp;nbsp;Maker&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Image of tombstone, with 'Your Text Goes Here' carved into it" src="/GFX/my_tombstone.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.customroadsign.com/"&gt;CustomRoadSign.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Highway sign with 'Your Text Goes Here' written on it" src="/GFX/menusign.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.custommotelsign.com/"&gt;CustomMotelSign.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Motel-style sign with 'Your Text Goes Here' written on it" src="/GFX/motelsign.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.getamedal.com/"&gt;GetAMedal.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Gold medal with 'Your Text Goes Here' written on it" src="/GFX/medal.jpg" /&gt;&lt;/p&gt;</summary><category term="graphics"></category><category term="humor"></category><category term="road sign"></category><category term="sign"></category><category term="tombstone"></category></entry><entry><title>All-Mechanical Computer Instructional Video</title><link href="http://blog.jasonantman.com/2012/10/all-mechanical-computer-instructional-video/" rel="alternate"></link><updated>2012-10-12T20:54:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-12:2012/10/all-mechanical-computer-instructional-video/</id><summary type="html">&lt;p&gt;I saw a link to &lt;a href="http://www.youtube.com/watch?v=s1i-dnAH9Y4"&gt;this YouTube
video&lt;/a&gt; shared on &lt;a href="http://everythingsysadmin.com/2012/10/mechanical-computer-instructio.html"&gt;Tom
Limoncelli&amp;#8217;s
blog&lt;/a&gt;.
It&amp;#8217;s a 1953 &lt;span class="caps"&gt;US&lt;/span&gt; Navy instructional video about an all-mechanical fire
control computer. Yes, I really mean a &lt;em&gt;computer&lt;/em&gt; that can solve
continuously changing 25-variable fire control problems using only
mechanical means (gears, cams, etc.). Think about it for a minute - it&amp;#8217;s
truly mind-boggling. And really gives one an amazing appreciation for
the power of a simple pocket calculator, and the amazing engineering
that went into solving these problems before electronic computers. I&amp;#8217;m
usually not much of a math geek, but I watched the whole 40 minute video
and was in awe of both the simple ability to use three arms and a pin to
multiply numbers, and the amazingly precise engineering and machining it
would take to translate various rotation inputs into landing a shell on
a moving ship miles away. It&amp;#8217;s a really good watch, and will probably
leave you astonished by both how far technology has come (and what we
take for granted every day), and by the fact that feats of engineering
like this one worked quite&amp;nbsp;well.&lt;/p&gt;</summary><category term="mechanical computer"></category></entry><entry><title>Pretty-Print a JSON response at the command line</title><link href="http://blog.jasonantman.com/2012/10/pretty-print-a-json-response-at-the-command-line/" rel="alternate"></link><updated>2012-10-09T14:44:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-09:2012/10/pretty-print-a-json-response-at-the-command-line/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been doing some work with &lt;a href="http://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;
lately, and have been doing some testing against its &lt;span class="caps"&gt;HTTP&lt;/span&gt;-based &lt;span class="caps"&gt;API&lt;/span&gt;,
which returns results in &lt;span class="caps"&gt;JSON&lt;/span&gt;. If you&amp;#8217;re looking to pretty-print a &lt;span class="caps"&gt;JSON&lt;/span&gt;
response for easier viewing, here&amp;#8217;s a nice way to do it at the command
line using Python and
&lt;a href="http://docs.python.org/library/json.html"&gt;json.tool&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl http://username:pass@hostname:55672/api/overview | python -m json.tool&lt;/code&gt;&lt;/p&gt;</summary><category term="curl"></category><category term="json"></category><category term="python"></category><category term="rabbitmq"></category></entry><entry><title>Nagstamon on Fedora 17</title><link href="http://blog.jasonantman.com/2012/10/nagstamon-on-fedora-17/" rel="alternate"></link><updated>2012-10-05T07:37:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-05:2012/10/nagstamon-on-fedora-17/</id><summary type="html">&lt;p&gt;Since I started my last job, I&amp;#8217;ve been using
&lt;a href="http://nagstamon.ifw-dresden.de/"&gt;Nagstamon&lt;/a&gt; on my workstation; it&amp;#8217;s a
really handy little system tray application that monitors a
Nagios/Icinga instance and shows status updates/summary in a handy
fashion, including flashing and (optionally) a sound alert when
something changes. Unfortunately, there doesn&amp;#8217;t seem to be a Fedora 17
package for it, though there is an entry on the &lt;a href="http://fedoraproject.org/wiki/Package_maintainers_wishlist#N-O"&gt;Fedora package
maintainers
wishlist&lt;/a&gt;.
The closest I was able to find is a
&lt;a href="http://pkgs.org/centos-6-rhel-6/repoforge-i386/nagstamon-0.9.7.1-2.el6.rf.noarch.rpm.html"&gt;repoforge/RPMforge&lt;/a&gt;
package of Nagstamon 0.9.7.1, along with a &lt;a href="http://apt.sw.be/source/nagstamon-0.9.7.1-2.rf.src.rpm"&gt;source
&lt;span class="caps"&gt;RPM&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are the steps to build that package on&amp;nbsp;F17:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download and install
    &lt;a href="http://apt.sw.be/source/rpm-macros-rpmforge-0-6.rf.src.rpm"&gt;rpm-macros-rpmforge&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;As root, edit &lt;code&gt;/etc/rpm/macros.rpmforge&lt;/code&gt; and comment out the &lt;code&gt;%dist&lt;/code&gt;
    macro, so we&amp;#8217;ll still have the default &amp;#8220;fc17&amp;#8221; dist&amp;nbsp;tag.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wget http://apt.sw.be/source/nagstamon-0.9.7.1-2.rf.src.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rpmbuild &amp;#8212;rebuild&amp;nbsp;nagstamon-0.9.7.1-2.rf.src.rpm&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hopefully this will help someone else as well. At the moment, Nagstamon
is actually up to version 0.9.9, so hopefully I&amp;#8217;ll build a newer package
sometime&amp;nbsp;soon.&lt;/p&gt;</summary><category term="fedora"></category><category term="nagios. icinga"></category><category term="nagstamon"></category><category term="package"></category><category term="rpm"></category></entry><entry><title>New Job</title><link href="http://blog.jasonantman.com/2012/09/new-job/" rel="alternate"></link><updated>2012-09-28T12:36:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-28:2012/09/new-job/</id><summary type="html">&lt;p&gt;Today is my last day in my almost-year-long stint as a System
Administrator at &lt;a href="http://www.techtarget.com/"&gt;TechTarget&lt;/a&gt;. Monday, I
start a new contract-to-perm position as a Linux Engineer with &lt;a href="http://cmgdigital.com/"&gt;Cox
Media Group Digital &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Strategy&lt;/a&gt;. I can&amp;#8217;t say a
whole lot about the new job, other than it will hopefully be a great
change for me, and they make heavy use of
&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt;. If you want to get a bit of an
idea of what they&amp;#8217;re about, here&amp;#8217;s a &lt;a href="https://github.com/coxmediagroup/jobs/blob/master/ethos.rst"&gt;document on their departmental
ethos&lt;/a&gt;.
Hopefully I&amp;#8217;ll be able to post more useful information here, and post
more often, in the future. I&amp;#8217;m really psyched about the new&amp;nbsp;gig.&lt;/p&gt;</summary><category term="cmg"></category><category term="coxmedia"></category><category term="job"></category><category term="techtarget"></category></entry><entry><title>Some questions from a tech interview with a big Internet company</title><link href="http://blog.jasonantman.com/2012/09/some-questions-from-a-tech-interview-with-a-big-internet-company/" rel="alternate"></link><updated>2012-09-12T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-12:2012/09/some-questions-from-a-tech-interview-with-a-big-internet-company/</id><summary type="html">&lt;p&gt;A while back, I did a technical phone screen with a big online &amp;#8220;social&amp;#8221;
company (I won&amp;#8217;t say who, but they&amp;#8217;re a household name, growing fast,
and doing cool things; that doesn&amp;#8217;t leave &lt;em&gt;too&lt;/em&gt; many options). I rarely
remember to write down interview questions, but I was cleaning out my
desk this morning and came by a ripped-out sheet of notebook paper with
a handful of the interview questions written on it. Most of them weren&amp;#8217;t
terribly difficult, or terribly unusual for competent technical
interviewers, but since I happen to actually have the list written down,
I though I&amp;#8217;d share it. I don&amp;#8217;t remember why the programming questions
are all Python; likely, I was asked to choose between Python (which I&amp;#8217;ve
used, though not lately), Ruby (which I can barely muddle my way through
reading on a good day), and something else I don&amp;#8217;t know. Here are some
of&amp;nbsp;them&amp;#8230;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is an inode? What does it&amp;nbsp;store?&lt;/li&gt;
&lt;li&gt;What is a hard&amp;nbsp;link?&lt;/li&gt;
&lt;li&gt;What is the difference between a hard link and a soft&amp;nbsp;link?&lt;/li&gt;
&lt;li&gt;What is a list in&amp;nbsp;Python?&lt;/li&gt;
&lt;li&gt;Name some data structures that you&amp;#8217;d use in Python. Describe them,
    and tell me why you would use&amp;nbsp;them.&lt;/li&gt;
&lt;li&gt;How would you list all the man pages containing the keyword&amp;nbsp;&amp;#8220;date&amp;#8221;?&lt;/li&gt;
&lt;li&gt;If the &lt;code&gt;chmod&lt;/code&gt; binary had its permissions set to &lt;code&gt;000&lt;/code&gt;, how would
    you fix&amp;nbsp;it?&lt;/li&gt;
&lt;/ul&gt;</summary><category term="hiring"></category><category term="interview"></category><category term="questions"></category><category term="sysadmin"></category></entry><entry><title>Dumping all Macros from an RPM Spec File</title><link href="http://blog.jasonantman.com/2012/09/dumping-all-macros-from-an-rpm-spec-file/" rel="alternate"></link><updated>2012-09-10T10:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-10:2012/09/dumping-all-macros-from-an-rpm-spec-file/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been doing a lot of &lt;span class="caps"&gt;RPM&lt;/span&gt; packaging lately, and on different (and
very old) distros and versions. Sometimes I lose track of all of the
macros used in specfiles (&lt;code&gt;_bindir _sbindir dist _localstatedir&lt;/code&gt;, etc).
There&amp;#8217;s no terribly easy way to dump a list of all of the available
macros. There is, however, a bit of a kludge. Insert the following code
in your specfile before the &lt;code&gt;%prep&lt;/code&gt; or &lt;code&gt;%setup&lt;/code&gt; lines:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;%dump
exit 1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;%dump&lt;/code&gt; macro will dump all defined macros to &lt;span class="caps"&gt;STDERR&lt;/span&gt;. The &lt;code&gt;exit 1&lt;/code&gt;
will prevent rpmbuild from going on and trying to build the package. If
you want to view the output nicely, you can pipe it through a pager like
less: &lt;code&gt;rpmbuild -ba filename.spec 2&amp;gt;&amp;amp;1 | less&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Just make sure to remove those two lines when you want to actually build
the&amp;nbsp;package.&lt;/p&gt;</summary><category term="packaging"></category><category term="rpm"></category><category term="rpmbuild"></category></entry><entry><title>Getting oVirt up and running</title><link href="http://blog.jasonantman.com/2012/09/getting-ovirt-up-and-running/" rel="alternate"></link><updated>2012-09-07T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-07:2012/09/getting-ovirt-up-and-running/</id><summary type="html">&lt;p&gt;The bulk of this post was written way back in April 2012. If you&amp;#8217;re just
coming here, and looking to setup oVirt, you should probably &lt;a href="#postscript"&gt;skip down
to the postscript&lt;/a&gt; for an update, and ignore most of the
content here (as it&amp;#8217;s applicable to an older oVirt&amp;nbsp;version).&lt;/p&gt;
&lt;p&gt;I recently started setting up &lt;a href="http://www.ovirt.org"&gt;oVirt&lt;/a&gt;, the
community version of Red Hat Enterprise Virtualization, at work for some
testing (mainly a &amp;#8220;sandbox&amp;#8221; &lt;span class="caps"&gt;VM&lt;/span&gt; environment, and because
&lt;a href="http://theforeman.org/"&gt;Foreman&lt;/a&gt;
&lt;a href="http://blog.theforeman.org/2012/03/vnc-support-built-in-foreman.html"&gt;supports&lt;/a&gt;
it). To start with, I had two nodes, each with two dual-core Xeon
processors (&lt;span class="caps"&gt;VT&lt;/span&gt;-x capable) with &lt;span class="caps"&gt;20GB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;, one with &lt;span class="caps"&gt;600GB&lt;/span&gt; internal storage
and one with &lt;span class="caps"&gt;140GB&lt;/span&gt; internal. While oVirt&amp;#8217;s documentation isn&amp;#8217;t exactly
wonderful, I found a blgo post by Jason Brooks, &lt;a href="http://blog.jebpages.com/archives/how-to-get-up-and-running-with-ovirt/"&gt;How to Get Up and
Running with
oVirt&lt;/a&gt;,
which gives a great walkthrough of getting the oVirt Engine setup on a
machine, and also setting up that same machine as a &lt;span class="caps"&gt;VM&lt;/span&gt; host. As oVirt is
still fairly young, this is all done on Fedora. I performed my
installation via Cobbler, though I&amp;#8217;m afraid to admit it was an entirely
manual, interactive&amp;nbsp;install.&lt;/p&gt;
&lt;p&gt;I did run into a few bumps during Jason&amp;#8217;s tutorial. In step 15, adding
the data &lt;span class="caps"&gt;NFS&lt;/span&gt; export as a Storage Domain, I was unable to add the &lt;span class="caps"&gt;NFS&lt;/span&gt;
export. I found the &lt;a href="http://www.ovirt.org/wiki/Troubleshooting_NFS_Storage_Issues"&gt;Troubleshooting &lt;span class="caps"&gt;NFS&lt;/span&gt; Storage Issues page on the
oVirt
wiki&lt;/a&gt;,
ensured that SELinux was disabled and that the export had the correct
permissions, confirmed that &lt;code&gt;/etc/nfsmount.conf&lt;/code&gt; specified &lt;code&gt;Nfsvers=3&lt;/code&gt;,
rebooted, and then ran the &lt;code&gt;nfs-check.py&lt;/code&gt; script. At this point, I was
able to add the other storage domains in steps 15 and&amp;nbsp;16.&lt;/p&gt;
&lt;p&gt;My second issue was that even on Fedora 16, I simply can&amp;#8217;t get the spice
client (through the &lt;code&gt;spice-xpi&lt;/code&gt; browser plugin) to work. As far as I can
tell from the logs, it looks like &lt;code&gt;spicec&lt;/code&gt; is being sent a value of
&amp;#8220;None&amp;#8221; for the secured port parameter, instead of the correct port
number. I assume this is a bug in oVirt, but I&amp;#8217;ll revisit this problem
when I have time. In the mean time, I changed my test &lt;span class="caps"&gt;VM&lt;/span&gt; to use &lt;span class="caps"&gt;VNC&lt;/span&gt;,
which is launched by installing the &lt;code&gt;ovirt-engine-cli&lt;/code&gt; package (see
below) on your client computer, connecting to the oVirt &lt;span class="caps"&gt;API&lt;/span&gt; with&amp;nbsp;ovirt-shell:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;ovirt-shell --connect --url=https://ovirt-engine.example.com:8443/api --user=admin@internal --password adminpassword&lt;/code&gt;&lt;br /&gt;
and then running &lt;code&gt;console vm_name&lt;/code&gt;. This launches the &lt;code&gt;vncviewer&lt;/code&gt;
binary, which is in the &amp;#8220;tigervnc&amp;#8221; package on&amp;nbsp;Fedora.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing&amp;nbsp;ovirt-engine-cli&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To run &lt;code&gt;ovirt-shell&lt;/code&gt; on your workstation (Fedora 16, of course&amp;#8230;)
you&amp;#8217;ll need the ovirt-engine-cli and ovirt-engine-sdk packages. I
manually downloaded them from
&lt;a href="http://www.ovirt.org/releases/nightly/fedora/16/"&gt;http://www.ovirt.org/releases/nightly/fedora/16/&lt;/a&gt;,
versions 2.1.3 and 1.6.2, respecitively. The &lt;span class="caps"&gt;SDK&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; are python
based, so there are a few Python dependencies, all of which were
automatically solved by yum. I know there are &lt;span class="caps"&gt;SDK&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; packages out
there for other distros, but haven&amp;#8217;t tried them&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Linux&amp;nbsp;Guests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Installing a CentOS 6.2 x86_64 guest was relatively straightforward,
and my usual kickstart infrastructure worked fine. The only catch was
the VirtIO storage interface, which shows up as &lt;code&gt;/dev/vdx&lt;/code&gt; instead of
&lt;code&gt;/dev/sdx&lt;/code&gt;; I just added another kickstart metadata option in Cobbler
that allows me to use &lt;code&gt;sdx&lt;/code&gt; by specifying &amp;#8220;virtual=yes&amp;#8221; (for our VMWare
hosts), or &lt;code&gt;vdx&lt;/code&gt; by specifying&amp;nbsp;&amp;#8220;virtual=ovirt&amp;#8221;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setting up&amp;nbsp;Authentication&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As installed, oVirt only has one user, &amp;#8220;admin@internal&amp;#8221;; it requires an
external directory service for user authentication. Currently, it
supports &lt;span class="caps"&gt;IPA&lt;/span&gt;, Red Hat&amp;#8217;s Enterprise Identity Management tool (combines
&lt;span class="caps"&gt;RHEL&lt;/span&gt;, oVirt Directory Server, Kerberos and &lt;span class="caps"&gt;NTP&lt;/span&gt;; perhaps
&lt;a href="http://freeipa.org"&gt;FreeIPA&lt;/a&gt; would work as well?) and Microsoft Active
Directory. As much as I&amp;#8217;d like to give &lt;span class="caps"&gt;IPA&lt;/span&gt; or FreeIPA a try, my company
already has an &lt;span class="caps"&gt;AD&lt;/span&gt; infrastructure, so I opted to go that route.
Documentation is given in the &lt;a href="http://www.ovirt.org/wiki/File:OVirt-3.0-Installation_Guide-en-US.pdf"&gt;oVirt 3.0 Installation
Guide&lt;/a&gt;,
starting on page 96. Unfortunately, I was never about to get &lt;span class="caps"&gt;AD&lt;/span&gt; auth
working correctly, so I just worked with the one admin&amp;nbsp;user.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adding a&amp;nbsp;Node&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The biggest issue I had was adding the second node to oVirt. I attempted
to use the &lt;span class="caps"&gt;DVD&lt;/span&gt; Import feature of Cobbler on the &lt;a href="http://www.ovirt.org/get-ovirt/"&gt;oVirt Node Image
&lt;span class="caps"&gt;ISO&lt;/span&gt;&lt;/a&gt;, but that failed. I then found the
image&amp;#8217;s &lt;code&gt;LiveOS/livecd-iso-to-pxeboot&lt;/code&gt; script and used that to make a
kernerl and initrd, and kernel parameters, for Cobbler. &lt;span class="caps"&gt;PXE&lt;/span&gt; works&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;&lt;a name="postscript"&gt;&lt;/a&gt;&lt;strong&gt;Postscript:&lt;/strong&gt; I ended up blowing away my
oVirt installation in favor of testing other things. At some point, the
engine install got corrupted in a way that I just couldn&amp;#8217;t fix; even
though I spent all day one Saturday working on it, it took more time
than I could allocate to a personal project. So this post is really
semi-complete at best. However, there is some good news. Jason Brooks&amp;#8217;
original post, &lt;a href="http://blog.jebpages.com/archives/how-to-get-up-and-running-with-ovirt/"&gt;How to Get Up and Running with
oVirt&lt;/a&gt;,
was written for oVirt 3.0, as was this post. Since then, there has been
a new release, &lt;a href="http://wiki.ovirt.org/wiki/OVirt_3.1_release_notes"&gt;oVirt
3.1&lt;/a&gt;, which
apparently has a better &lt;span class="caps"&gt;UI&lt;/span&gt; and a better installer. Jason Brooks has a
new post, &lt;a href="http://blog.jebpages.com/archives/up-and-running-with-ovirt-3-1-edition/"&gt;Up and Running with oVirt, 3.1
Edition&lt;/a&gt;,
which covers installation and configuration of both an all-in-one
machine and a separate node. If you&amp;#8217;re looking to try oVirt, I&amp;#8217;d
recommend you give that a shot. Unfortunately (and strangely, given that
this is supposed to be the &amp;#8220;upstream&amp;#8221; of RedHat&amp;#8217;s proprietary &lt;span class="caps"&gt;RHEV&lt;/span&gt;) it&amp;#8217;s
still all based on&amp;nbsp;Fedora.&lt;/p&gt;</summary><category term="fedora"></category><category term="kvm"></category><category term="ovirt"></category><category term="qemu"></category><category term="redhat"></category><category term="rhev"></category><category term="spice"></category><category term="virtualization"></category></entry><entry><title>Project - Storing and Analyzing Apache httpd Logs from Many Hosts</title><link href="http://blog.jasonantman.com/2012/09/project-storing-and-analyzing-apache-httpd-logs-from-many-hosts/" rel="alternate"></link><updated>2012-09-06T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-06:2012/09/project-storing-and-analyzing-apache-httpd-logs-from-many-hosts/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve recently started casual work on a side-project to collect, store,
and analyze apache logs from a bunch of servers - for the initial
implementation, I&amp;#8217;m looking to handle about 15M access_log lines per
day (that works out to 173 lines/second assuming an even distribution,
which there certainly isn&amp;#8217;t). Here is a selection of links that I&amp;#8217;ve
been using for ideas and inspiration, both for the technical side (data
collection, transport, storage and analysis) and&amp;nbsp;visualization:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://oss.oetiker.ch/rrdtool/gallery/index.en.html"&gt;RRDtool - RRDtool
    Gallery&lt;/a&gt; - I&amp;#8217;m
    starting a graphing/log analysis project, and looked here for some
    inspiration for my proof-of-concept&amp;nbsp;code&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aplawrence.com/Girish/gv-rrdtool.html"&gt;Creating pretty graphs with
    &lt;span class="caps"&gt;RRDTOOL&lt;/span&gt;&lt;/a&gt; from &lt;a href=""&gt;Girish
    Venkatachalam&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;There&amp;#8217;s some good information on RRDtool&amp;#8217;s &amp;#8220;Abberant Behavior
    Detection&amp;#8221; (Holt-Winters prediction, deviation and failure
    detection) on the
    &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdtool.en.html"&gt;rrdtool&lt;/a&gt;,
    &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdgraph_examples.en.html"&gt;rrdgraph_examples&lt;/a&gt;
    and &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdcreate.en.html"&gt;rrdcreate&lt;/a&gt;
    documentation pages, but unfortunately no anchors to link directly&amp;nbsp;to.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://square.github.com/cube/"&gt;Cube&lt;/a&gt; - &amp;#8220;Cube is a system for
    collecting timestamped events and deriving metrics. By collecting
    events rather than metrics, Cube lets you compute aggregate
    statistics post hoc. It also enables richer analysis, such as
    quantiles and histograms of arbitrary event sets. Cube is built on
    MongoDB and available under the Apache License on&amp;nbsp;GitHub.&amp;#8221;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://square.github.com/cubism/"&gt;Cubism.js&lt;/a&gt; - &amp;#8220;Cubism.js is a D3
    plugin for visualizing time series. Use Cubism to construct better
    realtime dashboards, pulling data from Graphite, Cube and other
    sources. Cubism is available under the Apache License on GitHub.&amp;#8221;
    The demo on that page looks pretty&amp;nbsp;cool.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.highcharts.com/demo/"&gt;Highcharts Demo Gallery&lt;/a&gt; - &lt;span class="caps"&gt;JS&lt;/span&gt;
    chart/graph library. It requires a paid license for commercial use
    (though it&amp;#8217;s a bit unclear to me whether an internal ops dashboard
    would fall under this license provision) so I probably wouldn&amp;#8217;t go
    with this one. They have some cool charts, including a &lt;a href="http://www.highcharts.com/demo/dynamic-update/gray"&gt;dynamic line
    chart updating every
    second&lt;/a&gt;, a
    &lt;a href="http://www.highcharts.com/demo/scatter/gray"&gt;scatter plot&lt;/a&gt; and a
    nice &lt;a href="http://www.highcharts.com/demo/line-time-series/gray"&gt;zoomable time-series
    graph&lt;/a&gt;, though
    &lt;span class="caps"&gt;IMHO&lt;/span&gt; it&amp;#8217;s not as nice as the Google Chart Tools (formerly Google
    Visualization) &lt;a href="https://developers.google.com/chart/interactive/docs/gallery/annotatedtimeline"&gt;annotated
    timeline&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://forums.cacti.net/viewtopic.php?t=29963"&gt;[ &lt;span class="caps"&gt;HOWTO&lt;/span&gt; ] Graphing Holt-Winters Predictive
    Analysis&lt;/a&gt; - Cacti&amp;nbsp;forums&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dygraphs.com/"&gt;dygraphs&lt;/a&gt; - an impressive permissive-license
    &lt;span class="caps"&gt;JS&lt;/span&gt; chart library dedicated to visualizing dense time-series data.
    Developed by Google and now used by them (Google Correlate, Google
    Latitude) as well as &lt;span class="caps"&gt;NASA&lt;/span&gt;, 10gen and others. There are some very
    cool demos on that main page, and also on the &lt;a href="http://dygraphs.com/tests/"&gt;tests
    page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.planetdevops.net/?p=12289"&gt;Graphite, JMXTrans, Ganglia, Logster, Collectd, say what ? « Planet&amp;nbsp;DevOps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://auxesis.github.com/visage/"&gt;Visage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kgorman/mongo_graph"&gt;kgorman/mongo_graph&lt;/a&gt; - a
    tool to pull data from MongoDB and put it in &lt;span class="caps"&gt;RRD&lt;/span&gt;&amp;nbsp;files&lt;/li&gt;
&lt;li&gt;&lt;a href="http://web.taranis.org/drraw/"&gt;drraw&lt;/a&gt; - a perl-based graphing
    frontend (web &lt;span class="caps"&gt;UI&lt;/span&gt;) for&amp;nbsp;RRDtool&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/logster"&gt;etsy/logster · GitHub&lt;/a&gt; - Etsy&amp;#8217;s
    Python tool to maintain a pointer on a log file, and parse at a
    regular rate feeding the data into a tool like Graphite or&amp;nbsp;Ganglia.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cebailey59/charcoal"&gt;cebailey59/charcoal&lt;/a&gt; - a
    Sinatra app that allows creation of dashboards from Graphite,
    collectd, or any other service that creates images from &lt;span class="caps"&gt;URL&lt;/span&gt;&amp;nbsp;calls.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/dashboard"&gt;etsy/dashboard&lt;/a&gt; - some examples
    of how Etsy builds monitoring&amp;nbsp;dashboards.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.devco.net/archives/2011/10/08/gdash-graphite-dashboard.php"&gt;GDash – Graphite Dashboard |
    &lt;span class="caps"&gt;R.I.&lt;/span&gt;Pienaar&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a Sinatra dashboard app for Graphite, using Twitter bootstrap for&amp;nbsp;visualization.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/paperlesspost/graphiti"&gt;paperlesspost/graphiti&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a Ruby and JavaScript front-end for&amp;nbsp;Graphite.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://graphite.wikidot.com/screen-shots"&gt;Graphite Screenshots&lt;/a&gt; -
    just two, but they get the idea across pretty&amp;nbsp;well.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://graylog2.org/"&gt;Graylog2&lt;/a&gt; - a centralized log management
    application with a powerful web interface. Stores logs in
    &lt;a href="http://www.elasticsearch.org/"&gt;ElasticSearch&lt;/a&gt; (which is built on
    Lucene, a Java-based index and search server) and statistics/graphs
    in MongoDB. It does analytics, alerting, monitoring/graphing and
    searching all through a web interface, and accepts log data via
    syslog, &lt;span class="caps"&gt;AMQP&lt;/span&gt; and &lt;span class="caps"&gt;GELF&lt;/span&gt; (its own log format). Java server and Ruby on
    Rails web&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; - another centralized log project
    that stores and indexes logs, with search via a web &lt;span class="caps"&gt;UI&lt;/span&gt;. &amp;#8220;Ship any
    event to anywhere over any protocol.&amp;#8221; Takes many inputs including
    files, syslog, &lt;span class="caps"&gt;AMQP&lt;/span&gt;, Flume, &lt;span class="caps"&gt;STOMP&lt;/span&gt;, &lt;span class="caps"&gt;HTTP&lt;/span&gt; and even twitter, performs a
    number of filters including timestamp checks, parsing, dropping,
    joins, etc, and then sends logs back on an output including &lt;span class="caps"&gt;AMQP&lt;/span&gt;,
    Graylog2 &lt;span class="caps"&gt;GELF&lt;/span&gt;, &lt;span class="caps"&gt;STOMP&lt;/span&gt;, MongoDB, ElasticSearch, syslog, WebSockets and
    to Nagios. One particularly cool feature is its &amp;#8220;file&amp;#8221; input, which
    continuously tails a file and claims to be log rotation safe. Just&amp;nbsp;cool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.google.com/present/view?id=dcmwwd94_16dfdxgpw8"&gt;jordansissel&amp;#8217;s Logstash intro
    slides&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rashidkpc.github.com/Kibana/"&gt;Kibana&lt;/a&gt; - an alternative
    interface for Logstash and
    &lt;a href="http://www.elasticsearch.org/"&gt;ElasticSearch&lt;/a&gt; that allows
    searching, graphing and analysis of log data stored in&amp;nbsp;Logstash.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pivotallabs.com/talks/139-metrics-metrics-everywhere"&gt;Pivotal Labs: Talks - Metrics Metrics
    Everywhere&lt;/a&gt;
    (Coda&amp;nbsp;Hale)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aq.iriscouch.com/swinger/_design/swinger/index.html#/preso/aq-mdd/display/1"&gt;PaperlessPost - @quirkey&amp;#8217;s talk on
    metrics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;very good high level stuff, but slides&amp;nbsp;only&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/paperlesspost/graphiti"&gt;paperlesspost/graphiti&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;graphiti, a &lt;span class="caps"&gt;JS&lt;/span&gt;/Ruby frontend for Graphite that does graphs,
dashboards, and point-in-time snapshots of graphs. Lots of&amp;nbsp;functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://redis.io/"&gt;Redis&lt;/a&gt; - a distributed key/value store that&amp;#8217;s
    really popular with the cool kids. &lt;a href="http://nosql.mypopescu.com/post/8652869828/another-redis-use-case-centralized-logging"&gt;Another Redis Use Case:
    Centralized Logging •&amp;nbsp;myNoSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cebailey59/charcoal"&gt;Charcoal&lt;/a&gt; - a
    &lt;a href="http://www.sinatrarb.com/"&gt;Sinatra&lt;/a&gt; (Ruby) dashboard app (ready for
    use on &lt;a href="http://www.heroku.com/"&gt;Heroku&lt;/a&gt; but usable anywhere).
    Graphite-oriented but will work with any tool that generates images
    from&amp;nbsp;URLs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/logster"&gt;etsy/logster&lt;/a&gt; - etsy&amp;#8217;s Logster
    tool, which keeps a tail on log files, parses them, and ships
    metrics to Graphite or&amp;nbsp;Ganglia.&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Some PowerDNS Links and Interesting Features</title><link href="http://blog.jasonantman.com/2012/09/some-powerdns-links-and-interesting-features/" rel="alternate"></link><updated>2012-09-05T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-05:2012/09/some-powerdns-links-and-interesting-features/</id><summary type="html">&lt;p&gt;At $&lt;span class="caps"&gt;WORK&lt;/span&gt; we lost a disk in the &lt;span class="caps"&gt;RAID1&lt;/span&gt; of one of our external nameservers,
and it rekindled an occasional discussion of migration from &lt;a&gt;&lt;span class="caps"&gt;ISC&lt;/span&gt;
&lt;span class="caps"&gt;BIND&lt;/span&gt;&lt;/a&gt; to &lt;a href="http://powerdns.com/content/products.html"&gt;PowerDNS&lt;/a&gt;.
PowerDNS has separate authoritative and recursive servers, and doesn&amp;#8217;t
seem to natively support views or split-horizon the way &lt;span class="caps"&gt;BIND&lt;/span&gt; does, but
it has some really cool features including very mature database
backends, load balancing, Lua scripting support to modify how recursive
queries are answered, and geolocation or &lt;span class="caps"&gt;IP&lt;/span&gt;-range based query&amp;nbsp;results.&lt;/p&gt;
&lt;p&gt;While this project is still just casual research, I thought I&amp;#8217;d share
some of the useful links and information I&amp;#8217;ve&amp;nbsp;found:&lt;/p&gt;
&lt;p&gt;PowerDNS&amp;nbsp;Front-ends:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.nicmus.com/community.html"&gt;JPowerAdmin&lt;/a&gt; - One of the two
    most popular, a GPLv3 Java (JBoss &lt;span class="caps"&gt;SEAM&lt;/span&gt;) based web &lt;span class="caps"&gt;UI&lt;/span&gt; with a RESTful
    &lt;span class="caps"&gt;API&lt;/span&gt;, with support for &amp;#8220;multiple&amp;#8221; database backends. Sponsored by
    Nicmus, Inc. &lt;a href="http://www.nicmus.com/JPowerAdmin"&gt;Online demo&lt;/a&gt;
    (demo:demo). Looks nice, simple &lt;span class="caps"&gt;UI&lt;/span&gt;, but no support for&amp;nbsp;split-horizon.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.poweradmin.org"&gt;PowerAdmin&lt;/a&gt; - the other most popular,
    though it seems to be undergoing a large overhaul at the moment. Has
    full support for most of PowerDNS&amp;#8217;s features, written in &lt;span class="caps"&gt;PHP&lt;/span&gt;,
    supports &amp;#8220;large&amp;#8221; databases, fine-grained user permissions, &lt;span class="caps"&gt;RFC&lt;/span&gt;
    validation, zone templates. &lt;a href="http://demo.poweradmin.org/"&gt;Online
    demo&lt;/a&gt; (demo:demo). I don&amp;#8217;t really like
    that it manages the SOAs as full text (without any templating,
    dropdowns or default values), and that it doesn&amp;#8217;t prepopulate
    default values for &lt;span class="caps"&gt;TTL&lt;/span&gt; in the new record form, but it looks like a
    good starting place for someone (like me) who&amp;#8217;s handy with&amp;nbsp;&lt;span class="caps"&gt;PHP&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://code.google.com/p/pdns-gui/"&gt;pdns-gui - PowerDNS &lt;span class="caps"&gt;GUI&lt;/span&gt; - Google Project
    Hosting&lt;/a&gt; - &lt;span class="caps"&gt;PHP&lt;/span&gt;/MySQL &lt;span class="caps"&gt;GUI&lt;/span&gt;.
    &lt;a href="http://www.powerdns-gui.org/"&gt;Online demo&lt;/a&gt;. Handles templates
    nicely but won&amp;#8217;t scale to too many of them. Window-based &lt;span class="caps"&gt;UI&lt;/span&gt; is
    visually pleasing but will probably be a problem for big&amp;nbsp;zones.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://code.google.com/p/powerdns-webinterface/"&gt;powerdns-webinterface - PowerDNS Webinterface - Google Project
    Hosting&lt;/a&gt; - A nice
    but relatively simplistic &lt;span class="caps"&gt;UI&lt;/span&gt; written in &lt;span class="caps"&gt;PHP&lt;/span&gt;. It has some nice
    features like multi-user authentication (and logging, though I
    haven&amp;#8217;t looked into how detailed it is), automatic &lt;span class="caps"&gt;SOA&lt;/span&gt; serial
    update, automatic &lt;span class="caps"&gt;PTR&lt;/span&gt; creation, etc. Unfortunately not geared
    towards people with lots of domains and multiple records; it has
    only one template for new domains (and no way to update domains
    created from a template), no easy filtering, and still treats &lt;span class="caps"&gt;SOA&lt;/span&gt;
    like a single text&amp;nbsp;record.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sourceforge.net/projects/zoneadmin/"&gt;ZoneAdmin |
    SourceForge.net&lt;/a&gt; and
    &lt;a&gt;Project website&lt;/a&gt; - Maybe not the fastest tool to use in bulk,
    but a nice, relatively intuitive and full-featured admin tool.
    &lt;a href="http://open.megabit.net/demos/ZoneAdmin/"&gt;Online demo&lt;/a&gt;&amp;nbsp;(demo:demo).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some links on PowerDNS&amp;nbsp;split-horizon&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://old.nabble.com/Split-Horizon-Scripts-td32843045.html"&gt;Old Nabble - PowerDNS - Split Horizon&amp;nbsp;Scripts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It looks to me that split-horizon is going to be the hardest part for
us, at least to also have a web &lt;span class="caps"&gt;UI&lt;/span&gt; to manage it. It looks like with
PowerDNS, the most common way to run split horizon &lt;span class="caps"&gt;DNS&lt;/span&gt; (views) is to run
two separate sets of servers or instances, either on different boxes or
multi-homed; one for internal and one for external. While that sounds
like quite a bit of overhead beyond what &lt;span class="caps"&gt;BIND&lt;/span&gt; does, the real problem is
finding a web &lt;span class="caps"&gt;UI&lt;/span&gt; that supports it; I don&amp;#8217;t care if it&amp;#8217;s in two separate
databases, but what I want is a logical (web &lt;span class="caps"&gt;UI&lt;/span&gt;) view that has zones
made up of resource names (i.e. the leftmost column in a zone file) with
one or two RRs (type, ttl, priority, value) - one for each view. That&amp;#8217;s
the real catch - all of our machines are in private &lt;span class="caps"&gt;IP&lt;/span&gt; space behind a
firewall, so I need to be able to manage the internal and external
records on one screen. While it&amp;#8217;s not exactly scalable, and the code
stagnated quite a bit once I got it to a point that was usable for me,
this was the main goal of my &lt;a href="http://multibindadmin.jasonantman.com/"&gt;MultiBIND
Admin&lt;/a&gt;&amp;nbsp;project.&lt;/p&gt;</summary><category term="bind"></category><category term="dns"></category><category term="multibindadmin"></category><category term="powerdns"></category></entry><entry><title>Wordpress - Automatically publish a pending post each weekday morning from a PHP script</title><link href="http://blog.jasonantman.com/2012/09/wordpress-automatically-publish-a-pending-post-each-weekday-morning-from-a-php-script/" rel="alternate"></link><updated>2012-09-04T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-04:2012/09/wordpress-automatically-publish-a-pending-post-each-weekday-morning-from-a-php-script/</id><summary type="html">&lt;p&gt;In an earlier post, &lt;a href="/2012/08/piwik-web-analytics-and-some-unfortunate-stats-about-my-blog/"&gt;Piwik Web Analytics, and some unfortunate stats
about my
blog&lt;/a&gt;,
I mentioned that the &lt;a href="http://feedburner.google.com/"&gt;Feedburner&lt;/a&gt; stats
for this blog show a relatively high subscribe/unsubscribe rate for this
blog. I think a large part of that is my tendency to blog in spurts, and
even worse, my tendency to write drafts and not publish them. In an
effort to combat this, I&amp;#8217;ve been trying to finish blog posts and then
set them to &amp;#8220;Pending&amp;#8221; status, and go back and publish one every day
(well, every day that I have some still sitting unpublished). Of course,
that counts on me logging in to Wordpress every day, which isn&amp;#8217;t
something I do. The following script is, at least for now, the answer
for&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;This script (a standalone &lt;span class="caps"&gt;PHP&lt;/span&gt; script) uses
&lt;a href="http://core.trac.wordpress.org/browser/trunk/wp-load.php"&gt;&lt;code&gt;wp-load.php&lt;/code&gt;&lt;/a&gt;
to load the wordpress environment, and then finds the oldest post with a
given status (&amp;#8220;pending&amp;#8221; in my case) and attempts to publish it. It only
does this if there has not been another post published in the last 24
hours. The following script can be found in Git at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/wordpress_daily_post.php"&gt;https://github.com/jantman/misc-scripts/blob/master/wordpress_daily_post.php&lt;/a&gt;&lt;/p&gt;
&lt;!---
sourceinclude
---&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;#!/usr/bin/php&lt;/span&gt;
&lt;span class="cp"&gt;&amp;lt;?php&lt;/span&gt;
&lt;span class="sd"&gt;/**&lt;/span&gt;
&lt;span class="sd"&gt; * wordpress_daily_post.php&lt;/span&gt;
&lt;span class="sd"&gt; * Script to publish the oldest post with a given status, if no&lt;/span&gt;
&lt;span class="sd"&gt; * other post has been published in 24 hours. Intended to be run&lt;/span&gt;
&lt;span class="sd"&gt; * via cron on weekdays.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Copyright 2012 Jason Antman &lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Licensed under the Apache License, Version 2.0 &lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * use it anywhere you want, however you want, provided that this header is left intact,&lt;/span&gt;
&lt;span class="sd"&gt; * and that if redistributed, credit is given to me.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * It is strongly requested, but not technically required, that any changes/improvements&lt;/span&gt;
&lt;span class="sd"&gt; * be emailed to the above address.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * The latest version of this script will always be available at:&lt;/span&gt;
&lt;span class="sd"&gt; * $HeadURL: http://svn.jasonantman.com/misc-scripts/wordpress_daily_post.php $&lt;/span&gt;
&lt;span class="sd"&gt; * $LastChangedRevision: 40 $&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Changelog:&lt;/span&gt;
&lt;span class="sd"&gt; * 2012-09-03 Jason Antman  - 1.0&lt;/span&gt;
&lt;span class="sd"&gt; *  - first version&lt;/span&gt;
&lt;span class="sd"&gt; */&lt;/span&gt;

&lt;span class="c1"&gt;# &lt;span class="caps"&gt;BEGIN&lt;/span&gt; &lt;span class="caps"&gt;CONFIGURATION&lt;/span&gt;&lt;/span&gt;
&lt;span class="nb"&gt;define&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;WP_LOAD_LOC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/var/www/vhosts/blog.jasonantman.com/wp-load.php&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// Configure this to the full path of your Wordpress wp-load.php&lt;/span&gt;
&lt;span class="nb"&gt;define&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SOURCE_POST_STATUS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// post status to publish&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;END&lt;/span&gt; &lt;span class="caps"&gt;CONFIGURATION&lt;/span&gt;&lt;/span&gt;

&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;array_shift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;isset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-d&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--dry-run&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;DRY&lt;/span&gt; &lt;span class="caps"&gt;RUN&lt;/span&gt; &lt;span class="caps"&gt;ONLY&lt;/span&gt; - &lt;span class="caps"&gt;NOT&lt;/span&gt; &lt;span class="caps"&gt;ACTUALLY&lt;/span&gt; &lt;span class="caps"&gt;PUBLISHING&lt;/span&gt;.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;isset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-v&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--verbose&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;WP_LOAD_LOC=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;WP_LOAD_LOC&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;SOURCE_POST_STATUS=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;SOURCE_POST_STATUS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nb"&gt;array_shift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nv"&gt;$_SERVER&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;HTTP_HOST&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// needed for wp-includes/ms-settings.php:100&lt;/span&gt;
&lt;span class="k"&gt;require_once&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;WP_LOAD_LOC&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;# check that we&amp;#39;re running on a weekday&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="c1"&gt;#  if($&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;){ fwrite(&lt;span class="caps"&gt;STDERR&lt;/span&gt;, &amp;quot;today is a saturday or sunday, dieing.\n&amp;quot;); }&lt;/span&gt;
&lt;span class="c1"&gt;#  exit(1);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# find the publish date/time of the last published post&lt;/span&gt;
&lt;span class="nv"&gt;$published&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;DESC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="nv"&gt;$post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$published&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="nv"&gt;$pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;strtotime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$pub_date&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;86400&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;last post (&lt;span class="caps"&gt;ID&lt;/span&gt; &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt;) within last day (&lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="s2"&gt;). Nothing to do. Exiting.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Found last post (&lt;span class="caps"&gt;ID&lt;/span&gt; &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt;) with post date &lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="s2"&gt;.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="c1"&gt;# find the earliest post of status SOURCE_POST_STATUS, if there is one.&lt;/span&gt;
&lt;span class="nv"&gt;$to_post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;ASC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;SOURCE_POST_STATUS&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$to_post&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nx"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$to_pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$to_pub_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;time&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="nv"&gt;$new_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y-m-d H:i:s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$now&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nv"&gt;$new_date_gmt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;gmdate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y-m-d H:i:s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$now&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Post to publish: &lt;span class="caps"&gt;ID&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_id&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;DATE&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_date&lt;/span&gt;&lt;span class="s2"&gt; NEW_DATE=&lt;/span&gt;&lt;span class="si"&gt;$new_date&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;TITLE&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_title&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# actually publish it&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="nv"&gt;$arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;ID&lt;/span&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$to_pub_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$new_date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date_gmt&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$new_date_gmt&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="nv"&gt;$ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;wp_update_post&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$arr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// publish the post&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$ret&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: Post &lt;/span&gt;&lt;span class="si"&gt;$to_pub_id&lt;/span&gt;&lt;span class="s2"&gt; was not successfully published.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Published post. New &lt;span class="caps"&gt;ID&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;$ret&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Dry run only, not publishing post.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# check that the post really was published&lt;/span&gt;
&lt;span class="nv"&gt;$published&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;DESC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="nv"&gt;$post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$published&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="nv"&gt;$pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_guid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;guid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$pub_title&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="nv"&gt;$to_pub_title&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: title of most recent post does not match title of what we wanted to post.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Published post &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt; at &lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Title: &lt;/span&gt;&lt;span class="si"&gt;$pub_title&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n\n\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;GUID&lt;/span&gt;/Link: &lt;/span&gt;&lt;span class="si"&gt;$pub_guid&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="k"&gt;__FILE__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; on &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;trim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;shell_exec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hostname --fqdn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; running as &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;get_current_user&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="cp"&gt;?&amp;gt;&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You&amp;#8217;ll need to set &lt;code&gt;WP_LOAD_LOC&lt;/code&gt; (line 29) to the full path of your
Wordpress installation&amp;#8217;s &lt;code&gt;wp-load.php&lt;/code&gt; (it should be in the top-level
directory of your Wordpress installation. I run this script from cron&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;0 6 * * 1-5 /home/jantman/bin/wordpress_daily_post.php --verbose # publish WP pending posts daily
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;so that it runs at &lt;span class="caps"&gt;6AM&lt;/span&gt; (local time) each weekday. Assuming you have cron
setup to send you mail, you&amp;#8217;ll get a daily message saying what was (or
wasn&amp;#8217;t)&amp;nbsp;done.&lt;/p&gt;</summary><category term="cron"></category><category term="PHP"></category><category term="wordpress"></category></entry><entry><title>Interesting Systems Links for September 3, 2012</title><link href="http://blog.jasonantman.com/2012/09/interesting-systems-links-for-september-3-2012/" rel="alternate"></link><updated>2012-09-03T09:42:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-03:2012/09/interesting-systems-links-for-september-3-2012/</id><summary type="html">&lt;p&gt;Here is a small selection of sysadmin links that I recently found, and
wanted to&amp;nbsp;share:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://codeascraft.etsy.com/2012/05/22/blameless-postmortems/"&gt;Blameless PostMortems and a Just Culture - Code as
    Craft&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;some really good ideas about a culture that recognizes and seeks
to remedy human errors, rather than punishing and generating&amp;nbsp;fear.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://agilesysadmin.net/pillar-one"&gt;The first pillar: We alert on what we draw - Agile&amp;nbsp;Sysadmin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.masterzen.fr/2010/11/14/puppet-ssl-explained/"&gt;Puppet &lt;span class="caps"&gt;SSL&lt;/span&gt; explained - Masterzen&amp;#8217;s&amp;nbsp;Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.infoq.com/news/2011/05/unix-orchestration"&gt;Unix Orchestration Roundup: Tools for Programmatic Systems&amp;nbsp;Administration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="devops"></category><category term="links"></category><category term="portmortem"></category><category term="sysadmin"></category></entry><entry><title>RVM and Ruby 1.9 to test logstash grok patterns on Fedora/CentOS</title><link href="http://blog.jasonantman.com/2012/09/rvm-and-ruby-1-9-to-test-logstash-grok-patterns-on-fedoracentos/" rel="alternate"></link><updated>2012-09-03T08:37:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-03:2012/09/rvm-and-ruby-1-9-to-test-logstash-grok-patterns-on-fedoracentos/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been working on a personal project with
&lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; lately, and it relies relatively
heavily on &lt;a href="https://github.com/jordansissel/grok"&gt;grok&lt;/a&gt; filters for
matching text and extracting matched parts. Today, I&amp;#8217;ve been parsing
syslog from &lt;a href="http://puppetlabs.com/puppet/puppet-open-source/"&gt;Puppet&lt;/a&gt;
to extract various metrics and timings, which will then be passed on
from Logstash to &lt;a href="https://github.com/etsy/statsd"&gt;Etsy&amp;#8217;s statsd&lt;/a&gt; and
then to &lt;a href="http://graphite.wikidot.com/"&gt;graphite&lt;/a&gt; for display.
Unfortunately, a few of my patterns are showing the &amp;#8220;_grokparsefailure&amp;#8221;
tag and I just can&amp;#8217;t seem to find the&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;The logstash wiki provides a page on &lt;a href="https://github.com/logstash/logstash/wiki/Testing-your-Grok-patterns-(--logstash-1.1.0-and-above-)"&gt;Testing your Grok
patterns&lt;/a&gt;,
as does Sean Laurent on his blog: &lt;a href="http://blog.bealetech.com/content/testing-logstash-grok-filters"&gt;Testing Logstash grok
filters&lt;/a&gt;.
Unfortunately, I work in a CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; shop, and we&amp;#8217;re decidedly &lt;em&gt;not&lt;/em&gt; a
Ruby shop. Our Logstash install is using the monolithic/standalone Java
&lt;span class="caps"&gt;JAR&lt;/span&gt;. We run Puppet, which is currently under ruby 1.8.7, and the
&lt;a href="http://rubygems.org/gems/jls-grok"&gt;jls-grok rubygem&lt;/a&gt; requires ruby 1.9.
There&amp;#8217;s no way I&amp;#8217;d feel safe installing 1.9 on any of our machines, as
they all run (and require) Puppet. So, I found out about
&lt;a href="https://rvm.io/"&gt;&lt;span class="caps"&gt;RVM&lt;/span&gt;&lt;/a&gt;, the Ruby Version Manager, which allows you to
run and switch between multiple ruby versions, and all of it is
installed on a per-user basis. So, I created a new user on my Fedora 16
desktop called &amp;#8220;rvmtest&amp;#8221; and went about the process of setting up what&amp;#8217;s
needed to test grok patterns in the user&amp;#8217;s local environment. I imagine
this would work similarly under CentOS or &lt;span class="caps"&gt;RHEL&lt;/span&gt;, but the following is
only tested on Fedora 16. If you have any issues, you should probably
refer back to the &lt;span class="caps"&gt;RVM&lt;/span&gt;&amp;nbsp;documentation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create the isolated user, just to be extra careful. Login as that&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As per &lt;a href="https://rvm.io/rvm/install/"&gt;Installing &lt;span class="caps"&gt;RVM&lt;/span&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl https://raw.github.com/wayneeseguin/rvm/master/binscripts/rvm-installer | bash -s stable
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;edit your &lt;code&gt;~/.bashrc&lt;/code&gt; and&amp;nbsp;add:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="o"&gt;[[&lt;/span&gt; -s &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;HOME&lt;/span&gt;/.rvm/scripts/rvm&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;HOME&lt;/span&gt;/.rvm/scripts/rvm&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt; -r &lt;span class="nv"&gt;$rvm_path&lt;/span&gt;/scripts/completion &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span class="nv"&gt;$rvm_path&lt;/span&gt;/scripts/completion
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first line sets up &lt;span class="caps"&gt;RVM&lt;/span&gt; for your sessions, and the second sources
in tab-completion for the &lt;code&gt;rvm&lt;/code&gt; command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;source .bashrc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;If you&amp;#8217;re interested, you can see a list of all known rubies with:
    &lt;code&gt;rvm list known&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install Ruby (&lt;span class="caps"&gt;MRI&lt;/span&gt;) 1.9.2: &lt;code&gt;rvm install 1.9.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;switch&amp;#8221; to that ruby: &lt;code&gt;rvm use 1.9.2&lt;/code&gt; and confirm it by running
    &lt;code&gt;ruby -v&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Make it the default ruby for us: &lt;code&gt;rvm use 1.9.2 --default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create a &amp;#8220;gemset&amp;#8221; (set of rubygems for our environment):
    &lt;code&gt;rvm gemset create groktest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use it, and set it as default: &lt;code&gt;rvm use 1.9.2@groktest --default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;for grok testing, &lt;code&gt;gem install jls-grok&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;check that it&amp;#8217;s there: &lt;code&gt;gem list&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download Logstash&amp;#8217;s default grok patterns &lt;a href="https://raw.github.com/logstash/logstash/master/patterns/grok-patterns"&gt;from&amp;nbsp;github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;You should now be ready to test some grok&amp;nbsp;patterns.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While the two howto&amp;#8217;s linked above use &lt;code&gt;irb&lt;/code&gt; to interactively test the
patterns, I prefer something easier to move to production, more
reliable, and more repeatable. The following quick little ruby script
takes test to match against on &lt;span class="caps"&gt;STDIN&lt;/span&gt; (log files, messages, etc.) and
prints the matches to &lt;span class="caps"&gt;STDOUT&lt;/span&gt;. The script is based on
&lt;a href="https://github.com/jordansissel/ruby-grok/blob/master/examples/test.rb"&gt;test.rb&lt;/a&gt;
from &lt;a href="https://github.com/jordansissel/ruby-grok"&gt;jordansissel&amp;#8217;s
ruby-grok&lt;/a&gt;. Note one
important thing here, I couldn&amp;#8217;t get the shebang (&lt;code&gt;#!&lt;/code&gt;) to work with
anything other than the explicit path to my &lt;span class="caps"&gt;RVM&lt;/span&gt; ruby install
(&lt;code&gt;which ruby&lt;/code&gt;) so you&amp;#8217;ll need to manually update this&amp;nbsp;yourself.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!.rvm/rubies/ruby-1.9.2-320bin/ruby&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;rubygems&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;grok-pure&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pp&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;grok&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;
&lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_patterns_from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;grok-patterns&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;your_grok_pattern_here&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;PATTERN&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;gets&lt;/span&gt;
  &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;IN&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;pp&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;captures&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;No Match.&amp;quot;&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&amp;#8217;s an example using a pattern to capture information from custom
syslog messages triggered by updating puppet configs. Here&amp;#8217;s some sample&amp;nbsp;messages:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[rvmtest@jantmanwork ~]$ cat puppet.log&lt;/span&gt;
&lt;span class="go"&gt;Updated 2 files in puppet svn (environment prod) to revision 754&lt;/span&gt;
&lt;span class="go"&gt;Updated 3 files in puppet svn (environment prod) to revision 756&lt;/span&gt;
&lt;span class="go"&gt;Updated 1 files in puppet svn (environment prod) to revision 757&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the pattern that I&amp;nbsp;use:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Updated%{SPACE}%{NUMBER:puppet_svn_num_files}%{SPACE}files%{SPACE}in%{SPACE}puppet%{SPACE}svn%{SPACE}\(environment%{SPACE}%{WORD:puppet_svn_env}\)%{SPACE}to%{SPACE}revision%{SPACE}%{NUMBER:puppet_svn_revision}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the output of the&amp;nbsp;script:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[rvmtest@jantmanwork ~]$ cat puppet.log | ./puppet-update-test.rb &lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;PATTERN&lt;/span&gt;: Updated%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files}%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}files%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}in%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}puppet%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}svn%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}\(environment%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env}\)%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}to%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}revision%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 2 files in puppet svn (environment prod) to revision 754&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;2&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;2&amp;quot;, &amp;quot;754&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;754&amp;quot;]}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 3 files in puppet svn (environment prod) to revision 756&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;3&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;3&amp;quot;, &amp;quot;756&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;756&amp;quot;]}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 1 files in puppet svn (environment prod) to revision 757&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;1&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;1&amp;quot;, &amp;quot;757&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;757&amp;quot;]}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopefully this will make the process a bit simpler for someone&amp;nbsp;else&amp;#8230;&lt;/p&gt;</summary><category term="grok"></category><category term="grokparsefailure"></category><category term="jruby"></category><category term="kibana"></category><category term="logstash"></category><category term="ruby"></category><category term="rvm"></category></entry><entry><title>Piwik Web Analytics, and some unfortunate stats about my blog</title><link href="http://blog.jasonantman.com/2012/08/piwik-web-analytics-and-some-unfortunate-stats-about-my-blog/" rel="alternate"></link><updated>2012-08-26T13:18:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-26:2012/08/piwik-web-analytics-and-some-unfortunate-stats-about-my-blog/</id><summary type="html">&lt;p&gt;Back in March when I selected a new template for this blog, I
&lt;a href="/2012/03/new-blog-theme/"&gt;posted&lt;/a&gt; that I was looking into open source
self-hosted web analytics tools to replace &lt;a href="http://www.google.com/analytics/"&gt;Google
Analytics&lt;/a&gt;. There were a few reasons
for this; most importantly, it started from a discussion with some
privacy-conscious coworkers, who said that they use
&lt;a href="http://noscript.net/"&gt;NoScript&lt;/a&gt; and specifically block Google from
tracking them (which also breaks Google Analytics). This was a serious
issue for me, as I no longer process server-side logs but relied solely
on Google Analytics for traffic information. So, I decided to try
something other than Google and ended up settling on
&lt;a href="http://piwik.org/"&gt;Piwik&lt;/a&gt; as my solution. I will say, in full
disclosure, that the amount of information Piwki gives is a bit scary; I
can watch users navigate this blog in realtime, and even the initial
dashboard page gives a list of the most recent visitors, with their &lt;span class="caps"&gt;IP&lt;/span&gt;
address, country of origin, browser, &lt;span class="caps"&gt;OS&lt;/span&gt;, and the pages they visited.
However my decision was made on two main points: first, that I wanted
something withich could use server-side &lt;span class="caps"&gt;PHP&lt;/span&gt; to log visits (albeit with a
lot less information) of people who had JavaScript or tracking disabled,
and second, that if &lt;em&gt;someone&lt;/em&gt; is going to have such amazingly detailed
information on my visitors, it should be me, so I can ensure that I&amp;#8217;m
the only person who has access to it and that it isn&amp;#8217;t used for the
wrong&amp;nbsp;purposes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Aside: The only revenue I get from this site is through &lt;a href=""&gt;Google
AdSense&lt;/a&gt;, which isn&amp;#8217;t a whole lot given the low traffic (certainly
not enough to pay for the hosting). Other than that, I keep this blog
to try and share my knowledge with others, and hope that someone else
can find the solution to their problem here instead of doing the work
that I did. So, I find analytics very helpful; I check my stats now
and then, go back and update or add to the most popular posts, and try
to write relevant posts if it seems like a lot of people are finding
their way here for something slightly different than the actual post
they landed on. Unfortunately, that last point isn&amp;#8217;t as easy since
&lt;a href="http://googleblog.blogspot.com/2011/10/making-search-more-secure.html"&gt;Google switched to &lt;span class="caps"&gt;HTTPS&lt;/span&gt; Search for logged-in users on October 18th,
2011&lt;/a&gt;
- I can no longer use Piwik see the search keywords that got Google
users to my site. Luckily, these are still available through &lt;a href="https://www.google.com/webmasters/tools/"&gt;Google
Webmaster Tools&lt;/a&gt; (via
Traffic -&gt; Search Queries on the left menu), though it adds an
additional step and removes some of my motivation to check regularly
and make sure people are getting useful content. Also, perhaps most
importantly, it doesn&amp;#8217;t let me associate search query with other stats
like time on page, so even if one search query was very popular, I
have no way of knowing whether all those people actually read the
page, or took one look at it and&amp;nbsp;left.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I really like Piwki. I don&amp;#8217;t use most of it terribly often, but it gives
me a nice overview visits graph on the WordPress dashboard (via the
&lt;a href="http://wordpress.org/extend/plugins/wp-piwik/"&gt;&lt;span class="caps"&gt;WP&lt;/span&gt;-Piwik&lt;/a&gt; plugin),
infinitely detailed information (most of which I haven&amp;#8217;t even looked at)
in the Piwki web interface, and nightly email reports of visits to the
site. It also supports multiple sites, so I have it on my ancient
&lt;a href="http://wiki.jasonantman.com"&gt;wiki&lt;/a&gt;, my
&lt;a href="http://redmine.jasonantman.com"&gt;Redmine&lt;/a&gt; instance, and even
&lt;a href="/2012/03/adding-piwik-web-analytics-integration-to-viewvc/"&gt;ViewVC&lt;/a&gt;.
I&amp;#8217;d highly recommend it; it&amp;#8217;s full-featured (beyond anything I can even
comprehend,&amp;nbsp;really)&lt;/p&gt;
&lt;p&gt;I was recently looking through the stats for this blog, and came by some
unfortunate, though not surprising, trends. Below is the graph of visits
per day, from April 1, 2012 through today (August 26,&amp;nbsp;2012):&lt;/p&gt;
&lt;p&gt;&lt;img alt="blog visits chart" src="/GFX/blog_visits.png" /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It&amp;#8217;s probably not terribly unusual for a site with as much technical
    content as mine (and mostly professional stuff, not just for
    hobbyists), my weekend traffic is usually a full 50% lower than
    weekday traffic. This can also be seen in the graph of visits by
    visitor&amp;#8217;s local time, which is decidedly biased towards the 9am-5pm
    window:&lt;br /&gt;
&lt;img alt="blog visits chart by visitor local
    time" src="/GFX/blog_visits_localtime.png" /&gt;&lt;br /&gt;
    I guess there&amp;#8217;s nothing I can really do about that, and it just
    gives me a nice maintenance window at 4am on Sunday mornings&amp;nbsp;:)&lt;/li&gt;
&lt;li&gt;Looking at the overall graph, there also appears to be quite a bit
    of oscillation of the average visits over time. It&amp;#8217;s nothing
    terribly large, but at a guess, I&amp;#8217;d attribute it to my sporadic&amp;nbsp;posting.&lt;/li&gt;
&lt;li&gt;Though it&amp;#8217;s not visible in these graphs, this site has an 80% bounce
    rate (the percent of visitors that viewed only one page and then
    left the site). I guess that&amp;#8217;s also not terribly unusual for a site
    with mostly how-to information on a wide variety of&amp;nbsp;topics.&lt;/li&gt;
&lt;li&gt;To add a little more information to some of the previous items, here
    is the chart of my &lt;a href="http://feedburner.google.com"&gt;Feedburner&lt;/a&gt;
    &lt;span class="caps"&gt;RSS&lt;/span&gt;/Atom feed, since I started using Feedburner in February. The
    number of subscribers is in green, and the reach (number of people
    who actually clicked through to a post) is in blue:&lt;br /&gt;
&lt;img alt="Feedburner stats" src="/GFX/feedburner_stats.png" /&gt;&lt;br /&gt;
    This is a clear indication of something even stronger than the
    &amp;#8220;bounce rate&amp;#8221;; the apparently high number of people who subscribe to
    and then unsubscribe from my feed (if these stats are accurate). To
    me, this is an even stronger indication that what I really need to
    do is post useful content on a more regular basis - I have a
    tendency to blog in spurts, and either start a draft and never
    finish it, or write a few posts and set them to &amp;#8220;pending&amp;#8221; status
    with the intent of publishing them over a few days&amp;#8230; and then
    forget the last&amp;nbsp;part.&lt;/li&gt;
&lt;/ol&gt;</summary><category term="blog"></category><category term="google analytics"></category><category term="piwik"></category></entry><entry><title>Puppet facter facts for syslog daemon type and version, symantec netbackup</title><link href="http://blog.jasonantman.com/2012/08/puppet-facter-facts-for-syslog-daemon-type-and-version-symantec-netbackup/" rel="alternate"></link><updated>2012-08-25T11:33:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-25:2012/08/puppet-facter-facts-for-syslog-daemon-type-and-version-symantec-netbackup/</id><summary type="html">&lt;p&gt;I have a few more custom facts that I&amp;#8217;ve added to my
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;puppet-facter-facts&lt;/a&gt;
github&amp;nbsp;repository:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_bin.rb"&gt;syslog_bin&lt;/a&gt;,
    &lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_type.rb"&gt;syslog_type&lt;/a&gt;,
    and
    &lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_version.rb"&gt;syslog_version&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;tell the absolute path to the &lt;em&gt;running&lt;/em&gt; syslog binary, its short
name (basename), and its version as a string. Currently only know
about &lt;code&gt;/sbin/syslogd&lt;/code&gt; and &lt;code&gt;/sbin/rsyslogd&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/has_netbackup.rb"&gt;has_netbackup&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;tests for presence of the &lt;code&gt;/usr/openv/netbackup/bin&lt;/code&gt; directory,
created by installation of &lt;a href="http://www.symantec.com/netbackup"&gt;Symantec
Netbackup&lt;/a&gt;. Useful for making
generation of include/exclude files conditional on having NetBackup&amp;nbsp;installed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hopefully some of these will be of use to someone else as&amp;nbsp;well.&lt;/p&gt;</summary><category term="facter"></category><category term="nbu"></category><category term="netbackup"></category><category term="puppet"></category><category term="rsyslog"></category><category term="syslog"></category></entry><entry><title>Puppet facter fact for all applied classes, returned as a CSV list</title><link href="http://blog.jasonantman.com/2012/08/puppet-facter-fact-for-all-applied-classes-returned-as-a-csv-list/" rel="alternate"></link><updated>2012-08-22T07:05:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-22:2012/08/puppet-facter-fact-for-all-applied-classes-returned-as-a-csv-list/</id><summary type="html">&lt;p&gt;I&amp;#8217;m unfortunatey stuck, at least for the time being, using flat-file
manifests to configure my puppet nodes. Without an &lt;span class="caps"&gt;ENC&lt;/span&gt;, it&amp;#8217;s pretty
difficult to get a good ovewview of what classes are used on each node,
and what nodes use a given class. I know I could write up a simple web
tool to do this (unfortunately, given my limited Ruby knowledge, it
would have to be in &lt;span class="caps"&gt;PHP&lt;/span&gt; or Perl, not a real modification to Dashboard in
Ruby). But where to get the data&amp;nbsp;from?&lt;/p&gt;
&lt;p&gt;After some research, I found a &lt;a href="http://sjoeboo.github.com/blog/2012/07/31/updated-puppet-facts-for-puppet-classes/"&gt;puppet fact for puppet
classes&lt;/a&gt;
on &lt;a href="http://sjoeboo.github.com/"&gt;Matthew Nicholson&amp;#8217;s Coffee &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Beer blog&lt;/a&gt;.
It parses &lt;code&gt;/var/lib/puppet/classes.txt&lt;/code&gt; and returns the list of classes
found as a &lt;span class="caps"&gt;JSON&lt;/span&gt; array. Great base, but I wanted something easier, that
would be more easily parsed from its direct storage in MySQL. My
modification to his code is onlty a few characters; I dropped out the
&lt;span class="caps"&gt;JSON&lt;/span&gt; require, and return the classes as a &lt;span class="caps"&gt;CSV&lt;/span&gt; list. This lets me to easy
&lt;code&gt;LIKE '%,classname,%'&lt;/code&gt; SELECTs in MySQL, and also gives me the fact
value stored in the puppet &lt;span class="caps"&gt;DB&lt;/span&gt;, so I can build a separate tool around
that data. Thanks,&amp;nbsp;Matt.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# facter fact for puppet classes on node, pulled from /var/lib/puppet/classes.txt&lt;/span&gt;
&lt;span class="c1"&gt;# from &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;facter&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;begin&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hostname&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loadfacts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="n"&gt;hostname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hostname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fqdn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;classes_txt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/var/lib/puppet/classes.txt&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;classes_txt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;classes_txt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;Array&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;each&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;chomp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_s&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;hostname&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;puppet_classes_csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All of my facts are now available in a GitHub repository:
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;https://github.com/jantman/puppet-facter-facts&lt;/a&gt;.&lt;/p&gt;</summary><category term="classes"></category><category term="csv"></category><category term="fact"></category><category term="facter"></category><category term="node"></category><category term="puppet"></category></entry><entry><title>Puppet facter fact for last applied configuration version</title><link href="http://blog.jasonantman.com/2012/08/puppet-facter-fact-for-last-applied-configuration-version/" rel="alternate"></link><updated>2012-08-21T08:55:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-21:2012/08/puppet-facter-fact-for-last-applied-configuration-version/</id><summary type="html">&lt;p&gt;For anyone else who sets the Puppet &lt;code&gt;config_version&lt;/code&gt; paramater to return
the current &lt;span class="caps"&gt;SVN&lt;/span&gt; or Git version of your configuration, here&amp;#8217;s a fact that
grabs that version (by parsing the cached &lt;span class="caps"&gt;YAML&lt;/span&gt; catalog) and sets it as a
fact called &amp;#8220;catalog_config_version&amp;#8221;. It can then be used for
sanity-checking your nodes, looking up via the Inventory Service, or you
can display it in the Dashboard using my patch: &lt;a href="http://blog.jasonantman.com/2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/"&gt;Patch to Puppet
Dashboard 1.2.10 to show arbitrary facts in the main node
table&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# facter fact for last applied config version, skeleton from /var/lib/puppet/client_yaml/catalog/fqdn.yaml&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;puppet&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;yaml&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;facter&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;localconfig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="no"&gt;Puppet&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:clientyamldir&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/catalog/&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.yaml&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;unless&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exist?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;localconfig&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;puts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Can&amp;#39;t find &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.yaml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;lc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;localconfig&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;begin&lt;/span&gt;
  &lt;span class="n"&gt;pup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Marshal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;TypeError&lt;/span&gt;
  &lt;span class="n"&gt;pup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;&lt;span class="caps"&gt;YAML&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;Exception&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
  &lt;span class="k"&gt;raise&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="ss"&gt;Puppet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="ss"&gt;:Resource&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Catalog&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;catalog_config_version&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="n"&gt;pup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;catalog_config_version&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="s2"&gt;&amp;quot;unknown&amp;quot;&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All of my facts are now available in a GitHub repository:
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;https://github.com/jantman/puppet-facter-facts&lt;/a&gt;.&lt;/p&gt;</summary><category term="config_version"></category><category term="fact"></category><category term="facter"></category><category term="puppet"></category></entry><entry><title>Setting emacs zone-mode based on path</title><link href="http://blog.jasonantman.com/2012/08/setting-emacs-zone-mode-based-on-path/" rel="alternate"></link><updated>2012-08-15T08:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-15:2012/08/setting-emacs-zone-mode-based-on-path/</id><summary type="html">&lt;p&gt;At work, we do a fair amount of &lt;span class="caps"&gt;DNS&lt;/span&gt; updates. Our zone files are stored
in subversion, and are named according to the domain (with no .zone
extension). It&amp;#8217;s a real pain when updating a few (or a few dozen) zones
in Emacs, since I have to remember to &amp;#8220;M-x zone-mode&amp;#8221; so the serial gets
automatically updated. Here&amp;#8217;s a lisp snippet to put in your &lt;code&gt;.emacs&lt;/code&gt;
file that will set zone-mode for all files in any path matching the
regex &lt;code&gt;svn/named/zones-internal&lt;/code&gt;. I deliberately made it a relative path
(or, really, any path containing that) so it would work for all of my
team&amp;#8217;s workstations, no matter where we have the svn repo checked&amp;nbsp;out:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;add-to-list&lt;/span&gt; &lt;span class="ss"&gt;&amp;#39;auto-mode-alist&lt;/span&gt; &lt;span class="o"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;svn/named/zones-internal/&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="nv"&gt;zone-mode&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Many thanks to &lt;code&gt;taylanub&lt;/code&gt; on #emacs on irc.freenode.net for helping
with&amp;nbsp;this.&lt;/p&gt;</summary><category term="bind"></category><category term="emacs"></category><category term="lisp"></category><category term="named"></category><category term="zone-mode"></category></entry><entry><title>Patch to Puppet Dashboard 1.2.10 to show arbitrary facts in the main node table</title><link href="http://blog.jasonantman.com/2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/" rel="alternate"></link><updated>2012-08-11T10:34:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-11:2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/</id><summary type="html">&lt;p&gt;We use &lt;a href="http://puppetlabs.com/puppet/related-projects/dashboard/"&gt;Puppet
Dashboard&lt;/a&gt; at
work to view the status of our puppet nodes. While it&amp;#8217;s very handy,
there&amp;#8217;s one feature I really wanted: the ability to show the value of
arbitrary puppet facts in the main node table on the home page.
Specifically, the facts we use for environment (we have eng/dev, qa,
prod, and test puppet environments), zone (physical location) and last
applied configuration version. I&amp;#8217;m not terribly experience with Ruby,
but I managed to muddle my way through a working patch to do this, along
with options in the settings file to enable it and configure the facts.
You&amp;#8217;ll need to restart dashboard (or your web server) to change the
facts, of course. The commit is currently &lt;a href="https://github.com/jantman/puppet-dashboard/commit/5364e2b0188d18ae62c355279e58c7ce6d7db654"&gt;available on
github&lt;/a&gt;,
but it doesn&amp;#8217;t strictly follow the &lt;a href="https://github.com/puppetlabs/puppet-dashboard/blob/master/CONTRIBUTING.md"&gt;puppet-dashboard contributing
checklist&lt;/a&gt;
so I may have to redo&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a&amp;nbsp;screenshot:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/dashboard_after_patch.png"&gt;&lt;img alt="Dashboard screenshot after
patch" src="/GFX/dashboard_after_patch_sm.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And here&amp;#8217;s that the configuration section added to settings.yml looks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# Enables display of arbitrary node facts in &amp;quot;home&amp;quot; page node table, between node name and latest report time&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;enable_home_facts&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;true&lt;/span&gt;

&lt;span class="c1"&gt;# If enable_home_facts is true, the fact names and column headings to display. Simply repeat the following two line pairs&lt;/span&gt;
&lt;span class="c1"&gt;# as needed:&lt;/span&gt;
&lt;span class="c1"&gt;#- name: &amp;#39;factname&amp;#39;&lt;/span&gt;
&lt;span class="c1"&gt;#  heading: &amp;#39;heading text&amp;#39;&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;home_facts&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; 
&lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;environment&amp;#39;&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Env&amp;#39;&lt;/span&gt;
&lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;zone&amp;#39;&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Zone&amp;#39;&lt;/span&gt;
&lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;catalog_config_version&amp;#39;&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Cfg&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;Ver&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If I feel really adventurous, I&amp;#8217;d like to implement my other big wish,
some sort of pop-up list of links, based on arbitrary facts (mainly
hostname and fqdn) for each node - something where I can mouse over the
node name/table cell, and see links (static URLs with node
name/fqdn/other facts plugged in) to things like Nagios/Icinga, our
backup system,&amp;nbsp;etc.&lt;/p&gt;</summary><category term="dashboard"></category><category term="facts"></category><category term="puppet"></category><category term="ruby"></category><category term="sysadmin"></category></entry><entry><title>Workflow for contributing to GitHub projects</title><link href="http://blog.jasonantman.com/2012/08/workflow-for-contributing-to-github-projects/" rel="alternate"></link><updated>2012-08-11T09:35:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-11:2012/08/workflow-for-contributing-to-github-projects/</id><summary type="html">&lt;p&gt;Lately I&amp;#8217;ve been contributing to some open source projects hosted on
&lt;a href="http://github.com"&gt;github&lt;/a&gt;. I&amp;#8217;m pretty new to git, and the process is a
bit confusing for beginners. So, here&amp;#8217;s a sample workflow, based on the
&lt;a href="http://theforeman.org"&gt;The Foreman&lt;/a&gt;&amp;#8216;s &lt;a href="https://github.com/theforeman/foreman"&gt;foreman github
repository&lt;/a&gt;. Note that I&amp;#8217;m
developing against the &amp;#8220;develop&amp;#8221; branch of that repository, not the
master, so that throws in a little difference that isn&amp;#8217;t documented in
most introductions. To throw in another wrench, I maintan a branch with
the code that I&amp;#8217;m currently actually using (i.e. the application code
that I have checked out on the production server), called &amp;#8220;jantman&amp;#8221;.
This is more or less composed of the upstream &amp;#8220;develop&amp;#8221; branch, with all
of my finished (but not yet merged in the upstream) topic branches. I&amp;#8217;m
pretty sure all this is correct, but honestly, I&amp;#8217;m still new enough at
git that I can&amp;#8217;t make any promises. Unfortunatelty, I haven&amp;#8217;t had the
time to &lt;em&gt;really&lt;/em&gt; learn git, and I also can&amp;#8217;t find a simple enough
tutorial that covers all&amp;nbsp;this&amp;#8230;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fork the original repository through the GitHub&amp;nbsp;interface.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On your machine, clone your&amp;nbsp;fork:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git clone git@github.com:username/reponame.git &amp;amp;&amp;amp; cd reponame
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure you&amp;#8217;ve&amp;nbsp;setup&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git config --global branch.autosetupmerge true
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add your upstream&amp;nbsp;repo:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add upstream git://github.com/upstream_user/upstream_repo.git
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fetch it and initialize any&amp;nbsp;submodules:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git fetch upstream &amp;amp;&amp;amp; git submodule update --init
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the current branch (&lt;code&gt;git branch&lt;/code&gt;, let&amp;#8217;s assume it&amp;#8217;s called
    &amp;#8220;develop&amp;#8221;) and rebase to its&amp;nbsp;upstream:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase upstream/develop develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create my &amp;#8220;jantman&amp;#8221; branch, which will be the upstream &amp;#8220;develop&amp;#8221;,
    plus my finished work merged into&amp;nbsp;it:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -b jantman origin/develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a topic branch to do some&amp;nbsp;work:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -b NewBranchName jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Periodically, push the topic branch to&amp;nbsp;github:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin NewBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you commit to this branch from another computer (or someone else
    commits to it), periodically update your local tracking&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git pull origin NewBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Periodically, you want to pull in the upstream&amp;nbsp;changes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;switch to the develop&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;grab the latest version of the upstream git&amp;nbsp;repo:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git fetch upstream
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;rebase develop to mirror the upstream develop&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase upstream/develop develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;switch to our personal&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;rebase our personal branch onto develop (pull all the new
    commits from develop into our personal&amp;nbsp;branch):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase develop jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we want those new upstream changes to continue down to our
    topic&amp;nbsp;branches:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase develop topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When we&amp;#8217;re done with a topic branch, we want to merge it into our
    &amp;#8220;personal&amp;#8221;&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    git checkout jantman; git merge --squash node-table-facts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and then&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    git commit
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;--squash&lt;/code&gt; will squash all the history of that branch down to
one commit. This is generally easier for integration into upstream,
and assuming the topic branch was created for a single feature or
bug, should be&amp;nbsp;logical.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we&amp;#8217;re sure we don&amp;#8217;t need it anymore, delete the topic branch from
    our local&amp;nbsp;machine:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git branch -d topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and from&amp;nbsp;github:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin --delete topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, make sure we push our &amp;#8220;personal&amp;#8221; branch back to&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assuming all went well, you&amp;#8217;ll see the new commit on github, and
    have a nice pull request&amp;nbsp;button.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;References:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.doctrine-project.org/contribute.html"&gt;Contribute -&amp;nbsp;Doctrine-Project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://qsapp.com/wiki/Github"&gt;Github - Quicksilver&amp;nbsp;Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/carmaa/inception/wiki/Contributor-Workflow-with-Github"&gt;Contributor Workflow with Github · carmaa/inception&amp;nbsp;Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://help.github.com/fork-a-repo/"&gt;Help.GitHub - Fork A&amp;nbsp;Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</summary><category term="foreman"></category><category term="git"></category><category term="github"></category><category term="workflow"></category></entry><entry><title>Easily comparing a bunch of files in one directory</title><link href="http://blog.jasonantman.com/2012/08/easily-comparing-a-bunch-of-files-in-one-directory/" rel="alternate"></link><updated>2012-08-10T09:50:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-10:2012/08/easily-comparing-a-bunch-of-files-in-one-directory/</id><summary type="html">&lt;p&gt;So I pulled a specific configuration file (rsyslog.conf) off of a &lt;span class="caps"&gt;LOT&lt;/span&gt; of
hosts. I&amp;#8217;m going to be managing it with &lt;a href=""&gt;Puppet&lt;/a&gt;, but before I do, I
need to know what&amp;#8217;s out there already lest it get overwritten. I used
&lt;a href="http://code.google.com/p/parallel-ssh/"&gt;pssh&lt;/a&gt; with &lt;code&gt;cat&lt;/code&gt; and an output
directory to grab the file from all 30 servers in question. Now, I&amp;#8217;ve
got a directory with 30 files in it, and I need to figure out how many
different files (by contents) there are, and which ones&amp;nbsp;differ.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;find . -type f -exec md5sum &lt;span class="s1"&gt;&amp;#39;{}&amp;#39;&lt;/span&gt; &lt;span class="se"&gt;\;&lt;/span&gt; | sort | uniq -d -w 36
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will check the contents of each file by &lt;span class="caps"&gt;MD5&lt;/span&gt; checksum, and print out
the (lexographically) first file in each group, along with its &lt;span class="caps"&gt;MD5&lt;/span&gt; sum.
You can also strip off the uniq command, and see the list sorted by&amp;nbsp;md5.&lt;/p&gt;
&lt;p&gt;A &lt;span class="caps"&gt;GUI&lt;/span&gt; alternative would be to use
&lt;a href="http://www.pixelbeat.org/fslint/"&gt;fslint&lt;/a&gt;, which is a graphical tool
that can (among other things) display a list of the duplicate files
within a path or set of&amp;nbsp;paths.&lt;/p&gt;</summary><category term="compare"></category><category term="diff"></category></entry><entry><title>Dear Mom and Dad - or, a book about what I actually do</title><link href="http://blog.jasonantman.com/2012/08/dear-mom-and-dad-or-a-book-about-what-i-actually-do/" rel="alternate"></link><updated>2012-08-05T08:52:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-05:2012/08/dear-mom-and-dad-or-a-book-about-what-i-actually-do/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve followed &lt;a href="http://everythingsysadmin.com/"&gt;Tom Limoncelli&amp;#8217;s blog&lt;/a&gt;
for quite a while; his books &lt;a href="http://everythingsysadmin.com/aboutbook.html"&gt;The Practice of System and Network
Administration&lt;/a&gt; and &lt;a href="http://www.tomontime.com/"&gt;Time
Management for System Administrators&lt;/a&gt; were
infinitely helpful in the early days of my professional life, and are
among the few (literally, 4 or 5) books that live on my desk. His
insight and information into the soft skills of &lt;span class="caps"&gt;SA&lt;/span&gt; work - time
management, hiring, working in teams, etc. - is not only excellent, but
also all too rare in a largely technical&amp;nbsp;field.&lt;/p&gt;
&lt;p&gt;Anyway, Tom posted the below article to his blog about a book that
recently came out, &lt;a href="http://www.amazon.com/dp/0195374126/tomontime-20"&gt;&amp;#8220;Taming Information Technology: Lessons from Studies
of System Administrators&amp;#8221; by Eser Kandogan, Paul Maglio, Eben Haber and
John Bailey&lt;/a&gt;. I
haven&amp;#8217;t read the book yet, and at $56, it&amp;#8217;s going to be a while before
my book budget recovers enough to justify it. But going on what I&amp;#8217;ve
read from Tom and others, I want it. Not only do I want to read it, but
I want to pass it around to my parents and in-laws and everyone else who
has asked what I do for a living, and I found myself at a loss for a
less-than-6-hour-long explanation. So, here&amp;#8217;s what Tom wrote on&amp;nbsp;it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Dear Mom And&amp;nbsp;Dad,&lt;/p&gt;
&lt;p&gt;Many times I&amp;#8217;ve tried to explain to you what I do for a living.
&amp;#8220;Computer system administrator&amp;#8221; or &amp;#8220;sysadmin&amp;#8221; is a career that is
difficult to explain and I&amp;#8217;m sure my attempts have left you even more
confused. I have good news. Oxford University Press has just published
a book by 4 scientists who video taped sysadmins doing their job,
analysed what they do, and explains it to the non-computer person.
They do it by telling compelling stories of sysadmins at work plus
they give interesting analysis with great&amp;nbsp;insight.&lt;/p&gt;
&lt;p&gt;Why did they do this? Because businesses depend on technology more and
more and that means they depend on sysadmins more and more. Yet most
CEOs don&amp;#8217;t understand what we do. The scientists made some interesting
discoveries: that our jobs are high-stress, high-risk, and highly
collaborative. We invent our own tools, often on the spot, to solve
complex problems. We are men and women of every age group. It is a
career unlike any other. These are things that most people don&amp;#8217;t know
about our profession. The book is very engaging: Some of the chapters
read like the opening scene of &amp;#8220;Indiana Jones&amp;#8221;; others like &amp;#8220;Gorillas
in the Mist.&amp;#8221; Kandogan, Maglio, Haber and Bailey have put together a
very serious, scientific book with care and&amp;nbsp;compassion.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m not one of the sysadmins they studied but every story they tell
reminds me of real experiences I have&amp;nbsp;had.&lt;/p&gt;
&lt;p&gt;I hope you enjoy reading this book. I know I&amp;nbsp;did.&lt;/p&gt;
&lt;p&gt;Pre-order it here:
&lt;a href="http://www.amazon.com/dp/0195374126/tomontime-20"&gt;http://www.amazon.com/dp/0195374126/tomontime-20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sincerely your son,&lt;br /&gt;&amp;nbsp;Tom&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;P.S.&lt;/span&gt; In all seriousness, I read a preview copy of this book and highly
recommend it to others. You may have seen the authors speak at Usenix
&lt;span class="caps"&gt;LISA&lt;/span&gt; or &lt;span class="caps"&gt;LOPSA&lt;/span&gt; &lt;span class="caps"&gt;PICC&lt;/span&gt; conferences where they showed clips of the video
tapes they made. The book conveys the same stories, plus many more,
with interesting analysis. If you think that the profession of system
administration would benefit from non-sysadmins better understanding
what we do, I highly recommend you pre-order this book and share it.
You can pre-order it here: &lt;a href="http://www.amazon.com/dp/0195374126/tomontime-20"&gt;&amp;#8220;Taming Information Technology: Lessons
from Studies of System Administrators&amp;#8221; by Eser Kandogan, Paul Maglio,
Eben Haber and John&amp;nbsp;Bailey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More about the book here:
&lt;a href="http://everythingsysadmin.com/2012/07/kandogan.html"&gt;http://everythingsysadmin.com/2012/07/kandogan.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you have any interest, I encourage you to go out and buy the book. If
you know someone who&amp;#8217;s an &lt;span class="caps"&gt;SA&lt;/span&gt;, you should buy them the book. If you can
justify any sort of book budget at work, you should buy the book. And
while you&amp;#8217;re at it, if you haven&amp;#8217;t read Tom&amp;#8217;s other books, you should
buy those too. You might be in the unfortunate position - like I am - of
probably never being able to implement most of his suggestions at work,
but at least you&amp;#8217;ll be aware of&amp;nbsp;them&amp;#8230;&lt;/p&gt;</summary><category term="books"></category><category term="limoncelli"></category><category term="sysadmin"></category></entry><entry><title>Logging OpenSSH SFTP Transactions</title><link href="http://blog.jasonantman.com/2012/07/logging-openssh-sftp-transactions/" rel="alternate"></link><updated>2012-07-16T08:47:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-07-16:2012/07/logging-openssh-sftp-transactions/</id><summary type="html">&lt;p&gt;I just came across a really handy post on &lt;a href="https://plus.google.com/117561367404774597588/posts"&gt;David
Busby&lt;/a&gt;&amp;#8216;s blog:
&lt;a href="http://blog.oneiroi.co.uk/linux/enable-logging-in-the-sftp-subsystem/"&gt;Enable logging in the &lt;span class="caps"&gt;SFTP&lt;/span&gt; subsystem -
Oneiroi&lt;/a&gt;.
From OpenSSH 4.4 on, you can pass arguments to Subsystem calls, and the
sftp subsystem supports logging to an aribtrary syslog facility and
priority. Simply adding a line&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Subsystem       sftp    /usr/libexec/openssh/sftp-server -f LOCAL5 -l INFO
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and the appropriate lines to your syslog config will give you a handy
transfer log&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Jul 16 09:22:25 hostname sftp-server[2058]: session opened for local user jantman from [A.B.C.D]
Jul 16 09:22:26 hostname sftp-server[2058]: open &amp;quot;/home/jantman/temp/sftp_test&amp;quot; flags WRITE,CREATE,TRUNCATE mode 0666
Jul 16 09:22:45 hostname sftp-server[2058]: close &amp;quot;/home/jantman/temp/sftp_test&amp;quot; bytes read 0 written 1464813
Jul 16 09:23:08 hostname sftp-server[2058]: session closed for local user jantman from [A.B.C.D]
Jul 16 09:27:50 hostname sftp-server[2309]: session opened for local user jantman from [A.B.C.D]
Jul 16 09:27:50 hostname sftp-server[2309]: open &amp;quot;/home/jantman/temp/sftp_test&amp;quot; flags READ mode 0666
Jul 16 09:27:54 hostname sftp-server[2309]: close &amp;quot;/home/jantman/temp/sftp_test&amp;quot; bytes read 1464813 written 0
Jul 16 09:27:54 hostname sftp-server[2309]: session closed for local user jantman from [A.B.C.D]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you have syslog write these logs to their own file, remember to setup
log rotation for&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;Unfortunately, I&amp;#8217;m not aware of any way to log &lt;span class="caps"&gt;SCP&lt;/span&gt; file&amp;nbsp;transfers.&lt;/p&gt;</summary><category term="logging"></category><category term="openssh"></category><category term="sftp"></category><category term="ssh"></category></entry><entry><title>Nagios Check Plugin for Rsnapshot Backups</title><link href="http://blog.jasonantman.com/2012/07/nagios-check-plugin-for-rsnapshot-backups/" rel="alternate"></link><updated>2012-07-07T06:34:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-07-07:2012/07/nagios-check-plugin-for-rsnapshot-backups/</id><summary type="html">&lt;p&gt;In a previous post, I described how I do &lt;a href="/2012/01/secure-rsnapshot-backups-over-the-wan-via-ssh/"&gt;Secure rsnapshot backups over
the &lt;span class="caps"&gt;WAN&lt;/span&gt; via
&lt;span class="caps"&gt;SSH&lt;/span&gt;&lt;/a&gt;. While my
layout of rsnapshot configuration files, data, and log files is a bit
esoteric, I monitor all this with a Nagios check plugin that runs on my
backup host. It Assumes that the output of
&lt;a href="http://rsnapshot.org/"&gt;rsnapshot&lt;/a&gt; is written to a text log file, one
file per host, at a path that matches
&lt;code&gt;/path_to_log_directory/log_HOSTNAME_YYYYMMDD-HHMMSS.log&lt;/code&gt; where
&lt;code&gt;HOSTNAME&lt;/code&gt; is the name of the host, and &lt;code&gt;YYYYMMDD-HHMMSS&lt;/code&gt; is a datestamp
(actually, the script just finds the newest file matching
&lt;code&gt;log_HOSTNAME_*.log&lt;/code&gt; in that directory). In order to obtain correct
timing of the runs, which rsnapshot doesn&amp;#8217;t offer, it assumes that you
trigger rsnapshot through a wrapper script, which runs it once per host
(inside a loop?) with per-host log files and some logging information
added,&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;for &lt;/span&gt;h in 
&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/mnt/backup/rsnapshot/logs/log_${h}_`date +%Y%m%d-%H%M%S`.txt&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;# Starting backup at `date` (`date +%s`)&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&amp;quot;&lt;/span&gt;
    /usr/bin/rsnapshot -c /etc/rsnapshot-&lt;span class="nv"&gt;$h&lt;/span&gt;.conf daily &amp;amp;&amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;# Finished backup at `date` (`date +%s`)&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;check_rsnapshot.pl&lt;/code&gt; plugin uses &lt;code&gt;utils.pm&lt;/code&gt; from Nagios, as well as
&lt;a href="http://search.cpan.org/~jv/Getopt-Long-2.38/lib/Getopt/Long.pm"&gt;Getopt::Long&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~makoto/File-Stat-0.01/Stat.pm"&gt;File::stat&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~flora/perl-5.14.2/lib/File/Basename.pm"&gt;File::Basename&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~smueller/PathTools-3.33/lib/File/Spec.pm"&gt;File::Spec&lt;/a&gt;
and
&lt;a href="http://search.cpan.org/~ferreira/Number-Bytes-Human-0.07/Human.pm"&gt;Number::Bytes::Human&lt;/a&gt;.
This was one of my first Perl plugins, but seems to be rather
acceptable. It makes the following checks based on the rsnapshot&amp;nbsp;log:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Backup run in the last X seconds (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Maximum time from start to finish (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Minimum size of backup (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Minimum number of files in backup (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In addition to &lt;code&gt;check_file_age&lt;/code&gt; checks on a number of files that are
included in backups and I know are modified before each backup run, this
seems to handle monitoring quite well for me. I certainly preferred
running &lt;a href="http://www.bacula.org/"&gt;Bacula&lt;/a&gt; and using my MySQL-based
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_bacula_job.php"&gt;check_bacula_job.php&lt;/a&gt;,
but as I&amp;#8217;m now backing up 4 machines to my desktop, I no longer have a
need for Bacula (or&amp;nbsp;tapes).&lt;/p&gt;
&lt;p&gt;The script itself can be found at
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_rsnapshot.pl"&gt;github&lt;/a&gt;.&lt;/p&gt;</summary><category term="backups"></category><category term="monitoring"></category><category term="Nagios"></category><category term="rsnapshot"></category><category term="rsync"></category></entry><entry><title>What I Look For When Interviwing SysAdmin Candidates</title><link href="http://blog.jasonantman.com/2012/07/what-i-look-for-when-interviwing-sysadmin-candidates/" rel="alternate"></link><updated>2012-07-05T11:07:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-07-05:2012/07/what-i-look-for-when-interviwing-sysadmin-candidates/</id><summary type="html">&lt;p&gt;I recently came by a question on ServerFault, &lt;a href="http://serverfault.com/questions/210218/listing-side-projects-in-a-jr-sysadmin-resume/405054#405054"&gt;Listing side projects in
a jr. sysadmin
resume&lt;/a&gt;
asking whether people (hiring managers) think it&amp;#8217;s appropriate to put
&amp;#8220;side projects&amp;#8221; (running your own web and mail servers, freelance web
work, etc.) on your resume. Since I&amp;#8217;ve been interviewing candidates for
a few SysAdmin positions lately, I thought I&amp;#8217;d take the time to write
down a few of my ideas on this. Two disclaimers first, though. (1) I tend
to be pretty geeky, progressive, and very open source/DevOps focused at
heart. Not everyone I work with will agree with what I say here. As a
candidate, remember that you&amp;#8217;ll probably interview with all types, and
what I say here won&amp;#8217;t be the best advice with Enterprise types. I&amp;#8217;m very
open source centric, and have always held &lt;span class="caps"&gt;SA&lt;/span&gt; jobs where the majority of
the software I run is open source and not vendor supported. (2) If you
happen to actually interview with me, don&amp;#8217;t make the mistake of reading
this and tailoring your resume/responses to fit if that&amp;#8217;s not accurate.
I&amp;#8217;m not a manager, I&amp;#8217;m a line&amp;nbsp;&lt;span class="caps"&gt;SA&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;First, my response to the ServerFault&amp;nbsp;question:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Not a hiring manager, but an &lt;span class="caps"&gt;SA&lt;/span&gt; doing technical interviews and hiring
recommendations, and also have only been with my current employer for
7 months (so I&amp;#8217;ve been on both sides of the table recently). My
current employer is a pretty big company and pays well, so we&amp;#8217;re quite&amp;nbsp;selective.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;SA&lt;/span&gt; candidates with 5-10 years experience and a laundry list of
certifications, software and hardware names, protocols, etc. are a
dime a dozen. I&amp;#8217;m looking for people who really love what they do. I
have an instant bias against resumes that don&amp;#8217;t have either a personal
website/&lt;span class="caps"&gt;URL&lt;/span&gt;, or some personal projects/experience other than 9-5 job
on them. There are lots of people who meet the technical
qualifications. I want someone truly passionate, and that means
learning and experimenting outside of&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;Personally, on my resume, I have a few personal projects listed
(mainly programming projects and volunteer &lt;span class="caps"&gt;IT&lt;/span&gt; work I did for
non-profits), and I also have a link to my personal resume site that
has links to my &lt;span class="caps"&gt;SVN&lt;/span&gt; repo, and a bunch of other&amp;nbsp;projects.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Some things I look&amp;nbsp;for:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not in all cases, but I like to see a website or blog listed on a
    resume. It&amp;#8217;s a big plus. I have
    &lt;a href="http://resume.jasonantman.com"&gt;resume.jasonantman.com&lt;/a&gt; with copies
    of my resume in various formats, as well as a bunch of links I&amp;#8217;d
    like employers to&amp;nbsp;see.&lt;/li&gt;
&lt;li&gt;If you&amp;#8217;re a working &lt;span class="caps"&gt;SA&lt;/span&gt;, I should be able to find you on Google.
    Either by name or email address, I expect to google the contact
    information I find on your resume and find at least some mailing
    list/forum posts, bug reports, or software&amp;nbsp;projects.&lt;/li&gt;
&lt;li&gt;I can&amp;#8217;t stress this enough, &lt;strong&gt;do not overstate your experience&lt;/strong&gt;.
    I&amp;#8217;ve been an &lt;span class="caps"&gt;SA&lt;/span&gt; for 5 years, a hobbyist for much longer, and I&amp;#8217;ve
    never used the word &amp;#8220;expert&amp;#8221;. I list software, protocols, languages
    on my resume as beginner/basic, intermediate, and &amp;#8220;strongest&amp;#8221;. If
    you list something as &amp;#8220;advanced&amp;#8221; or &amp;#8220;expert&amp;#8221;, be prepared to answer
    expert-level questions. If you can&amp;#8217;t explain a 3-way handshake,
    don&amp;#8217;t list &lt;span class="caps"&gt;TCP&lt;/span&gt;/&lt;span class="caps"&gt;IP&lt;/span&gt; on your resume. If you list &amp;#8220;strong knowledge of
    Linux internals&amp;#8221;, you should be able to at least explain &lt;code&gt;open()&lt;/code&gt;
    and &lt;code&gt;close()&lt;/code&gt;. If you list advanced &lt;span class="caps"&gt;RADIUS&lt;/span&gt; experience, I &lt;em&gt;will&lt;/em&gt; ask
    you to explain &lt;span class="caps"&gt;CSID&lt;/span&gt;, &lt;span class="caps"&gt;WPA&lt;/span&gt; key exchange, and what attributes are valid
    in an Access-Reject. In short, don&amp;#8217;t say you&amp;#8217;re a genius in
    something unless you are; you never know when your interviewer may
    have spent the last 6 months immersed in&amp;nbsp;it.&lt;/li&gt;
&lt;li&gt;All SAs should have some programming skills. If you&amp;#8217;re a recent
    graduate (let&amp;#8217;s say any time in the last 5-8 years) I&amp;#8217;d expect at
    the very least a vague memory of C++, &lt;span class="caps"&gt;VB&lt;/span&gt; or Java. If you&amp;#8217;re a
    working &lt;span class="caps"&gt;SA&lt;/span&gt;, I expect to see either strong Bash skills, or at least a
    functional knowledge of Perl. Python, &lt;span class="caps"&gt;PHP&lt;/span&gt; or Ruby; preferably both.
    If you&amp;#8217;re a &amp;#8220;senior&amp;#8221; Linux &lt;span class="caps"&gt;SA&lt;/span&gt;, you should know enough C to be able
    to make sense of &lt;code&gt;strace&lt;/code&gt; output.&lt;/li&gt;
&lt;li&gt;As stated above, non-full-time-job projects are a big plus. When I
    took my first &lt;span class="caps"&gt;SA&lt;/span&gt; job, the majority of my experience had been doing
    volunteer work for a non-profit ambulance corps (which I was also a
    volunteer &lt;span class="caps"&gt;EMT&lt;/span&gt; on). If I said that I did 40 hours a week for them, it
    would be an understatement. I wrote a few 10,000+ line &lt;span class="caps"&gt;PHP&lt;/span&gt;
    applications for them, and designed the infrastructure to run them
    24x7x365. Small shop? Sure. But I learned a &lt;span class="caps"&gt;LOT&lt;/span&gt;, especially about
    how to make things resilient enough that I didn&amp;#8217;t get paged&amp;nbsp;often.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;#8217;m sure I&amp;#8217;ll update this over time as I distill more of my&amp;nbsp;ideas.&lt;/p&gt;</summary></entry><entry><title>Tools for watching apache httpd and memcached</title><link href="http://blog.jasonantman.com/2012/06/tools-for-watching-apache-httpd-and-memcached/" rel="alternate"></link><updated>2012-06-26T13:46:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-06-26:2012/06/tools-for-watching-apache-httpd-and-memcached/</id><summary type="html">&lt;p&gt;Recently I was working on a code release on a site running &lt;span class="caps"&gt;PHP&lt;/span&gt; on
&lt;a href="http://httpd.apache.org/"&gt;Apache httpd&lt;/a&gt;, and using
&lt;a href="http://memcached.org/"&gt;memcached&lt;/a&gt;. Without getting into specifics, we
had a number of issues that were both Apache and memcached problems, and
little visibility into them as it was running on an older server without
much monitoring in place. I started looking around for simple tools that
could provide a bit more insight, without many dependencies (as the
machine is a relatively minimalist install). Here are some of the
options I&amp;nbsp;found:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://code.google.com/p/memcache-top/"&gt;memcache-top&lt;/a&gt; - A top-like
    script that pulls stats from memcached instances and can show both
    per-instance, total and average usage %, hit rate, number of
    connections, time to run the stats query, evictions, gets, sets, and
    read and write amounts. Best of all, it&amp;#8217;s a very small perl script
    that requires only &lt;span class="caps"&gt;IO&lt;/span&gt;::Socket and Time::HiRes. Here&amp;#8217;s a small
    example of the&amp;nbsp;output:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;memcache-top v0.6       (default port: 11211, color: on, refresh: 3 seconds)

INSTANCE                USAGE   HIT %   CONN    TIME    EVICT   GETS    SETS    READ    WRITE
127.0.0.1:11211         86.6%   99.4%   115     0.6ms   0.0     4114    1669    1.3M    24.2M
127.0.0.1:11212         85.5%   59.9%   2       0.4ms   0.0     0       0       90      8055

AVERAGE:                86.0%   79.6%   58      0.5ms   0.0     2057    834     682.4K  12.1M

TOTAL:          0.9GB/  1.0GB           117     1.0ms   0.0     4114    1669    1.3M    24.2M
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/dormando/damemtop"&gt;damemtop&lt;/a&gt; is also a nice
    top-like memcached tool. On the positive side, you can specify any
    column from &amp;#8220;stats&amp;#8221;, &amp;#8220;stats items&amp;#8221; or &amp;#8220;stats slabs&amp;#8221; in the
    configuration file, and can choose between average or one-second
    snapshots for each column. On the down side, it requires the &lt;span class="caps"&gt;YAML&lt;/span&gt;
    and AnyEvent Perl modules, so it has some uncommon&amp;nbsp;dependencies.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;damemtop: Tue Jun 26 14:02:24 2012 [sort: hostname asc] [delay: 3s]
hostname           all_version  all_fill_rate  hit_rate  evictions  curr_items  curr_connections   cmd_get  cmd_set  bytes_written  bytes_read  get_hits  get_misses  
TOTAL:             
NA                 NA           NA             NA        NA         NA          NA                 87       32       491,735        30,894      86        1           
AVERAGE:           
NA                 NA           86.00%         99.00%    NA         NA          NA                 43       16       122,933        7,723       43        1           
10.200.1.78:11211  1.2.6        86.63%         98.04%    0          0           -1.00204024880524  51       19       386,492        21,613      50        1           
10.200.1.78:11212  1.2.6        85.46%         NA        0          0           0                  0        0        11,373         31          0         0           
10.200.1.79:11211  1.2.6        87.31%         100.00%   0          0           -1.00204024880524  36       13       82,479         9,219       36        0           
10.200.1.79:11212  1.2.6        85.08%         NA        0          0           0                  0        0        11,389         31          0         0           
loop took: 0.305617094039917
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;#8217;m still looking around for something for apache that uses mod_status
and isn&amp;#8217;t too verbose; ideally I&amp;#8217;d like to be able to watch memcached,
apache response codes/times, and apache mod_status all in the same
terminal&amp;nbsp;window.&lt;/p&gt;</summary><category term="apache"></category><category term="memcached"></category><category term="perl"></category><category term="top"></category><category term="troubleshooting"></category></entry><entry><title>Emacs Mode Variable for HTML</title><link href="http://blog.jasonantman.com/2012/06/emacs-mode-variable-for-html/" rel="alternate"></link><updated>2012-06-26T08:43:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-06-26:2012/06/emacs-mode-variable-for-html/</id><summary type="html">&lt;p&gt;Unfortunately, I often find myself editing files that are mixed &lt;span class="caps"&gt;PHP&lt;/span&gt; and
&lt;span class="caps"&gt;HTML&lt;/span&gt;, and ending with a &amp;#8220;.php&amp;#8221; extension. For most smaller
projects/tasks, I use &lt;a href="http://www.gnu.org/software/emacs/"&gt;emacs&lt;/a&gt; at the
command line (nox) and my .emacs settings for
&lt;a href="http://php-mode.sourceforge.net/"&gt;php-mode&lt;/a&gt; will latch onto the &amp;#8220;.php&amp;#8221;
extension and open it with &lt;span class="caps"&gt;PHP&lt;/span&gt; mode. Unfortunately, &lt;span class="caps"&gt;PHP&lt;/span&gt; mode really
doesn&amp;#8217;t like embedded &lt;span class="caps"&gt;HTML&lt;/span&gt; (let alone mostly &lt;span class="caps"&gt;HTML&lt;/span&gt; with some inline &lt;span class="caps"&gt;PHP&lt;/span&gt;),
and the indentation gets very messy, among other&amp;nbsp;problems.&lt;/p&gt;
&lt;p&gt;The simple solution is to add the following (&lt;span class="caps"&gt;XHTML&lt;/span&gt; 1.0
Transitional-compliant) comment to the first line of the file, which
tells emacs to load&amp;nbsp;html-mode:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;&amp;lt;!-- -*- mode: html; -*- --&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can also get emacs to do this for you, as per the &lt;a href="http://www.gnu.org/software/emacs/manual/html_node/emacs/Specifying-File-Variables.html"&gt;Specifying File
Variables&lt;/a&gt;
documentation page. Once in html-mode, simply &lt;code&gt;M-x
add-file-local-variable-prop-line&lt;/code&gt;, enter &amp;#8220;mode&amp;#8221; for the variable
name and use the default of the current&amp;nbsp;mode.&lt;/p&gt;</summary><category term="emacs"></category><category term="html. php"></category></entry><entry><title>Script to Chart Intervals Between Problem and Recovery from Nagios/Icinga Log Files</title><link href="http://blog.jasonantman.com/2012/05/script-to-chart-intervals-between-problem-and-recovery-from-nagiosicinga-log-files/" rel="alternate"></link><updated>2012-05-31T13:54:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-05-31:2012/05/script-to-chart-intervals-between-problem-and-recovery-from-nagiosicinga-log-files/</id><summary type="html">&lt;p&gt;At work, we use &lt;a href="http://www.icinga.org"&gt;Icinga&lt;/a&gt; (a fork of
&lt;a href="http://nagios.org/"&gt;Nagios&lt;/a&gt;) for monitoring. We have a few services
which are restarted or otherwise poked by event handlers, but the
recovery takes a while - so we often get paged for problems which
recover in a few minutes. I wrote a small perl script that greps through
the archived log files for a given regex (service and/or host name) and
then calculates the time from problem to recovery and graphs those&amp;nbsp;times.&lt;/p&gt;
&lt;p&gt;The script is called &lt;code&gt;nagios_log_problem_interval.pl&lt;/code&gt; and can be
downloaded from &lt;a href="https://github.com/jantman/nagios-scripts/blob/master/nagios_log_problem_interval.pl"&gt;my
github&lt;/a&gt;.
Below is some sample output, the number of minutes from problem to
recovery are along the Y axis and the count is along the X&amp;nbsp;axis:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt; nagios_log_problem_interval.pl --archivedir&lt;span class="o"&gt;=&lt;/span&gt;/var/icinga/archive --match&lt;span class="o"&gt;=&lt;/span&gt;myhost --backtrack&lt;span class="o"&gt;=&lt;/span&gt;10 myhost;&lt;span class="caps"&gt;HTTP&lt;/span&gt;
&lt;span class="go"&gt;Count&lt;/span&gt;
&lt;span class="go"&gt;1:########(8)&lt;/span&gt;
&lt;span class="go"&gt;2:##(2)&lt;/span&gt;
&lt;span class="go"&gt;3:#(1)&lt;/span&gt;
&lt;span class="go"&gt;4:##(2)&lt;/span&gt;
&lt;span class="go"&gt;5:#######(7)&lt;/span&gt;
&lt;span class="go"&gt;6:(0)&lt;/span&gt;
&lt;span class="go"&gt;7:(0)&lt;/span&gt;
&lt;span class="go"&gt;8:#(1)&lt;/span&gt;
&lt;span class="go"&gt;9:(0)&lt;/span&gt;
&lt;span class="go"&gt;10:(0)&lt;/span&gt;
&lt;span class="go"&gt;11:#(1)&lt;/span&gt;
&lt;span class="go"&gt;12:(0)&lt;/span&gt;
&lt;span class="go"&gt;13:#(1)&lt;/span&gt;
&lt;span class="go"&gt;14:(0)&lt;/span&gt;
&lt;span class="go"&gt;15:(0)&lt;/span&gt;
&lt;span class="go"&gt;16-29:(0)&lt;/span&gt;
&lt;span class="go"&gt;30-59:(0)&lt;/span&gt;
&lt;span class="go"&gt;60+:(0)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="chart"></category><category term="icinga"></category><category term="monitoring"></category><category term="Nagios"></category><category term="perl"></category></entry><entry><title>Apache httpd - logging for sites with and without load balancing</title><link href="http://blog.jasonantman.com/2012/05/apache-httpd-logging-for-sites-with-and-without-load-balancing/" rel="alternate"></link><updated>2012-05-30T09:46:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-05-30:2012/05/apache-httpd-logging-for-sites-with-and-without-load-balancing/</id><summary type="html">&lt;p&gt;There are a few unfortunate places where I have an Apache httpd server
serving multiple vhosts, some behind a F5 BigIp load balancer and some
with direct traffic. For sites behind the &lt;span class="caps"&gt;LB&lt;/span&gt;, the remote &lt;span class="caps"&gt;IP&lt;/span&gt;/host will
always show up as the &lt;span class="caps"&gt;LB&lt;/span&gt;&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;/host, not that of the actual client. Using
the default configuration with LogFormat directives in &lt;code&gt;httpd.conf&lt;/code&gt;,
this means that either we need to define log formats per-vhost or lose
the client &lt;span class="caps"&gt;IP&lt;/span&gt; in one of our scenarios (&lt;span class="caps"&gt;LB&lt;/span&gt; or no&amp;nbsp;&lt;span class="caps"&gt;LB&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;I came by a simple solution to this on &lt;a href="http://www.maretmanu.org/homepage/inform/apache-forwarded.php"&gt;Emmanuel
Chantréau&lt;/a&gt;&amp;#8216;s
blog, and here is my condensed version of it. It sets an environment
variable (&amp;#8220;bigip-request&amp;#8221;) if the BIOrigClientAddr request header is set
(this header holds the client&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;; it&amp;#8217;s the BigIp proprietary version
of the X-Forwarded-For header. You could easily substitute that more
standard header in the following snippet) and then sets the &amp;#8220;combined&amp;#8221;
LogFormat based on that variable - a version using BIOrigClientAddr if
it is set, and a version using the normal &amp;#8220;%h&amp;#8221; remote host&amp;nbsp;otherwise.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;httpd.conf:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# set the &amp;quot;bigip-request&amp;quot; env variable to &amp;quot;1&amp;quot; if there is a BIOrigClientAddr header in the request                                                                                                   &lt;/span&gt;
&lt;span class="nb"&gt;SetEnvIf&lt;/span&gt; BIOrigClientAddr . bigip-request
&lt;span class="c"&gt;# we&amp;#39;ll use this following LogFormat (BIOrigClientAddr in place of remote host) as &amp;quot;combined&amp;quot; &lt;span class="caps"&gt;IF&lt;/span&gt; the bigip-request env variable is set                                                                     &lt;/span&gt;
&lt;span class="nb"&gt;LogFormat&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%{BIOrigClientAddr}i %l %u %t %v \&amp;quot;%r\&amp;quot; %&amp;gt;s %b \&amp;quot;%{Referer}i\&amp;quot; \&amp;quot;%{User-Agent}i\&amp;quot;&amp;quot;&lt;/span&gt; combined_lb
&lt;span class="c"&gt;# else we&amp;#39;ll use this one (remote host &lt;span class="caps"&gt;IP&lt;/span&gt; address) as &amp;quot;combined&amp;quot; &lt;span class="caps"&gt;IF&lt;/span&gt; the bigip-request env variable is &lt;span class="caps"&gt;NOT&lt;/span&gt; set                                                                                   &lt;/span&gt;
&lt;span class="nb"&gt;LogFormat&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%h %l %u %t %v \&amp;quot;%r\&amp;quot; %&amp;gt;s %b \&amp;quot;%{Referer}i\&amp;quot; \&amp;quot;%{User-Agent}i\&amp;quot;&amp;quot;&lt;/span&gt; combined
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then in our vhost&amp;nbsp;configuration:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# use this log format if we&amp;#39;re behind an &lt;span class="caps"&gt;LB&lt;/span&gt;&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; logs/&amp;lt;%= domain %&amp;gt;_access_log combined env=!bigip-request
&lt;span class="c"&gt;# or this format if we&amp;#39;re not&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; logs/&amp;lt;%= domain %&amp;gt;_access_log combined_lb env=bigip-request
&lt;/pre&gt;&lt;/div&gt;</summary><category term="apache"></category><category term="bigip"></category><category term="f5"></category><category term="httpd"></category><category term="load balancer"></category><category term="logging"></category></entry><entry><title>Creating RPMs from Perl CPAN Modules</title><link href="http://blog.jasonantman.com/2012/05/creating-rpms-from-perl-cpan-modules/" rel="alternate"></link><updated>2012-05-15T15:01:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-05-15:2012/05/creating-rpms-from-perl-cpan-modules/</id><summary type="html">&lt;p&gt;I try my absolute best to always install software on my Linux boxes as
&lt;a href="http://en.wikipedia.org/wiki/RPM_Package_Manager"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt;&lt;/a&gt;s, installed
through &lt;a href="http://yum.baseurl.org/"&gt;Yum&lt;/a&gt; (yes, I use
&lt;a href="http://www.centos.org"&gt;CentOS&lt;/a&gt; on servers and
&lt;a href="http://fedoraproject.org/"&gt;Fedora&lt;/a&gt; on my desktops/laptops). Not only is
this more-or-less required to sanely manage configuration through
Puppet, but it also lets me recreate a machine, or install dependencies
for something, in one simple command line. Unfortunately, I run quite a
bit of Perl code, and there are a lot of &lt;a href="http://www.cpan.org/"&gt;&lt;span class="caps"&gt;CPAN&lt;/span&gt;&lt;/a&gt;
Perl modules that aren&amp;#8217;t in any of the usual CentOS/Fedora&amp;nbsp;repositories.&lt;/p&gt;
&lt;p&gt;Enter cpan2rpm: a Perl script that, in its simplest invocation,
downloads a specified &lt;span class="caps"&gt;CPAN&lt;/span&gt; module and automatically builds RPMs and
SRPMs for it. The &lt;a href="http://perl.arix.com/cpan2rpm/"&gt;original version&lt;/a&gt; by
&lt;a href="http://www.arix.com/ec/"&gt;Erick Calder&lt;/a&gt; hasn&amp;#8217;t been touched since 2005,
but there&amp;#8217;s &lt;a href="http://www.mediaburst.co.uk/blog/creating-perl-module-rpms/"&gt;a newer version from
Mediaburst&lt;/a&gt;,
&lt;a href="http://www2.mbstatic.co.uk/wp-content/uploads/2009/09/cpan2rpmmb"&gt;cpan2rpmmb&lt;/a&gt;,
that seems to incorporate some nice improvements and worked quite well
for&amp;nbsp;me.&lt;/p&gt;</summary><category term="cpan"></category><category term="cpan2rpm"></category><category term="perl"></category><category term="rpm"></category><category term="yum"></category></entry><entry><title>Perl script to convert F5 BigIp VIP address to list of internal pool member addresses</title><link href="http://blog.jasonantman.com/2012/04/perl-script-to-convert-f5-bigip-vip-address-to-list-of-internal-pool-member-addresses/" rel="alternate"></link><updated>2012-04-24T22:04:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-24:2012/04/perl-script-to-convert-f5-bigip-vip-address-to-list-of-internal-pool-member-addresses/</id><summary type="html">&lt;p&gt;I often find myself logging in to the web &lt;span class="caps"&gt;UI&lt;/span&gt; of &lt;a href="http://www.f5.com/products/big-ip/"&gt;F5
BigIp&lt;/a&gt; load balancers and tracing
down a &lt;span class="caps"&gt;VIP&lt;/span&gt; address to the servers that actually back it. This is an
arduous, repetitive task of tracing from the &lt;span class="caps"&gt;VIP&lt;/span&gt; list to the &lt;span class="caps"&gt;VIP&lt;/span&gt; details
page to find the default pool, then matching up that in the pool list
and checking the pool members page. Luckily, the F5 boxes have a &lt;a href="https://devcentral.f5.com/"&gt;web
service &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; that can be used for tasks like
this. They have &lt;span class="caps"&gt;GPL&lt;/span&gt; sample code in Perl that uses only
&lt;a href="http://search.cpan.org/~mkutter/SOAP-Lite-0.714/lib/SOAP/Lite.pm"&gt;&lt;span class="caps"&gt;SOAP&lt;/span&gt;::Lite&lt;/a&gt;
(as well as Getopt::Long and Pod::Usage) to interact with an F5 BigIp. I
wrote a simple script to trace a &lt;span class="caps"&gt;VIP&lt;/span&gt; to the appropriate internal pool
member addresses, assuming you have a simple configuration of &lt;span class="caps"&gt;VIP&lt;/span&gt; -&gt;
Single default pool -&amp;gt; pool&amp;nbsp;members.&lt;/p&gt;
&lt;p&gt;Usage is quite&amp;nbsp;simple:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt; ./VipToInternalHosts.pl --host&lt;span class="o"&gt;=&lt;/span&gt;prod-lb1.example.com --user&lt;span class="o"&gt;=&lt;/span&gt;myname --pass&lt;span class="o"&gt;=&lt;/span&gt;mypassword --vip&lt;span class="o"&gt;=&lt;/span&gt;128.6.30.130:80
&lt;span class="go"&gt;&lt;span class="caps"&gt;VIP&lt;/span&gt; 128.6.30.130:80 (f5_vip_name) -&amp;gt; Pool &amp;#39;pool_name&amp;#39;&lt;/span&gt;
&lt;span class="go"&gt;Members of Pool &amp;#39;pool_name&amp;#39;:&lt;/span&gt;
&lt;span class="go"&gt;    10.145.15.10:80&lt;/span&gt;
&lt;span class="go"&gt;    10.145.15.11:80&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code can be found at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/VipToInternalHosts.pl"&gt;https://github.com/jantman/misc-scripts/blob/master/VipToInternalHosts.pl&lt;/a&gt;. I hope it&amp;#8217;s of use to someone else as&amp;nbsp;well.&lt;/p&gt;</summary><category term="bigip"></category><category term="f5"></category><category term="load balancer"></category><category term="perl"></category></entry><entry><title>SysAdmin Links of The Day</title><link href="http://blog.jasonantman.com/2012/04/sysadmin-links-of-the-day/" rel="alternate"></link><updated>2012-04-24T21:18:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-24:2012/04/sysadmin-links-of-the-day/</id><summary type="html">&lt;p&gt;A few links that I&amp;#8217;ve had in my &amp;#8220;mention in a blog post&amp;#8221; category for a&amp;nbsp;while:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blogs.msdn.com/b/windowsazure/archive/2012/03/09/summary-of-windows-azure-service-disruption-on-feb-29th-2012.aspx"&gt;Summary of Windows Azure Service Disruption on Feb 29th, 2012 -
    Windows Azure - Site Home - &lt;span class="caps"&gt;MSDN&lt;/span&gt;
    Blogs&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a &lt;em&gt;very&lt;/em&gt; detailed and interesting post on what caused the Windows
Azure cloud outage on February 29th, 2012. &lt;span class="caps"&gt;IMHO&lt;/span&gt; many of these
failures were predictable, and the bulk of the outage was caused by
a combination of inputs not being checked for validity in code, or
the invalid case not being handled&amp;nbsp;properly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/blog/2012/3/12/google-taming-the-long-latency-tail-when-more-machines-equal.html"&gt;High Scalability - High Scalability - Google: Taming the Long
    Latency Tail - When More Machines Equals Worse&amp;nbsp;Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://everythingsysadmin.com/2012/03/fear-of-rebooting.html"&gt;Everything Sysadmin: Fear of&amp;nbsp;Rebooting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://everythingsysadmin.com/2012/03/using-statements-of-undeniable.html"&gt;Everything Sysadmin: Using statements of &amp;#8220;Undeniable&amp;nbsp;Value&amp;#8221;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="azure"></category><category term="failure"></category><category term="microsoft"></category><category term="sysadmin"></category></entry><entry><title>Instagram - Scaling a Startup</title><link href="http://blog.jasonantman.com/2012/04/instagram-scaling-a-startup/" rel="alternate"></link><updated>2012-04-24T19:31:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-24:2012/04/instagram-scaling-a-startup/</id><summary type="html">&lt;p&gt;If you keep up with news on the &amp;#8216;net, you may have heard about photo
sharing startup &lt;a href="http://instagr.am"&gt;Instagram&lt;/a&gt;, which was &lt;a href="http://finance.fortune.cnn.com/2012/04/09/breaking-facebook-buying-instagram-for-1-billion/?section=magazines_fortune"&gt;purchased by
Facebook for $1
Billion&lt;/a&gt;
just 9 days after they released their Android app. Well, not only are
they based mostly on open source software (well, yeah, pretty much a
given for web startups these days), but they&amp;#8217;ve dealt with scaling
issues like a million new users in 12 hours, and they&amp;#8217;re &lt;a href="http://instagram-engineering.tumblr.com/post/20541814340/keeping-instagram-up-with-over-a-million-new-users-in"&gt;talking about
it&lt;/a&gt;.
There&amp;#8217;s the &lt;a href="http://techcrunch.com/2012/04/12/how-to-scale-a-1-billion-startup-a-guide-from-instagram-co-founder-mike-krieger/"&gt;slide deck to a talk that co-founder Mike Krieger
gave&lt;/a&gt;
on TechCrunch and
&lt;a href="http://www.scribd.com/doc/89025069/Mike-Krieger-Instagram-at-the-Airbnb-tech-talk-on-Scaling-Instagram"&gt;Scribd&lt;/a&gt;,
along with a &lt;a href="http://highscalability.com/blog/2012/4/16/instagram-architecture-update-whats-new-with-instagram.html"&gt;High Scalability article about
it&lt;/a&gt;,
and an &lt;a href="http://highscalability.com/blog/2012/4/9/the-instagram-architecture-facebook-bought-for-a-cool-billio.html"&gt;earlier High Scalability article that gives an overview of the
company and some details of what and how they&amp;#8217;re
running&lt;/a&gt;.
Instagram Engineering also has a
&lt;a href="http://instagram-engineering.tumblr.com/"&gt;tumblr&lt;/a&gt; account, with a bunch
of cool posts like &lt;a href="http://instagram-engineering.tumblr.com/post/20541814340/keeping-instagram-up-with-over-a-million-new-users-in"&gt;Keeping Instagram up with over a million new users
in twelve
hours&lt;/a&gt;
(which specifically mentions &lt;a href="http://github.com/etsy/statsd/"&gt;statsd&lt;/a&gt;,
&lt;a href="http://blog.bitbucket.org/2011/05/17/tracking-slow-requests-with-dogslow/"&gt;dogslow&lt;/a&gt;,
&lt;a href="http://pgfouine.projects.postgresql.org/"&gt;PGFouine&lt;/a&gt;,
&lt;a href="http://github.com/Instagram/node2dm"&gt;node2dm&lt;/a&gt; and some database stuff)
and &lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances-dozens-of"&gt;What Powers Instagram: Hundreds of Instances, Dozens of
Technologies&lt;/a&gt;
which talks about their &lt;span class="caps"&gt;OS&lt;/span&gt; and hosting (Ubuntu 11.04 on &lt;span class="caps"&gt;EC2&lt;/span&gt;), load
balancing (nginx, &lt;span class="caps"&gt;DNS&lt;/span&gt; and Amazon Elastic Load Balancer), Django, Redis,
Solr, Munin,&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;This is a really cool company, doing some &lt;em&gt;really&lt;/em&gt; cool stuff, at a
&lt;em&gt;really&lt;/em&gt; large scale, and growing&amp;nbsp;fast.&lt;/p&gt;
&lt;p&gt;On another note, I&amp;#8217;m continuing my attempt to read all of the excellent
Puppet articles on &lt;a href="http://www.masterzen.fr/blog/archives/"&gt;Brice Figureau&amp;#8217;s (aka masterzen)
blog&lt;/a&gt;. It&amp;#8217;s taking a while, as
it&amp;#8217;s really good, in-depth information that I want to rememeber, but I&amp;#8217;d
highly recommend it for anyone working with&amp;nbsp;Puppet.&lt;/p&gt;</summary><category term="dogslow"></category><category term="facebook"></category><category term="high scalability"></category><category term="instagram"></category><category term="node2dm"></category><category term="pgfouine"></category><category term="puppet"></category><category term="scaling"></category><category term="statsd"></category></entry><entry><title>A Collection of Great Links on Monitoring, SysAdmin, Scaling, etc.</title><link href="http://blog.jasonantman.com/2012/04/a-collection-of-great-links-on-monitoring-sysadmin-scaling-etc/" rel="alternate"></link><updated>2012-04-21T10:24:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-21:2012/04/a-collection-of-great-links-on-monitoring-sysadmin-scaling-etc/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve had a bunch of tabs open in my browser for a while - stuff that I
read, thought was wonderful, and wanted to comment on. At risk of
letting it pile up forever, here&amp;#8217;s a collection of links that I thought
were really interesting or&amp;nbsp;insightful&amp;#8230;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blog.mongodb.org/post/172254834/mongodb-is-fantastic-for-logging"&gt;MongoDB is Fantastic for
    Logging&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;I was looking into some log storage ideas, and came by this post
(on the MongoDB blog) about why Mongo is well-suited to storing&amp;nbsp;logs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.sonian.com/cloud-monitoring-sensu/"&gt;Sensu&lt;/a&gt; - a
    Ruby-based cloud-oriented monitoring system. It uses &lt;span class="caps"&gt;AMQP&lt;/span&gt;/RabbitMQ
    to communicate between the clients and server, which is a really big
    part of what I think monitoring should&amp;nbsp;be.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High Scalability&lt;/a&gt; - this is one of the
    few blogs I follow on a regular basis. Some really wonderful stuff,
    and great food for&amp;nbsp;thought.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://everythingsysadmin.com/2012/03/fear-of-rebooting.html"&gt;Everything Sysadmin: Fear of
    Rebooting&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;A great article on Tom Limoncelli&amp;#8217;s blog about why we fear
rebooting machines and why this is bad - moreover, why we should
reboot&amp;nbsp;often.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://techblog.netflix.com/2012/02/fault-tolerance-in-high-volume.html"&gt;The Netflix Tech Blog: Fault Tolerance in a High Volume,
    Distributed
    System&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;This is a &lt;em&gt;really, really&lt;/em&gt; cool post NetFlix about how latency
increases in a single subsystem can bring down their whole &lt;span class="caps"&gt;API&lt;/span&gt; in
seconds, and how they combat this. Really cool&amp;nbsp;stuff.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arstechnica.com/business/news/2012/04/exclusive-a-behind-the-scenes-look-at-facebook-release-engineering.ars/1"&gt;Ars Technica - Exclusive: a behind-the-scenes look at Facebook
    release
    engineering&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Ars Technical is more or less &amp;#8220;mainstream media&amp;#8221; to me, but this
is a really interesting writeup on Facebook&amp;#8217;s release engineering
process, albeit at a higher level. Specifically, it talks about
their automation, phased rollouts, rollbacks, and how they release
the Facebook codebase as a single giant binary, sent out via&amp;nbsp;BitTorrent.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/monitoringsucks/blog-posts"&gt;Monitoring Sucks blog posts
    (github)&lt;/a&gt; - The
    &amp;#8220;monitoing sucks&amp;#8221; movement really speaks to me, having worked
    extensively with Nagios, Cacti, and similar technologies.
    Specifically, having rolled out monitoring in a variety of &amp;#8220;weird&amp;#8221;
    scenarios (a lot of monitoring devices or whole networks behind &lt;span class="caps"&gt;NAT&lt;/span&gt;,
    on dynamic &lt;span class="caps"&gt;IP&lt;/span&gt; connections, or otherwise unreachable from a central
    server), I&amp;#8217;ve felt a lot of pain in the current want of doing
    things. There are a lot of &lt;strong&gt;really&lt;/strong&gt; good thoughts linked here,
    especially the &lt;a href="http://jedi.be/blog/2012/01/03/monitoring-wonderland-survey-introduction"&gt;&amp;#8220;wonderland&amp;#8221; series by Patrick
    Debois&lt;/a&gt;
    and the &lt;a href="http://holmwood.id.au/~lindsay/2012/01/09/monitoring-sucks-latency-sucks-more"&gt;&amp;#8220;Latency sucks&amp;#8221; series by Lindsay
    Holmwood&lt;/a&gt;.
    This really got me thinking about my ideal monitoring system, which
    among other things, would integrate the &amp;#8220;alerting&amp;#8221; functions of
    Nagios with graphing/trending and correlation, would be based on
    some sort of message queue architecture (that supports multiple
    levels of proxies that could gracefully support &lt;span class="caps"&gt;NAT&lt;/span&gt; and multiple
    hops), and would be configured almost totally on the originating
    &amp;#8220;client&amp;#8221; (unlike the pain of distributed&amp;nbsp;Nagios/Icinga).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://assets.en.oreilly.com/1/event/65/Metrics-driven%20Engineering%20at%20Etsy%20Presentation.pdf"&gt;Mike Brittain - Metrics Driven Engineering at Etsy (3.&lt;span class="caps"&gt;2MB&lt;/span&gt;
    &lt;span class="caps"&gt;PDF&lt;/span&gt;)&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;presentation slides. I&amp;#8217;d &lt;em&gt;love&lt;/em&gt; to see the video. Some really good
ideas about putting the science back into being a SysAdmin. Also
mentions a few tools I really want to play around with (including
ganglia, graphite, logster and StatsD). Also mentions adding &lt;span class="caps"&gt;PHP&lt;/span&gt;
memory usage and time to Apache logs, which I don&amp;#8217;t believe I never
thought&amp;nbsp;of.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Some really thoughtful posts from &lt;span class="caps"&gt;R. I.&lt;/span&gt; Pienaar on &lt;a href="http://www.devco.net/archives/2011/03/19/thinking_about_monitoring_frameworks.php"&gt;Thinking about
    monitoring
    frameworks&lt;/a&gt;
    and &lt;a href="http://www.devco.net/archives/2011/04/04/monitoring_framework_composable_architectures.php"&gt;Composable
    Architectures&lt;/a&gt;.
    Some really good stuff, but what else would you expect from someone
    &lt;a href="https://github.com/ripienaar/"&gt;like this&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</summary><category term="amqp"></category><category term="etsy"></category><category term="facebook"></category><category term="limoncelli"></category><category term="links"></category><category term="mongodb"></category><category term="monitoring"></category><category term="monitoringsucks"></category><category term="netflix"></category><category term="sensu"></category></entry><entry><title>What Does a Sysadmin Look Like in 10 Years?</title><link href="http://blog.jasonantman.com/2012/04/what-does-a-sysadmin-look-like-in-10-years/" rel="alternate"></link><updated>2012-04-15T22:29:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-15:2012/04/what-does-a-sysadmin-look-like-in-10-years/</id><summary type="html">&lt;p&gt;I just read a wondeful blog post by Adam Fletcher, &lt;a href="http://www.thesimplelogic.com/2011/03/22/what-does-a-sysadmin-look-like-in-10-years/"&gt;What Does A Sysadmin
Look Like In 10
Years?&lt;/a&gt;.
This almost totally describes what I see as the future of system
administors/engineers/architects, and DevOps. And what I try, or want,
to do. It&amp;#8217;s the most accurate and succinct description I&amp;#8217;ve ever&amp;nbsp;read.&lt;/p&gt;</summary><category term="engineer"></category><category term="sysadmin"></category></entry><entry><title>CentOS/Fedora Install on SuperMicro Servers via IPMI Card KVM Over IP</title><link href="http://blog.jasonantman.com/2012/04/centosfedora-install-on-supermicro-servers-via-ipmi-card-kvm-over-ip/" rel="alternate"></link><updated>2012-04-13T15:19:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-13:2012/04/centosfedora-install-on-supermicro-servers-via-ipmi-card-kvm-over-ip/</id><summary type="html">&lt;p&gt;I recently had to setup Fedora 16 to test something on a &lt;a href="http://www.supermicro.com/products/system/1U/6015/SYS-6015T-T.cfm"&gt;SuperMicro
6015T-&lt;span class="caps"&gt;TV&lt;/span&gt;&lt;/a&gt;
1U &amp;#8220;dual&amp;#8221; server. This is a 1U enclosure with two separate servers in it
- based on the &lt;a href="http://www.supermicro.com/products/motherboard/Xeon1333/5000P/X7DBT.cfm"&gt;SuperMicro
&lt;span class="caps"&gt;X7DBT&lt;/span&gt;&lt;/a&gt;
motherboards - each with an
&lt;a href="http://www.supermicro.com/products/accessories/addon/SIM.cfm"&gt;&lt;span class="caps"&gt;AOC&lt;/span&gt;-&lt;span class="caps"&gt;SIMSO&lt;/span&gt;+&lt;/a&gt;
&lt;span class="caps"&gt;IPMI&lt;/span&gt; and &lt;span class="caps"&gt;KVM&lt;/span&gt;-over-&lt;span class="caps"&gt;IP&lt;/span&gt; management card. Every time I tried different
options for the kernel parameters (I was using Cobbler), I could get the
&lt;span class="caps"&gt;OS&lt;/span&gt; to boot, but once Anaconda started, I&amp;#8217;d lose image (&amp;#8220;No Signal&amp;#8221;) on
the &lt;span class="caps"&gt;IP&lt;/span&gt; &lt;span class="caps"&gt;KVM&lt;/span&gt;, and the serial console would go quiet. It took me about a
dozen tries before I found a mailing list reference to the &amp;#8220;nomodeset&amp;#8221;
option. This did the trick perfectly, and kept Anaconda&amp;nbsp;working.&lt;/p&gt;</summary><category term="anaconda"></category><category term="centos"></category><category term="fedora"></category><category term="ipmi"></category><category term="kvm"></category><category term="linux"></category><category term="raritan"></category><category term="supermicro"></category></entry><entry><title>Adjusting the VirtualBox F12 BIOS Boot Prompt Timeout</title><link href="http://blog.jasonantman.com/2012/04/adjusting-the-virtualbox-f12-bios-boot-prompt-timeout/" rel="alternate"></link><updated>2012-04-09T13:52:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-09:2012/04/adjusting-the-virtualbox-f12-bios-boot-prompt-timeout/</id><summary type="html">&lt;p&gt;I&amp;#8217;m working from home today, connected by &lt;span class="caps"&gt;VPN&lt;/span&gt;. I&amp;#8217;m in the process of
testing a bunch of Puppet stuff, and needed to re-image a bunch of
&lt;a href="https://www.virtualbox.org/"&gt;VirtualBox&lt;/a&gt; VMs on my desktop at work,
using &lt;span class="caps"&gt;PXE&lt;/span&gt; boot to &lt;a href="https://fedorahosted.org/cobbler/"&gt;Cobbler&lt;/a&gt;. I&amp;#8217;m only
connected to the desktop by &lt;span class="caps"&gt;SSH&lt;/span&gt;, and running the VMs with &lt;code&gt;VBoxHeadless&lt;/code&gt;
and connecting to them via &lt;span class="caps"&gt;RDP&lt;/span&gt; (well, &lt;span class="caps"&gt;VRDP&lt;/span&gt;). The problem with this is
that if I start a &lt;span class="caps"&gt;VM&lt;/span&gt; on my console window, then switch to my &lt;span class="caps"&gt;RDP&lt;/span&gt; client
and connect, by the time the &lt;span class="caps"&gt;VM&lt;/span&gt; gets keyboard focus, it&amp;#8217;s already past
the VBox &amp;#8220;Press F12 to select boot device&amp;#8221; prompt and booting from disk.
I could modify the boot order on the &lt;span class="caps"&gt;VM&lt;/span&gt;, but then that becomes a pain
when it reboots after the&amp;nbsp;install.&lt;/p&gt;
&lt;p&gt;Thanks to some of the guys on the &lt;a href="https://www.virtualbox.org/wiki/IRC"&gt;VirtualBox &lt;span class="caps"&gt;IRC&lt;/span&gt;
channel&lt;/a&gt;, I found out about the
&lt;code&gt;--bioslogodisplaytime&lt;/code&gt; option for VMs, which controls the length of
time (in milliseconds) that the boot splash screen is shown (the default
value seems to be 0). It&amp;#8217;s included in the &lt;a href="http://www.virtualbox.org/manual/ch08.html#vboxmanage-modifyvm"&gt;reference guide to
VBoxManage&lt;/a&gt;
in the modifyvm section. Setting this to a value of 10 seconds or so, as
shown below, is more than enough for me to start the &lt;span class="caps"&gt;VM&lt;/span&gt;, Alt-Tab to my
&lt;span class="caps"&gt;RDP&lt;/span&gt; client, connect to the &lt;span class="caps"&gt;VM&lt;/span&gt;, and hit &amp;#8216;F12&amp;#8217; to select a one-time
network&amp;nbsp;boot:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;VBoxManage modifyvm VMNAME --bioslogodisplaytime 10000
&lt;/pre&gt;&lt;/div&gt;</summary><category term="provisioning"></category><category term="pxe"></category><category term="rdp"></category><category term="sysadmin"></category><category term="vbox"></category><category term="virtualbox"></category><category term="virtualization"></category><category term="vm"></category></entry><entry><title>Rsync on an Android phone</title><link href="http://blog.jasonantman.com/2012/04/rsync-on-an-android-phone/" rel="alternate"></link><updated>2012-04-04T20:40:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-04:2012/04/rsync-on-an-android-phone/</id><summary type="html">&lt;p&gt;Every once in a while, there are some files that I want kept in sync
between my Android-based phone and one of my Linux (or Mac, or any Unix,
or maybe Windows too, but I use Linux&amp;#8230;) boxes. Yeah, I can copy them
over manually via &lt;span class="caps"&gt;USB&lt;/span&gt; or even something a bit simpler like
&lt;a href="https://market.android.com/details?id=lysesoft.andftp"&gt;AndFTP&lt;/a&gt;
(assuming you can &lt;span class="caps"&gt;SCP&lt;/span&gt; to the target machine). But that&amp;#8217;s a real pain for
anything like my &lt;a href="http://keepass.info/"&gt;KeePass&lt;/a&gt; (well, actually
&lt;a href="http://www.keepassx.org/"&gt;KeePassX&lt;/a&gt; and
&lt;a href="https://market.android.com/details?id=com.android.keepass"&gt;KeePassDroid&lt;/a&gt;)
password database, that I might add something to at any time and forget
to sync. I also try to occasionally (waiting in line?) backup &lt;span class="caps"&gt;SMS&lt;/span&gt;, call
logs, etc. on my phone, and like to have those synced back to the
desktop&amp;nbsp;automatically.&lt;/p&gt;
&lt;p&gt;Enter the solution: &lt;a href="https://market.android.com/details?id=eu.kowalczuk.rsync4android"&gt;rsync backup for
Android&lt;/a&gt;,
a &lt;a href="http://rsync.samba.org/"&gt;rsync&lt;/a&gt; client for Android that includes
Tasker plugins (there are a few things about the app that I don&amp;#8217;t like,
but it seems to be the only option at the moment), and
&lt;a href="https://market.android.com/details?id=net.dinglisch.android.taskerm"&gt;Tasker&lt;/a&gt;,
an automation framework for Android.Tasker is one of the few Android
apps that I&amp;#8217;ve actually bought (i.e. not free/no-cost), and is currently
selling for $6.49. It&amp;#8217;s an incredibly capable task automator, very much
akin to &lt;a href="http://www.twofortyfouram.com/"&gt;Locale&lt;/a&gt; on steroids. On the
down side, Tasker can eat up battery life if you don&amp;#8217;t configure it
intelligently, and it&amp;#8217;s not &lt;em&gt;always&lt;/em&gt; 100% reliable when interacting with
the system. On the positive side, Tasker can identify practically any
combination of states in the android system (from hardware and software
events to &lt;span class="caps"&gt;GPS&lt;/span&gt; location, time, signal status, etc.) and perform almost
any task on the system based on this information. Sure, this specific
problem could be solved with a cron replacement (which Android lacks, of
course), but Tasker can do things like play specific audio files when
you get an &lt;span class="caps"&gt;SMS&lt;/span&gt; from a specific number, mute audio at certain &lt;span class="caps"&gt;GPS&lt;/span&gt;
locations, or turn WiFi on when I get home and off when I leave the
house. It also has a plugin architecture, and rsync backup for Android
happens to have a plugin that works with&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;So, our goal is to have a daily, bi-directional, newest-file-wins sync
between a directory on our Android phone and a directory on a computer.
I&amp;#8217;m not going to go into a lot of the computer-side stuff, mainly
because that varies quite a bit between operating systems, and also
because my personal setup is a bit paranoid in terms of security. For
the computer side, we&amp;#8217;ll need a machine that can be SSHed to from the
Internet (either a static &lt;span class="caps"&gt;IP&lt;/span&gt; or a known hostname/dynamic &lt;span class="caps"&gt;DNS&lt;/span&gt;), a user
that can run rsync over &lt;span class="caps"&gt;SSH&lt;/span&gt;, and a directory that&amp;#8217;s writable&amp;nbsp;(obviously).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Buy and install the
    &lt;a href="https://play.google.com/store/apps/details?id=net.dinglisch.android.taskerm"&gt;Tasker&lt;/a&gt;&amp;nbsp;app.&lt;/li&gt;
&lt;li&gt;Install the &lt;a href="https://play.google.com/store/apps/details?id=eu.kowalczuk.rsync4android"&gt;rsync backup for
    Android&lt;/a&gt;&amp;nbsp;app.&lt;/li&gt;
&lt;li&gt;Configure the rsync stuff on the computer. In the simplest form,
    we&amp;#8217;ll just need a user that can login and run rsync, and a directory
    to sync from/to &lt;em&gt;(note: this should be a directory used only for
    syncing the&amp;nbsp;phone&amp;#8230;).&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Open the rsync backup for Android app. Use Menu -&gt; Generate Keys to
    generate a new pair of &lt;span class="caps"&gt;SSH&lt;/span&gt; keys, and then get the public key setup
    on the target computer. See &lt;a href="http://android.kowalczuk.eu/rsync4android/"&gt;the developer&amp;#8217;s web
    site&lt;/a&gt; for&amp;nbsp;instructions.&lt;/li&gt;
&lt;li&gt;Once keys are setup, create a new profile called &amp;#8220;&lt;span class="caps"&gt;PC&lt;/span&gt;-droid&amp;#8221;. Set the
    local directory to a new empty directory (I used &lt;code&gt;/sdcard/sync&lt;/code&gt;),
    enter the remote host address, port, username, and remote directory,
    and select the private &lt;span class="caps"&gt;SSH&lt;/span&gt; key that you created. Check off &amp;#8220;rsync on
    reverse direction&amp;#8221;. As this program is just a &lt;span class="caps"&gt;GUI&lt;/span&gt; wrapper around
    normal rsync binaries, you can specify additional options to the
    rsync command; my string ended up being
    &lt;code&gt;-vHrltDuO --chmod=Du+rwx,go-rwx,Fu+rw,go-rw --no-perms&lt;/code&gt;. If it
    helps, at the bottom of the screen you can see the actual rsync
    command line that will be run. Save when&amp;nbsp;done.&lt;/li&gt;
&lt;li&gt;Save the profile, then long-press it and select &amp;#8220;Duplicate&amp;#8221;. Change
    the name to &amp;#8220;droid-&lt;span class="caps"&gt;PC&lt;/span&gt;&amp;#8221;, uncheck &amp;#8220;rsync in reverse direction&amp;#8221;, and
    change your additional options as needed (mine became
    &lt;code&gt;-vHrltDu --chmod=Dug+rwx,o-rwx,Fug+rw,o-rw --no-perms&lt;/code&gt;). Save when&amp;nbsp;done.&lt;/li&gt;
&lt;li&gt;Create a test file in the sync directory on the &lt;span class="caps"&gt;PC&lt;/span&gt;, and a different
    one in the sync directory on the&amp;nbsp;droid.&lt;/li&gt;
&lt;li&gt;One at a time, in the rsync backup app, tap on the profile names. If
    all goes well, the syncs should run, and both files will now be in
    both places. If there are any problems, the output should help; the
    most likely issues are probably permissions, rsync command options,
    or &lt;span class="caps"&gt;SSH&lt;/span&gt;&amp;nbsp;keys.&lt;/li&gt;
&lt;li&gt;Long-press each profile, select &amp;#8220;Edit&amp;#8221;, and check off &amp;#8220;Close log
    window after job is done&amp;#8221;. Save&amp;nbsp;profile.&lt;/li&gt;
&lt;li&gt;Now fire up Tasker. Click the &amp;#8220;+&amp;#8221; at the bottom of the screen to
    create a new profile, call it &amp;#8220;sync&amp;#8221;, and click the check&amp;nbsp;mark.&lt;/li&gt;
&lt;li&gt;On the First Context panel, tap Time, and select when you want the
    jobs to run; I chose 03:01. Tap the check&amp;nbsp;mark.&lt;/li&gt;
&lt;li&gt;On the Task Selection panel, tap New Task. Give it a name, like&amp;nbsp;&amp;#8220;sync2&amp;#8221;.&lt;/li&gt;
&lt;li&gt;On the Task Edit panel, tap the &amp;#8220;+&amp;#8221; button at the bottom left, tap
    Plugin, tap &amp;#8220;rsync backup for Android&amp;#8221;, click the &amp;#8220;Edit&amp;#8221; button on
    the Configuration line, and select the &lt;span class="caps"&gt;PC&lt;/span&gt;-droid rsync profile. Tap
    the check mark in the lower left to&amp;nbsp;save.&lt;/li&gt;
&lt;li&gt;Repeat the last step for the droid-&lt;span class="caps"&gt;PC&lt;/span&gt; rsync&amp;nbsp;profile.&lt;/li&gt;
&lt;li&gt;Tap the check box in the lower left. This saves the&amp;nbsp;profile.&lt;/li&gt;
&lt;li&gt;In the main Tasker screen, make sure there&amp;#8217;s a green check to the
    right of the profile you just added, and that the button at the
    bottom right of the screen is set to&amp;nbsp;&amp;#8220;On&amp;#8221;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Assuming this all went well, the next time the time you specified rolls
around, your sync should run. If you gave the task a name in step 12,
you can setup additional profiles to run it at other times (or use the
repeat logic&amp;nbsp;builtin).&lt;/p&gt;</summary><category term="android"></category><category term="rsync"></category><category term="tasker"></category></entry><entry><title>Python script to find dependency cycles in GraphViz dot files</title><link href="http://blog.jasonantman.com/2012/03/python-script-to-find-dependency-cycles-in-graphviz-dot-files/" rel="alternate"></link><updated>2012-03-28T22:05:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-28:2012/03/python-script-to-find-dependency-cycles-in-graphviz-dot-files/</id><summary type="html">&lt;p&gt;Using &lt;a href="http://www.graphviz.org/"&gt;GraphViz&lt;/a&gt; to describe configurations is
relatively popular in the software and systems architecture world; the
simple text-based format makes it quiet simple, and the directed graph
(dot file) is a simple method to store a graph of information flow or
component relationships. &lt;a href="http://puppetlabs.com"&gt;Puppet&lt;/a&gt; includes
builtin support for &lt;a href="http://docs.puppetlabs.com/guides/faq.html#how-do-i-use-puppets-graphing-support"&gt;generating dot
graphs&lt;/a&gt;
of its configuration resources and relationships (both those specified
by the user, and all relationships including ones generated by Puppet&amp;nbsp;itself).&lt;/p&gt;
&lt;p&gt;One of the common uses for puppet&amp;#8217;s graphs is to identify dependency
cycles, as cyclic dependencies cause an error condition. However,
Puppet&amp;#8217;s own
&lt;a href="http://docs.puppetlabs.com/guides/faq.html#how-do-i-use-puppets-graphing-support"&gt;&lt;span class="caps"&gt;FAQ&lt;/span&gt;&lt;/a&gt;
only mentions using the &lt;code&gt;dot&lt;/code&gt; command to generate a &lt;span class="caps"&gt;PNG&lt;/span&gt; graphical
representation of the the graph. When debugging a recent problem with
puppet, I ended up with a message&amp;nbsp;like:  &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Could not apply complete catalog: Found dependency cycles in the following relationships: Service[puppet] =&amp;gt; File[/var/lib/puppet/yaml/foreman], File[/var/lib/puppet/yaml] =&amp;gt; File[/var/lib/puppet/yaml/foreman], Service[puppet] =&amp;gt; File[/etc/puppet/node.rb], File[fileserver.conf] =&amp;gt; Service[apache], File[namespaceauth.conf] =&amp;gt; Service[apache], File[puppet.conf] =&amp;gt; Service[apache], File[puppet.conf] =&amp;gt; Service[puppet], Service[puppet] =&amp;gt; File[foreman-report.rb], File[/var/lib/puppet/yaml/foreman] =&amp;gt; Package[puppet-server], Service[foreman-proxy] =&amp;gt; Package[puppet-server], File[foreman-proxy-settings.yml] =&amp;gt; Package[puppet-server], Package[foreman-proxy] =&amp;gt; Package[puppet-server], User[foreman-proxy] =&amp;gt; Package[puppet-server], File[/var/lib/puppet/yaml] =&amp;gt; Package[puppet-server], File[foreman-report.rb] =&amp;gt; Package[puppet-server], File[/etc/puppet/node.rb] =&amp;gt; Package[puppet-server], File[/var/lib/puppet/yaml/foreman] =&amp;gt; Exec[create_puppetmaster_certs], Service[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], File[foreman-proxy-settings.yml] =&amp;gt; Exec[create_puppetmaster_certs], Package[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], User[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], File[/var/lib/puppet/yaml] =&amp;gt; Exec[create_puppetmaster_certs], File[foreman-report.rb] =&amp;gt; Exec[create_puppetmaster_certs], File[/etc/puppet/node.rb] =&amp;gt; Exec[create_puppetmaster_certs], File[/var/lib/puppet/yaml/foreman] =&amp;gt; File[/etc/puppet/environments], Service[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], File[foreman-proxy-settings.yml] =&amp;gt; File[/etc/puppet/environments], Package[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], User[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], File[/var/lib/puppet/yaml] =&amp;gt; File[/etc/puppet/environments], File[foreman-report.rb] =&amp;gt; File[/etc/puppet/environments], File[/etc/puppet/node.rb] =&amp;gt; File[/etc/puppet/environments], File[foreman-proxy-settings.yml] =&amp;gt; Service[foreman-proxy], Package[foreman-proxy] =&amp;gt; Service[foreman-proxy], Service[puppet]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Not exactly easy to follow, or to pull much meaning out of, even if I
did some slight reformatting by putting in some newlines. I then
generated the png as described in the Puppet FAQs, but even scrolling
back and forth on this for 20 minutes didn&amp;#8217;t help: &lt;em&gt;(note: link is to
the original 14405x665px png)&lt;/em&gt;&lt;br /&gt;
&lt;a href="/GFX/relationships.dot.png"&gt;&lt;img alt="dot file
png" src="/GFX/relationships.dot.small.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With a little research, I managed to find the
&lt;a href="http://networkx.lanl.gov"&gt;NetworkX&lt;/a&gt; package for Python; according to
their site, &amp;#8220;NetworkX is a Python language software package for the
creation, manipulation, and study of the structure, dynamics, and
functions of complex networks.&amp;#8221; Among its features are the ability to
&lt;a href="http://networkx.lanl.gov/reference/drawing.html#module-networkx.drawing.nx_pydot"&gt;read dot
files&lt;/a&gt;
using the &lt;a href="http://code.google.com/p/pydot/"&gt;pydot&lt;/a&gt; library, and the
ability to &lt;a href="http://networkx.lanl.gov/reference/generated/networkx.algorithms.cycles.simple_cycles.html#networkx.algorithms.cycles.simple_cycles"&gt;find simple
cycles&lt;/a&gt;
within a graph. In about 20 minutes, I hacked together the dead-simple
script&amp;nbsp;below.&lt;/p&gt;
&lt;p&gt;Given a dot file (of the type generated, for example, by Puppet), this
will output all of the cycles found within the graph. I ran this script
on the &lt;code&gt;expanded_relationships.dot&lt;/code&gt; file from Puppet, which had 99 nodes
(nodes on the graph, not puppet clients), and got the following&amp;nbsp;output:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;[&amp;#39;File[foreman-report.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-report.rb]&amp;#39;]
[&amp;#39;File[foreman-report.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-report.rb]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/var/lib/puppet/yaml/foreman]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;]
[&amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/var/lib/puppet/yaml/foreman]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It probably would have taken me hours to come up with that by hand, let
alone realize that &lt;code&gt;Service[puppet]&lt;/code&gt; is the common item in all of them,
and hence the problem. With that little tidbit of information, I managed
to track down an extraneous &amp;#8220;require puppet&amp;#8221; that this all originated
from. I sincerely hope that this script will save someone else at least
as much time as it took me to write (I know it will for&amp;nbsp;me&amp;#8230;).&lt;/p&gt;
&lt;p&gt;You can always obtain the latest version of this script from
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/dot_find_cycles.py"&gt;my github repository&lt;/a&gt;
It&amp;#8217;s free for use
and distribution, provided that you leave my copyright/attribution and
source &lt;span class="caps"&gt;URL&lt;/span&gt; notice intact, update the changelog, and send any
features/fixes back to me. The script is written in Python, and depends
on the python-networkx, graphviz-python, and pydot packages (all of
which are available as packages in the default repos of Fedora and
CentOS at least). For Puppet purposes, I&amp;#8217;d recommend running this on
&lt;code&gt;expanded_relationships.dot&lt;/code&gt; to get the full&amp;nbsp;information.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;dot_find_cycles.py - uses Pydot and NetworkX to find cycles in a dot file directed graph.&lt;/span&gt;

&lt;span class="sd"&gt;Very helpful for &lt;/span&gt;

&lt;span class="sd"&gt;By Jason Antman  2012.&lt;/span&gt;

&lt;span class="sd"&gt;Free for all use, provided that you send any changes you make back to me, update the changelog, and keep this comment intact.&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;REQUIREMENTS&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;Python&lt;/span&gt;
&lt;span class="sd"&gt;python-networkx - &lt;/span&gt;
&lt;span class="sd"&gt;graphviz-python - &lt;/span&gt;
&lt;span class="sd"&gt;pydot - &lt;/span&gt;
&lt;span class="sd"&gt;(all of these are available as native packages at least on CentOS)&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;USAGE&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;dot_find_cycles.py /path/to/file.dot&lt;/span&gt;

&lt;span class="sd"&gt;The canonical source of this script can always be found from:&lt;/span&gt;


&lt;span class="sd"&gt;$HeadURL: http://svn.jasonantman.com/misc-scripts/dot_find_cycles.py $&lt;/span&gt;
&lt;span class="sd"&gt;$LastChangedRevision: 33 $&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;CHANGELOG&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;    Wednesday 2012-03-28 Jason Antman :&lt;/span&gt;
&lt;span class="sd"&gt;        - initial script creation&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;access&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;R_OK&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;networkx&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;nx&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;dot_find_cycles.py by Jason Antman &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;  finds cycles in dot file graphs, such as those from Puppet&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: dot_find_cycles.py /path/to/file.dot&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;fh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;IOError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: could not read file &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# read in the specified file, create a networkx DiGraph&lt;/span&gt;
    &lt;span class="n"&gt;G&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DiGraph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;simple_cycles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;G&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;

&lt;span class="c"&gt;# Run&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="dot"></category><category term="graph"></category><category term="graphviz"></category><category term="puppet"></category><category term="python"></category></entry><entry><title>Github as a repository in Redmine</title><link href="http://blog.jasonantman.com/2012/03/github-as-a-repository-in-redmine/" rel="alternate"></link><updated>2012-03-27T21:36:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-27:2012/03/github-as-a-repository-in-redmine/</id><summary type="html">&lt;p&gt;As a follow-up to my &lt;a href="/2012/03/cvs-to-svn-to-git/"&gt;&lt;span class="caps"&gt;CVS&lt;/span&gt; to &lt;span class="caps"&gt;SVN&lt;/span&gt; to Git&lt;/a&gt;
post, I have the &lt;a href="http://www.php-ems-tools.com"&gt;&lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt; Tools&lt;/a&gt;
repository migrated from my &lt;span class="caps"&gt;SVN&lt;/span&gt; to
&lt;a href="https://github.com/jantman/php-ems-tools"&gt;github&lt;/a&gt;. Since I&amp;#8217;m moving the
website and all development to a &lt;a href="http://www.redmine.org/"&gt;Redmine&lt;/a&gt;
instance, the next step is setting up Github to work as a revision
control repository in redmine. Well, it&amp;#8217;s dead simple. I just followed
the instructions for the &lt;a href="http://mentalized.net/journal/2009/08/03/redmine_plugin_github_hook/"&gt;Redmine plugin: Github
hook&lt;/a&gt;
, with the exception that I followed the &lt;a href="http://www.redmine.org/projects/redmine/wiki/HowTo_keep_in_sync_your_git_repository_for_redmine"&gt;redmine instructions for
setting up the repository
clone&lt;/a&gt;
instead of Step #2 in the plugin instructions. All worked well, though
I&amp;#8217;ll admit I only tried it talking to redmine over plain &lt;span class="caps"&gt;HTTP&lt;/span&gt;, not&amp;nbsp;&lt;span class="caps"&gt;HTTPS&lt;/span&gt;.&lt;/p&gt;</summary><category term="git"></category><category term="github"></category><category term="redmine"></category></entry><entry><title>CVS to SVN to Git</title><link href="http://blog.jasonantman.com/2012/03/cvs-to-svn-to-git/" rel="alternate"></link><updated>2012-03-25T12:11:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-25:2012/03/cvs-to-svn-to-git/</id><summary type="html">&lt;p&gt;Thanks to some new interest, I&amp;#8217;ve decided to resurrect an old project of
mine, &lt;a href="http://www.php-ems-tools.com"&gt;&lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt; Tools&lt;/a&gt;. It&amp;#8217;s a web-based
tool for small emergency services organizations, mainly aimed at
volunteer &lt;span class="caps"&gt;EMS&lt;/span&gt;/ambulance providers. The tool handles roster tracking,
scheduling, equipment maintenance and checks, and a bunch of other
administrative tasks. I first started it in 2007 for the &lt;a href="http://www.midlandparkambulance.com"&gt;Midland Park
Ambulance Corps&lt;/a&gt; (&lt;span class="caps"&gt;MPAC&lt;/span&gt;), which I
was a volunteer &lt;span class="caps"&gt;EMT&lt;/span&gt; with from 2005 through 2011. I&amp;#8217;ll admit that it&amp;#8217;s a
perfect model of how not to run a software project. The first few
releases are plain awful code. I was keeping the project in &lt;span class="caps"&gt;CVS&lt;/span&gt; at the
time, and posted some early releases on
&lt;a href="http://sourceforge.net/projects/php-ems-tools/"&gt;sourceforge&lt;/a&gt; and
FreshMeat, now &lt;a href="http://freecode.com/projects/php-ems-tools"&gt;FreeCode&lt;/a&gt;.
Sometime in 2009, I migrated the contents of the trunk of the &lt;span class="caps"&gt;CVS&lt;/span&gt; module
to a &lt;a href="http://svn.jasonantman.com/php-ems-tools/"&gt;&lt;span class="caps"&gt;SVN&lt;/span&gt; repository&lt;/a&gt;, but
discarded the history. I also setup a MediaWiki-based website for the
project, giving some information and mainly asking for feedback. Around
that time I started working on a new and heavily updated (fixed) version
for &lt;span class="caps"&gt;MPAC&lt;/span&gt;, but since it appeared that there was no interest in the
project, and there were many many local customizations and
organization-specific features, I let their codebase diverge from what
was released, and as a result, stopped keeping it in version control.
Until now, when they need to migrate to a new server, and I&amp;#8217;ve also
gotten some outside interest in the&amp;nbsp;project.&lt;/p&gt;
&lt;p&gt;So, as of this morning, I was left with at least four code&amp;nbsp;bases:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the original &lt;a href="http://cvs.jasonantman.com/cgi-bin/viewvc.cgi/cvs/php-ems-tools-trunk/"&gt;&lt;span class="caps"&gt;CVS&lt;/span&gt;
    repository&lt;/a&gt;
    with branches and tags and some history, untouched since&amp;nbsp;2007&lt;/li&gt;
&lt;li&gt;the &lt;a href="http://svn.jasonantman.com/php-ems-tools/"&gt;&lt;span class="caps"&gt;SVN&lt;/span&gt; repository&lt;/a&gt;
    circa 2009, with only 3 commits, all related to the migration from
    &lt;span class="caps"&gt;CVS&lt;/span&gt; to&amp;nbsp;&lt;span class="caps"&gt;SVN&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;a &amp;#8220;release&amp;#8221; tarball that at least one outside organization is
    actually&amp;nbsp;using.&lt;/li&gt;
&lt;li&gt;the code that &lt;span class="caps"&gt;MPAC&lt;/span&gt; is running, which has been largely rewritten
    since 2009, but also contains a lot of organization-specific&amp;nbsp;customizations.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As a first step, I created a new &lt;span class="caps"&gt;SVN&lt;/span&gt; repository and migrated the
original &lt;span class="caps"&gt;CVS&lt;/span&gt; repo, complete with history, branches, and tags, to it
using &lt;a href="http://cvs2svn.tigris.org/"&gt;cvs2svn&lt;/a&gt;, and then removed write
permissions on the actual module in the repository. This gave me a &lt;span class="caps"&gt;SVN&lt;/span&gt;
repository with all of the history of previous so-called releases, with
a trunk matching r1 of the &amp;#8220;current&amp;#8221; &lt;span class="caps"&gt;SVN&lt;/span&gt; repository. I then manually
applied patches to trunk/ for the two commits in the current &lt;span class="caps"&gt;SVN&lt;/span&gt;
repository, and set the svn:date revision property to the correct 2009
date for those commits. I also confirmed that the correct tag matches up
to the &amp;#8220;release&amp;#8221; tarball mentioned above. So, I&amp;#8217;m down to a &amp;#8220;current&amp;#8221;
trunk, plus the locally modified code running on &lt;span class="caps"&gt;MPAC&lt;/span&gt;&amp;#8217;s current server.
My plan of action from this point is as&amp;nbsp;follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Move the &lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt; Tools website from Mediawiki to my local redmine
    installation, and update the news with a link to this&amp;nbsp;post.&lt;/li&gt;
&lt;li&gt;Migrate the &lt;span class="caps"&gt;SVN&lt;/span&gt; repository, which now contains full history, to Git
    hosted at Github. Add Github integration to&amp;nbsp;Redmine.&lt;/li&gt;
&lt;li&gt;Update freshmeat, sourceforge, and anywhere else online that knows
    about the&amp;nbsp;project.&lt;/li&gt;
&lt;li&gt;Working in a git branch, begin converging the code &lt;span class="caps"&gt;MPAC&lt;/span&gt; is currently
    running with the latest (now git) trunk, trying to provide
    configuration options for anything organization specific, and
    testing as I&amp;nbsp;go.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If all works well, I&amp;#8217;ll end up with &lt;span class="caps"&gt;MPAC&lt;/span&gt; running the current trunk, just
some different configuration options, and a working, up-to-date release.
The biggest issues are going to be how I handle the &lt;span class="caps"&gt;MPAC&lt;/span&gt;-specific
additions and customizations (a lot of stuff hard-coded for our position
titles, plus our very custom call report and telephone-based call-in
software, which is pretty tightly linked with the &lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt; Tools core),
and how I balance abstracting things to be configurable for other users
versus getting this all done in a reasonable amount of&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;Stay&amp;nbsp;tuned&amp;#8230;&lt;/p&gt;</summary><category term="cvs"></category><category term="git"></category><category term="svn"></category><category term="version control"></category></entry><entry><title>Adding Piwik Web Analytics Integration to ViewVC</title><link href="http://blog.jasonantman.com/2012/03/adding-piwik-web-analytics-integration-to-viewvc/" rel="alternate"></link><updated>2012-03-23T21:15:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-23:2012/03/adding-piwik-web-analytics-integration-to-viewvc/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update February 2014:&lt;/strong&gt; Give up the analytics, and just host your code
on &lt;a href="https://github.com"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All of my public &lt;a href="http://viewvc.jasonantman.com"&gt;subversion
repositories&lt;/a&gt; and &lt;a href="http://cvs.jasonantman.com"&gt;&lt;span class="caps"&gt;CVS&lt;/span&gt;
repositories&lt;/a&gt; are available online through a
great Python application called &lt;a href="http://viewvc.org/"&gt;ViewVC&lt;/a&gt;, which
provides a web-based interface to &lt;span class="caps"&gt;CVS&lt;/span&gt; and &lt;span class="caps"&gt;SVN&lt;/span&gt; repositories, as well as
history browsing, graphical diffs, etc. An amazingly large amount of the
traffic to my web server is for the vhosts that serve this, so I decided
that I should add some analytics to it. I&amp;#8217;m in the process of trying out
&lt;a href="http://piwik.org"&gt;Piwik&lt;/a&gt;, a full-featured, &lt;span class="caps"&gt;GPL&lt;/span&gt;-licensed, self-hosted
alternative to &lt;a href="http://www.google.com/analytics/"&gt;Google Analytics&lt;/a&gt;. It
gives lots of useful information like number of visits and unique visits
per page, search engine keywords, referrers, average time on page,
bounce rate (number of one-page visits),&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;I have ViewVC installed from the &lt;a href="http://pkgs.repoforge.org/viewvc/"&gt;RPMforge
packages&lt;/a&gt;, so there&amp;#8217;s one code base
for both of my vhosts. This means that I can&amp;#8217;t simply slap the tracking
code at the bottom of the templates and call it a day. I opted to go for
a nicer solution, and what follows is a patch (diff -u) to the current
(1.1.13) version of ViewVC that adds a &amp;#8220;piwik&amp;#8221; section to viewvc.conf,
and adds the piwik tracking code with the specified base &lt;span class="caps"&gt;URL&lt;/span&gt; and site &lt;span class="caps"&gt;ID&lt;/span&gt;
into all ViewVC pages.&amp;nbsp;Enjoy.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/lib/config.py viewvc/lib/config.py&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/lib/config.py   2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/lib/config.py    2012-03-23 21:57:08.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -108,6 +108,7 @@&lt;/span&gt;
     &amp;#39;query&amp;#39;,
     &amp;#39;templates&amp;#39;,
     &amp;#39;utilities&amp;#39;,
&lt;span class="gi"&gt;+    &amp;#39;piwik&amp;#39;,&lt;/span&gt;
     )
   _force_multi_value = (
     # Configuration values with multiple, comma-separated values.
&lt;span class="gu"&gt;@@ -127,6 +128,7 @@&lt;/span&gt;
                &amp;#39;options&amp;#39;,
                &amp;#39;templates&amp;#39;,
                &amp;#39;utilities&amp;#39;,
&lt;span class="gi"&gt;+               &amp;#39;piwik&amp;#39;,&lt;/span&gt;
                ),
     &amp;#39;root&amp;#39;  : (&amp;#39;authz-*&amp;#39;,
                &amp;#39;options&amp;#39;,
&lt;span class="gu"&gt;@@ -461,7 +463,14 @@&lt;/span&gt;
     self.cvsdb.check_database_for_root = 0

     self.query.viewvc_base_url = None
&lt;span class="gd"&gt;-    &lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+    # begin  patch for piwik integration&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.use_piwik = 0&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.base_url = &amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.site_id = &amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.use_jsindex = 0&lt;/span&gt;
&lt;span class="gi"&gt;+    # end  patch for piwik integration&lt;/span&gt;
&lt;span class="gi"&gt;+   &lt;/span&gt;
 def _startswith(somestr, substr):
   return somestr[:len(substr)] == substr

&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include/footer.ezt viewvc/templates/include/footer.ezt&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include/footer.ezt    2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/templates/include/footer.ezt 2012-03-23 22:03:04.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -13,5 +13,17 @@&lt;/span&gt;



&lt;span class="gi"&gt;+[is cfg.piwik.use_piwik &amp;quot;1&amp;quot;]&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+var pkBaseURL = ((&amp;quot;https:&amp;quot; == document.location.protocol) ? &amp;quot;https://[cfg.piwik.base_url]/&amp;quot; : &amp;quot;http://[cfg.piwik.base_url]/&amp;quot;);&lt;/span&gt;
&lt;span class="gi"&gt;+document.write(unescape(&amp;quot;%3Cscript src=&amp;#39;&amp;quot; + pkBaseURL + &amp;quot;[is cfg.piwik.use_jsindex &amp;quot;1&amp;quot;]js/[else]piwik.js[end]&amp;#39; type=&amp;#39;text/javascript&amp;#39;%3E%3C/script%3E&amp;quot;));&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+try {&lt;/span&gt;
&lt;span class="gi"&gt;+var piwikTracker = Piwik.getTracker(pkBaseURL + &amp;quot;piwik.php&amp;quot;, [cfg.piwik.site_id]);&lt;/span&gt;
&lt;span class="gi"&gt;+piwikTracker.trackPageView();&lt;/span&gt;
&lt;span class="gi"&gt;+piwikTracker.enableLinkTracking();&lt;/span&gt;
&lt;span class="gi"&gt;+} catch( err ) {}&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+[else][end]&lt;/span&gt;


Only in viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include: header.ezt~
&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/viewvc.conf.dist viewvc/viewvc.conf.dist&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/viewvc.conf.dist    2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/viewvc.conf.dist 2012-03-23 21:44:02.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -1131,3 +1131,29 @@&lt;/span&gt;
 #viewvc_base_url =

 ##---------------------------------------------------------------------------
&lt;span class="gi"&gt;+[piwik]&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+## This section enables Piwik  web analytics tracking.&lt;/span&gt;
&lt;span class="gi"&gt;+## If piwik is enabled (use_piwik = 1) all other options must be specified.&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## This is based on a patch by Jason Antman  &lt;/span&gt;
&lt;span class="gi"&gt;+## to ViewVC 1.1.13, written 2012-03-23.&lt;/span&gt;
&lt;span class="gi"&gt;+## The latest version of the patch, and information on it, can always be found at:&lt;/span&gt;
&lt;span class="gi"&gt;+## &lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## To enable piwik, change use_piwik to 1. Set to 0 to disable&lt;/span&gt;
&lt;span class="gi"&gt;+use_piwik = 1&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set base_url to the hostname and path to your piwik installation, with no trailing slash.&lt;/span&gt;
&lt;span class="gi"&gt;+## i.e. piwik.example.com or www.example.com/piwik&lt;/span&gt;
&lt;span class="gi"&gt;+base_url = piwik.example.com&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set to the numeric id of your website in Piwik&lt;/span&gt;
&lt;span class="gi"&gt;+site_id = 5&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set to 1 if you want to use js/index.php to serve the tracking code, &lt;/span&gt;
&lt;span class="gi"&gt;+## or leave at 0 if you want to call piwik.js directly&lt;/span&gt;
&lt;span class="gi"&gt;+use_jsindex = 0&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+##---------------------------------------------------------------------------&lt;/span&gt;
\ No newline at end of file
&lt;/pre&gt;&lt;/div&gt;</summary><category term="analytics"></category><category term="piwik"></category><category term="python"></category><category term="subversion"></category><category term="svn"></category><category term="tracking"></category><category term="viewvc"></category></entry><entry><title>New Blog Theme</title><link href="http://blog.jasonantman.com/2012/03/new-blog-theme/" rel="alternate"></link><updated>2012-03-20T19:25:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-20:2012/03/new-blog-theme/</id><summary type="html">&lt;p&gt;In a follow-up to my &lt;a href="/2012/03/some-thoughts-on-choosing-a-new-wordpress-theme/"&gt;Some Thoughts on Choosing a New Wordpress
Theme&lt;/a&gt; post
from a few days ago, I decided on the
&lt;a href="http://wordpress.org/extend/themes/admired"&gt;Admired&lt;/a&gt;
&lt;a href="http://wp-ultra.com/themes/admired/"&gt;theme&lt;/a&gt; by &lt;a href="https://plus.google.com/103391260195864203534/posts"&gt;Brad
Thomas&lt;/a&gt;. It&amp;#8217;s
amazingly full-featured and has a good set of options. I had to manually
change a few things in the &lt;span class="caps"&gt;CSS&lt;/span&gt; (I wanted to tweak the top bar colors a
bit in a way that&amp;#8217;s not supported in the options), but overall it was a
very simple transition. While it&amp;#8217;s unfortunately very far from valid
&lt;a href="http://validator.w3.org/check?verbose=1&amp;amp;uri=http://blog.jasonantman.com/"&gt;&lt;span class="caps"&gt;HTML&lt;/span&gt;&lt;/a&gt;
or
&lt;a href="http://jigsaw.w3.org/css-validator/validator?profile=css3&amp;amp;warning=0&amp;amp;uri=http://blog.jasonantman.com/"&gt;&lt;span class="caps"&gt;CSS&lt;/span&gt;&lt;/a&gt;,
it seems quite&amp;nbsp;nice.&lt;/p&gt;
&lt;p&gt;If you happen to read this post and see anything wrong with the theme,
or it doesn&amp;#8217;t display properly for you, please leave a comment below
(with browser version and &lt;span class="caps"&gt;OS&lt;/span&gt;, if you&amp;nbsp;please).&lt;/p&gt;
&lt;p&gt;My next project, continuing on from my &lt;a href="/2012/03/inaccuracies-in-google-analytics-for-website-stats/"&gt;Inaccuracies in Google Analytics
for Website
Stats&lt;/a&gt;
post, is to compare the two self-hosted JavaScript-based open source
Google Analytics alternatives I&amp;#8217;ve identified
(&lt;a href="http://piwik.org/"&gt;Piwik&lt;/a&gt; and &lt;a href="http://www.openwebanalytics.com/"&gt;Open Web
Analytics&lt;/a&gt;) and try one out on my site
(keeping in mind that my server is pretty heavily loaded, and I don&amp;#8217;t
want to push it over the edge). Once I come to some sort of conclusion
on that, I&amp;#8217;ll get back to some useful&amp;nbsp;posts.&lt;/p&gt;</summary><category term="blog"></category><category term="theme"></category><category term="wordpress"></category></entry><entry><title>Leap Year Windows Azure Cloud Outage</title><link href="http://blog.jasonantman.com/2012/03/leap-year-windows-azure-cloud-outage/" rel="alternate"></link><updated>2012-03-20T18:12:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-20:2012/03/leap-year-windows-azure-cloud-outage/</id><summary type="html">&lt;p&gt;I haven&amp;#8217;t talked about Microsoft in quite a while (mainly because I
don&amp;#8217;t follow mainstream tech news as much anymore), but I happened by a
very interesting &lt;a href="http://blogs.msdn.com/b/windowsazure/archive/2012/03/09/summary-of-windows-azure-service-disruption-on-feb-29th-2012.aspx"&gt;post on the Windows Azure
blog&lt;/a&gt;
the other day. It&amp;#8217;s a very detailed postmortem of the major outage of
the Windows Azure cloud service which occurred from 4:00 &lt;span class="caps"&gt;PM&lt;/span&gt; &lt;span class="caps"&gt;PST&lt;/span&gt; on
February 28&lt;sup&gt;th&lt;/sup&gt; through 2:15 &lt;span class="caps"&gt;AM&lt;/span&gt; on March 1&lt;sup&gt;st&lt;/sup&gt;. Before I get into any of
the details, I should say that it really is a nice, well-done post. And
the fact that they&amp;#8217;re willing to do such a detailed, public postmortem -
and admit the failures that they did - is a step in the right direction
for Microsoft (a company that I don&amp;#8217;t particularly care for, to put it&amp;nbsp;lightly).&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m going to glance over the majority of the post, though I highly
recommend that anyone interested in running web-scale services,
specifically highly available ones, read it. The general overview
(really just the points that are germane to my discussion) is as
follows: An agent running inside the guest &lt;span class="caps"&gt;VM&lt;/span&gt; instances (i.e. domU)
communicates with a counterpart on the host &lt;span class="caps"&gt;OS&lt;/span&gt; (i.e. dom0) over an
encrypted channel, authenticated by certificate. The certs are generated
and passed from the guest to the host when the guest instance is first
initialized, which means when an app is first deployed, scaled out, &lt;span class="caps"&gt;OS&lt;/span&gt;
updated, or when an app is reinitialized on a new host. This cert was
generated for a 1-year validity period, by adding 1 to the integer year
- hence, the generation process failed on February 29th of a leap year,
as the cert end date wasn&amp;#8217;t valid. When the cert generation failed, the
guest agent essentially stopped cold. The host agent waited for a 25
minute timeout, then re-initialized the guest and started over. After
three of these failures, the host assumes there&amp;#8217;s a hardware error
(since the guest would have reported a more specific error otherwise),
declares itself in an error state, and tries to move its current
workload over to another host. Which re-initializes the guests on that
host, thereby causing a chain-reaction of failures in this case. Skip
forward the 2-1/2 hours it took them to identify the problem, and
further 2-1/2 hours to get a fix ready. They fast-tracked their fix to 7
clusters that had already been in the process of a software update, but
ended up with those clusters in an inconsistent state with
incompatibilities between the guest and host networking subsystems,
bringing down previously-unaffected instances on these&amp;nbsp;clusters.&lt;/p&gt;
&lt;p&gt;This whole scenario offers a few important points on both the
development and operations&amp;nbsp;sides:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Inputs need error checking, and errors need to be raised.&lt;/strong&gt; So the
first problem here was the failed cert generation. I&amp;#8217;ll leave alone the
fact that, in my opinion, doing math on a the integer year of a date is
a high school or college programming mistake, and never should have been
made by someone doing platform coding for a major company (believe it or
not, 25% of years are leap years &amp;lt;/sarcasm&gt;). If whatever code was
generating the cert was smart enough to check the cert end date validity
and error out, that error should have been pushed up the stack to
somewhere where it could be handled - or, at least, sent to a central
log server that does error&amp;nbsp;trending.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Secure communications when provisioning need an insecure error path.&lt;/strong&gt;
This is somewhat connected to the previous point. If the normal process
of creating a new instance and communicating errors up the stack relies
on certs and authentication or encryption, there should be some method
of communicating errors with &lt;em&gt;that&lt;/em&gt; process either up the stack, or to a
separate event correlation/trending system. Errors with a
certificate-based system are not unusual, and even something as simple
as a vastly incorrect time set on the guests could have caused this same
problem. In environments where management/control communication between
levels of a system are encrypted or authenticated, there should be some
way for lower levels of the system to deliver a meaningful error message
&amp;#8220;somewhere&amp;#8221;. Even if this is just a syslog server or web service that
listens for errors and can escalate a warning when the numbers spike,
it&amp;#8217;s a useful alarm and debugging&amp;nbsp;tool.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Autonomous systems shouldn&amp;#8217;t lightly assume hardware failures.&lt;/strong&gt; It&amp;#8217;s
arrogance for a host system to assume that just because it can&amp;#8217;t
instantiate new guests, a hardware failure exists. This entire incident
is a perfect example that, at least if hardware error indicators are
properly monitored, it&amp;#8217;s more likely for a software problem to be
falsely identified as a hardware problem than the other way around. All
of my points are somewhat related, but I can think of many more reasons
why a new guest can&amp;#8217;t be instantiated that are software-related rather
than&amp;nbsp;hardware-related.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Autonomous control mechanisms need historical trending, and need to
call for help if this looks wrong.&lt;/strong&gt; These host systems tried to
instantiate new guests three times, waiting 25 minutes in between, and
then declared themselves bad and tried to migrate guests to other hosts.
From what I understand, Microsoft got it right in having a &amp;#8220;kill switch&amp;#8221;
that prevented further migration of guests. What they didn&amp;#8217;t have right
was reporting of autonomous actions (guest migration) to a central
location that performs trending. The 25 minute timeout with three
attempts is a great safety feature, but if the status of guest creation
actions was reported to a central server, it would have been much more
quickly apparent that 100% of guest creations in the past, say, 10
minutes, had failed - across all clusters. I know plenty of shops that
do little, if any, real-time analysis and historical comparisons of
their log data. But when systems are designed to perform self-healing
and autonomous actions, it&amp;#8217;s imperative that these actions are tracked
in near-real-time, compared to historical averages, and that deviation
from a baseline is identified and escalated to&amp;nbsp;humans.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Release procedures are more, not less, important when the sky is
falling.&lt;/strong&gt; The extended downtime of the last seven clusters was because
of an improperly &lt;span class="caps"&gt;QA&lt;/span&gt;&amp;#8217;ed update that was pushed out bypassing the normal
release and testing procedures. As a matter of fact, it was so poorly
&lt;span class="caps"&gt;QA&lt;/span&gt;&amp;#8217;ed that the update totally broke networking for the guest VMs, and
was still pushed out. I&amp;#8217;m sure this was more of a management/executive
decision than one made by the actual engineers, but organizations (even
management) need to understand that when the sky is falling, services
are down, and everybody is stressed, it&amp;#8217;s &lt;em&gt;more&lt;/em&gt; likely for mistakes and
oversights to happen, and this is when a proper, well-documented &lt;span class="caps"&gt;QA&lt;/span&gt; and
release procedure (including phased rollout) is &lt;em&gt;most&lt;/em&gt; important.
Failure to follow these procedures results in exactly what happened in
this case - making an already bad problem much&amp;nbsp;worse.&lt;/p&gt;
&lt;p&gt;Even &lt;em&gt;I&lt;/em&gt; can&amp;#8217;t blame Microsoft specifically for all this (though the
whole thing would have been avoided if they just represented timestamps
as integers like the rest of us&amp;#8230;), but it is a good opportunity for us
all to learn from a major incident at a &amp;#8220;pretty well known&amp;#8221;&amp;nbsp;company.&lt;/p&gt;
&lt;p&gt;release procedures are most important when things are already going&amp;nbsp;wrong&lt;/p&gt;</summary><category term="azure"></category><category term="microsoft"></category><category term="outage"></category><category term="release"></category><category term="testing"></category><category term="windows"></category></entry><entry><title>Some Thoughts on Choosing a New Wordpress Theme</title><link href="http://blog.jasonantman.com/2012/03/some-thoughts-on-choosing-a-new-wordpress-theme/" rel="alternate"></link><updated>2012-03-17T11:48:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-17:2012/03/some-thoughts-on-choosing-a-new-wordpress-theme/</id><summary type="html">&lt;p&gt;I think I&amp;#8217;m going to choose a new theme for my blog. The current theme
is &lt;a href="http://wordpress.org/extend/themes/inove"&gt;iNove&lt;/a&gt; (albeit an older
version with some custom modifications), and I feel like it looks a bit
messy and has gotten a bit cluttered, so it&amp;#8217;s time to find something
new. I like the 2-column layout, and have a few other things I&amp;#8217;m looking
for - specifically, aside from something with advanced features like
lots of widget support and hooks, something that has good visual
separation between different posts and widgets. I also really want
something, if possible, with relative column widths. My current home and
work desktops both have dual monitors, and the minimum resolution I have
on one screen is 1920x1080. When I look at my blog in a maximized
window, about half the screen width is wasted with empty space. So,
ideally, I&amp;#8217;d like a theme that&amp;#8217;s based on relative widths, probably with
a &amp;#8220;min-width&amp;#8221; property so it wouldn&amp;#8217;t get compressed to an absurdly
narrow width on small&amp;nbsp;screens.&lt;/p&gt;
&lt;p&gt;I use &lt;a href="http://www.google.com/analytics/"&gt;Google Analytics&lt;/a&gt; (as noted in
the &lt;a href="/privacy-policy/"&gt;privacy policy&lt;/a&gt;) for visitor statistics on this
blog (more about that in a moment). So, I took a peek at the breakdown
of visitors by screen resolution, and saw that for the past year, 94% of
the 27,500 visits had a screen width of 1024px or more (and the majority
of the others looked like mobile device resolutions, so they&amp;#8217;d probably
zoom the page correctly). So, my first gut reaction was to assume that I
could use a theme approximately 1000px wide. Unfortunately, there&amp;#8217;s two
main problems with that: first, as mentioned by &lt;a href="http://css-tricks.com/screen-resolution-notequalto-browser-window/"&gt;Chris Coyier on
&lt;span class="caps"&gt;CSS&lt;/span&gt;-Tricks.com&lt;/a&gt;,
just because someone has a given screen resolution doesn&amp;#8217;t mean their
browser window (let alone the viewport) is that size. As a matter of
fact, I usually have my main browser window set at about 80% of the
width of one of my monitors, with my instant messaging client
&lt;a href="http://pidgin.im/"&gt;Pidgin&lt;/a&gt; taking up the rest of the space. So there&amp;#8217;s
one inaccuracy. There&amp;#8217;s a potentially much greater inaccuracy in my
stats as well, which I&amp;#8217;m going to discuss in a &lt;a href="/2012/03/inaccuracies-in-google-analytics-for-website-stats/"&gt;separate
post&lt;/a&gt;.&lt;/p&gt;</summary><category term="analysis"></category><category term="analytics"></category><category term="blog"></category><category term="google"></category><category term="logging"></category><category term="stats"></category><category term="theme"></category><category term="wordpress"></category></entry><entry><title>Inaccuracies in Google Analytics for Website Stats</title><link href="http://blog.jasonantman.com/2012/03/inaccuracies-in-google-analytics-for-website-stats/" rel="alternate"></link><updated>2012-03-17T11:46:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-17:2012/03/inaccuracies-in-google-analytics-for-website-stats/</id><summary type="html">&lt;p&gt;I use Google Analytics for visitor stats on this blog. Not because I&amp;#8217;m
trying to direct-market to my readers or become Big Brother, but for a
number of simple&amp;nbsp;reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It&amp;#8217;s simple - no software for me to update, and nothing that needs
    to run on my server and read through giant log files every night.
    Google does it all for&amp;nbsp;me.&lt;/li&gt;
&lt;li&gt;It gives a lot more information than I can get from just web server&amp;nbsp;logs.&lt;/li&gt;
&lt;li&gt;Because of Google&amp;#8217;s &amp;#8220;big brother&amp;#8221; tracking, and the vast number of
    sites that they track people on, I can tell things I&amp;#8217;d have no other
    way of knowing, like how long someone stayed on my&amp;nbsp;page.&lt;/li&gt;
&lt;li&gt;They tell me &lt;em&gt;useful&lt;/em&gt; stats like which search keywords brought the
    most people to my site and which posts are the most popular, which I
    keep in mind when writing new stuff and updating older&amp;nbsp;posts.&lt;/li&gt;
&lt;li&gt;They tell me information about client operating system and browser
    version, which I think tells quite a bit about my&amp;nbsp;audience.&lt;/li&gt;
&lt;li&gt;As far as I know, they&amp;#8217;re pretty good at filtering out anything
    other than an actual human&amp;nbsp;visitor.&lt;/li&gt;
&lt;li&gt;They tell me stats that have no real use to me, but are just cook -
    like what countries my visitors are from, what type of Internet
    connection they&amp;#8217;re on, their screen resolution,&amp;nbsp;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obviously not for google, but for me, all of these stats are totally
anonymous - I just get percentages or numbers of visits, it&amp;#8217;s not like I
can see all of the details per-&lt;span class="caps"&gt;IP&lt;/span&gt; address. The most important aspect to
me is just the ease of use - I sign up and put a little snippet of code
on my pages, and I get an amazing dashboard interface with all of this
information. Nothing to install and update on my server, and (most
importantly, since I&amp;#8217;m now running everything of mine on one virtualized
server) no massive program to run as a cron job that has to read all my
server log&amp;nbsp;files.&lt;/p&gt;
&lt;p&gt;Last week I was talking with a couple of my co-workers, specifically
about the stats that I get from Google Analytics. While I know it&amp;#8217;s not
uncommon to run &lt;a href="http://noscript.net/"&gt;NoScript&lt;/a&gt; especially among the
more security- and privacy-conscious groups of people, I was a bit
disturbed to hear that they all block Google&amp;#8217;s tracking code in their
browsers via NoScript. I assume there&amp;#8217;s also a percentage of people who
still just turn off JavaScript alltogether (although I can&amp;#8217;t imagine how
they use the modern Web), and many who use the &lt;a href="http://tools.google.com/dlpage/gaoptout?hl=en"&gt;Google Analytics
Opt-Out&lt;/a&gt; feature. So,
especially with as technical an audience as I have, I guess that means
I&amp;#8217;m likely missing a large number of visitors in my stats. On one hand,
I want to respect the privacy of my visitors, and respect their desire
to opt-out of advanced tracking. On the other hand, since I no longer
parse web server logs for statistics, these privacy-conscious visitors
aren&amp;#8217;t even showing up in what I think of as my monthly visit count, or
in my information on what posts and search keywords are most popular,
which I only use for &amp;#8220;good&amp;#8221; purposes - to make my blog more useful. So
that&amp;#8217;s a bit of a&amp;nbsp;conundrum.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ll admit that I do run &lt;a href="https://www.google.com/adsense/"&gt;Google AdSense
Ads&lt;/a&gt; on my blog, and I&amp;#8217;m sure there are
some people who block the ads. On one hand, that upsets me a bit; I run
this blog to try and share information that I find or learn with others,
and the hosting costs aren&amp;#8217;t insignificant. If I can get paid to just
show some ads, to try and help offset the cost of running the site, I
think that&amp;#8217;s good. And if other people can help support the site by just
letting the ads stay on the page, why not? On the other hand, my hosting
costs $50/month (granted the server also handles all of my email, and a
&lt;em&gt;whole bunch&lt;/em&gt; of other sites). I&amp;#8217;ve been participating in Google AdSense
since March 5, 2010 (two years and two weeks), and my &amp;#8220;estimated
earnings&amp;#8221; are currently $80. The payout is in $100 increments. So, I
haven&amp;#8217;t seen a cent from it in two years, so I&amp;#8217;ve given up being
concerned with it. If you want to be nice, and find my posts
interesting, click on one of the ads. Unfortunately, unless I get
famous, the ads aren&amp;#8217;t going to come close to offsetting even part of
the cost of running the&amp;nbsp;site.&lt;/p&gt;
&lt;p&gt;Google itself
&lt;a href="http://support.google.com/googleanalytics/bin/answer.py?hl=en&amp;amp;answer=55610"&gt;says&lt;/a&gt;,
&amp;#8220;In order for Google Analytics to record a visit, the visitor must have
JavaScript, images, and cookies enabled for your website.&amp;#8221; There seems
to be some buzz about this on the &amp;#8216;net, and I&amp;#8217;ve seen
&lt;a href="http://garmahis.com/tips/google-analytics/#use-Google-Analytics-without-JavaScript"&gt;a&lt;/a&gt;
&lt;a href="http://djangosnippets.org/snippets/2338/"&gt;number&lt;/a&gt;
&lt;a href="http://translate.google.com/translate?hl=en&amp;amp;sl=nl&amp;amp;u=http://andrescholten.nl/google-analytics-zonder-javascript/"&gt;of&lt;/a&gt;
(translated; &lt;a href="http://andrescholten.nl/google-analytics-zonder-javascript/"&gt;original post in
Dutch&lt;/a&gt;)
posts advocating building a request to a Google Analytics &lt;span class="caps"&gt;GIF&lt;/span&gt; manually
on the server side, and then including it as an image element inside a
&lt;code&gt;&amp;lt;noscript&amp;gt;&lt;/code&gt; tag in the page. While this is probably one of the nicer
solutions (and much more likely to reduce double-counting), it doesn&amp;#8217;t
capture any of the advanced data (screen resolution, etc.) that
JavaScript-based Analytics does, and more importantly, I imagine that
many of the Ad blocking extensions also block traffic to
google-analytics.com, so this is an incremental improvement at best.
There are also
&lt;a href="http://www.vdgraaf.info/google-analytics-without-javascript.html"&gt;quite&lt;/a&gt;
&lt;a href="http://blog.datalicious.com/google-analytics-without-javascript-rss-xml-e"&gt;a&lt;/a&gt;
&lt;a href="http://blogs.walkerart.org/newmedia/2009/11/12/building-walkers-mobile-site-google-analytics-without-javascript-pt2/"&gt;few&lt;/a&gt;
posts about how to make a request to Analytics purely server-side. This
has a few disadvantages as well; it bypasses the google domain
blacklisting problem that the client-side image has, but it also means
you lose the client &lt;span class="caps"&gt;IP&lt;/span&gt; address (and therefore geolocation), and that you
double-track any user who allows javascript (so you need a separate
profile, and then need to average out the results). It also means that
you track every search engine and bot that crawls your site, and
possibly every person who clicks a link and then hits &amp;#8220;back&amp;#8221; before the
page finishes loading. I found another blogger who &lt;a href="http://www.realityburst.com/battle-of-the-inaccuracies-how-accurate-is-google-analyticsawstatsstatpress"&gt;commented
about&lt;/a&gt;
the wide disparity he saw between Google Analytics, the
&lt;a href="http://wordpress.org/extend/plugins/statpress/"&gt;StatsPress&lt;/a&gt; WordPress
plugin, and &lt;a href="http://awstats.sourceforge.net/"&gt;AWstats&lt;/a&gt; (a server-side
log file&amp;nbsp;analyzer).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So what&amp;#8217;s the&amp;nbsp;solution?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Most of the options have a down side, but I&amp;#8217;m looking for something
that&amp;#8217;s the best I can reasonably do. As much as I&amp;#8217;d rather not, I&amp;#8217;m
going to look into self-hosted alternatives to Google Analytics (a
self-hosted JavaScript-based stats provider), in the hopes that NoScript
users will be more friendly to scripts coming from my own domain, and
sending requests to my own domain, than ones from Google or other major
trackers. I don&amp;#8217;t think I want to try anything that parses web server
logs as a primary approach, as I don&amp;#8217;t think I could ever get a
meaningful comparison to Google Analytics or something else&amp;nbsp;JavaScript-based.&lt;/p&gt;
&lt;p&gt;I did have one other idea which I think is interesting, though a bit of
an overhead. I could have Apache (or, more likely, a Perl script called
in the Apache configuration) generate a random string for each request,
and save it in an Apache environment variable. The environment variable
would then be added to a field in the server logs, and also added (via
&lt;span class="caps"&gt;PHP&lt;/span&gt; or whatever else generates the pages server-side) as a custom
parameter for the &lt;span class="caps"&gt;JS&lt;/span&gt; tracking code, enabling page hits to be correlated
between the &lt;span class="caps"&gt;JS&lt;/span&gt; tracking and the server logs. Assuming the &lt;span class="caps"&gt;JS&lt;/span&gt; tacking
backend stores its data in a sane format (and as raw data, not just
aggregated), and at the cost of a serious performance penalty, a
server-side statistics program like
&lt;a href="http://awstats.sourceforge.net/"&gt;AWstats&lt;/a&gt; or
&lt;a href="http://www.webalizer.org/"&gt;Webalizer&lt;/a&gt; could be patched to lookup the
unique identifier in the &lt;span class="caps"&gt;JS&lt;/span&gt; stats data store, and ignore all hits which
were tracked that&amp;nbsp;way.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m going to start by looking into self-hosted open source alternatives
to Google Analytics, which I&amp;#8217;ll post about sometime hopefully&amp;nbsp;soon.&lt;/p&gt;</summary><category term="analytics"></category><category term="google"></category><category term="logging"></category><category term="statistics"></category><category term="stats"></category></entry><entry><title>World of Warcraft Realm Status Check Plugin for Nagios</title><link href="http://blog.jasonantman.com/2012/03/world-of-warcraft-realm-status-check-plugin-for-nagios/" rel="alternate"></link><updated>2012-03-16T07:40:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-16:2012/03/world-of-warcraft-realm-status-check-plugin-for-nagios/</id><summary type="html">&lt;p&gt;My wife &lt;a href="http://www.jackieantman.com/"&gt;Jackie&lt;/a&gt;
(&lt;a href="http://us.battle.net/wow/en/character/Arthas/Syrilia/simple"&gt;Syrilia&lt;/a&gt;)
is an avid &lt;a href="http://en.wikipedia.org/wiki/World_of_Warcraft"&gt;World of
Warcraft&lt;/a&gt; player (it&amp;#8217;s a
&lt;a href="http://en.wikipedia.org/wiki/Massively_multiplayer_online_role-playing_game"&gt;&lt;span class="caps"&gt;MMORPG&lt;/span&gt;&lt;/a&gt;
with over 10 million players). They have weekly server
maintenance/update windows every Tuesday morning - total downtime. The
length is never really fixed, so I looked around to see if there was a
logical way to notify when the servers came back&amp;nbsp;up.&lt;/p&gt;
&lt;p&gt;I managed to find a &lt;a href="http://exchange.nagios.org/directory/Plugins/Games/World-of-Warcraft-Realm-status/details"&gt;World of Warcraft Realm status check
plugin&lt;/a&gt;
on Nagios Exchange, but it was written to a now-discontinued &lt;span class="caps"&gt;API&lt;/span&gt;. It was
also last modified in 2008, and I can&amp;#8217;t seem to get in contact with the
author, Scott A&amp;#8217;Hearn (webmaster@scottahearn.com) - that email returns
undeliverable, there&amp;#8217;s no email link on the site that his domain now
redirects to, and the domain scottahearn.com is a (eek) private
registration in &lt;span class="caps"&gt;WHOIS&lt;/span&gt;, so I don&amp;#8217;t really have any way of finding contact
information. Regardless, I&amp;#8217;ve modified the script to use the &lt;a href="http://blizzard.github.com/api-wow-docs/#id3381933"&gt;new
Blizzard &lt;span class="caps"&gt;REST&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt;
and it&amp;#8217;s now working. Of course, this is pulling from Blizzard&amp;#8217;s data
feed, not doing any actual monitoring itself, and be warned that they
impose query limits (at the moment, their
&lt;a href="http://blizzard.github.com/api-wow-docs/#id3379836"&gt;docs&lt;/a&gt; say 3,000
requests per day for anonymous access; to be nice to them, I only check
on Tuesdays from 3am-4pm, when I&amp;#8217;m most concerned about it). The updated
source code is shown below, but the most up-to-date version will always
live&amp;nbsp;at  &lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_wow.pl"&gt;https://github.com/jantman/nagios-scripts/blob/master/check_wow.pl&lt;/a&gt;.
If you want, you can also see a diff of my changes to Scott&amp;#8217;s original
version on
&lt;a href="https://github.com/jantman/nagios-scripts/commit/f84eede5256aa6621812e91f0b3b73e91f3b11e8#check_wow.pl"&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!/usr/bin/perl -w&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# World of Warcraft Realm detector plugin for Nagios&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Written by Scott A&amp;#39;Hearn (webmaster@scottahearn.com), version 1.2, Last Modified: 07-21-2008&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Modified by Jason Antman  02-22-2012, to cope with the change from&lt;/span&gt;
&lt;span class="c1"&gt;# the deprecated worldofwarcraft.com &lt;span class="caps"&gt;XML&lt;/span&gt; feed to the BattleNet &lt;span class="caps"&gt;JSON&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Usage: ./check_wow -r &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Description:&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# This plugin will check the status of a World of Warcraft realm, based &lt;/span&gt;
&lt;span class="c1"&gt;# on input from the battle.net &lt;span class="caps"&gt;JSON&lt;/span&gt; realm status &lt;span class="caps"&gt;API&lt;/span&gt;.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Output:&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# If the realm is up, the plugin will&lt;/span&gt;
&lt;span class="c1"&gt;# return an &lt;span class="caps"&gt;OK&lt;/span&gt; state with a message containing the status of the realm as well &lt;/span&gt;
&lt;span class="c1"&gt;# as some extended information such as type (PvP, PvE, etc) and population.  &lt;/span&gt;
&lt;span class="c1"&gt;# If the realm is down, the plugin will return a &lt;span class="caps"&gt;CRITICAL&lt;/span&gt; state with a message&lt;/span&gt;
&lt;span class="c1"&gt;# containing the status of the realm as well as any available extended &lt;/span&gt;
&lt;span class="c1"&gt;# information such as type (PvP, PvE, etc) and population. If the realm is&lt;/span&gt;
&lt;span class="c1"&gt;# shown as currently having a queue, a &lt;span class="caps"&gt;WARNING&lt;/span&gt; state will be returned.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# If the requested realm is not found, the plugin will&lt;/span&gt;
&lt;span class="c1"&gt;# return an &lt;span class="caps"&gt;UNKNOWN&lt;/span&gt; state with an appropriate warning message.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# If there is an invalid [or no] response from the battle.net server,&lt;/span&gt;
&lt;span class="c1"&gt;# the plugin will return a &lt;span class="caps"&gt;CRITICAL&lt;/span&gt; state.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# $HeadURL: http://svn.jasonantman.com/public-nagios/check_wow.pl $&lt;/span&gt;
&lt;span class="c1"&gt;# $LastChangedRevision: 13 $&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Changelog:&lt;/span&gt;
&lt;span class="c1"&gt;# 2012-02-22 Jason Antman  (version 1.3):&lt;/span&gt;
&lt;span class="c1"&gt;#     * modified for new BattleNet &lt;span class="caps"&gt;JSON&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/span&gt;
&lt;span class="c1"&gt;#     * added &lt;span class="caps"&gt;WARNING&lt;/span&gt; output if realm has queue&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# 2008-07-21 Scott A&amp;#39;Hearn  (version 1.2):&lt;/span&gt;
&lt;span class="c1"&gt;#     * version on Nagios Exchange&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="c1"&gt;# use modules&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;strict&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;             &lt;span class="c1"&gt;# good coding practices&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="nn"&gt;Getopt::&lt;/span&gt;&lt;span class="n"&gt;Long&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;           &lt;span class="c1"&gt;# command-line option parsing&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;LWP&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;                &lt;span class="c1"&gt;# external content retrieval&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;JSON&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;                               &lt;span class="c1"&gt;# &lt;span class="caps"&gt;JSON&lt;/span&gt; for &lt;span class="caps"&gt;API&lt;/span&gt; reply&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;lib&lt;/span&gt;  &lt;span class="s"&gt;&amp;quot;/usr/lib/nagios/plugins&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;# nagios plugins&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;utils&lt;/span&gt; &lt;span class="sx"&gt;qw(%&lt;span class="caps"&gt;ERRORS&lt;/span&gt; &amp;amp;print_revision &amp;amp;support &amp;amp;usage )&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;# nagios error and message libraries&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="nn"&gt;Data::&lt;/span&gt;&lt;span class="n"&gt;Dumper&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;                       &lt;span class="c1"&gt;# debugging&lt;/span&gt;

&lt;span class="c1"&gt;# init global vars&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;vars&lt;/span&gt; &lt;span class="sx"&gt;qw($&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;check_wow&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$ver_string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$browser&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$jsonurl&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$raw_json&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$opt_V&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$opt_h&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$opt_r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;undef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;undef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;undef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;undef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;undef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;undef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;undef&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;undef&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nv"&gt;$jsonurl&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://us.battle.net/api/wow/realm/status?realm=&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$ver_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;1.3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="c1"&gt;# init subs&lt;/span&gt;
&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;print_help&lt;/span&gt; &lt;span class="p"&gt;($$);&lt;/span&gt;
&lt;span class="p"&gt;sub print_usage ($);&lt;/span&gt;

&lt;span class="p"&gt;# define command-line option handling&lt;/span&gt;
&lt;span class="p"&gt;Getopt::Long::Configure(&amp;#39;bundling&amp;#39;);&lt;/span&gt;
&lt;span class="p"&gt;GetOptions(&lt;/span&gt;
&lt;span class="p"&gt;    &amp;quot;V&amp;quot;   =&amp;gt; \$opt_V, &amp;quot;version&amp;quot; =&amp;gt; \$opt_V,&lt;/span&gt;
&lt;span class="p"&gt;    &amp;quot;h&amp;quot;   =&amp;gt; \$opt_h, &amp;quot;help&amp;quot;    =&amp;gt; \$opt_h,&lt;/span&gt;
&lt;span class="p"&gt;    &amp;quot;r=s&amp;quot; =&amp;gt; \$opt_r, &amp;quot;realm=s&amp;quot; =&amp;gt; \$opt_r);&lt;/span&gt;

&lt;span class="p"&gt;# show version info, exit&lt;/span&gt;
&lt;span class="p"&gt;if ($opt_V) {&lt;/span&gt;
    &lt;span class="n"&gt;print_revision&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$ver_string&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;OK&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# show help, exit&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$opt_h&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;print_help&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$ver_string&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;OK&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# get first command-line param&lt;/span&gt;
&lt;span class="nv"&gt;$opt_r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;shift&lt;/span&gt; &lt;span class="k"&gt;unless&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$opt_r&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;# if no command-line param passed, show usage/help, exit&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="nv"&gt;$opt_r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;print_usage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;UNKNOWN&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# new browser object, with agent&lt;/span&gt;
&lt;span class="nv"&gt;$browser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nn"&gt;&lt;span class="caps"&gt;LWP&lt;/span&gt;::&lt;/span&gt;&lt;span class="n"&gt;UserAgent&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="nv"&gt;$browser&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;check_wow/$ver_string&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;# retrieve &lt;span class="caps"&gt;JSON&lt;/span&gt; from WoW site&lt;/span&gt;
&lt;span class="nv"&gt;$jsonurl&lt;/span&gt; &lt;span class="o"&gt;.=&lt;/span&gt; &lt;span class="nv"&gt;$opt_r&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$raw_json&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$browser&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nn"&gt;&lt;span class="caps"&gt;HTTP&lt;/span&gt;::&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;&lt;span class="caps"&gt;GET&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$jsonurl&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$raw_json&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;is_success&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;# if success, process&lt;/span&gt;
    &lt;span class="nv"&gt;$raw_json&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$raw_json&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;# otherwise, fail &lt;span class="caps"&gt;UNKNOWN&lt;/span&gt;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;UNKNOWN&lt;/span&gt; - Realm &amp;#39;$opt_r&amp;#39; status not received.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;UNKNOWN&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nv"&gt;$decoded&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;decode_json&lt;/span&gt; &lt;span class="nv"&gt;$raw_json&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;CRITICAL&lt;/span&gt; - Realm &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; Down (&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;, population: &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;population&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;)\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;CRITICAL&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;elsif&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;WARNING&lt;/span&gt; - Realm &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; Has Queue (&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;, population: &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;population&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;)\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;WARNING&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;OK&lt;/span&gt; - Realm &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; Up (&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;, population: &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$decoded&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;realms&lt;/span&gt;&lt;span class="p"&gt;}[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;population&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;)\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;OK&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# usage function&lt;/span&gt;
&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;print_usage&lt;/span&gt; &lt;span class="p"&gt;($)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;@_&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Usage:\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  $&lt;span class="caps"&gt;PROGNAME&lt;/span&gt; [-r | --realm ]\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  $&lt;span class="caps"&gt;PROGNAME&lt;/span&gt; [-h | --help]\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  $&lt;span class="caps"&gt;PROGNAME&lt;/span&gt; [-V | --version]\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# help function&lt;/span&gt;
&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;print_help&lt;/span&gt; &lt;span class="p"&gt;($$)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$ver_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;@_&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;print_revision&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$ver_string&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Copyright (c) 2008 Scott A&amp;#39;Hearn, 2012 Jason Antman\n\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;print_usage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;   Standard World of Warcraft realm name, case sensitive.\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="c1"&gt;# support();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="blizzard"></category><category term="check plugin"></category><category term="monitoring"></category><category term="Nagios"></category><category term="warcraft"></category><category term="wow"></category></entry><entry><title>MediaWiki - Preformatted Text within Lists</title><link href="http://blog.jasonantman.com/2012/03/mediawiki-preformatted-text-within-lists/" rel="alternate"></link><updated>2012-03-15T18:10:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-15:2012/03/mediawiki-preformatted-text-within-lists/</id><summary type="html">&lt;p&gt;As I discovered this morning, with &lt;a href="http://www.mediawiki.org"&gt;MediaWiki&lt;/a&gt;
1.5.7+, if you attempt to put a &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; wraped block of code within a
numbered list, the indentation breaks and the numbering starts over
after the &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; block. This was pretty annoying, as I was trying to
document a procedure including the commands to be run and their
explanation. It took a few minutes, but I found the solution in the
&lt;a href="http://meta.wikimedia.org/wiki/Help:Editing_FAQ#Q:_Can_I_put_preformatted_text_inside_a_numbered_list.3F"&gt;wikimedia Help:Editing
&lt;span class="caps"&gt;FAQ&lt;/span&gt;&lt;/a&gt;
page, thanks to &lt;a href="http://meta.wikimedia.org/wiki/User:Rompe"&gt;Ulf Rompe&lt;/a&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# one
# two
#:
#:here are a couple lines
#:of preformatted text
#:
# and the numbering
# continues
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code lines are indented a bit more than what looks right, but it&amp;nbsp;works.&lt;/p&gt;</summary><category term="formatting"></category><category term="mediawiki"></category><category term="wiki"></category></entry><entry><title>Meld - Graphical Diff Tool for SVN Directories</title><link href="http://blog.jasonantman.com/2012/03/meld-graphical-diff-tool-for-svn-directories/" rel="alternate"></link><updated>2012-03-12T09:48:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-12:2012/03/meld-graphical-diff-tool-for-svn-directories/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been in the process of manually merging two directories in a
subversion repo. The second started out as a &amp;#8220;development&amp;#8221; copy of the
first (without branching, unfortunately). Since there&amp;#8217;s quite a few
files, I decided that a graphical diff program is a must. I usually use
&lt;a href="http://kdiff3.sourceforge.net"&gt;kdiff3&lt;/a&gt;, but my requirements for this
are a bit more stringent than usual: it has to handle recursive diffs on
two directories, and it has to be able to ignore &lt;span class="caps"&gt;SVN&lt;/span&gt; keywords (or an
arbitrary regex) since all of the files have keyword substitution on
LastChangedRevision and HeadURL. Kdiff3 supports &lt;a href="http://kdiff3.sourceforge.net/doc/preprocessors.html"&gt;preprocessor
commands&lt;/a&gt; which
can include filtering the text through sed before performing the diff
(so I modified their regex to ignore version control keywords), but for
some reason (perhaps either bimary differences, or metadata differences)
I couldn&amp;#8217;t get the file difference indicator in the diretory tree view
to reflect this; even when ignoring keyword lines and whitespace, it
still showed every pair of files as&amp;nbsp;different.&lt;/p&gt;
&lt;p&gt;Enter &lt;a href="http://meldmerge.org/"&gt;Meld&lt;/a&gt;, a graphical diff project. I&amp;#8217;ve only
used it for half an hour or so, but it seems wonderful. It&amp;#8217;s easy to
use, has a pleasing interface similar to
&lt;a href="http://www.caffeinated.me.uk/kompare/"&gt;Kompare&lt;/a&gt;, and even has simple
check boxes in the options menu to ignore whitespace and &lt;span class="caps"&gt;SVN&lt;/span&gt; keywords -
and they work! So far, I&amp;#8217;m about half way through my 300+ file tree, and
the merge is going&amp;nbsp;wonderfully.&lt;/p&gt;</summary><category term="diff"></category><category term="kde"></category><category term="kdiff"></category><category term="meld"></category><category term="merge"></category><category term="subversion"></category><category term="svn"></category></entry><entry><title>Using VirtualBox Remotely</title><link href="http://blog.jasonantman.com/2012/03/using-virtualbox-remotely/" rel="alternate"></link><updated>2012-03-09T12:00:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-09:2012/03/using-virtualbox-remotely/</id><summary type="html">&lt;p&gt;At work, I have a pretty beefy workstation (a Dell OptiPlex 990 with a
3.4GHz Intel Core i7-2600 and &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt; running Fedora 16) that I usually
run a few VMs on as my test/development environment. I usually reboot my
machine every other week or so, and start VirtualBox and my VMs once the
system boots. All of the VMs are Linux boxes, running test-only, so I
never really cared about &lt;span class="caps"&gt;RDP&lt;/span&gt; or anything like that. Today I&amp;#8217;m working
from home and need to setup a new development environment, so here&amp;#8217;s how
to get VirtualBox working nicely assuming you&amp;#8217;ve never set it up for
&lt;span class="caps"&gt;VRDP&lt;/span&gt; (its Virtual Remote Desktop Protocol) before, and have a network
connection (&lt;span class="caps"&gt;LAN&lt;/span&gt; or &lt;span class="caps"&gt;VPN&lt;/span&gt; or something) to the machine running VirtualBox.
I currently have VirtualBox &lt;span class="caps"&gt;OSE&lt;/span&gt; 4.1.8 installed from
&lt;a href="http://nonfree.rpmfusion.org/"&gt;rpmfusion&lt;/a&gt; &lt;span class="caps"&gt;RPM&lt;/span&gt;. Most of this can be
found in &lt;a href="http://www.virtualbox.org/manual/ch07.html"&gt;Chapter 7 of the VirtualBox
manual&lt;/a&gt;, but here&amp;#8217;s a
step-by-step&amp;nbsp;method.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First, download the Oracle (non-free) Oracle VirtualBox &lt;span class="caps"&gt;VM&lt;/span&gt; Extension
Pack tarball from the &lt;a href="https://www.virtualbox.org/wiki/Downloads"&gt;VirtualBox Downloads
Page&lt;/a&gt;, which provides &lt;span class="caps"&gt;VRDP&lt;/span&gt;
support (as well as support for the virtual &lt;span class="caps"&gt;USB&lt;/span&gt; 2.0 device, Intel &lt;span class="caps"&gt;PXE&lt;/span&gt;
Boot &lt;span class="caps"&gt;ROM&lt;/span&gt; support for the E1000 &lt;span class="caps"&gt;NIC&lt;/span&gt; driver, and experimental Linux host
&lt;span class="caps"&gt;PCI&lt;/span&gt; passthrough suport). Then install it&amp;nbsp;using:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;sudo VBoxManage extpack install Oracle_VM_VirtualBox_Extension_Pack-4.1.8-75467.vbox-extpack
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assuming you have an existing &lt;span class="caps"&gt;VM&lt;/span&gt; (you can list them using &lt;code&gt;VBoxManage list vms&lt;/code&gt;), enable &lt;span class="caps"&gt;VRDP&lt;/span&gt; support on&amp;nbsp;it:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;VBoxManage modifyvm &amp;quot;VM name&amp;quot; --vrde on
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I like to assign specific ports to &lt;span class="caps"&gt;VRDP&lt;/span&gt; on each &lt;span class="caps"&gt;VM&lt;/span&gt; so I can &amp;#8220;bookmark&amp;#8221;
them in my &lt;a href="http://kde.org/applications/internet/krdc/"&gt;&lt;span class="caps"&gt;KRDC&lt;/span&gt;&lt;/a&gt; client by
&lt;span class="caps"&gt;VM&lt;/span&gt; name. I generally start with 10011, as the 10011-10049 range is both
unassigned and doesn&amp;#8217;t appear in my &lt;code&gt;/etc/services&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;VBoxManage modifyvm &amp;quot;VM name&amp;quot; --vrdeport 10011
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the &lt;span class="caps"&gt;VM&lt;/span&gt;, using VBoxHeadless (shows more debugging/errors, but also
stays in the foreground, so you&amp;#8217;ll want to use
&lt;a href="http://www.gnu.org/software/screen/"&gt;screen&lt;/a&gt; or something like&amp;nbsp;it):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;VBoxHeadless --startvm &amp;quot;VM name&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If all went well, it should show some output including a confirmation
that the &lt;span class="caps"&gt;VRDE&lt;/span&gt; server is running on the correct&amp;nbsp;port:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Oracle VM VirtualBox Headless Interface 4.1.8_OSE
(C) 2008-2012 Oracle Corporation
All rights reserved.

VRDE server is listening on port 3389.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That&amp;#8217;s it. Assuming you&amp;#8217;re using something like
&lt;a href="http://www.gnu.org/software/screen/"&gt;screen&lt;/a&gt;, you can start a whole
bunch of new VMs, and still keep the VBoxHeadless output in case of an&amp;nbsp;error.&lt;/p&gt;</summary><category term="rdp"></category><category term="virtualbox"></category><category term="virtualization"></category><category term="vm"></category></entry><entry><title>Nagios Check Plugin for Linode Monthly Bandwidth Usage</title><link href="http://blog.jasonantman.com/2012/02/nagios-check-plugin-for-linode-monthly-bandwidth-usage/" rel="alternate"></link><updated>2012-02-29T20:32:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-29:2012/02/nagios-check-plugin-for-linode-monthly-bandwidth-usage/</id><summary type="html">&lt;p&gt;Since I have most of my public-facing stuff hosted with
&lt;a href="http://www.linode.com/?r=5c8ad2931b410b55455aadbcf0a8d86d6f698a91"&gt;Linode&lt;/a&gt;,
and I have a monthly bandwidth cap (albeit one that I&amp;#8217;ll probably never
come close to), I decided that it would be a good idea to add my monthly
bandwidth usage to my monitoring system. Luckily, Linode offers this
(their billing view of it - which is, of course, what I&amp;#8217;m concerned
about) via their &lt;a href="http://www.linode.com/api/"&gt;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt;, and it&amp;#8217;s very nicely
implemented in &lt;a href="http://michael.thegrebs.com/"&gt;Michael Greb&amp;#8217;s&lt;/a&gt;
&lt;a href="http://search.cpan.org/~mikegrb/WebService-Linode/"&gt;WebService::Linode&lt;/a&gt;
Perl (&lt;span class="caps"&gt;CPAN&lt;/span&gt;)&amp;nbsp;module.&lt;/p&gt;
&lt;p&gt;Using Michael&amp;#8217;s Perl module, I wrote
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_linode_transfer.pl"&gt;check_linode_transfer.pl&lt;/a&gt;
(github link) as a Nagios check plugin. It seems to be working fine for
me, and runs with the embedded perl interpreter, though it may not be
100% up to par with the Nagios plugin spec (for one, I used utils.pm
instead of
&lt;a href="http://search.cpan.org/~tonvoon/Nagios-Plugin-0.36/lib/Nagios/Plugin.pm"&gt;Nagios::Plugin&lt;/a&gt;).
About the only thing unusual is that I store my &lt;span class="caps"&gt;API&lt;/span&gt; keys in a perl
module, so you&amp;#8217;ll need to create something like this in your plugin
directory (usually &lt;code&gt;/usr/lib/nagios/plugins&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;package&lt;/span&gt; &lt;span class="n"&gt;api_keys&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="n"&gt;Exporter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;@&lt;span class="caps"&gt;ISA&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sx"&gt;qw(Exporter)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;@EXPORT_OK&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sx"&gt;qw($API_KEY_LINODE)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="nv"&gt;$API_KEY_LINODE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;yourApiKeyGoesHere&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The latest version of the plugin will always be available at
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_linode_transfer.pl"&gt;https://github.com/jantman/nagios-scripts/blob/master/check_linode_transfer.pl&lt;/a&gt;.
The current version is also below. It&amp;#8217;s free for anyone to use under the
terms of &lt;a href="http://www.gnu.org/licenses/gpl.html"&gt;&lt;span class="caps"&gt;GNU&lt;/span&gt; GPLv3&lt;/a&gt;, though I
would really like it if any changes/patches/updates are sent back to me
for inclusion in the latest&amp;nbsp;version.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#! /usr/bin/perl -w&lt;/span&gt;

&lt;span class="c1"&gt;# check_linode_transfer.pl Copyright (C) 2012 Jason Antman &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Define your Linode &lt;span class="caps"&gt;API&lt;/span&gt; key as $API_KEY_LINODE in api_keys.pm in the plugin library directory&lt;/span&gt;
&lt;span class="c1"&gt;#  a sample should be included in this distribution.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# This plugin requires WebService::Linode from &lt;span class="caps"&gt;CPAN&lt;/span&gt;, with a patch - add the following to the end of sub _error{} in Linode/Base.pm:&lt;/span&gt;
&lt;span class="c1"&gt;#  $self-&amp;gt;{err} = $err; $self-&amp;gt;{errstr} = $errstr;&lt;/span&gt;
&lt;span class="c1"&gt;# Also - bug in WebService::Linode::Base docs, example, line 3 should be:&lt;/span&gt;
&lt;span class="c1"&gt;#  my $data = $api-&amp;gt;do_request( api_action =&amp;gt; &amp;#39;domains.list&amp;#39; );&lt;/span&gt;
&lt;span class="c1"&gt;# not:&lt;/span&gt;
&lt;span class="c1"&gt;#  my $data = $api-&amp;gt;do_request( action =&amp;gt; &amp;#39;domains.list&amp;#39; );&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;##################################################################################&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# This program is free software; you can redistribute it and/or&lt;/span&gt;
&lt;span class="c1"&gt;# modify it under the terms of the &lt;span class="caps"&gt;GNU&lt;/span&gt; General Public License&lt;/span&gt;
&lt;span class="c1"&gt;# as published by the Free Software Foundation; either version 2&lt;/span&gt;
&lt;span class="c1"&gt;# of the License, or (at your option) any later version.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# This program is distributed in the hope that it will be useful,&lt;/span&gt;
&lt;span class="c1"&gt;# but &lt;span class="caps"&gt;WITHOUT&lt;/span&gt; &lt;span class="caps"&gt;ANY&lt;/span&gt; &lt;span class="caps"&gt;WARRANTY&lt;/span&gt;; without even the implied warranty&lt;/span&gt;
&lt;span class="c1"&gt;# of &lt;span class="caps"&gt;MERCHANTABILITY&lt;/span&gt; or &lt;span class="caps"&gt;FITNESS&lt;/span&gt; &lt;span class="caps"&gt;FOR&lt;/span&gt; A &lt;span class="caps"&gt;PARTICULAR&lt;/span&gt; &lt;span class="caps"&gt;PURPOSE&lt;/span&gt;.  See the&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;GNU&lt;/span&gt; General Public License for more details.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# you should have received a copy of the &lt;span class="caps"&gt;GNU&lt;/span&gt; General Public License&lt;/span&gt;
&lt;span class="c1"&gt;# along with this program (or with Nagios);  if not, write to the&lt;/span&gt;
&lt;span class="c1"&gt;# Free Software Foundation, Inc., 59 Temple Place - Suite 330,&lt;/span&gt;
&lt;span class="c1"&gt;# Boston, &lt;span class="caps"&gt;MA&lt;/span&gt; 02111-1307, &lt;span class="caps"&gt;USA&lt;/span&gt;&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;##################################################################################&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# The latest version of this plugin can always be obtained from:&lt;/span&gt;
&lt;span class="c1"&gt;#  $HeadURL$&lt;/span&gt;
&lt;span class="c1"&gt;#  $LastChangedRevision$&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;strict&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;English&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="nn"&gt;Getopt::&lt;/span&gt;&lt;span class="n"&gt;Long&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;vars&lt;/span&gt; &lt;span class="sx"&gt;qw($&lt;span class="caps"&gt;PROGNAME&lt;/span&gt; $&lt;span class="caps"&gt;REVISION&lt;/span&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;lib&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/usr/lib/nagios/plugins&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;utils&lt;/span&gt; &lt;span class="sx"&gt;qw (%&lt;span class="caps"&gt;ERRORS&lt;/span&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;print_revision&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;support&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;api_keys&lt;/span&gt; &lt;span class="sx"&gt;qw($API_KEY_LINODE)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="nn"&gt;WebService::&lt;/span&gt;&lt;span class="n"&gt;Linode&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="nn"&gt;Data::&lt;/span&gt;&lt;span class="n"&gt;Dumper&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;print_help&lt;/span&gt; &lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;sub print_usage ();&lt;/span&gt;

&lt;span class="p"&gt;my ($opt_c, $opt_w, $opt_h, $opt_V, $opt_s, $opt_S, $opt_l, $opt_H);&lt;/span&gt;
&lt;span class="p"&gt;my ($result, $message);&lt;/span&gt;

&lt;span class="p"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;=&amp;quot;check_linode_transfer.pl&amp;quot;;&lt;/span&gt;
&lt;span class="p"&gt;$&lt;span class="caps"&gt;REVISION&lt;/span&gt;=&amp;#39;1.0&amp;#39;;&lt;/span&gt;

&lt;span class="p"&gt;$opt_w = 60;&lt;/span&gt;
&lt;span class="p"&gt;$opt_c = 80;&lt;/span&gt;

&lt;span class="p"&gt;Getopt::Long::Configure(&amp;#39;bundling&amp;#39;);&lt;/span&gt;
&lt;span class="p"&gt;GetOptions(&lt;/span&gt;
&lt;span class="p"&gt;    &amp;quot;V&amp;quot;   =&amp;gt; \$opt_V, &amp;quot;version&amp;quot; =&amp;gt; \$opt_V,&lt;/span&gt;
&lt;span class="p"&gt;    &amp;quot;h&amp;quot;   =&amp;gt; \$opt_h, &amp;quot;help&amp;quot;    =&amp;gt; \$opt_h,&lt;/span&gt;
&lt;span class="p"&gt;    &amp;quot;w=f&amp;quot; =&amp;gt; \$opt_w, &amp;quot;warning=f&amp;quot; =&amp;gt; \$opt_w,&lt;/span&gt;
&lt;span class="p"&gt;    &amp;quot;c=f&amp;quot; =&amp;gt; \$opt_c, &amp;quot;critical=f&amp;quot; =&amp;gt; \$opt_c&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="p"&gt;if ($opt_V) {&lt;/span&gt;
    &lt;span class="n"&gt;print_revision&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;REVISION&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;OK&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$opt_h&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;print_help&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;OK&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nv"&gt;$result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;OK&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$api&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nn"&gt;WebService::&lt;/span&gt;&lt;span class="n"&gt;Linode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;apikey&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$API_KEY_LINODE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nowarn&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$api&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;do_request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;api_action&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;account.info&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nv"&gt;$result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;UNKNOWN&lt;/span&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;LINODE&lt;/span&gt; &lt;span class="caps"&gt;TRANSFER&lt;/span&gt; $result: &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;$api&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;errstr&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$result&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$used&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$pool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$pct&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;TRANSFER_USED&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;TRANSFER_POOL&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="nv"&gt;$pct&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$used&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nv"&gt;$pool&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$pct&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="nv"&gt;$opt_c&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="nv"&gt;$result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;CRITICAL&lt;/span&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;elsif&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$pct&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="nv"&gt;$opt_w&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="nv"&gt;$result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;WARNING&lt;/span&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;LINODE&lt;/span&gt; &lt;span class="caps"&gt;TRANSFER&lt;/span&gt; $result: $pct&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; of monthly bandwidth used ($used / $pool &lt;span class="caps"&gt;GB&lt;/span&gt;)|usedBW=$used; totalBW=$pool\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;ERRORS&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$result&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;print_usage&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Usage:\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  $&lt;span class="caps"&gt;PROGNAME&lt;/span&gt; [-w ] [-c ]\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  $&lt;span class="caps"&gt;PROGNAME&lt;/span&gt; [-h | --help]\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;  $&lt;span class="caps"&gt;PROGNAME&lt;/span&gt; [-V | --version]\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;print_help&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;print_revision&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PROGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;REVISION&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Copyright (c) 2012 Jason Antman\n\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;print_usage&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;    Percent of network transfer used\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;support&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="linode"></category><category term="monitoring"></category><category term="Nagios"></category><category term="plugin"></category></entry><entry><title>VMWare vSphere CLI and Perl SDK as an RPM</title><link href="http://blog.jasonantman.com/2012/02/vmware-vsphere-cli-and-perl-sdk-as-an-rpm/" rel="alternate"></link><updated>2012-02-28T19:01:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-28:2012/02/vmware-vsphere-cli-and-perl-sdk-as-an-rpm/</id><summary type="html">&lt;p&gt;Lately I&amp;#8217;ve been playing around with the VMWare &lt;a href="http://www.vmware.com/support/developer/viperltoolkit/"&gt;vSphere &lt;span class="caps"&gt;SDK&lt;/span&gt; for
Perl&lt;/a&gt;, since the
new job uses a bunch of VMWare stuff (and I&amp;#8217;ve been starting my foray
into Perl as a new language, and am amazed by the &lt;a href="http://www.cpan.org/"&gt;massive
number&lt;/a&gt; of modules out there). As much as I find
&lt;a href="http://yum.baseurl.org/"&gt;&lt;code&gt;yum&lt;/code&gt;&lt;/a&gt; limiting having used
&lt;a href="http://en.opensuse.org/Portal:Zypper"&gt;&lt;code&gt;zypper&lt;/code&gt;&lt;/a&gt; on OpenSuSE, I&amp;#8217;m not
much of a fan of non-natively-packaged software. Not only is it more
difficult to maintain and upgrade a system and nearly impossible to
nicely automate when building from source (or a proprietary installer
script), it&amp;#8217;s also much more difficult to transition from a development
environment to&amp;nbsp;production.&lt;/p&gt;
&lt;p&gt;In a quick search, I found a perfectly working spec file and some
&lt;span class="caps"&gt;RHEL&lt;/span&gt;/Cent-specific patches (and even beginner-level &lt;code&gt;rpmbuild&lt;/code&gt;
instructions) for the current 5.0.0-422456 VMWare &lt;span class="caps"&gt;CLI&lt;/span&gt; and Perl &lt;span class="caps"&gt;SDK&lt;/span&gt; for
x86_64 at
&lt;a href="http://www.firetooth.net/confluence/display/public/vSphere+Perl+SDK+and+CLI+RPM+Packages"&gt;http://www.firetooth.net/confluence/display/public/vSphere+Perl+&lt;span class="caps"&gt;SDK&lt;/span&gt;+and+&lt;span class="caps"&gt;CLI&lt;/span&gt;+&lt;span class="caps"&gt;RPM&lt;/span&gt;+Packages&lt;/a&gt;.
Many thanks to &lt;a href="http://www.linkedin.com/in/vwhitteron"&gt;Vaughan
Whitteron&lt;/a&gt; of &lt;span class="caps"&gt;NSW&lt;/span&gt; in Australia
for posting this! It built and installed without any problems on my
Fedora 16 desktop, and a CentOS 6.2 development&amp;nbsp;box.&lt;/p&gt;</summary><category term="perl"></category><category term="rpm"></category><category term="vcli"></category><category term="vmware"></category><category term="vsphere"></category></entry><entry><title>Nagios / Icinga Configuration Highlighting with GeSHi</title><link href="http://blog.jasonantman.com/2012/02/nagios-icinga-configuration-highlighting-with-geshi/" rel="alternate"></link><updated>2012-02-28T18:42:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-28:2012/02/nagios-icinga-configuration-highlighting-with-geshi/</id><summary type="html">&lt;p&gt;As you may know from former posts, this blog
(&lt;a href="http://wordpress.org"&gt;WordPress&lt;/a&gt;-powered) and a few
&lt;a href="http://www.mediawiki.org"&gt;MediaWiki&lt;/a&gt; sites that I have use the
excellent &lt;span class="caps"&gt;PHP&lt;/span&gt;-based &lt;a href="http://qbnz.com/highlighter/"&gt;GeSHi&lt;/a&gt; syntax
highlighter. Today I was writing &lt;a href="/2012/02/sending-aim-messages-from-a-perl-script/"&gt;a
post&lt;/a&gt; that includes
some Icinga (Nagios) configuration snippets. After a quick search, I
found a &lt;a href="https://github.com/adepertat/geshi-nagios"&gt;Nagios language file for
GeSHi&lt;/a&gt; on GitHub. Thanks very
much to &lt;a href="https://github.com/adepertat"&gt;Albéric de Pertat (adepertat)&lt;/a&gt;
for writing this and providing it to the&amp;nbsp;public.&lt;/p&gt;</summary><category term="GeSHi"></category><category term="icinga"></category><category term="mediawiki"></category><category term="Nagios"></category><category term="PHP"></category><category term="wordpress"></category></entry><entry><title>Sending AOL Instant Messenger (AIM) Messages from a Perl Script</title><link href="http://blog.jasonantman.com/2012/02/sending-aim-messages-from-a-perl-script/" rel="alternate"></link><updated>2012-02-28T18:33:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-28:2012/02/sending-aim-messages-from-a-perl-script/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been doing some work on &lt;a href="http://www.icinga.org"&gt;icinga&lt;/a&gt; (a Nagios
fork) and wanted to implement notification via &lt;span class="caps"&gt;AOL&lt;/span&gt; Instant Messenger
(&lt;span class="caps"&gt;AIM&lt;/span&gt;), since I&amp;#8217;m almost always signed on when I&amp;#8217;m at a computer.
Unfortunately, most of the
&lt;a href="http://vuksan.com/linux/nagios_scripts.html#send_aim_messages"&gt;scripts&lt;/a&gt;
that I could find use
&lt;a href="http://search.cpan.org/~friffin/Net-AIM-TOC-0.97/TOC.pm"&gt;Net::&lt;span class="caps"&gt;AIM&lt;/span&gt;::&lt;span class="caps"&gt;TOC&lt;/span&gt;&lt;/a&gt;
which implements a now-defunct protocol. So, I found Perl&amp;#8217;s
&lt;a href="http://search.cpan.org/~toddr/Net-OSCAR-1.928/lib/Net/OSCAR.pm"&gt;Net::&lt;span class="caps"&gt;OSCAR&lt;/span&gt;&lt;/a&gt;
and &lt;a href="http://moo.net/code/aim.html"&gt;James Nonnemaker&amp;#8217;s script&lt;/a&gt;, and
decided to rework them into something a bit more&amp;nbsp;full-featured.&lt;/p&gt;
&lt;p&gt;The below script sends a single &lt;span class="caps"&gt;IM&lt;/span&gt; to a single contact via the command
line (using a specified &lt;span class="caps"&gt;AIM&lt;/span&gt; username and password). It&amp;#8217;s intended to be
a Nagios notification script (using the configurations shown below), but
could be used for any purpose. The most up-to-date version of the script
will be available at:
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/send_aim.pl"&gt;github.com/jantman/public-nagios/master/send_aim.pl&lt;/a&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!/usr/bin/perl&lt;/span&gt;

&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Script to send &lt;span class="caps"&gt;AIM&lt;/span&gt; messages from the command line&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Copyright 2012 Jason Antman  &lt;/span&gt;
&lt;span class="c1"&gt;# based on the simple version (C) 2008 James Nonnemaker / james[at]ustelcom[dot]net &lt;/span&gt;
&lt;span class="c1"&gt;#    found at: &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# The canonical, up-to-date version of this script can be found at:&lt;/span&gt;
&lt;span class="c1"&gt;#  &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# For updates, news, etc., see:&lt;/span&gt;
&lt;span class="c1"&gt;#  &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# $HeadURL$&lt;/span&gt;
&lt;span class="c1"&gt;# $LastChangedRevision$&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;strict&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;warnings&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="nn"&gt;Net::&lt;/span&gt;&lt;span class="n"&gt;&lt;span class="caps"&gt;OSCAR&lt;/span&gt;&lt;/span&gt; &lt;span class="sx"&gt;qw(:standard)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="nn"&gt;Getopt::&lt;/span&gt;&lt;span class="n"&gt;Long&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$screenname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$passwd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$ToSn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$Msg&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERSION&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;r17&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GetOptions&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;screenname=s&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;\&lt;/span&gt;&lt;span class="nv"&gt;$screenname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="s"&gt;&amp;quot;password=s&amp;quot;&lt;/span&gt;   &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;\&lt;/span&gt;&lt;span class="nv"&gt;$passwd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="s"&gt;&amp;quot;to=s&amp;quot;&lt;/span&gt;         &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;\&lt;/span&gt;&lt;span class="nv"&gt;$ToSn&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="nv"&gt;$screenname&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="nv"&gt;$passwd&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="nv"&gt;$ToSn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;send_aim.pl $&lt;span class="caps"&gt;VERSION&lt;/span&gt; by Jason Antman \n\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: send_aim.pl --screenname= --password= --to=\n\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# slurp message from &lt;span class="caps"&gt;STDIN&lt;/span&gt;&lt;/span&gt;
&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$holdTerminator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="vg"&gt;$/&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;undef&lt;/span&gt; &lt;span class="vg"&gt;$/&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$Msg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="vg"&gt;$/&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$holdTerminator&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;@lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;split&lt;/span&gt; &lt;span class="sr"&gt;/$holdTerminator/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$Msg&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$Msg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;init&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$Msg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;join&lt;/span&gt; &lt;span class="nv"&gt;$holdTerminator&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;@lines&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$oscar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nn"&gt;Net::&lt;/span&gt;&lt;span class="n"&gt;&lt;span class="caps"&gt;OSCAR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;loglevel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;signon&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$screenname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$passwd&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;set_callback_snac_unknown&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;\&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;snac_unknown&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;set_callback_im_ok&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;\&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;log_out&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;set_callback_signon_done&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;\&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;do_it&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;do_one_loop&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;do_it&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;send_im&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$ToSn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$Msg&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;log_out&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;signoff&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;sub &lt;/span&gt;&lt;span class="nf"&gt;snac_unknown&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$oscar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$connection&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$snac&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;@_&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="c1"&gt;# just use this to override the default snac_unknown handler, which prints a data dump of the packet&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The command line usage is pretty simple - it takes the message to send
on stdin and parameters for the sender&amp;#8217;s screen name and password, and
the recipient&amp;#8217;s screen name,&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;Hello\nworld\n&amp;quot;&lt;/span&gt; | send_aim.pl --screenname&lt;span class="o"&gt;=&lt;/span&gt;mySN --password&lt;span class="o"&gt;=&lt;/span&gt;myPass --to&lt;span class="o"&gt;=&lt;/span&gt;recipientSN
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The Icinga configs that I used for this are as follows. I just used the
default Icinga 1.6 notify by email commands, since &lt;span class="caps"&gt;AIM&lt;/span&gt; should handle the
full length&amp;nbsp;fine.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# host notification command
define command{
        command_name    notify-host-by-aim
        command_line    /usr/bin/printf &amp;quot;%b&amp;quot; &amp;quot;***** Icinga *****\n\nNotification Type: $NOTIFICATIONTYPE$\nHost: $HOSTNAME$\nState: $HOSTSTATE$\nAddress: $HOSTADDRESS$\nInfo: $HOSTOUTPUT$\n\nDate/Time: $LONGDATETIME$\n&amp;quot; | /usr/lib/nagios/plugins/notification/send_aim.pl --screenname=mySN --password=myPass --to=$CONTACTADDRESS1$
}

# service notification command
define command{
        command_name    notify-service-by-aim
        command_line    /usr/bin/printf &amp;quot;%b&amp;quot; &amp;quot;***** Icinga *****\n\nNotification Type: $NOTIFICATIONTYPE$\n\nService: $SERVICEDESC$\nHost: $HOSTALIAS$\nAddress: $HOSTADDRESS$\nState: $SERVICESTATE$\n\nDate/Time: $LONGDATETIME$\n\nAdditional Info:\n\n$SERVICEOUTPUT$\n&amp;quot; | /usr/lib/nagios/plugins/notification/send_aim.pl --screenname=mySN --password=myPass --to=$CONTACTADDRESS1$
}

# example contact
define contact{
        contact_name                    joeadmin
        alias                           Joe Admin
        use                             generic-with-AIM-contact
        email                           joeadmin@example.com
        pager                           5555555555@vtext.com
        address1                        joeAdminSN ; AIM screen name
}
&lt;/pre&gt;&lt;/div&gt;</summary><category term="aim"></category><category term="aol"></category><category term="icinga"></category><category term="instant messenger"></category><category term="Nagios"></category><category term="notifications"></category><category term="perl"></category></entry><entry><title>The state of Puppet External Node Classifiers</title><link href="http://blog.jasonantman.com/2012/02/the-state-of-puppet-external-node-classifiers/" rel="alternate"></link><updated>2012-02-26T12:45:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-26:2012/02/the-state-of-puppet-external-node-classifiers/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update November 2013&lt;/strong&gt;: This post has brought an amazing amount of
traffic to my blog, probably because it still seems to be one of the
only &lt;span class="caps"&gt;ENC&lt;/span&gt; comparisons out there. Both Dashboard (and Puppet Enterprise
Console) and The Foreman have changed quite a bit since I wrote this.
Foreman has certainly been developed at warp speed. I&amp;#8217;ll try to write an
update to this sometime soon, but be advised that the information here
is somewhat&amp;nbsp;dated.&lt;/p&gt;
&lt;p&gt;At work, we&amp;#8217;re in the process of rolling out
&lt;a href="http://projects.puppetlabs.com/projects/puppet"&gt;puppet&lt;/a&gt; for
configuration management of our servers. It will be an integral part of
the provisioning process of all new physical and virtual hosts, and will
also be phased in on existing hosts as possible. Right now, we have an
initial puppet install that was &amp;#8220;development&amp;#8221;, but we&amp;#8217;re about to move
to &amp;#8220;production&amp;#8221; (new puppetmaster in our production infrastructure,
production MySQL, etc.). We&amp;#8217;ve been using
&lt;a href="http://puppetlabs.com/puppet/related-projects/dashboard/"&gt;Dashboard&lt;/a&gt;,
but just as a report viewer. Up until now, we&amp;#8217;ve been using nodes.pp and
per-node flat-file manifests. I&amp;#8217;ve got a few issues with this, but the
biggest is that all of our node definitions (and their classes and
parameters) live in the same &lt;span class="caps"&gt;SVN&lt;/span&gt; repository as our modules and other
puppet configuration. Not only does this mean a checkout and commit just
to change a node parameter or add a module/class to a node, but it also
means that for my team members who don&amp;#8217;t have previous puppet
experience, it greatly blurs the line between administering puppet
(developing and maintaining modules) and using puppet (building a node,
changing node params or modules/classes), since both tasks are
accomplished in the same &lt;span class="caps"&gt;SVN&lt;/span&gt;&amp;nbsp;repository.&lt;/p&gt;
&lt;p&gt;So, I&amp;#8217;ve been pushing an &lt;a href="http://docs.puppetlabs.com/guides/external_nodes.html"&gt;External Node Classifier
(&lt;span class="caps"&gt;ENC&lt;/span&gt;)&lt;/a&gt; with a web
interface as one of the biggest feature enhancements we need for our
puppet install. The complicating factor is that I&amp;#8217;ve been given a time
frame of approximately 1 week to get the &amp;#8220;production&amp;#8221; puppetmaster
running on our production infrastructure and marked as &amp;#8220;done&amp;#8221;. That
includes the &lt;span class="caps"&gt;ENC&lt;/span&gt;. At my last gig, at Rutgers University, I wrote our &lt;span class="caps"&gt;ENC&lt;/span&gt;
in &lt;span class="caps"&gt;PHP&lt;/span&gt; (actually I wrote it for my half-dozen or so boxes at home, and
brought it to Rutgers gratis), and it also handled kickstart file
distribution and &lt;span class="caps"&gt;PXE&lt;/span&gt; configuration, and was extended to also set &lt;span class="caps"&gt;DHCP&lt;/span&gt;
and &lt;span class="caps"&gt;DNS&lt;/span&gt; for the hosts - a one-stop solution. Unfortunately the code is
very organization-specific, not terribly solid, and the &lt;span class="caps"&gt;UI&lt;/span&gt; looks awful,
so it&amp;#8217;s not a fit for the current employer. So I have to find something
else that fits the bill. I have a list of initial (&amp;#8220;phase 1&amp;#8221;)
requirements that are a mix of functionality that we require and
management&amp;nbsp;requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Must support environments, since we make use of&amp;nbsp;them.&lt;/li&gt;
&lt;li&gt;Must support default values for parameters based on environment,
    &amp;#8220;zone&amp;#8221; (a custom fact and variable we define), or a combination of&amp;nbsp;both.&lt;/li&gt;
&lt;li&gt;For accountability and legal reasons, must have full auditing of all
    changes by all users (and, obviously, support&amp;nbsp;authentication).&lt;/li&gt;
&lt;li&gt;Display node last run time and&amp;nbsp;status.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As well as at least the ability to implement some of our phase 2&amp;nbsp;requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ability to show modules and classes applied to a node, including
    those required/included through other&amp;nbsp;modules/classes/roles.&lt;/li&gt;
&lt;li&gt;Should support at least some level of puppet report&amp;nbsp;display.&lt;/li&gt;
&lt;li&gt;Ability to trigger a node run (kick) from the&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Some level of permission separation, &lt;span class="caps"&gt;ACL&lt;/span&gt; or &lt;span class="caps"&gt;RBAC&lt;/span&gt; so that we could
    potentially delegate control of a certain module or parameter, on a
    certain group of nodes, to the development&amp;nbsp;team.&lt;/li&gt;
&lt;li&gt;Per-node links to other tools such as Icinga/Nagios or our&amp;nbsp;wiki.&lt;/li&gt;
&lt;li&gt;Some way of detecting valid classes and modules (and our &amp;#8220;role&amp;#8221;
    module) per-environment (i.e. available modules/classes/roles should
    be pulled from the configs, not manually&amp;nbsp;entered).&lt;/li&gt;
&lt;li&gt;Ability to display puppet docs from&amp;nbsp;modules/classes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our current situation makes this even more difficult: we&amp;#8217;re an
operations team of five (hiring at the moment to fill the position of
the sixth), and I believe I&amp;#8217;m the only member of the team with any real
software development experience. And none of us have experience with
Ruby (which Puppet and most of its universe is written in). This means
that any in-house solution runs the risk of being unmaintainable should
I get hit by a bus (some of our team have various levels of experience
with Perl and other scripting languages, but not really from an app
development perspective). Because of these reasons, there&amp;#8217;s a management
aversion to anything that we code ourselves (well, these reasons, and
the fact that with a shorthanded team we don&amp;#8217;t have much time for
projects without an immediate&amp;nbsp;impact).&lt;/p&gt;
&lt;p&gt;So, I spent hours looking around online trying to find existing
web-based &lt;span class="caps"&gt;ENC&lt;/span&gt; projects, and came up with a pretty small&amp;nbsp;list:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://puppetlabs.com/puppet/related-projects/dashboard/"&gt;Dashboard&lt;/a&gt;,
    the Puppet Labs web &lt;span class="caps"&gt;UI&lt;/span&gt;. It&amp;#8217;s the most common web-based puppet &lt;span class="caps"&gt;ENC&lt;/span&gt; as
    far as I know, and since it&amp;#8217;s an official Puppet Labs project (and
    the basis for their Puppet Enterprise &lt;span class="caps"&gt;UI&lt;/span&gt;), its future is pretty
    secure. But it&amp;#8217;s still very basic (let alone enterprise features),
    and has a plugin system that is very&amp;nbsp;young.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://theforeman.org/projects/foreman"&gt;The Foreman&lt;/a&gt; is probably
    the second-most-common puppet &lt;span class="caps"&gt;ENC&lt;/span&gt;, and has also been around about as
    long as Dashboard. Its features are nice, and it includes support
    for Kickstart (management of &lt;span class="caps"&gt;TFTP&lt;/span&gt; and &lt;span class="caps"&gt;DHCP&lt;/span&gt;) and &lt;span class="caps"&gt;DNS&lt;/span&gt;, as well as some
    virtual machine management. Unfortunately, we already have &lt;span class="caps"&gt;DHCP&lt;/span&gt; and
    &lt;span class="caps"&gt;DNS&lt;/span&gt; infrastructure so I&amp;#8217;m sure it would be quite a bit of effort to
    integrate it with our environment, and for a non-Ruby shop, it has
    the same problem with maintainability of custom&amp;nbsp;code.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ingent.net/projects/initr/wiki"&gt;initr&lt;/a&gt;, a
    &lt;a href="http://www.redmine.org/"&gt;Redmine&lt;/a&gt; plugin that functions as an &lt;span class="caps"&gt;ENC&lt;/span&gt;
    and manages modules. It includes &lt;span class="caps"&gt;RBAC&lt;/span&gt; and leverages Redmine. But
    since we don&amp;#8217;t use Redmine, it&amp;#8217;s not much of an&amp;nbsp;advantage.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.gitorious.org/opennms-puppet-node-pusher"&gt;OpenNMS Puppet Node
    Pusher&lt;/a&gt;An &lt;span class="caps"&gt;ENC&lt;/span&gt;
    script for &lt;a href="http://www.opennms.org/"&gt;OpenNMS&lt;/a&gt;, which we also don&amp;#8217;t&amp;nbsp;use.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was pretty amazed to see that nobody had written a puppet web &lt;span class="caps"&gt;UI&lt;/span&gt;/&lt;span class="caps"&gt;ENC&lt;/span&gt;
in &lt;span class="caps"&gt;PHP&lt;/span&gt; (or Perl or Python), especially since Puppet is now quite&amp;nbsp;popular.&lt;/p&gt;
&lt;p&gt;So, I&amp;#8217;m essentially left with the following&amp;nbsp;options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start from scratch and write my own in &lt;span class="caps"&gt;PHP&lt;/span&gt;. By far the worst option,
    since we don&amp;#8217;t have anyone on our team who&amp;#8217;s likely to maintain it,
    and the Puppet community is&amp;nbsp;Ruby-focused.&lt;/li&gt;
&lt;li&gt;Use Foreman, since it&amp;#8217;s the only one that appears to offer audit
    logging, have a bunch of features that don&amp;#8217;t work for us, and
    hopefully deal with&amp;nbsp;it.&lt;/li&gt;
&lt;li&gt;Learn Ruby, write plugins for Dashboard, and hope that Puppet Labs
    or someone else will pick them up and maintain them if I&amp;nbsp;can&amp;#8217;t.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the moment, I&amp;#8217;ve decided to investigate Foreman and initr in a bit
more depth, and also play around with the Dashboard code and try to pick
up some Ruby (as they&amp;#8217;re all written in Ruby anyway). I&amp;#8217;ll also discuss
these options with the team and see how opinions go (keeping in mind
that the higher the likelihood of the community picking up/merging my
changes, the&amp;nbsp;better).&lt;/p&gt;</summary><category term="dashboard"></category><category term="foreman"></category><category term="node classifier"></category><category term="puppet"></category></entry><entry><title>Petit for Log Analysis</title><link href="http://blog.jasonantman.com/2012/02/petit-for-log-analysis/" rel="alternate"></link><updated>2012-02-21T11:57:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-21:2012/02/petit-for-log-analysis/</id><summary type="html">&lt;p&gt;I recently discovered the
&lt;a href="http://crunchtools.com/software/petit/"&gt;petit&lt;/a&gt; program for log
analysis. It&amp;#8217;s a simple tool to pull out useful information from syslog
logs in a variety of ways. I&amp;#8217;ve only used it a few times so far, mainly
on logs from problems I&amp;#8217;ve already solved but didn&amp;#8217;t know the cause of
at first. So far, it&amp;#8217;s proven quite useful. Here are a few&amp;nbsp;examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;petit --wordcount /var/log/messages&lt;/code&gt; - displays ordered count of
    words appearing in the log. My first step, especially if &amp;#8220;warning&amp;#8221;,
    &amp;#8220;error&amp;#8221; or &amp;#8220;fatal&amp;#8221; shows up near the&amp;nbsp;top&amp;#8230;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;petit --hash --fingerprint /var/log/messages&lt;/code&gt; - hashes the log,
    removes filters (such as numerics, datestamp), and displays count of
    matching lines. Absolutely wonderful for web error logs, as it
    removes client &lt;span class="caps"&gt;IP&lt;/span&gt; addresses, line numbers,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;petit --mgraph /var/log/messages&lt;/code&gt; - graph messages per minute for
    the first hour of the log (&lt;span class="caps"&gt;ASCII&lt;/span&gt; of&amp;nbsp;course)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;petit --hgraph /var/log/messages&lt;/code&gt; - same as above, but messages per
    hour for the first&amp;nbsp;day&lt;/li&gt;
&lt;li&gt;Petit will also read from stdin with the &amp;#8212;Xgraph options, so you
    can &lt;code&gt;cat logfile | grep word | petit --mgraph&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Just one note - this tool appears to work only on standard syslog
formatted logs. If some non-datestamped lines managed to work their way
into the log (i.e. someone used echo &gt;&gt; logfile instead of &lt;code&gt;logger&lt;/code&gt;),
it will&amp;nbsp;choke.&lt;/p&gt;
&lt;p&gt;Many thanks to Scott McCarty for this wonderful&amp;nbsp;tool!&lt;/a&gt;&lt;/p&gt;</summary><category term="analysis"></category><category term="log"></category><category term="logging"></category><category term="petit"></category><category term="syslog"></category></entry><entry><title>F5 BigIp - Manually Changing Session Persistence Cookies on the Client Side</title><link href="http://blog.jasonantman.com/2012/02/f5-bigip-manually-changing-session-persistence-cookies-on-the-client-side/" rel="alternate"></link><updated>2012-02-03T13:32:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-03:2012/02/f5-bigip-manually-changing-session-persistence-cookies-on-the-client-side/</id><summary type="html">&lt;p&gt;Yesterday I was asked to help out a bit debugging issues with a site
that sits behind a &lt;a href="http://www.f5.com/products/big-ip/"&gt;F5 &lt;span class="caps"&gt;BIG&lt;/span&gt;-&lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/a&gt; load
balancer (&lt;span class="caps"&gt;LB&lt;/span&gt;). It&amp;#8217;s a pretty simple site, load balanced between two web
servers. The developers were complaining about intermittent page load
issues, so I immediately considered a problem with one of the two
servers (&lt;em&gt;ass&lt;/em&gt;uming that the devs were clearing cookies and cache
between attempts). The &lt;span class="caps"&gt;LB&lt;/span&gt; is using &lt;span class="caps"&gt;HTTP&lt;/span&gt; Cookies for client session
persistence, but no matter how many times I cleared my cookies, I kept
being sent to the same back-end server. I know I could have added an
iRule to the &lt;span class="caps"&gt;LB&lt;/span&gt;, but it seems like bad practice to change a production
configuration for debugging something like&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;If your site uses a BigIp with cookies for persistence, it&amp;#8217;s no problem
to edit the cookies manually to force yourself to another back-end
server. Simply look through the cookies for a given site using something
like the &lt;a href="https://addons.mozilla.org/en-US/firefox/addon/web-developer/"&gt;Web Developer addon for
Firefox&lt;/a&gt;;
the BigIp cookie is named like &amp;#8220;BigIpServer&amp;lt;poolname&gt;&amp;#8221;. The encoding
information is specified by F5 in their knowledge base &lt;a href="http://support.f5.com/kb/en-us/solutions/public/6000/900/sol6917.html"&gt;sol6917:
Overview of &lt;span class="caps"&gt;BIG&lt;/span&gt;-&lt;span class="caps"&gt;IP&lt;/span&gt; persistence cookie
encoding&lt;/a&gt;.
I also managed to find a Perl one-liner from Tyler Krpata, Manger of
Security Engineering at Constant Contact, &lt;a href="http://www.tylerkrpata.com/2009/06/decode-f5-bigip-cookie-in-one-line-of.html"&gt;in a post on his
blog&lt;/a&gt;.
I built on that work to develop the following perl script, which can
both encode and decode BigIP cookie &lt;span class="caps"&gt;IP&lt;/span&gt;/port values. The latest version lives
on my &lt;a href="https://github.com/jantman/misc-scripts/blob/master/bigipcookie.pl"&gt;GitHub misc-scripts repository&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!/usr/bin/perl&lt;/span&gt;

&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Perl script to de/encode F5 BigIp persistence cookies.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# The latest version of this script can always be obtained from:&lt;/span&gt;
&lt;span class="c1"&gt;#    via &lt;span class="caps"&gt;HTTP&lt;/span&gt; ot &lt;span class="caps"&gt;SVN&lt;/span&gt;&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Update information and description can be found at:&lt;/span&gt;
&lt;span class="c1"&gt;#   &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Copyright 2012 Jason Antman  .&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#########################################################################################&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;LICENSE&lt;/span&gt;: AGPLv3 &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#    This program is free software: you can redistribute it and/or modify&lt;/span&gt;
&lt;span class="c1"&gt;#    it under the terms of the &lt;span class="caps"&gt;GNU&lt;/span&gt; Affero General Public License as published by&lt;/span&gt;
&lt;span class="c1"&gt;#    the Free Software Foundation, either version 3 of the License, or&lt;/span&gt;
&lt;span class="c1"&gt;#    (at your option) any later version.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#    This program is distributed in the hope that it will be useful,&lt;/span&gt;
&lt;span class="c1"&gt;#    but &lt;span class="caps"&gt;WITHOUT&lt;/span&gt; &lt;span class="caps"&gt;ANY&lt;/span&gt; &lt;span class="caps"&gt;WARRANTY&lt;/span&gt;; without even the implied warranty of&lt;/span&gt;
&lt;span class="c1"&gt;#    &lt;span class="caps"&gt;MERCHANTABILITY&lt;/span&gt; or &lt;span class="caps"&gt;FITNESS&lt;/span&gt; &lt;span class="caps"&gt;FOR&lt;/span&gt; A &lt;span class="caps"&gt;PARTICULAR&lt;/span&gt; &lt;span class="caps"&gt;PURPOSE&lt;/span&gt;.  See the&lt;/span&gt;
&lt;span class="c1"&gt;#    &lt;span class="caps"&gt;GNU&lt;/span&gt; Affero General Public License for more details.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#    You should have received a copy of the &lt;span class="caps"&gt;GNU&lt;/span&gt; Affero General Public License&lt;/span&gt;
&lt;span class="c1"&gt;#    along with this program.  If not, see .&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# If you make any modifications/fixes/feature additions, it would be greatly appreciated&lt;/span&gt;
&lt;span class="c1"&gt;# if you send them back to me at the above email address.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#########################################################################################&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;CREDITS&lt;/span&gt;:&lt;/span&gt;
&lt;span class="c1"&gt;# - F5 itself for the formula: &lt;/span&gt;
&lt;span class="c1"&gt;# - Tyler Krpata &lt;/span&gt;
&lt;span class="c1"&gt;#     for the Perl one-liner that this logic is based on.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# $HeadURL: http://svn.jasonantman.com/misc-scripts/bigipcookie.pl $&lt;/span&gt;
&lt;span class="c1"&gt;# $LastChangedRevision: 27 $&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Changelog:&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# 2012-02-02 Jason Antman :&lt;/span&gt;
&lt;span class="c1"&gt;#   - initial version&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;strict&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;warnings&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="nv"&gt;$#&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: bigipcookie.pl \n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt; &lt;span class="sr"&gt;m/^(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3}):(\d+)$/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$ipEnc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$3&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$portEnc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;hex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;join&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reverse&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;sprintf&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%04x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt;&lt;span class="sr"&gt; /../g&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$ipEnc.$portEnc.0000\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;elsif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt; &lt;span class="sr"&gt;m/^(\d+)\.(\d+)\.0000$/&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="c1"&gt;# decode a cookie value&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$ipEnc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$portEnc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;join&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;map&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;hex&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nb"&gt;reverse&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;sprintf&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%08x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;split&lt;/span&gt; &lt;span class="sr"&gt;/\./&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$ipEnc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt;&lt;span class="sr"&gt; /../g&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$portDec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;hex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;join&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reverse&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;sprintf&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%04x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$portEnc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt;&lt;span class="sr"&gt; /../g&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$ip:$portDec\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: bigipcookie.pl \n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;An example of the&amp;nbsp;usage:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;jantman@palantir:pts/8:~/bin/misc-scripts &amp;gt; ./bigipcookie.pl 192.168.23.50:80&lt;/span&gt;
&lt;span class="go"&gt;840411328.20480.0000&lt;/span&gt;
&lt;span class="go"&gt;jantman@palantir:pts/8:~/bin/misc-scripts &amp;gt; ./bigipcookie.pl 840411328.20480.0000&lt;/span&gt;
&lt;span class="go"&gt;192.168.23.50:80&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;On a side note for those of your who are security-conscious: yes, of
course, this means that if you&amp;#8217;re using BigIp with cookie persistence,
it is disclosing the internal &lt;span class="caps"&gt;IP&lt;/span&gt; and port of your server to your end&amp;nbsp;users.&lt;/p&gt;</summary><category term="bigip"></category><category term="cookies"></category><category term="debugging"></category><category term="f5"></category><category term="load balancer"></category><category term="perl"></category><category term="persistence"></category><category term="web app"></category></entry><entry><title>GNU Screen and Multiple Regions</title><link href="http://blog.jasonantman.com/2012/02/gnu-screen-and-multiple-regions/" rel="alternate"></link><updated>2012-02-03T09:13:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-03:2012/02/gnu-screen-and-multiple-regions/</id><summary type="html">&lt;p&gt;Since I always seem to forget this wonderful feature of &lt;a href="http://www.gnu.org/software/screen/"&gt;&lt;span class="caps"&gt;GNU&lt;/span&gt;
screen&lt;/a&gt; (probably one of the pieces
of software I use the most every&amp;nbsp;day)&amp;#8230;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To split the current region horizontally into two equal regions:
    &lt;code&gt;C-a S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To switch between those regions: &lt;code&gt;C-a Tab&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To close all regions but the current one: &lt;code&gt;C-a Q&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is absolutely invaluable for watching logs on multiple machines at&amp;nbsp;once.&lt;/p&gt;</summary><category term="console"></category><category term="screen"></category><category term="sysadmin"></category></entry><entry><title>Using Templates to Track Outdated Content in a Documentation MediaWiki</title><link href="http://blog.jasonantman.com/2012/02/using-templates-to-track-outdated-content-in-a-documentation-mediawiki/" rel="alternate"></link><updated>2012-02-02T11:02:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-02:2012/02/using-templates-to-track-outdated-content-in-a-documentation-mediawiki/</id><summary type="html">&lt;p&gt;Both my last and current jobs use &lt;a href="http://www.mediawiki.org/"&gt;MediaWiki&lt;/a&gt;
for internal documentation. As always happens, some of this
documentation will inevitably get out-of-date, or totally deprecated. As
is also the case, many times when we&amp;#8217;re looking for docs in the middle
of an incident, we don&amp;#8217;t have the time to go back and fix what&amp;#8217;s wrong.
So, I devised the following template/category system to help keep track
of these problem&amp;nbsp;pages.&lt;/p&gt;
&lt;p&gt;First, create some templates that you will apply to the problem pages. I
use three - one for totally deprecated pages, one for pages that need
updating, and one for pages that just need cleanup. For the cleanup
template, in the MediaWiki search box, enter &amp;#8220;Template:Cleanup&amp;#8221; and
click &amp;#8220;go&amp;#8221;. You should be told that the page doesn&amp;#8217;t exist, and given a
link to create the page. Create it, and enter the following&amp;nbsp;content:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;[[Image:Cleanup.png]]

&amp;#39;&amp;#39;&amp;#39;This page needs to be cleaned up or reorganized.&amp;#39;&amp;#39;&amp;#39;

[[Category:Pages Needing Cleanup]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we create a category page for it, &amp;#8220;Category:Pages Needing Cleanup&amp;#8221;,
with the&amp;nbsp;content:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;__HIDDENCAT__

This category is for pages that are mostly correct and just need minor corrections or reorganization.

&amp;#39;&amp;#39;&amp;#39;To add pages to this category&amp;#39;&amp;#39;&amp;#39;, include the following at the &amp;#39;&amp;#39;&amp;#39;TOP&amp;#39;&amp;#39;&amp;#39; of the page:

{{cleanup}}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and save the&amp;nbsp;page.&lt;/p&gt;
&lt;p&gt;Now there&amp;#8217;s a few other changes we need to make. First, upload the
Cleanup.png graphic, which I got from wikimedia.org
&lt;a href="http://upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/40px-Edit-clear.svg.png"&gt;here&lt;/a&gt;
and uploaded as&amp;nbsp;Cleanup.png.&lt;/p&gt;
&lt;p&gt;If you refresh the Template:Cleanup page, you should now see the image.
On a side note, &amp;#8220;__HIDDENCAT__&amp;#8221; on the category page prevents that
category from showing up in the category list at the bottom of the pages
we add to it, but this only works in MediaWiki 1.13 and&amp;nbsp;up.&lt;/p&gt;
&lt;p&gt;The last step is to add the &lt;a href="http://www.mediawiki.org/wiki/Template:Mbox"&gt;MediaWiki mbox
template&lt;/a&gt; and its
dependencies. While I did this once before, I didn&amp;#8217;t really remember the
steps, but I found a post on &lt;a href="http://glynor.com/2010/05/the-trouble-with-ambox-and-mbox/"&gt;Glynor&amp;#8217;s
blog&lt;/a&gt; that
details them rather&amp;nbsp;nicely:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Enable the &lt;a href="http://www.mediawiki.org/wiki/Extension:ParserFunctions"&gt;ParserFunctions
    extension&lt;/a&gt;.
    There are download and install instructions on the extension page,
    but you&amp;#8217;ll want to enable string functions. To do this, include the
    extension in LocalSettings.php&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;require_once( &amp;quot;$&lt;span class="caps"&gt;IP&lt;/span&gt;/extensions/ParserFunctions/ParserFunctions.php&amp;quot; );&lt;/span&gt;
&lt;span class="x"&gt;$wgPFEnableStringFunctions = true;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a new page in your wiki called &amp;#8220;Mediawiki:Common.css&amp;#8221;, and
    paste in the content from &lt;a href="http://www.mediawiki.org/wiki/MediaWiki:Common.css"&gt;MediaWiki.org
    MediaWiki:Common.css&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Go to &lt;a href="http://en.wikipedia.org/w/index.php?title=Special:Export"&gt;Wikipedia&amp;#8217;s
    Special:Export&lt;/a&gt;
    page, and enter &amp;#8220;Template:Ambox&amp;#8221; in the box, check off &amp;#8220;Include
    templates&amp;#8221;, and export the template (and all dependencies) to a
    local &lt;span class="caps"&gt;XML&lt;/span&gt;&amp;nbsp;file.&lt;/li&gt;
&lt;li&gt;Go to the &amp;#8220;Special:Import&amp;#8221; page of your wiki, and upload the &lt;span class="caps"&gt;XML&lt;/span&gt;
    file you just grabbed from Wikipedia. This will import the Ambox and
    mbox templates, as well as their&amp;nbsp;dependencies.&lt;/li&gt;
&lt;li&gt;Now, if you go back and refresh the Template:Cleanup page you
    created, you should see the icon and a nice message&amp;nbsp;box:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="cleanup message box" src="/GFX/mw_cleanup.png" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, add the template and category pages for update and&amp;nbsp;deprecated:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Template:Update&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;[[Image:Warning.png]]

&amp;#39;&amp;#39;&amp;#39;This page is in need of updating. Some information on it may be out of date, and should not be relied on.&amp;#39;&amp;#39;&amp;#39;

[[Category:Pages Needing Updates]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;Category:Pages Needing Updates&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;__HIDDENCAT__

This category keeps track of pages that need changes or updates.

&amp;#39;&amp;#39;&amp;#39;To add pages to this category&amp;#39;&amp;#39;&amp;#39;, include the following at the &amp;#39;&amp;#39;&amp;#39;TOP&amp;#39;&amp;#39;&amp;#39; of the page:

{{update}}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;Template:Deprecated&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;[[Image:Critical.png]]

&amp;#39;&amp;#39;&amp;#39;The information on this page is badly out-of-date.&amp;#39;&amp;#39;&amp;#39; It describes a system that is no longer in production or has drastically changed, and &amp;#39;&amp;#39;&amp;#39;needs to be updated or rewritten&amp;#39;&amp;#39;&amp;#39;.

[[Category:Deprecated Content]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;Category:Deprecated Content&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt; __HIDDENCAT__

This category keeps track of pages that are &amp;#39;&amp;#39;&amp;#39;seriously old&amp;#39;&amp;#39;&amp;#39; or otherwise describe systems/hosts/etc. that have seriously changed from what is described in the page.

&amp;#39;&amp;#39;&amp;#39;To add pages to this category&amp;#39;&amp;#39;&amp;#39;, include the following at the &amp;#39;&amp;#39;&amp;#39;TOP&amp;#39;&amp;#39;&amp;#39; of the page:

{{deprecated}}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the download the two images -
&lt;a href="http://upload.wikimedia.org/wikipedia/commons/9/98/Ambox_deletion.png"&gt;http://upload.wikimedia.org/wikipedia/commons/9/98/Ambox_deletion.png&lt;/a&gt;
gets uploaded as Critical.png and
&lt;a href="http://upload.wikimedia.org/wikipedia/en/f/f4/Ambox_content.png"&gt;http://upload.wikimedia.org/wikipedia/en/f/f4/Ambox_content.png&lt;/a&gt;
gets uploaded as&amp;nbsp;Warning.png.&lt;/p&gt;
&lt;p&gt;That&amp;#8217;s it. To use this, just add &lt;code&gt;{{cleanup}}&lt;/code&gt;, &lt;code&gt;{{deprecated}}&lt;/code&gt; or
&lt;code&gt;{{update}}&lt;/code&gt; to the top of a wiki article (adding the &lt;span class="caps"&gt;HTML&lt;/span&gt; comment
before it is also recommended), and it will add the page to the
appropriate category and show a nice message box at the top of the&amp;nbsp;page:  &lt;/p&gt;
&lt;p&gt;Cleanup:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="cleanup message box" src="/GFX/mw_cleanup.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Update:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="update message box" src="/GFX/mw_update.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Deprecated:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="deprecated message box" src="/GFX/mw_deprecated.png" /&gt;&lt;/p&gt;
&lt;p&gt;I also add a link to the top of the main wiki&amp;nbsp;page:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Things that need to be done: [[:Category:Pages Needing Updates|Pages Needing Updates]], [[:Category:Deprecated Content|Pages with Largely Deprecated Content]], [[:Category:Pages Needing Cleanup|Pages Needing Cleanup]], [[Special:WantedPages|Links to Nonexistent Pages]]
&lt;/pre&gt;&lt;/div&gt;</summary><category term="documentation"></category><category term="mediawiki"></category><category term="sysadmin"></category></entry><entry><title>Synaptics touchpad driver synclient in Fedora 16 / Xorg with UDEV</title><link href="http://blog.jasonantman.com/2012/01/synaptics-touchpad-driver-synclient-in-fedora-16-xorg-with-udev/" rel="alternate"></link><updated>2012-01-27T17:51:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-27:2012/01/synaptics-touchpad-driver-synclient-in-fedora-16-xorg-with-udev/</id><summary type="html">&lt;p&gt;I just installed &lt;a href="http://fedoraproject.org"&gt;Fedora 16&lt;/a&gt; on an older &lt;span class="caps"&gt;IBM&lt;/span&gt;
&lt;a href="http://www.thinkwiki.org/wiki/Category:T42"&gt;ThinkPad T42&lt;/a&gt; laptop.
Unfortunately, the two mouse buttons below the
&lt;a href="http://www.thinkwiki.org/wiki/UltraNav"&gt;UltraNav&lt;/a&gt; touchpad just won&amp;#8217;t
work at all. Before opening up the case and fiddling around, I decided
to try a software solution. Even after fairly exhaustive research, I
couldn&amp;#8217;t find anyone with a similar&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;I did, however, find out that the synaptics touchpad driver has a
&lt;code&gt;synclient&lt;/code&gt; tool that can output the hardware events read directly from
the input device. I tried running &lt;code&gt;synclient -m 100&lt;/code&gt; (to monitor
hardware events every 100ms), but the only output that I got was
&lt;code&gt;Can't access shared memory area. SHMConfig disabled?&lt;/code&gt;. This was all a
bit confusing to me, since Fedora 16 doesn&amp;#8217;t even use an &lt;code&gt;xorg.conf&lt;/code&gt;
file. I was even more confused by a fair amount of information saying
that SHMConfig is no longer used in synaptics&amp;nbsp;1.2+.&lt;/p&gt;
&lt;p&gt;Long story short, the solution lies in
&lt;code&gt;/usr/share/X11/xorg.conf.d/50-synaptics.conf&lt;/code&gt;, which holds the
synaptics config snippets for xorg. All you need to do is add the
SHMConfig line before the end of the&amp;nbsp;section:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Section &amp;quot;InputClass&amp;quot;
    Identifier &amp;quot;touchpad catchall&amp;quot;
    Driver &amp;quot;synaptics&amp;quot;
    ...
    Option &amp;quot;SHMConfig&amp;quot; &amp;quot;on&amp;quot;
EndSection
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and then restart your X server. Now, running &lt;code&gt;synclient -m&lt;/code&gt; should work&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;I have to thank Red Hat&amp;#8217;s &lt;a href="http://fedoraproject.org/wiki/User:Kevin"&gt;Kevin
Fenzi&lt;/a&gt; (nirik on &lt;a href="http://webchat.freenode.net/?randomnick=1&amp;amp;channels=fedora&amp;amp;uio=d4"&gt;#fedora on
irc.freenode.org&lt;/a&gt;)
for putting another set of eyeballs on the problem, and throwing out
some ideas that finally led me to the&amp;nbsp;solution.&lt;/p&gt;</summary><category term="synaptics"></category><category term="synclient"></category><category term="thinkpad"></category><category term="touchpad"></category><category term="xorg"></category></entry><entry><title>Two Interesting Conference Presentations</title><link href="http://blog.jasonantman.com/2012/01/two-interesting-conference-presentations/" rel="alternate"></link><updated>2012-01-25T21:07:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-25:2012/01/two-interesting-conference-presentations/</id><summary type="html">&lt;p&gt;Two interesting presentations - which, unfortunately, I only heard the
audio for (they came up in my podcast playlist during my commute&amp;nbsp;today).&lt;/p&gt;
&lt;p&gt;For the non-techie-geeks out there, &lt;a href="http://www.oscon.com/oscon2011/public/schedule/detail/18941"&gt;All Your Brains Suck - Known Bugs
And Exploits In Wetware: &lt;span class="caps"&gt;OSCON&lt;/span&gt; 2011 - O&amp;#8217;Reilly Conferences, July 25 -
29, 2011, Portland,
&lt;span class="caps"&gt;OR&lt;/span&gt;&lt;/a&gt; is an
interesting talk from Paul Fenwick. Yes, it&amp;#8217;s from a techie conference
(&lt;a href="http://en.wikipedia.org/wiki/Wetware_(brain)"&gt;wetware&lt;/a&gt; == the brain),
but it&amp;#8217;s mostly psychology-based, and covers some &lt;span class="caps"&gt;REALLY&lt;/span&gt; interesting
things about how the human brain works, especially with an emphasis on
how the brain is manipulated in advertising and&amp;nbsp;otherwise.&lt;/p&gt;
&lt;p&gt;For the techie-geeks among us (well, given the other link, &amp;#8220;geeks&amp;#8221; would
be too vague), &lt;a href="http://www.youtube.com/watch?v=y0mHo7SMCQk&amp;amp;list=PLC394849408B5F203&amp;amp;index=5&amp;amp;feature=plpp_video"&gt;Velocity 2011: Theo Schlossnagle, &amp;#8220;Career
Development&amp;#8221;&lt;/a&gt;.
It&amp;#8217;s a bit of a rant, but a good talk for us infrastructure/ops people,
and developers as well, and covers some thoughts on both careers and how
we should do out&amp;nbsp;jobs.&lt;/p&gt;</summary></entry><entry><title>SOPA Blackouts</title><link href="http://blog.jasonantman.com/2012/01/sopa-blackouts/" rel="alternate"></link><updated>2012-01-24T20:29:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-24:2012/01/sopa-blackouts/</id><summary type="html">&lt;p&gt;Well, good news about &lt;span class="caps"&gt;SOPA&lt;/span&gt;. All of my sites participated in the &lt;a href="http://sopastrike.com/"&gt;&lt;span class="caps"&gt;SOPA&lt;/span&gt;
Strike&lt;/a&gt;. While I didn&amp;#8217;t fully black everything
out (I guess I wasn&amp;#8217;t keeping up enough on what others were doing&amp;#8230;), I
displayed a full-screen popover with a message (I have a version of my
homepage with the popover enabled
&lt;a href="http://www.jasonantman.com/sopa.php"&gt;here&lt;/a&gt;). I actually spent a few
hours trying to come up with a safe, effective, cross-browser way to do
it with one line of javascript put in all of my pages (everything from
static &lt;span class="caps"&gt;HTML&lt;/span&gt; to &lt;a href="http://wordpress.org/"&gt;WordPress&lt;/a&gt; and
&lt;a href="http://www.redmine.org/"&gt;redmine&lt;/a&gt;), but ended up giving up and
including a few javascript files and a stylesheet too. At some point,
I&amp;#8217;ll try and post the info on how I did&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Anyway, I just wanted to share a &lt;em&gt;really&lt;/em&gt; cool &lt;span class="caps"&gt;SOPA&lt;/span&gt; protest blackout
page that I saw:
&lt;a href="http://www.zachstronaut.com/lab/text-shadow-box/stop-sopa.html"&gt;http://www.zachstronaut.com/lab/text-shadow-box/stop-sopa.html&lt;/a&gt;,
by Zachary Johnson. Of course, apparently, I&amp;#8217;m not the only person who
saw&amp;nbsp;it&amp;#8230;&lt;/p&gt;</summary><category term="blackout"></category><category term="censorship"></category><category term="SOPA"></category></entry><entry><title>PHP Script to Query Linode DNS Manager API</title><link href="http://blog.jasonantman.com/2012/01/php-script-to-query-linode-dns-manager-api/" rel="alternate"></link><updated>2012-01-20T22:49:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-20:2012/01/php-script-to-query-linode-dns-manager-api/</id><summary type="html">&lt;p&gt;I&amp;#8217;m in the process of moving all of my public-facing services, currently
hosted on a single
&lt;a href="http://www.linode.com/?r=5c8ad2931b410b55455aadbcf0a8d86d6f698a91"&gt;Linode&lt;/a&gt;,
to a new virtual machine (still with Linode, of course, just a new
CentOS 6 &lt;span class="caps"&gt;VM&lt;/span&gt;). Of course, I&amp;#8217;ve got a &lt;em&gt;lot&lt;/em&gt; (about 60) of &lt;span class="caps"&gt;DNS&lt;/span&gt; records,
spread across 8 domains, that point at the old machine. For name-based
vhosts in Apache, my usual procedure is to migrate everything over to
the new host and then change &lt;span class="caps"&gt;DNS&lt;/span&gt;, and once the change propagates (I&amp;#8217;m
using Linode&amp;#8217;s &lt;span class="caps"&gt;DNS&lt;/span&gt; hosting, so it makes things a &lt;span class="caps"&gt;LOT&lt;/span&gt; easier but I don&amp;#8217;t
have &lt;code&gt;rndc reload&lt;/code&gt; anymore) I test in a browser and, assuming all is
well, disable the vhost on the old server. To do all this, I need an
easy way to get a list of all the &lt;span class="caps"&gt;DNS&lt;/span&gt; records that still point to the
old&amp;nbsp;machine.&lt;/p&gt;
&lt;p&gt;Luckily, to augment their web-based control panel (Linode Manager),
Linode has a pretty full-featured &lt;a href="http://www.linode.com/api/"&gt;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; with
bindings for Python, Perl, &lt;span class="caps"&gt;PHP&lt;/span&gt;, Ruby, Java and others. While I like
Python and I&amp;#8217;m starting to learn Perl (by trying to shift most of my
non-time-sensitive scripting to it) for my new job, &lt;span class="caps"&gt;PHP&lt;/span&gt; is still my
strongest language (and the majority of my existing administrative
scripting is written in it, especially handy when it comes time to add a
web front-end to things). So I wrote the following script to query
Linode&amp;#8217;s &lt;a href="http://www.linode.com/api/dns"&gt;&lt;span class="caps"&gt;DNS&lt;/span&gt; Manager &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; using &lt;a href="https://github.com/krmdrms/linode/"&gt;Kerem
Durmus&amp;#8217; Linode &lt;span class="caps"&gt;API&lt;/span&gt; &lt;span class="caps"&gt;PHP&lt;/span&gt; wrapper&lt;/a&gt;
(installation instructions and info at that Github link). The script
simply writes all Linode &lt;span class="caps"&gt;DNS&lt;/span&gt; records for all zones to a &lt;span class="caps"&gt;CSV&lt;/span&gt; file (this
could take a while if you have a lot of&amp;nbsp;records&amp;#8230;).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * &lt;span class="caps"&gt;INSTALLATION&lt;/span&gt; (as per krmdrms &lt;span class="caps"&gt;README&lt;/span&gt;):&lt;/span&gt;
&lt;span class="x"&gt;   *  pear install Net_URL2-0.3.1&lt;/span&gt;
&lt;span class="x"&gt;   *  pear install HTTP_Request2-0.5.2&lt;/span&gt;
&lt;span class="x"&gt;   *  pear channel-discover pear.keremdurmus.com&lt;/span&gt;
&lt;span class="x"&gt;   *  pear install krmdrms/Services_Linode&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * Also requires php-openssl / php5-openssl&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * &lt;span class="caps"&gt;USAGE&lt;/span&gt;: php linodeDnsToCsv.php&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * Copyright 2011 Jason Antman  , all rights reserved.&lt;/span&gt;
&lt;span class="x"&gt;   * This script is free for use by anyone anywhere, provided that you comply with the following terms:&lt;/span&gt;
&lt;span class="x"&gt;   * 1) Keep this notice and copyright statement intact.&lt;/span&gt;
&lt;span class="x"&gt;   * 2) Send any substantial changes, improvements or bog fixes back to me at the above address.&lt;/span&gt;
&lt;span class="x"&gt;   * 3) If you include this in a product or redistribute it, you notify me, and include my name in the credits or changelog.&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * The following &lt;span class="caps"&gt;URL&lt;/span&gt; always points to the newest version of this script. If you obtained it from another source, you should&lt;/span&gt;
&lt;span class="x"&gt;   * check here:&lt;/span&gt;
&lt;span class="x"&gt;   * $HeadURL: http://svn.jasonantman.com/misc-scripts/linodeDnsToCsv.php $&lt;/span&gt;
&lt;span class="x"&gt;   * $LastChangedRevision: 25 $&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * &lt;span class="caps"&gt;CHANGELOG&lt;/span&gt;:&lt;/span&gt;
&lt;span class="x"&gt;   * 2011-12-17 Jason Antman :&lt;/span&gt;
&lt;span class="x"&gt;   *    merged into my svn repo&lt;/span&gt;
&lt;span class="x"&gt;   * 2011-09-12 Jason Antman :&lt;/span&gt;
&lt;span class="x"&gt;   *    initial version of script&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   */&lt;/span&gt;

&lt;span class="x"&gt;require_once(&amp;quot;/var/www/linode_apikey.php&amp;quot;); // &lt;span class="caps"&gt;PHP&lt;/span&gt; file containing:   define(&amp;quot;API_KEY_LINODE&amp;quot;, &amp;quot;myApiKeyHere&amp;quot;);&lt;/span&gt;
&lt;span class="x"&gt;require_once(&amp;#39;Services/Linode.php&amp;#39;);&lt;/span&gt;

&lt;span class="x"&gt;// get list of all domains&lt;/span&gt;
&lt;span class="x"&gt;$domains = array(); // &lt;span class="caps"&gt;DOMAINID&lt;/span&gt; =&amp;gt; domain.tld&lt;/span&gt;
&lt;span class="x"&gt;try {&lt;/span&gt;
&lt;span class="x"&gt;  $linode = new Services_Linode(API_KEY_LINODE);&lt;/span&gt;
&lt;span class="x"&gt;  $result = $linode-&amp;gt;domain_list();&lt;/span&gt;

&lt;span class="x"&gt;  foreach($result[&amp;#39;&lt;span class="caps"&gt;DATA&lt;/span&gt;&amp;#39;] as $domain)&lt;/span&gt;
&lt;span class="x"&gt;    {&lt;/span&gt;
&lt;span class="x"&gt;      $domains[$domain[&amp;#39;&lt;span class="caps"&gt;DOMAINID&lt;/span&gt;&amp;#39;]] = $domain[&amp;quot;&lt;span class="caps"&gt;DOMAIN&lt;/span&gt;&amp;quot;];&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;
&lt;span class="x"&gt;catch (Services_Linode_Exception $e)&lt;/span&gt;
&lt;span class="x"&gt;{&lt;/span&gt;
&lt;span class="x"&gt;  echo $e-&amp;gt;getMessage();&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;

&lt;span class="x"&gt;$records = array(); // array of resource records&lt;/span&gt;
&lt;span class="x"&gt;$linode-&amp;gt;batching = true;&lt;/span&gt;
&lt;span class="x"&gt;foreach($domains as $id =&amp;gt; $name)&lt;/span&gt;
&lt;span class="x"&gt;{&lt;/span&gt;
&lt;span class="x"&gt;  $linode-&amp;gt;domain_resource_list(array(&amp;#39;DomainID&amp;#39; =&amp;gt; $id));&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;

&lt;span class="x"&gt;try {&lt;/span&gt;
&lt;span class="x"&gt;  $result = $linode-&amp;gt;batchFlush();&lt;/span&gt;

&lt;span class="x"&gt;  foreach($result as $batchPart)&lt;/span&gt;
&lt;span class="x"&gt;    {&lt;/span&gt;
&lt;span class="x"&gt;      foreach($batchPart[&amp;#39;&lt;span class="caps"&gt;DATA&lt;/span&gt;&amp;#39;] as $rrec)&lt;/span&gt;
&lt;span class="x"&gt;    {&lt;/span&gt;
&lt;span class="x"&gt;      if(! isset($records[$rrec[&amp;#39;&lt;span class="caps"&gt;DOMAINID&lt;/span&gt;&amp;#39;]])){ $records[$rrec[&amp;#39;&lt;span class="caps"&gt;DOMAINID&lt;/span&gt;&amp;#39;]] = array();}&lt;/span&gt;
&lt;span class="x"&gt;      $records[$rrec[&amp;#39;&lt;span class="caps"&gt;DOMAINID&lt;/span&gt;&amp;#39;]][$rrec[&amp;#39;&lt;span class="caps"&gt;RESOURCEID&lt;/span&gt;&amp;#39;]] = array(&amp;#39;name&amp;#39; =&amp;gt; $rrec[&amp;#39;&lt;span class="caps"&gt;NAME&lt;/span&gt;&amp;#39;], &amp;#39;type&amp;#39; =&amp;gt; $rrec[&amp;#39;&lt;span class="caps"&gt;TYPE&lt;/span&gt;&amp;#39;], &amp;#39;target&amp;#39; =&amp;gt; $rrec[&amp;#39;&lt;span class="caps"&gt;TARGET&lt;/span&gt;&amp;#39;]);&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;
&lt;span class="x"&gt;catch (Services_Linode_Exception $e)&lt;/span&gt;
&lt;span class="x"&gt;{&lt;/span&gt;
&lt;span class="x"&gt;  echo $e-&amp;gt;getMessage();&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;

&lt;span class="x"&gt;echo &amp;#39;&amp;quot;recid&amp;quot;,&amp;quot;domain&amp;quot;,&amp;quot;name&amp;quot;,&amp;quot;type&amp;quot;,&amp;quot;target&amp;quot;&amp;#39;.&amp;quot;\n&amp;quot;;&lt;/span&gt;
&lt;span class="x"&gt;foreach($domains as $id =&amp;gt; $name)&lt;/span&gt;
&lt;span class="x"&gt;{&lt;/span&gt;
&lt;span class="x"&gt;  foreach($records[$id] as $recid =&amp;gt; $arr)&lt;/span&gt;
&lt;span class="x"&gt;    {&lt;/span&gt;
&lt;span class="x"&gt;      echo &amp;#39;&amp;quot;&amp;#39;.$recid.&amp;#39;&amp;quot;,&amp;quot;&amp;#39;.$name.&amp;#39;&amp;quot;,&amp;quot;&amp;#39;.$arr[&amp;#39;name&amp;#39;].&amp;#39;&amp;quot;,&amp;quot;&amp;#39;.$arr[&amp;#39;type&amp;#39;].&amp;#39;&amp;quot;,&amp;quot;&amp;#39;.$arr[&amp;#39;target&amp;#39;].&amp;quot;\&amp;quot;\n&amp;quot;;&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;


&lt;span class="x"&gt;?&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That will print out a list containing the Linode &lt;span class="caps"&gt;DNS&lt;/span&gt; record id (recid),
domain, record name, type and&amp;nbsp;target:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&amp;quot;recid&amp;quot;,&amp;quot;domain&amp;quot;,&amp;quot;name&amp;quot;,&amp;quot;type&amp;quot;,&amp;quot;target&amp;quot;
&amp;quot;137423&amp;quot;,&amp;quot;jasonantman.com&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;TXT&amp;quot;,&amp;quot;v=spf1 mx:jasonantman.com -all&amp;quot;
&amp;quot;3597859&amp;quot;,&amp;quot;jasonantman.com&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;MX&amp;quot;,&amp;quot;linode1.jasonantman.com&amp;quot;
&amp;quot;3488952&amp;quot;,&amp;quot;jasonantman.com&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;mx&amp;quot;,&amp;quot;linode2.jasonantman.com&amp;quot;
&amp;quot;3472952&amp;quot;,&amp;quot;jasonantman.com&amp;quot;,&amp;quot;blog&amp;quot;,&amp;quot;CNAME&amp;quot;,&amp;quot;linode1.jasonantman.com&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you want to, say, search for only records that include host
&amp;#8220;example&amp;#8221;, you could use grep and awk&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;php linodeDnsToCsv.php | grep linode1 | grep -v &lt;span class="s1"&gt;&amp;#39;&amp;quot;linode1&amp;quot;,&amp;quot;a&amp;quot;&amp;#39;&lt;/span&gt; | awk -F , &lt;span class="s1"&gt;&amp;#39;{printf &amp;quot;%-27s %-20s %-7s %s\n&amp;quot;, $2, $3, $4, $5}&amp;#39;&lt;/span&gt; | sed &lt;span class="s1"&gt;&amp;#39;s/&amp;quot;//g&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I hope this helps someone else out, and saves them a few minutes of&amp;nbsp;coding&amp;#8230;&lt;/p&gt;</summary><category term="api"></category><category term="dns"></category><category term="linode"></category><category term="PHP"></category><category term="sysadmin"></category></entry><entry><title>Secure rsnapshot backups over the WAN via SSH</title><link href="http://blog.jasonantman.com/2012/01/secure-rsnapshot-backups-over-the-wan-via-ssh/" rel="alternate"></link><updated>2012-01-15T17:26:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-15:2012/01/secure-rsnapshot-backups-over-the-wan-via-ssh/</id><summary type="html">&lt;p&gt;Since I moved all of my &lt;span class="caps"&gt;WAN&lt;/span&gt;-facing stuff (mail, web, this blog, svn
etc.) to a virtual server with &lt;a href="http://www.linode.com"&gt;Linode&lt;/a&gt;, and just
have a desktop at home, it&amp;#8217;s no longer practical to use
&lt;a href="http://www.bacula.org/"&gt;Bacula&lt;/a&gt; for backups. Linode manages daily and
weekly backups through their backup service, but they&amp;#8217;ll only restore a
full filesystem at a time. I wanted something that would keep daily and
weekly incremental backups long enough that I could find a file changed
(or accidentally deleted) a few days or weeks ago. Since I&amp;#8217;d be backing
up to my desktop at home (which is on a residential dynamic &lt;span class="caps"&gt;IP&lt;/span&gt;
connection), the logical solution was something using
&lt;a href="http://rsync.samba.org/"&gt;rsync&lt;/a&gt;. Even better than that is the
&lt;a href="http://rsnapshot.org/"&gt;rsnapshot&lt;/a&gt; tool, which builds upon rsync and
hard links to manage incremental backups with as little disk usage as
possible (though I&amp;#8217;d certainly recommend excluding log&amp;nbsp;files).&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m pretty strict about security. Since my home connection has a dynamic
&lt;span class="caps"&gt;IP&lt;/span&gt;, things are a bit more complicated - I can&amp;#8217;t push from the server, I
can&amp;#8217;t &lt;span class="caps"&gt;ACL&lt;/span&gt; or firewall the server to just my home &lt;span class="caps"&gt;IP&lt;/span&gt;, and an IPsec &lt;span class="caps"&gt;VPN&lt;/span&gt;
would be difficult to accomplish (not to mention add a lot of overhead
to big file transfers). So, I opted for a solution that uses &lt;span class="caps"&gt;SSH&lt;/span&gt;
key-based authentication, forced comands, and a C&amp;nbsp;wrapper.&lt;/p&gt;
&lt;p&gt;The configuration of rsync and rsnapshot is mostly out of the scope of
this post. There are plenty of good resources for that, so I&amp;#8217;ll just
cover the things that won&amp;#8217;t be found in most tutorials. Also, I&amp;#8217;ll be
referring to the remote machine to be backed up as the &amp;#8220;remote host&amp;#8221; and
the local machine which triggers the backup and stores the data as the
&amp;#8220;local&amp;nbsp;host&amp;#8221;.&lt;/p&gt;
&lt;h2 id="local-host-setup-part-i"&gt;Local Host Setup - Part&amp;nbsp;I&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Choose and create a directory to store your backups in. I have a &lt;span class="caps"&gt;1TB&lt;/span&gt;
    external disk mounted at &lt;code&gt;/mnt/backup/&lt;/code&gt;, so I chose
    &lt;code&gt;/mnt/backup/rsnapshot/&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Generate two sets of password-less &lt;span class="caps"&gt;SSH&lt;/span&gt; keys using the &lt;code&gt;ssh-keygen&lt;/code&gt;
    program. One will be used to run the rsync command on the remote
    host, the other will be used to trigger your pre- and post-backup
    scripts. Name them accordingly (i.e.
    &amp;#8220;remoteHostname_remoteBackupUsername_cmd&amp;#8221; and
    &amp;#8220;remoteHostname_remoteBackupUsername_rsync&amp;#8221;). Now, get (scp) the
    public key for each pair to the remote&amp;nbsp;host.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="remote-host-setup"&gt;Remote Host&amp;nbsp;Setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Ensure that rsync is installed on the&amp;nbsp;host.&lt;/li&gt;
&lt;li&gt;Create a user to run the backups. I called this user &amp;#8220;rsyncuser&amp;#8221;.
    Create a home directory, and a group for the user. Do not set a
    password (you don&amp;#8217;t want password&amp;nbsp;logins).&lt;/li&gt;
&lt;li&gt;Copy the public key files you created above to the user&amp;#8217;s &lt;code&gt;~/.ssh/&lt;/code&gt;
    directory.&lt;/li&gt;
&lt;li&gt;Cat the &amp;#8220;remoteHostname_remoteBackupUsername_cmd&amp;#8221; public key into
    the user&amp;#8217;s &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Now comes the first fun part. Let&amp;#8217;s assume that your pre- and
    post-backup scripts are &lt;code&gt;/root/bin/rsnapshot-pre.sh&lt;/code&gt; and
    &lt;code&gt;/root/bin/rsnapshot-post.sh&lt;/code&gt;, respectively. As root, grab a copy of
    cmd-wrapper.c (from
    &lt;a href="https://github.com/jantman/misc-scripts/blob/master/cmd-wrapper.c"&gt;GitHub&lt;/a&gt;
    or at the bottom of this post). Modify for your use - the only thing
    likely to change is line 38, which ensures it will only run for a
    member of &lt;span class="caps"&gt;GID&lt;/span&gt; 502. Change this to rsyncuser&amp;#8217;s &lt;span class="caps"&gt;GID&lt;/span&gt;. Compile the
    wrapper with &lt;code&gt;gcc -o cmd-wrapper cmd-wrapper.c&lt;/code&gt;. Copy it to
    rsyncuser&amp;#8217;s home directory (/home/rsyncuser), &lt;code&gt;chown root:rsyncuser&lt;/code&gt;
    and &lt;code&gt;chmod 4750&lt;/code&gt;. Yes, this sets the &lt;span class="caps"&gt;SUID&lt;/span&gt; bit. The program will now
    be owned by root, and runnable &lt;em&gt;as root&lt;/em&gt; by rsyncuser (or, more
    specifically, any member of the rsyncuser&amp;nbsp;group).&lt;/li&gt;
&lt;li&gt;Open rsyncuser&amp;#8217;s &lt;code&gt;.ssh/authorized_keys&lt;/code&gt; file in a text editor. At
    the beginning of the &amp;#8220;remoteHostname_remoteBackupUsername_cmd&amp;#8221; key
    line, prepend &lt;code&gt;command="/home/rsyncuser/cmd-wrapper"&lt;/code&gt;. This sets up
    &lt;span class="caps"&gt;SSH&lt;/span&gt; forced command (there&amp;#8217;s a good overview in &lt;a href="http://oreilly.com/catalog/sshtdg/chapter/ch08.html"&gt;O&amp;#8217;Reilly&amp;#8217;s &lt;span class="caps"&gt;SSH&lt;/span&gt;: The
    Definitive
    Guide&lt;/a&gt;) so that
    when this key is used to login, it will directly execute
    &lt;code&gt;/home/rsyncuser/cmd-wrapper&lt;/code&gt; and then exit, without allowing access
    to anything&amp;nbsp;else.&lt;/li&gt;
&lt;li&gt;Add rsyncuser to &lt;code&gt;AllowUsers&lt;/code&gt; in &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt; (you &lt;em&gt;do&lt;/em&gt;
    limit user access via &lt;span class="caps"&gt;SSH&lt;/span&gt;, right?) and then reload&amp;nbsp;sshd.&lt;/li&gt;
&lt;li&gt;Now, if you &lt;span class="caps"&gt;SSH&lt;/span&gt; to rsyncuser@remoteHost from the local host, using
    the &amp;#8220;_cmd&amp;#8221; ssh key and a command of &amp;#8220;pre&amp;#8221; (i.e.
    &lt;code&gt;ssh -i /path/to/remoteHostname_remoteBackupUsername_cmd rsyncuser@remoteHost pre&lt;/code&gt;),
    it should execute &lt;code&gt;/root/bin/rsnapshot-pre.sh&lt;/code&gt; ad root, and you
    should see the output&amp;nbsp;locally.&lt;/li&gt;
&lt;li&gt;Repeat the above step for the post-backup script (replacing &amp;#8220;pre&amp;#8221;
    above with &amp;#8220;post&amp;#8221;). You should now have your pre- and post-backup
    scripts working, and triggered remotely. &lt;em&gt;(Note: these steps, and
    some of the other setup here, is a bit more complex so that it will
    work better with rsnapshot backups of multiple remote&amp;nbsp;hosts.)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Cat the &amp;#8220;remoteHostname_remoteBackupUsername_rsync&amp;#8221; public key
    into the backup user&amp;#8217;s &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;As root, grab a copy of rsync-wrapper.c (from
    &lt;a href="https://github.com/jantman/misc-scripts/blob/master/rsync-wrapper.c"&gt;GitHub&lt;/a&gt;
    or at the bottom of this post). Modify for your use - the only thing
    likely to change is line 38, which ensures it will only run for a
    member of &lt;span class="caps"&gt;GID&lt;/span&gt; 502 (change this to rsyncuser&amp;#8217;s &lt;span class="caps"&gt;GID&lt;/span&gt;), and perhaps the
    path of or arguments passed to rsync (the wrapper will call
    &lt;code&gt;/usr/bin/rsync --server --sender -vlogDtprRe.iLsf --numeric-ids . /&lt;/code&gt;).
    Compile the wrapper with &lt;code&gt;gcc -o rsync-wrapper rsync-wrapper.c&lt;/code&gt;.
    Copy it to rsyncuser&amp;#8217;s home directory (/home/rsyncuser),
    &lt;code&gt;chown root:rsyncuser&lt;/code&gt; and &lt;code&gt;chmod 4750&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Open rsyncuser&amp;#8217;s &lt;code&gt;.ssh/authorized_keys&lt;/code&gt; file in a text editor. At
    the beginning of the &amp;#8220;remoteHostname_remoteBackupUsername_rsync&amp;#8221;
    key line, prepend &lt;code&gt;command="/home/rsyncuser/rsync-wrapper"&lt;/code&gt;. This
    will run rsync with the arguments specified in rsync-wrapper.c every
    time this key is used to&amp;nbsp;login.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="local-host-setup-part-ii"&gt;Local Host Setup - Part&amp;nbsp;&lt;span class="caps"&gt;II&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;I use totally separate configs for each host that I backup, to keep
things clean and to let me enable, disable, or tweak one remote backup
without affecting the&amp;nbsp;others.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create host-specific pre- and post-backup scripts. I put them in
    &lt;code&gt;/etc/rsnapshot.d/&lt;/code&gt;.
    &lt;code&gt;/etc/rsnapshot.d/pre-remoteHostName.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="c"&gt;# do anything else needed on the local system before a backup&lt;/span&gt;
ssh -i /path/to/remoteHostname_remoteBackupUsername_cmd rsyncuser@remoteHost pre
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;/etc/rsnapshot.d/post-remoteHostName.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="c"&gt;# do anything else needed on the local system after a backup&lt;/span&gt;
ssh -i /path/to/remoteHostname_remoteBackupUsername_cmd rsyncuser@remoteHost post
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setup a set of rsync include and exclude files (see &lt;code&gt;man rsync(1)&lt;/code&gt;,
    &lt;code&gt;--include-from=&lt;/code&gt; and &lt;code&gt;--exclude-from=&lt;/code&gt;). I put mine at
    &lt;code&gt;/etc/rsnapshot.d/rsync-include-remoteHostName.txt&lt;/code&gt; and
    &lt;code&gt;/etc/rsnapshot.d/rsync-exclude-remoteHostName.txt&lt;/code&gt;, respectively.
    (Examples included at the bottom of this&amp;nbsp;post).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configure rsnapshot. I use a separate config file for each remote
    host. Copy the default &lt;code&gt;/etc/rsnapshot.conf&lt;/code&gt; to
    &lt;code&gt;/etc/rsnapshot-remoteHostName.conf&lt;/code&gt;. The important items are
    &lt;code&gt;rsync_short_args&lt;/code&gt;, &lt;code&gt;rsync_long_args&lt;/code&gt;, &lt;code&gt;ssh_args&lt;/code&gt;, &lt;code&gt;cmd_preexec&lt;/code&gt;,
    &lt;code&gt;cmd_postexec&lt;/code&gt; and &lt;code&gt;backup&lt;/code&gt;. Here&amp;#8217;s an example of my config file,
    with comments and blank lines&amp;nbsp;removed:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;config_version  1.2
snapshot_root   /mnt/backup/rsnapshot/
cmd_cp          /bin/cp
cmd_rm          /bin/rm
cmd_rsync       /usr/bin/rsync
cmd_ssh         /usr/bin/ssh
cmd_logger      /bin/logger
cmd_du          /usr/bin/du
cmd_rsnapshot_diff      /usr/bin/rsnapshot-diff
interval        daily   14 # save 14 daily backups
interval        weekly  6 # save 6 weekly backups
verbose         2
loglevel        3
logfile /var/log/rsnapshot-remoteHostName.log
lockfile        /var/run/rsnapshot-remoteHostName.pid
rsync_short_args        -a
rsync_long_args --delete --numeric-ids --relative --delete-excluded
ssh_args        -i /path/to/remoteHostname_remoteBackupUsername_rsync
exclude_file    /etc/rsnapshot.d/rsync-exclude-remoteHostName.txt
include_file    /etc/rsnapshot.d/rsync-include-remoteHostName.txt
link_dest       1
use_lazy_deletes        1
cmd_preexec     /etc/rsnapshot.d/pre-remoteHostName.sh
cmd_postexec    /etc/rsnapshot.d/post-remoteHostName.sh
backup  rsyncuser@remoteHostName:/      remoteHostName/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;backup&lt;/code&gt; line is what tells rsync what to back up (&lt;code&gt;/&lt;/code&gt; on
remoteHostName, logging in as rsyncuser), and where to back up to&amp;nbsp;(snapshot_root/remoteHostName/).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create two scripts that will actually trigger the backups, which
    I&amp;#8217;ll call &lt;code&gt;/root/bin/rsnapshot-daily.sh&lt;/code&gt; and &lt;code&gt;/root/bin/rsnapshot-weekly.sh&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/root/bin/rsnapshot-daily.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

/usr/bin/rsnapshot -c /etc/rsnapshot-remoteHostName.conf daily
&lt;span class="c"&gt;# add other hosts here; note, they&amp;#39;ll run in series&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;/root/bin/rsnapshot-weekly.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

/usr/bin/rsnapshot -c /etc/rsnapshot-remoteHostName.conf weekly
&lt;span class="c"&gt;# add other hosts here; note, they&amp;#39;ll run in series&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add two entries to root&amp;#8217;s croontab to run the rsnapshot backups.
    Adjust the following days and times to your&amp;nbsp;liking:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;0 1 * * Mon /root/bin/rsnapshot-weekly.sh # run the weekly backups every Monday at 01:00
30 2 * * * /root/bin/rsnapshot-daily.sh # run the daily backups every day at 02:30, which *should* be after the weekly finished on Monday morning
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check, after the next scheduled runs, that everything appears to
    have run correctly. If you want, you can manually trigger the daily
    script and watch what happens. If you do this more than once, you
    should delete the directories it creates, or else rotation will be
    messed up. If you have issues with rsync, aside from the usual
    troubleshooting, check that rsync-wrapper.c is calling rsync with
    the same arguments that rsnapshot is sending. It may be useful to
    use my
    &lt;a href="https://github.com/jantman/misc-scripts/blob/master/print-cmd.sh"&gt;print-cmd.sh&lt;/a&gt;
    script in place of the &amp;#8220;rsync-wrapper&amp;#8221; forced command. This script
    will simply log the command rsnapshot calls via&amp;nbsp;&lt;span class="caps"&gt;SSH&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Assuming all of this worked, you should now have a fairly secure
&lt;span class="caps"&gt;SSH&lt;/span&gt;-based remotely-triggered backup system. In a follow-up post I
provide my &lt;a href="/2012/02/nagios-check-plugin-for-rsnapshot-backups/"&gt;Nagios Check Plugin for Rsnapshot
Backups&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The referenced scripts, config files, etc. are&amp;nbsp;below:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cmd-wrapper.c&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;

&lt;span class="cm"&gt;/********************************************&lt;/span&gt;
&lt;span class="cm"&gt; * Wrapper - Secure Yourself                &lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; * 2007 - Mike Golvach - eggi@comcast.net   &lt;/span&gt;
&lt;span class="cm"&gt; * Modified 2012 by Jason Antman  &lt;/span&gt;
&lt;span class="cm"&gt; *  - configured for use as pre- and post-backup script wrapper&lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; * &lt;span class="caps"&gt;USAGE&lt;/span&gt;: cmd-wrapper [pre|post]&lt;/span&gt;
&lt;span class="cm"&gt; *&lt;/span&gt;
&lt;span class="cm"&gt; * $HeadURL: http://svn.jasonantman.com/misc-scripts/cmd-wrapper.c $&lt;/span&gt;
&lt;span class="cm"&gt; * $LastChangedRevision: 26 $&lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; ********************************************/&lt;/span&gt;

&lt;span class="cm"&gt;/* Creative Commons Attribution-Noncommercial-Share Alike 3.0 United States License */&lt;/span&gt;

&lt;span class="cm"&gt;/* Define global variables */&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;gid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="cm"&gt;/* main(int argc, char **argv) - main process loop */&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;envp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;origcmd&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="n"&gt;origcmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;SSH_ORIGINAL_COMMAND&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="cm"&gt;/* printf (&amp;quot;Original Command:%s\n&amp;quot;, origcmd); */&lt;/span&gt;

  &lt;span class="cm"&gt;/* Set euid and egid to actual user */&lt;/span&gt;

  &lt;span class="n"&gt;gid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getgid&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="n"&gt;setegid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getgid&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
  &lt;span class="n"&gt;seteuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getuid&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;

  &lt;span class="cm"&gt;/* Confirm user is in &lt;span class="caps"&gt;GROUP&lt;/span&gt;(502) group */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;gid&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;502&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;User Not Authorized! Exiting...&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* Check argc count only at this point */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Usage: cmd-wrapper [pre|post]&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* Set uid, gid, euid and egid to root */&lt;/span&gt;

  &lt;span class="n"&gt;setegid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;seteuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;setgid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;setuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="cm"&gt;/* Check argv for proper arguments and run&lt;/span&gt;
&lt;span class="cm"&gt;   * the corresponding script, if invoked.&lt;/span&gt;
&lt;span class="cm"&gt;   */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;strncmp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;origcmd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;pre&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;execl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/root/bin/rsnapshot-pre.sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;rsnapshot-pre.sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;&lt;span class="caps"&gt;NULL&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;perror&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Execl:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;strncmp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;origcmd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;post&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;execl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/root/bin/rsnapshot-post.sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;rsnapshot-post.sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;&lt;span class="caps"&gt;NULL&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;perror&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Execl:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: Invalid command: %s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;origcmd&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Usage: &lt;span class="caps"&gt;COMMAND&lt;/span&gt; [pre|post]&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;rsync-wrapper.c&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;

&lt;span class="cm"&gt;/********************************************&lt;/span&gt;
&lt;span class="cm"&gt; * Wrapper - Secure Yourself                &lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; * 2007 - Mike Golvach - eggi@comcast.net   &lt;/span&gt;
&lt;span class="cm"&gt; * Modified 2012 by Jason Antman  &lt;/span&gt;
&lt;span class="cm"&gt; *  - configured for use as rsync wrapper&lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; * $HeadURL: http://svn.jasonantman.com/misc-scripts/rsync-wrapper.c $&lt;/span&gt;
&lt;span class="cm"&gt; * $LastChangedRevision: 26 $&lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; ********************************************/&lt;/span&gt;

&lt;span class="cm"&gt;/* Creative Commons Attribution-Noncommercial-Share Alike 3.0 United States License */&lt;/span&gt;

&lt;span class="cm"&gt;/* Define global variables */&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;gid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="cm"&gt;/* main(int argc, char **argv) - main process loop */&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="cm"&gt;/* Set euid and egid to actual user */&lt;/span&gt;

  &lt;span class="n"&gt;gid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getgid&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="n"&gt;setegid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getgid&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
  &lt;span class="n"&gt;seteuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getuid&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;

  &lt;span class="cm"&gt;/* Confirm user is in &lt;span class="caps"&gt;GROUP&lt;/span&gt;(502) group */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;gid&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;502&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;User Not Authorized! Exiting...&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* Check argc count only at this point */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Usage: rsync-wrapper&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* Set uid, gid, euid and egid to root */&lt;/span&gt;

  &lt;span class="n"&gt;setegid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;seteuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;setgid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;setuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="cm"&gt;/* Check argv for proper arguments and run&lt;/span&gt;
&lt;span class="cm"&gt;   * the corresponding script, if invoked.&lt;/span&gt;
&lt;span class="cm"&gt;   */&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;execl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/usr/bin/rsync&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;rsync&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;--server&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;--sender&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;-vlogDtprRe.iLsf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;--numeric-ids&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;&lt;span class="caps"&gt;NULL&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;perror&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Execl:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;/etc/rsnapshot.d/rsync-include-remoteHostName.txt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# Include
+ /dev/console
+ /dev/initctl
+ /dev/null
+ /dev/zero
+ /usr/local/*
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;/etc/rsnapshot.d/rsync-exclude-remoteHostName.txt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# Exclude
- /cgroup/*
- /dev/*
- /lib/*
- lost+found/
- /proc/*
- /sys/
- /tmp/
- /var/log/*
&lt;/pre&gt;&lt;/div&gt;</summary><category term="backups"></category><category term="linode"></category><category term="rsnapshot"></category><category term="rsync"></category><category term="security"></category><category term="ssh"></category><category term="wrapper"></category></entry><entry><title>WP-Syntax Plugin GeSHi Path Fix</title><link href="http://blog.jasonantman.com/2012/01/wp-syntax-plugin-geshi-path-fix/" rel="alternate"></link><updated>2012-01-12T19:09:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-12:2012/01/wp-syntax-plugin-geshi-path-fix/</id><summary type="html">&lt;p&gt;The &lt;a href="http://wordpress.org/extend/plugins/wp-syntax/"&gt;Wp-Syntax&lt;/a&gt; plugin
for &lt;a href="http://wordpress.org"&gt;WordPress&lt;/a&gt; provides syntax highlighting for
WordPress blogs via the &lt;a href="http://qbnz.com/highlighter"&gt;GeSHi&lt;/a&gt; &lt;span class="caps"&gt;PHP&lt;/span&gt; syntax
highlighter. Unfortunately, the plugin includes a builtin version of
GeSHi (currently 1.0.8.9) in &lt;code&gt;geshi/&lt;/code&gt;. As a result, not only are users
of the plugin not instructed to use the latest version of GeSHi, but it
won&amp;#8217;t use a host-wide GeSHi installation that&amp;#8217;s already in the &lt;span class="caps"&gt;PHP&lt;/span&gt;
include path (i.e. &lt;code&gt;/usr/share/php/&lt;/code&gt;), like the the many &lt;a href="http://pkgs.org/search/?keyword=php-geshi&amp;amp;search_on=name&amp;amp;distro=0&amp;amp;arch=32-bit"&gt;php-geshi
packages&lt;/a&gt;
offered by repositories including
&lt;a href="http://fedoraproject.org/wiki/EPEL"&gt;&lt;span class="caps"&gt;EPEL&lt;/span&gt;&lt;/a&gt; (for Fedora, CentOS and&amp;nbsp;&lt;span class="caps"&gt;RHEL&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;The fix is quite simple. Just open &lt;code&gt;wp-syntax.php&lt;/code&gt; in the &lt;code&gt;wp-syntax/&lt;/code&gt;
plugin directory in your favorite text editor and change the GeSHi
include line (for &lt;span class="caps"&gt;WP&lt;/span&gt;-Syntax 0.9.12, this is line 53)&amp;nbsp;from:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;include_once(&amp;quot;geshi/geshi.php&amp;quot;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;include_once(&amp;quot;geshi.php&amp;quot;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you already have GeSHi installed in the &lt;span class="caps"&gt;PHP&lt;/span&gt; include path, just remove
the &lt;code&gt;geshi&lt;/code&gt; directory in your &lt;code&gt;wp-syntax/&lt;/code&gt; plugin directory, flush the
WordPress caches (if any), and load a page which uses GeSHi - it should
now use the host-wide version. If you want to still use a local version
for wp-syntax, you can move things around to where they &lt;em&gt;should&lt;/em&gt; be in
the &lt;code&gt;wp-syntax/&lt;/code&gt; plugin&amp;nbsp;directory:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;mv geshi/geshi.php . &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; mv geshi/geshi/* geshi/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; rmdir geshi/geshi
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note - if you&amp;#8217;re in a shared hosting environment, or are otherwise not
able to upgrade the php-geshi package on your server yourself, you might
not want to do&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;I also &lt;a href="http://wordpress.org/support/topic/wp-syntax-move-geshi-include-path-to-allow-use-with-host-wide-geshi?replies=1#post-2556903"&gt;posted about this in the WordPress support
forums&lt;/a&gt;.
Hopefully the &lt;span class="caps"&gt;WP&lt;/span&gt;-Syntax devs will include this change in the next&amp;nbsp;version&amp;#8230;&lt;/p&gt;</summary><category term="GeSHi"></category><category term="PHP"></category><category term="syntax highlighting"></category><category term="wordpress"></category></entry><entry><title>Puppet Syntax Highlighting with GeSHi</title><link href="http://blog.jasonantman.com/2012/01/puppet-syntax-highlighting-with-geshi/" rel="alternate"></link><updated>2012-01-11T12:32:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-11:2012/01/puppet-syntax-highlighting-with-geshi/</id><summary type="html">&lt;p&gt;This blog is run on wordpress, and I also do quite a bit in &lt;span class="caps"&gt;PHP&lt;/span&gt;, so I&amp;#8217;m
familiar with the &lt;a href="http://qbnz.com/highlighter/"&gt;GeSHi&lt;/a&gt; syntax
highlighter. It&amp;#8217;s &lt;span class="caps"&gt;PHP&lt;/span&gt;-based, and can run both as a Wordpress plugin
(&lt;a href="http://wordpress.org/extend/plugins/wp-syntax/"&gt;&lt;span class="caps"&gt;WP&lt;/span&gt;-Syntax&lt;/a&gt;) and as a
&lt;span class="caps"&gt;PHP&lt;/span&gt; module. It also works quite well with the MediaWiki &lt;a href="http://www.mediawiki.org/wiki/Extension:SyntaxHighlight_GeSHi"&gt;SyntaxHighlight
GeSHi&lt;/a&gt;&amp;nbsp;extension.&lt;/p&gt;
&lt;p&gt;Today I was documenting some &lt;a href="http://www.puppet.org"&gt;Puppet&lt;/a&gt; code in a
wiki, and realized that I didn&amp;#8217;t have syntax highlighting. Well, fellow
Linux sysadmin and puppetmaster Jason Hancock was nice enough to post on
his blog (&lt;a href="http://geek.jasonhancock.com/2011/10/14/puppet-syntax-highlighting-geshi/"&gt;Puppet Syntax Highlighting with
GeSHi&lt;/a&gt;)
that he&amp;#8217;s developed a GeSHi language file for Puppet, available from
&lt;a href="https://github.com/jasonhancock/geshi-language-files"&gt;GitHub&lt;/a&gt;. Many&amp;nbsp;thanks!&lt;/p&gt;</summary><category term="GeSHi"></category><category term="mediawiki"></category><category term="PHP"></category><category term="puppet"></category><category term="wordpress"></category></entry><entry><title>Firefox QR Code Generator</title><link href="http://blog.jasonantman.com/2012/01/firefox-qr-code-generator/" rel="alternate"></link><updated>2012-01-10T23:06:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-10:2012/01/firefox-qr-code-generator/</id><summary type="html">&lt;p&gt;Just a quick little tip, I happened by the &lt;a href="https://addons.mozilla.org/en-US/firefox/addon/mobile-barcoder/"&gt;Mobile
Barcoder&lt;/a&gt;
Firefox add-on the other day. It&amp;#8217;s a Firefox add-on that generates &lt;a href="http://en.wikipedia.org/wiki/Qr_code"&gt;&lt;span class="caps"&gt;QR&lt;/span&gt;
Code&lt;/a&gt; barcodes for text or links,
right in your browser. While my Droid3 has a full keyboard, sometimes I
still want to quickly send links from my desktop browser session to my
phone. Firefox Sync helps a lot but is a bit slow on the phone (since I
usually have 100+ tabs open between all of my desktop Firefox sessions),
and email is an option but a bit&amp;nbsp;slower.&lt;/p&gt;
&lt;p&gt;There are two caveats about this add-on&amp;nbsp;though:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The feature to generate a &lt;span class="caps"&gt;QR&lt;/span&gt; code for the &lt;span class="caps"&gt;URL&lt;/span&gt; of the current page
    shows up in the status bar, which isn&amp;#8217;t shown in modern versions of
    Firefox. You&amp;#8217;ll need to enable the &lt;a href="https://support.mozilla.org/en-US/kb/what-add-bar"&gt;Add-on
    bar&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;It uses the
    &lt;a href="http://mobilecodes.nokia.com/"&gt;http://mobilecodes.nokia.com/&lt;/a&gt;
    server to generate barcodes, so it&amp;#8217;s dependent on connectivity and
    that&amp;nbsp;service.&lt;/li&gt;
&lt;/ol&gt;</summary><category term="barcode"></category><category term="firefox"></category><category term="mobile"></category><category term="Mozilla"></category><category term="qr code"></category></entry><entry><title>Vyatta - Showing ISC dhcpd fixed-address leases</title><link href="http://blog.jasonantman.com/2011/12/vyatta-showing-isc-dhcpd-fixed-address-leases/" rel="alternate"></link><updated>2011-12-24T14:42:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-12-24:2011/12/vyatta-showing-isc-dhcpd-fixed-address-leases/</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;ISC&lt;/span&gt; &lt;a href="http://www.isc.org/software/dhcp"&gt;dhcpd&lt;/a&gt; has the ability to always
give a specific &lt;span class="caps"&gt;MAC&lt;/span&gt; address the same &lt;span class="caps"&gt;IP&lt;/span&gt; address &amp;#8220;lease&amp;#8221; using the
fixed-address configuration option. This is configured in
&lt;a href="http://www.vyatta.org"&gt;Vyatta&lt;/a&gt; using the &lt;code&gt;static-mapping&lt;/code&gt; configuration
statement. Unfortunately, since dhcpd doesn&amp;#8217;t store fixed-address leases
in the &lt;code&gt;dhcpd.leases&lt;/code&gt; file, the Vyatta &lt;code&gt;show dhcp leases&lt;/code&gt; command
doesn&amp;#8217;t show anything about them - which makes it difficult to debug
anything dhcp-related if all of the hosts on your network are setup for
fixed addresses. I found a mention of this on the &lt;a href="http://www.vyatta.org/forum/viewtopic.php?p=121558"&gt;vyatta
forum&lt;/a&gt;, and also an
&lt;a href="https://bugzilla.vyatta.com/show_bug.cgi?id=1990"&gt;open bug (1990)&lt;/a&gt; to
fix it, but no proposed resolution. Since I came across this problem and
happen to know a bit about &lt;span class="caps"&gt;ISC&lt;/span&gt; dhcpd, I developed both a workaround for
users (including a perl script) and a possible solution for the Vyatta
developers to&amp;nbsp;implement.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Workaround for&amp;nbsp;Users:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s no way to get dhcpd to store fixed-address hosts in the
dhcpd.leases file (though it&amp;#8217;s been discussed on the dhcpd-users mailing
list a few times). There is, however, a way to get dhcpd to log every
time it sends an &lt;span class="caps"&gt;ACK&lt;/span&gt; to a client. The following Vyatta configuration
commands will get dhcpd to log all transactions to syslog, will have
&lt;a href="http://rsyslog.com/"&gt;rsyslog&lt;/a&gt; put that in &lt;code&gt;/var/log/user/dhcpd&lt;/code&gt;. Since
this log can fill up very quickly on a busy server, the latter two
commands will tell &lt;a href="https://fedorahosted.org/logrotate/"&gt;logrotate&lt;/a&gt; to
rotate the log file when it reaches 3000k in size, and keep 5 copies
(feel free to adjust to your&amp;nbsp;needs):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;set &lt;/span&gt;service dhcp-server global-parameters &lt;span class="s2"&gt;&amp;quot;log-facility local2;&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;set &lt;/span&gt;system syslog file dhcpd facility local2 level debug
&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;set &lt;/span&gt;system syslog file dhcpd archive files 5
&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;set &lt;/span&gt;system syslog file dhcpd archive size 3000
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once this is done, you can &lt;code&gt;tail -f /var/log/user/dhcpd&lt;/code&gt; to watch &lt;span class="caps"&gt;DHCP&lt;/span&gt;
discover/request/offer/ack in realtime, or grep through the log file for
a specific &lt;span class="caps"&gt;IP&lt;/span&gt; or &lt;span class="caps"&gt;MAC&lt;/span&gt;. If you want an easier method, I&amp;#8217;ve written a perl
script (latest version will always live in &lt;a href="https://github.com/jantman/misc-scripts/blob/master/show_dhcp_fixed_ACKs.pl"&gt;my GitHub misc-scripts
repo&lt;/a&gt;)
to grep through &lt;code&gt;/var/log/user/dhcpd&lt;/code&gt; and show the most recent &lt;span class="caps"&gt;DHCPACK&lt;/span&gt;
for each &lt;span class="caps"&gt;IP&lt;/span&gt; address, sorted by &lt;span class="caps"&gt;IP&lt;/span&gt;. Here&amp;#8217;s the code of the simple script,
which is more than half comments. To use it, after performing the above
steps, all you need to do is login to your Vyatta box,
&lt;code&gt;wget https://raw.github.com/jantman/misc-scripts/master/show_dhcp_fixed_ACKs.pl&lt;/code&gt;
and then &lt;code&gt;perl show_dhcp_fixed_ACKs.pl&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!/usr/bin/perl&lt;/span&gt;

&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# show_dhcp_fixed_ACKs.pl - script to show the most recent &lt;span class="caps"&gt;DHCP&lt;/span&gt; ACKs per &lt;span class="caps"&gt;IP&lt;/span&gt; address for &lt;span class="caps"&gt;ISC&lt;/span&gt; DHCPd,&lt;/span&gt;
&lt;span class="c1"&gt;#   from a log file. Originally written for Vyatta routers that just show the dynamic leases.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# To use this, you need to have dhcpd logging to syslog, and your syslog server putting the log file at&lt;/span&gt;
&lt;span class="c1"&gt;# /var/log/user/dhcpd (or a file path specified by the $logfile variable below.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# To accomplish this on Vyatta 6.3, run:&lt;/span&gt;
&lt;span class="c1"&gt;# set service dhcp-server global-parameters &amp;quot;log-facility local2;&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# set system syslog file dhcpd facility local2 level debug&lt;/span&gt;
&lt;span class="c1"&gt;# set system syslog file dhcpd archive files 5&lt;/span&gt;
&lt;span class="c1"&gt;# set system syslog file dhcpd archive size 3000&lt;/span&gt;
&lt;span class="c1"&gt;# commit&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Copyright 2011 Jason Antman  All Rights Reserved.&lt;/span&gt;
&lt;span class="c1"&gt;# This script is free for use by anyone anywhere, provided that you comply with the following terms:&lt;/span&gt;
&lt;span class="c1"&gt;# 1) Keep this notice and copyright statement intact.&lt;/span&gt;
&lt;span class="c1"&gt;# 2) Send any substantial changes, improvements or bog fixes back to me at the above address.&lt;/span&gt;
&lt;span class="c1"&gt;# 3) If you include this in a product or redistribute it, you notify me, and include my name in the credits or changelog.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# The following &lt;span class="caps"&gt;URL&lt;/span&gt; always points to the newest version of this script. If you obtained it from another source, you should&lt;/span&gt;
&lt;span class="c1"&gt;# check here:&lt;/span&gt;
&lt;span class="c1"&gt;# $HeadURL$&lt;/span&gt;
&lt;span class="c1"&gt;# $LastChangedRevision$&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;CHANGELOG&lt;/span&gt;:&lt;/span&gt;
&lt;span class="c1"&gt;# 2011-12-24 jason@jasonantman.com:&lt;/span&gt;
&lt;span class="c1"&gt;#    initial version of script&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;strict&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;warnings&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$logfile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/var/log/user/dhcpd&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;%data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;();&lt;/span&gt;

&lt;span class="nb"&gt;open&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;DF&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$logfile&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;die&lt;/span&gt; &lt;span class="vg"&gt;$!&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="nv"&gt;$line&lt;/span&gt; &lt;span class="o"&gt;!~&lt;/span&gt; &lt;span class="sr"&gt;m/dhcpd: &lt;span class="caps"&gt;DHCPACK&lt;/span&gt;/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;next&lt;/span&gt;&lt;span class="p"&gt;;}&lt;/span&gt;
    &lt;span class="nv"&gt;$line&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt; &lt;span class="sr"&gt;m/([A-Za-z]+ [0-9]+ [0-9]{1,2}:[0-9]{2}:[0-9]{2}) [^\/x]+ dhcpd: &lt;span class="caps"&gt;DHCPACK&lt;/span&gt; on (\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}) to ((?:[0-9a-f]{2}[:-]){5}[0-9a-f]{2}) via (.+)/&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="c1"&gt;#print &amp;quot;$1==$2==$3==$4==\n&amp;quot; ;&lt;/span&gt;
    &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mac&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;if&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$4&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ip&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;    
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%-18s %-20s %-18s %-10s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;IP&lt;/span&gt; Address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Hardware Address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Interface&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%-18s %-20s %-18s %-10s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;----------&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;----------------&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;----&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;---------&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;# begin sort by &lt;span class="caps"&gt;IP&lt;/span&gt; address&lt;/span&gt;
&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;@keys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
  &lt;span class="nb"&gt;map&lt;/span&gt;  &lt;span class="nb"&gt;substr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class="nb"&gt;sort&lt;/span&gt;
  &lt;span class="nb"&gt;map&lt;/span&gt;  &lt;span class="nb"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;C4&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class="sr"&gt;/(\d+)\.(\d+)\.(\d+)\.(\d+)/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="nv"&gt;$_&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys&lt;/span&gt; &lt;span class="nv"&gt;%data&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="c1"&gt;# end sort by &lt;span class="caps"&gt;IP&lt;/span&gt; address&lt;/span&gt;

&lt;span class="k"&gt;foreach&lt;/span&gt; &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$key&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;@keys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%-18s %-20s %-18s %-10s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$key&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ip&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$key&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mac&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$key&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$key&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;if&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;A solution for&amp;nbsp;Vyatta:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I suggested this to Vyatta in a reply to &lt;a href="https://bugzilla.vyatta.com/show_bug.cgi?id=1990"&gt;bug
1990&lt;/a&gt;. Since they
already use &lt;a href="http://rsyslog.com/"&gt;rsyslog&lt;/a&gt; which has very powerful
processing capabilities, it would be easy to have rsyslog parse the
&lt;span class="caps"&gt;DHCPACK&lt;/span&gt; messages in real time and update some data store (flat files or
a simple database) with the information. While how to store this would
be up to the Vyatta guys, I have some rsyslog configuration to parse
&lt;span class="caps"&gt;DHCPACK&lt;/span&gt; messages and update a MySQL database (with two tables; one for
most recent &lt;span class="caps"&gt;ACK&lt;/span&gt; per &lt;span class="caps"&gt;IP&lt;/span&gt; address and one for most recent &lt;span class="caps"&gt;ACK&lt;/span&gt; per &lt;span class="caps"&gt;MAC&lt;/span&gt;
address) that might be of some&amp;nbsp;use:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;$template DHCPACKonIP, &amp;quot;INSERT INTO dhcplog_ip   
       SET   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       msg_type=&amp;#39;DHCPACK&amp;#39;,   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,6,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;   
       ON DUPLICATE KEY UPDATE   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       gateway=&amp;#39;%msg:R,ERE,6,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;  
&amp;quot;,SQL

$template DHCPACKonMAC, &amp;quot;INSERT INTO dhcplog_mac   
       SET   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       msg_type=&amp;#39;DHCPACK&amp;#39;,   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,6,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;   
       ON DUPLICATE KEY UPDATE   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,6,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;  
&amp;quot;,SQL

$template DHCPACKtoIP, &amp;quot;INSERT INTO dhcplog_ip   
       SET   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       msg_type=&amp;#39;DHCPACK&amp;#39;,   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,4,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;   
       ON DUPLICATE KEY UPDATE   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       gateway=&amp;#39;%msg:R,ERE,4,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;  
&amp;quot;,SQL

$template DHCPACKtoMAC, &amp;quot;INSERT INTO dhcplog_mac   
       SET   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       msg_type=&amp;#39;DHCPACK&amp;#39;,   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,4,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;   
       ON DUPLICATE KEY UPDATE   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,4,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;  
&amp;quot;,SQL

:msg, startswith, &amp;quot; DHCPACK on&amp;quot; :ommysql:hostname,database,dbuser,dbpass;DHCPACKonIP
&lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; :ommysql:hostname,database,dbuser,dbpass;DHCPACKonMAC
&lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; ~ ### &lt;span class="caps"&gt;DISCARD&lt;/span&gt;

if $msg startswith &amp;#39; &lt;span class="caps"&gt;DHCPACK&lt;/span&gt; to&amp;#39; and ( not ( $msg contains &amp;#39;no client hardware address&amp;#39; ) )   
then :ommysql:hostname,database,dbuser,dbpass;DHCPACKtoMAC
&lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; :ommysql:hostname,database,dbuser,dbpass;DHCPACKtoIP
&lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; ~ ### &lt;span class="caps"&gt;DISCARD&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="dhcpd"></category><category term="rsyslog"></category><category term="vyatta"></category></entry><entry><title>php-suhosin syslog issues</title><link href="http://blog.jasonantman.com/2011/10/php-suhosin-syslog-issues/" rel="alternate"></link><updated>2011-10-21T10:24:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-10-21:2011/10/php-suhosin-syslog-issues/</id><summary type="html">&lt;p&gt;I just installed php-&lt;a href="http://www.hardened-php.net/suhosin/"&gt;suhosin&lt;/a&gt;
0.9.29 from &lt;span class="caps"&gt;EPEL&lt;/span&gt; on a CentOS 5.6 box. I&amp;#8217;m running a whole bunch of
name-based vhosts in Apache, and have a bunch of web apps, so I opted to
run suhosin in simulation mode (don&amp;#8217;t actually block anything, but log
errors) and have it log via syslog to a single file. Unfortunately, when
I configured this, the syslog messages started showing up in the wrong
place, apparently with the wrong facility &lt;em&gt;and&lt;/em&gt; priority. After some
roundabout debugging (at first assuming syslogd to be the problem), I
determined that, for whatever really strange reason (perhaps an
incorrect syslog.h on the &lt;span class="caps"&gt;EPEL&lt;/span&gt; box that built the suhosin package?) the
LOG_* constants were incorrect. I looked up the correct integer values
in &lt;code&gt;/usr/include/sys/syslog.h&lt;/code&gt; and the following configuration
directives accomplished the task&amp;nbsp;correctly:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="na"&gt;suhosin.log.syslog.facility&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;128&lt;/span&gt;
&lt;span class="c1"&gt;; 128 = LOG_LOCAL0&lt;/span&gt;

&lt;span class="na"&gt;suhosin.log.syslog.priority&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;5&lt;/span&gt;
&lt;span class="c1"&gt;; 5 = LOG_NOTICE&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This one line puts suhosin into simulation mode, where it only logs
errors instead of enforcing on&amp;nbsp;them:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="na"&gt;suhosin.simulation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;On&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="centos"></category><category term="logging"></category><category term="PHP"></category><category term="security"></category><category term="suhosin"></category><category term="syslog"></category></entry><entry><title>Blackberry Oops</title><link href="http://blog.jasonantman.com/2011/10/blackberry-oops/" rel="alternate"></link><updated>2011-10-13T22:20:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-10-13:2011/10/blackberry-oops/</id><summary type="html">&lt;p&gt;If you&amp;#8217;ve been following the tech news lately, you&amp;#8217;ve probably heard at
least a bit about the
&lt;a href="http://www.cnn.com/2011/10/12/tech/mobile/blackberry-outage/"&gt;massive&lt;/a&gt;
&lt;a href="http://abcnews.go.com/blogs/technology/2011/10/blackberry-outage-spreads-to-u-s/"&gt;blackberry&lt;/a&gt;
&lt;a href="http://www.nytimes.com/2011/10/14/technology/rim-struggles-to-overcome-blackberry-outages.html?_r=1"&gt;outage&lt;/a&gt;
over the past three days. While yes, it&amp;#8217;s the first truly grand failure
of &lt;span class="caps"&gt;RIM&lt;/span&gt;&amp;#8217;s infrastructure in their 12-year history, it&amp;#8217;s also a wonderful
case&amp;nbsp;study.&lt;/p&gt;
&lt;p&gt;Apparently the outage started Monday morning with &lt;span class="caps"&gt;RIM&lt;/span&gt; infrastructure in
Europe, the Middle East and Asia. However, by Wednesday, it had become a
global outage/slowdown of BlackBerry infrastructure (specifically the
parts that go through &lt;span class="caps"&gt;RIM&lt;/span&gt; - email, web browsing, and &lt;span class="caps"&gt;BBM&lt;/span&gt;; voice calls
and &lt;span class="caps"&gt;SMS&lt;/span&gt;/&lt;span class="caps"&gt;MMS&lt;/span&gt; were unaffected). With BlackBerry&amp;#8217;s market share falling,
Android&amp;#8217;s rapidly growing (and Android slowly becoming a viable
enterprise option), and the launch of the iPhone 4S just around the
corner, the timing of this couldn&amp;#8217;t be worse for&amp;nbsp;&lt;span class="caps"&gt;RIM&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;RIM&lt;/span&gt;&amp;#8217;s original
&lt;a href="http://www.rim.com/newsroom/service-update.shtml"&gt;statement&lt;/a&gt; about the
problem, at 21:30 on Tuesday October 11th,&amp;nbsp;was,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The messaging and browsing delays that some of you are still
experiencing were caused by a core switch failure within &lt;span class="caps"&gt;RIM&lt;/span&gt;’s
infrastructure. Although the system is designed to failover to a
back-up switch, the failover did not function as previously tested. As
a result, a large backlog of data was generated and we are now working
to clear that backlog and restore normal service as quickly as
possible. We sincerely apologise for the inconvenience caused to many
of you and we will continue to keep you&amp;nbsp;informed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I haven&amp;#8217;t been able to find much more technical information than that -
a &lt;a href="http://www.computerworld.com/s/article/9220736/RIM_global_outage_caused_by_core_switch_failure_fix_under_way"&gt;&lt;span class="caps"&gt;CNET&lt;/span&gt; article from
Tuesday&lt;/a&gt;
goes into as much depth as anything I could find. I did find one mention
(misplaced the link) that the core switch in question uses technology
from &amp;#8220;multiple vendors&amp;#8221;. So what follows is part common sense (for me&amp;#8230;
why not for a multi-national corporation?) and part speculation. If
you&amp;#8217;re unfamiliar with &lt;span class="caps"&gt;RIM&lt;/span&gt;&amp;#8217;s architecture, the pertinent points are that
all Internet-bound traffic (browsing, email, and &lt;span class="caps"&gt;BBM&lt;/span&gt;) is piped through
&lt;span class="caps"&gt;RIM&lt;/span&gt;&amp;#8217;s data centers, where it&amp;#8217;s encypted and who-knows-what-else&amp;#8217;ed
(perhaps
&lt;a href="http://online.wsj.com/article/SB10001424052970204612504576608561811929654.html"&gt;monitored&lt;/a&gt;)
before going back out onto the &amp;#8216;net. In the Enterprise market, their big
claim is encryption/security, and monitoring/management/policy
enforcement on&amp;nbsp;handsets.&lt;/p&gt;
&lt;p&gt;First main point: &lt;span class="caps"&gt;RIM&lt;/span&gt; is a &lt;em&gt;big&lt;/em&gt; company. The thought that they rely on
an (apparently custom) core switch - a &lt;em&gt;single&lt;/em&gt; core switch for multiple
&lt;em&gt;continents&lt;/em&gt; - is amazing. It&amp;#8217;s even more amazing that they&amp;#8217;d let such a
large part of their infrastructure ride on an architecture with,
apparently, an untested failover mechanism. Of course I don&amp;#8217;t know all
the details, but I&amp;#8217;d hope that for a single piece of hardware which is
so critical, they&amp;#8217;d a) have a cold spare physically nearby so a
replacement wouldn&amp;#8217;t take a day or two, and b) if they can&amp;#8217;t do an
online failover test, at least have a full lab environment to test the
failover&amp;nbsp;in.&lt;/p&gt;
&lt;p&gt;Second main point: Their big claim through all of this is that they
didn&amp;#8217;t lose any data - email, &lt;span class="caps"&gt;BBM&lt;/span&gt;, etc. - it just got delayed. So if
there was a core switch failure in their data center serving &lt;span class="caps"&gt;EMEA&lt;/span&gt;, and
the next day global services slowed to a crawl, the only thing that
comes to mind to me is a waterfall; &lt;span class="caps"&gt;EMEA&lt;/span&gt; went down, and they started
rerouting traffic to their North America data center. The increased load
- probably a disaster recovery plan they never truly tested or even
planned - brought everything to a screeching halt, and caused them to
resort to simply caching messaging and pushing it out bit by bit as the
infrastructure could handle.&amp;nbsp;Oops.&lt;/p&gt;
&lt;p&gt;So what are my (admittedly poorly-informed) thoughts on&amp;nbsp;this?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Scaling out works. Scaling up - especially with single points of
    failure, or N+1 redundancy - is dangerous. If &lt;span class="caps"&gt;RIM&lt;/span&gt; had scaled out and
    used regional data centers, with a close-to-commodity core and as
    much redundancy as possible, this wouldn&amp;#8217;t have happened. Sure,
    infrastructure costs money. But if that one &amp;#8220;core switch&amp;#8221; had been
    1,000 devices spread across multiple racks in multiple data centers,
    this never would have happened. And the devices would be
    comparatively cheap enough to probably keep spares on hand too. And
    regularly test their failover procedures. To all of the big
    businesses (apparently like &lt;span class="caps"&gt;RIM&lt;/span&gt;) who still think that big iron is
    the only way to do things right&amp;#8230; maybe it&amp;#8217;s time to take a hard
    look at that, and compare your architecture to that of the modern,
    new, hip giants like Google and Facebook. Grids and clusters. Nodes
    that can fail without anyone blinking. Scaling out might not fix
    every problem, but having half the world on a single core switch
    with N+1 redundancy probably isn&amp;#8217;t smart&amp;nbsp;either.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disasters need to be planned for. Every possible contingency needs
    to be planned for. Plans need to be tested, regularly. If your giant
    core switch goes down and the failover doesn&amp;#8217;t &amp;#8220;function as
    previously tested&amp;#8221;, there&amp;#8217;s a serious problem both in your disaster
    planning, and in your validation and test procedure. If you have
    half of your customer base riding on a failover plan that isn&amp;#8217;t
    &lt;em&gt;regularly&lt;/em&gt; tested or otherwise validated, that&amp;#8217;s bad. While I can
    argue that the whole architecture - given this massive point of
    failure - could stand to be re-thought, the real issue here is with
    test/validation methodologies and procedures. For a company with 70
    million users, having a piece of infrastructure this critical fail,
    and the failover &amp;#8216;not work as tested&amp;#8217; is a very serious&amp;nbsp;issue.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Damage control is important. As I said, I can only imagine that the
    severe service degradation outside of &lt;span class="caps"&gt;EMEA&lt;/span&gt; was due to rerouting data
    from &lt;span class="caps"&gt;EMEA&lt;/span&gt; to the remaining functional data center(s). Such a
    solution should only be considered if it has been tested, or at
    least has engineering validation. If it was part of the disaster
    recovery plan, it obviously isn&amp;#8217;t actually a suitable solution, and
    served only to increase the scope of the outage. If it wasn&amp;#8217;t part
    of the disaster recovery plan, and was decided on-the-fly, someone
    really didn&amp;#8217;t do their research and engineering before putting the
    fix in place. A workable solution should have been planned ahead of
    time. And if one wasn&amp;#8217;t, it&amp;#8217;s very bad practice - this outage shows
    the results - to put in place a fix that hasn&amp;#8217;t been thought&amp;nbsp;out.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For a company whose business is so telecom-focused, this seems like a
glaringly bad design that shouldn&amp;#8217;t be acceptable in a&amp;nbsp;telecom.&lt;/p&gt;</summary><category term="blackberry"></category><category term="outage"></category></entry><entry><title>Vyatta NetworkOS router/firewall on Alix board / Compact Flash</title><link href="http://blog.jasonantman.com/2011/09/vyatta-networkos-routerfirewall-on-alix-board-compact-flash/" rel="alternate"></link><updated>2011-09-30T14:16:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-09-30:2011/09/vyatta-networkos-routerfirewall-on-alix-board-compact-flash/</id><summary type="html">&lt;p&gt;With the impending move to an apartment in Georgia and the migration of
my rack full of servers to a hosting provider, there&amp;#8217;s no longer a need
for me to run my &lt;a href="http://www.vyatta.org/"&gt;Vyatta &lt;span class="caps"&gt;VC&lt;/span&gt;&lt;/a&gt; router on a beefy
dual-&lt;span class="caps"&gt;CPU&lt;/span&gt; RAIDed &lt;a href="http://h18000.www1.hp.com/products/quickspecs/11504_na/11504_na.HTML"&gt;&lt;span class="caps"&gt;DL360&lt;/span&gt;
G3&lt;/a&gt;
&lt;span class="caps"&gt;HP&lt;/span&gt; Proliant server chassis. I found an older PCEngines &lt;a href="http://pcengines.ch/alix2c1.htm"&gt;Alix
2c1&lt;/a&gt; single board computer (433 MHz &lt;span class="caps"&gt;AMD&lt;/span&gt;
Geode &lt;span class="caps"&gt;LX700&lt;/span&gt; , &lt;span class="caps"&gt;128MB&lt;/span&gt; &lt;span class="caps"&gt;DDR&lt;/span&gt; &lt;span class="caps"&gt;DRAM&lt;/span&gt;, CompactFlash (&lt;span class="caps"&gt;CF&lt;/span&gt;) card socket, MiniPCI, 3x
10/100 ethernet) lying around, and decided to turn that into the new
router. But I&amp;#8217;ve been so spoiled by Vyatta&amp;#8217;s good performance (well, at
least on an x86 server) and the &lt;em&gt;real&lt;/em&gt; &lt;span class="caps"&gt;CLI&lt;/span&gt;, so I don&amp;#8217;t think I can go
back to something like &lt;a href="http://m0n0.ch/wall/"&gt;m0n0wall&lt;/a&gt; or
&lt;a href="http://www.pfsense.org/"&gt;pfSense&lt;/a&gt;, and since it&amp;#8217;s going to be my only
network services box (also doing &lt;span class="caps"&gt;DNS&lt;/span&gt;, &lt;span class="caps"&gt;DHCP&lt;/span&gt;, firewalling, &lt;span class="caps"&gt;NAT&lt;/span&gt;, and maybe
IPsec &lt;span class="caps"&gt;VPN&lt;/span&gt;) it&amp;#8217;s not viable to use the type of older Cisco or Juniper
hardware that I can&amp;nbsp;afford.&lt;/p&gt;
&lt;p&gt;The down side is that Vyatta isn&amp;#8217;t really designed or tuned for small
systems, let alone &lt;span class="caps"&gt;CF&lt;/span&gt; media that doesn&amp;#8217;t take too well to lots of
writes. So, I&amp;#8217;m going to begin experimentation with doing a &lt;span class="caps"&gt;CF&lt;/span&gt; install
of the current Vyatta Core 6.3, and we&amp;#8217;ll see how it goes and what
tuning I do over&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;I found two relatively good references; a &lt;a href="http://www.vyatta.org/forum/viewtopic.php?t=502"&gt;post on the vyatta.org
forum&lt;/a&gt; from 2008,
relating to Vyatta version 4 (also on the author&amp;#8217;s
&lt;a href="http://dataflip.blogspot.com/2008/06/optimizing-vyatta-for-compact-flash.html"&gt;blog&lt;/a&gt;),
and a &lt;a href="http://peytongroup.wordpress.com/2010/02/16/vyatta-community-on-a-compact-flash/"&gt;blog
post&lt;/a&gt;
detailing a more complex
&lt;a href="http://squashfs.sourceforge.net/"&gt;SquashFS&lt;/a&gt;/&lt;a href="http://en.wikipedia.org/wiki/Tmpfs"&gt;tmpfs&lt;/a&gt;/&lt;a href="http://unionfs.filesystems.org/"&gt;UnionFS&lt;/a&gt;
read-only Vyatta install. Given my relatively short timeframe and little
free time, I decided to try the former approach for now, and plan to
make a more customized and tuned &lt;span class="caps"&gt;CF&lt;/span&gt; version of Vyatta in the&amp;nbsp;future.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Creating the actual disk&amp;nbsp;image:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;My development platform at the moment is an intel-based MacBook Pro,
running MacOS X 10.6.4 and VirtualBox 4.0.12. As much of a Linux fan as
I am, my work laptop runs Mac (like everyone else in the office) and
lately I can&amp;#8217;t guarantee that I&amp;#8217;ll be at my desktop long enough to
finish anything. The target is an Alix2c1 with a &lt;span class="caps"&gt;2GB&lt;/span&gt; SanDisk Ultra &lt;span class="caps"&gt;CF&lt;/span&gt;
card (yes, I know an industrial card would be better, but I couldn&amp;#8217;t get
my hands on one). For starters, I created a new VirtualBox &lt;span class="caps"&gt;VM&lt;/span&gt; with the
following&amp;nbsp;settings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="caps"&gt;OS&lt;/span&gt; Type: Linux&amp;nbsp;2.6&lt;/li&gt;
&lt;li&gt;Base Memory:&amp;nbsp;&lt;span class="caps"&gt;128MB&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Boot Order: Floppy, &lt;span class="caps"&gt;CD&lt;/span&gt;-&lt;span class="caps"&gt;ROM&lt;/span&gt;, Hard&amp;nbsp;Disk&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;IDE&lt;/span&gt; Controller Primary: mounted vyatta-livecd_VC6.3 &lt;span class="caps"&gt;ISO&lt;/span&gt;&amp;nbsp;image&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;IDE&lt;/span&gt; Controller Secondary: &lt;span class="caps"&gt;RAW&lt;/span&gt; &lt;span class="caps"&gt;VMDK&lt;/span&gt; image (created&amp;nbsp;below)&lt;/li&gt;
&lt;li&gt;Audio:&amp;nbsp;None&lt;/li&gt;
&lt;li&gt;Network: Disabled &lt;em&gt;(this is important, as Vyatta saves the
    interfaces by hardware address, and it would require some config
    editing and reboots to change&amp;nbsp;them)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Serial Port: disconnected (but&amp;nbsp;present)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One difficulty I ran into on Mac is mounting the raw &lt;span class="caps"&gt;CF&lt;/span&gt; card in the
VirtualBox guest. I plugged it in via a &lt;span class="caps"&gt;USB&lt;/span&gt; reader, and of course it
automatically mounted in MacOS. I ejected it and the &lt;code&gt;/dev/disk1&lt;/code&gt; device
disappeared. It turns out that the full procedure (as far as I could
tell) for Mac&amp;nbsp;is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plug in the &lt;span class="caps"&gt;CF&lt;/span&gt; card and&amp;nbsp;reader.&lt;/li&gt;
&lt;li&gt;It should automount. Run &lt;code&gt;mount&lt;/code&gt; to see what the actual device is -
    in my case, the &lt;code&gt;/dev/disk1s1&lt;/code&gt; partition was mounted, so the disk is
    &lt;code&gt;/dev/disk1&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;sudo umount -f /dev/disk1&lt;/code&gt;. It seems that the MacOS automounter
    has a god complex, so you may need to re-run this command quite a
    few times throughout the process if you get device or resource busy&amp;nbsp;errors.&lt;/li&gt;
&lt;li&gt;In an appropriate directory, create the raw &lt;span class="caps"&gt;VMDK&lt;/span&gt; image with:
    &lt;code&gt;VBoxManage internalcommands createrawvmdk -filename rawdisk.vmdk -rawdisk /dev/disk1&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;When creating your &lt;span class="caps"&gt;VM&lt;/span&gt;, you&amp;#8217;ll have an option to select Use an
    Existing Virtual Disk. Use that option, and select the file created
    in the last&amp;nbsp;step.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once that&amp;#8217;s done, and you&amp;#8217;ve setup the &lt;span class="caps"&gt;VM&lt;/span&gt; with the raw disk, boot the &lt;span class="caps"&gt;VM&lt;/span&gt;
(should boot to the Vyatta LiveCD), login as usual for an install
(vyatta:vyatta), and the the fun&amp;nbsp;begins:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;At the prompt after logging in, &lt;code&gt;sudo su -&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Edit &lt;code&gt;/opt/vyatta/sbin/install-system&lt;/code&gt; (hint: Vyatta has nano and vi
    installed. &lt;code&gt;nano -c filename&lt;/code&gt; shows line numbers) and change the
    &lt;code&gt;ROOT_FSTYPE&lt;/code&gt; variable (line 78 in &lt;span class="caps"&gt;VC6&lt;/span&gt;.3) from &amp;#8220;ext4&amp;#8221; to&amp;nbsp;&amp;#8220;ext2&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;install-system&lt;/code&gt;. I used all default options (including one
    partition) and it seemed to work fine. It took a minute or two to
    create the ext2 filesystem on my &lt;span class="caps"&gt;2GB&lt;/span&gt; &lt;span class="caps"&gt;CF&lt;/span&gt;&amp;nbsp;card.&lt;/li&gt;
&lt;li&gt;The file copy took even longer&amp;#8230; so be patient, or have a book&amp;nbsp;handy.&lt;/li&gt;
&lt;li&gt;When system-install finishes and you get the root prompt back,
    before rebooting, continue with some minor&amp;nbsp;tweaks:&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mkdir /mnt/temp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mount /dev/sda1 /mnt/temp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd /mnt/temp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Edit &lt;code&gt;boot/grub/grub.cfg&lt;/code&gt; and change all occurrences of
    &amp;#8220;root=&lt;span class="caps"&gt;UUID&lt;/span&gt;=&amp;#8230;&amp;#8221; entries for the &amp;#8220;linux&amp;#8221; lines (lines 13, 18, 23, 28
    in my grub.cfg) to &amp;#8220;root=/dev/sda1&amp;#8221;. My only real reason for this
    change is so that I can move my altered config files (config.boot,
    fstab and grub.cfg) with minimal changes when I upgrade or make a
    different vyatta &lt;span class="caps"&gt;CF&lt;/span&gt; card, without having to update the &lt;span class="caps"&gt;UUID&lt;/span&gt; for the
    new&amp;nbsp;partition.&lt;/li&gt;
&lt;li&gt;Edit &lt;code&gt;etc/fstab&lt;/code&gt; and change the &amp;#8220;&lt;span class="caps"&gt;UUID&lt;/span&gt;=&amp;#8230;&amp;#8221; device to&amp;nbsp;&amp;#8221;/dev/sda1&amp;#8221;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;shutdown&lt;/code&gt;. Once the &lt;span class="caps"&gt;VM&lt;/span&gt; is stopped, you can remove the &lt;span class="caps"&gt;CF&lt;/span&gt;&amp;nbsp;card.&lt;/li&gt;
&lt;li&gt;The PCEngines Alix.2 boards use a default serial console speed of
    38400 baud. Pretty much every network device, plus Linux and Vyatta,
    use a default speed of 9600 baud. Once I got the &lt;span class="caps"&gt;CF&lt;/span&gt; card installed
    in the Alix board and hooked it up to my laptop (null modem cable to
    a &lt;span class="caps"&gt;PL&lt;/span&gt;-2303 based &lt;span class="caps"&gt;USB&lt;/span&gt; to serial adapter, minicom for terminal
    emulation), I set my terminal emulator to 38400 8N1, powered the
    board, and then pressed &amp;#8216;s&amp;#8217; during &lt;span class="caps"&gt;POST&lt;/span&gt; to get into &lt;span class="caps"&gt;BIOS&lt;/span&gt; settings.
    Option &amp;#8216;9&amp;#8217; sets the Alix to 9600 baud, &amp;#8216;Q&amp;#8217; to quit, and &amp;#8216;Y&amp;#8217; to save
    changes permanently. The board will reboot, and once the terminal
    emulator is set back to 9600 baud, serial console should work fine
    both in &lt;span class="caps"&gt;BIOS&lt;/span&gt; and in the&amp;nbsp;&lt;span class="caps"&gt;OS&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If all worked well, you should be able to boot into Vyatta and login as
the default &amp;#8220;vyatta&amp;#8221; user (which you set a password for during the
install). Assuming you know your way around Vyatta, it&amp;#8217;s pretty standard
from here, though there are a few things you may want to check or
configure right&amp;nbsp;away:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In configuration mode (&lt;code&gt;configure&lt;/code&gt;) run &lt;code&gt;show interfaces&lt;/code&gt;. All of
    your physical ethernet interfaces should appear, along with their
    &lt;span class="caps"&gt;MAC&lt;/span&gt;&amp;nbsp;addresses.&lt;/li&gt;
&lt;li&gt;Some changes to reduce the number of log writes to the &lt;span class="caps"&gt;CF&lt;/span&gt; card:
    &lt;code&gt;set system syslog console facility all level notice&lt;/code&gt; and
    &lt;code&gt;set system syslog global facility protocols level notice&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Configure interfaces. with firewalls, &lt;span class="caps"&gt;IP&lt;/span&gt; addresses or &lt;span class="caps"&gt;DHCP&lt;/span&gt;,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;Do whatever other configuration you need for a minimal system -
    dhcp, dns, nat,&amp;nbsp;etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And that&amp;#8217;s it - this should give you a working Vyatta system on &lt;span class="caps"&gt;CF&lt;/span&gt; on an
Alix board. Stay tuned, hopefully in a month or so I&amp;#8217;ll get around to
customizing it a bit more, based on the second blog entry linked&amp;nbsp;above.&lt;/p&gt;</summary><category term="alix"></category><category term="embedded"></category><category term="network"></category><category term="pcengines"></category><category term="router"></category><category term="vyatta"></category></entry><entry><title>New server, and looking for work</title><link href="http://blog.jasonantman.com/2011/09/new-server-and-looking-for-work/" rel="alternate"></link><updated>2011-09-27T19:35:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-09-27:2011/09/new-server-and-looking-for-work/</id><summary type="html">&lt;p&gt;First off, I&amp;#8217;ve moved this blog from a server in my basement to
&lt;a href="http://www.linode.com"&gt;Linode&lt;/a&gt; virtual hosting, in preparation for my
move from New Jersey to an apartment in Georgia. This will mark the
first time since 2001 (when I was 14) that I didn&amp;#8217;t have at least a
publicly-accessible Linux server in my home. It also means that, as sad
as it is, the rack will probably all be either going in Ebay or to scrap
(after a good &lt;a href="http://en.wikipedia.org/wiki/Gutmann_method"&gt;Guttmann
wipe&lt;/a&gt;, of&amp;nbsp;course).&lt;/p&gt;
&lt;p&gt;&lt;img alt="server rack" src="/GFX/rack_2011-09-27_small.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m a bit sad to give up hosting &lt;span class="caps"&gt;DNS&lt;/span&gt; myself and having my beautiful
per-zone, per-domain, hourly &lt;span class="caps"&gt;DNS&lt;/span&gt; statistics, but that was my first move,
and Linode&amp;#8217;s web-based &lt;span class="caps"&gt;DNS&lt;/span&gt; manager is much nicer than my collection of
&lt;span class="caps"&gt;PHP&lt;/span&gt; scripts, MySQL backend, and rndc reload wrapper (and I no longer
need &lt;span class="caps"&gt;BIND&lt;/span&gt; split-horizon since the hosting is remote). Mail was next, and
I&amp;#8217;ve got one web server moved and the other on the way. The biggest
disappointment is losing my testbed for all the fun stuff I can&amp;#8217;t do (or
doesn&amp;#8217;t make sense) with a virtualized hosting provider -
&lt;a href="http://puppetlabs.com/"&gt;Puppet&lt;/a&gt;, real &lt;span class="caps"&gt;ISC&lt;/span&gt; &lt;span class="caps"&gt;DHCP&lt;/span&gt;, &lt;span class="caps"&gt;BIND9&lt;/span&gt;, Cisco CatOS and
&lt;span class="caps"&gt;IOS&lt;/span&gt; devices, &lt;a href="http://www.bacula.org"&gt;Bacula&lt;/a&gt;, running my own edge
router, etc. There&amp;#8217;s at least a handful of current production Rutgers
services and tools that got their start here as projects in my spare
time. But I&amp;#8217;m sure I&amp;#8217;ll make up somehow, and I&amp;#8217;m planning on putting
aside some money for a massive new desktop to run a slew of&amp;nbsp;VMs.&lt;/p&gt;
&lt;p&gt;On a second note, the one thing holding back my move to Georgia is,
well, my lack of a job there. I&amp;#8217;m really just starting to look around,
and am very much hoping to find something comparable to my current
position at Rutgers - a group supporting diverse services, doing mainly
architecture and implementation of new services, a good dose of
automation and custom tool development, and hopefully also some work
with performance and availability monitoring (think
&lt;a href="http://www.nagios.org"&gt;Nagios&lt;/a&gt; and &lt;a href="http://www.cacti.net/"&gt;Cacti&lt;/a&gt;),
logging, etc. And, of course, something that&amp;#8217;s network-focused, whether
wireless or wired. Maintaining some data center space/physical
infrastructure and occasionally working with my hands is fun too. So, if
you know anyone who&amp;#8217;s hiring a Linux/open source dude in the general
vicinity of Athens, &lt;span class="caps"&gt;GA&lt;/span&gt; (including Atlanta and the surrounding area),
please give me a heads-up, or pass them along to
&lt;a href="http://resume.jasonantman.com"&gt;resume.jasonantman.com&lt;/a&gt;.&lt;/p&gt;</summary><category term="linode"></category><category term="move"></category><category term="rack"></category><category term="servers"></category></entry><entry><title>Quick and Simple Timestamping of Debug Logs</title><link href="http://blog.jasonantman.com/2011/09/quick-and-simple-timestamping-of-debug-logs/" rel="alternate"></link><updated>2011-09-08T07:06:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-09-08:2011/09/quick-and-simple-timestamping-of-debug-logs/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been having some issues that may be
&lt;a href="http://puppetlabs.com/"&gt;Puppet&lt;/a&gt;-related. Unfortunately, Puppet (at
least the old 0.25.4 client that I&amp;#8217;m running) doesn&amp;#8217;t timestamp the
debug logs sent to stdout. I know it&amp;#8217;s hanging somewhere, but I need
concrete numbers to look at. Here&amp;#8217;s a wonderfully simple bash script
that timestamps everything sent to it on stdin, and echoes it back to&amp;nbsp;stdout:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;DATECMD&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;date +%H:%M:%S&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;while &lt;/span&gt;&lt;span class="nb"&gt;read &lt;/span&gt;line; &lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;$($&lt;span class="caps"&gt;DATECMD&lt;/span&gt;) $line&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Call it as simply as: &lt;code&gt;command | ~/bin/ts&lt;/code&gt;, or maybe like
&lt;code&gt;command 2&amp;gt;&amp;amp;1 | ~/bin/ts | tee foo.log&lt;/code&gt;. Dead simple, but very helpful
when the developers didn&amp;#8217;t think to timestamp debug log&amp;nbsp;output.&lt;/p&gt;</summary><category term="debugging"></category><category term="logs"></category><category term="puppet"></category><category term="sysadmin"></category><category term="timestamp"></category></entry><entry><title>Linux Memory Usage and Disk Caching</title><link href="http://blog.jasonantman.com/2011/08/linux-memory-usage-and-disk-caching/" rel="alternate"></link><updated>2011-08-23T08:17:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-08-23:2011/08/linux-memory-usage-and-disk-caching/</id><summary type="html">&lt;p&gt;I recently added some &lt;a href="http://www.cacti.net"&gt;Cacti&lt;/a&gt;-based graphing to a
number of Linux-based servers prior to rolling out a new service. When I
was looking over the performance graphs of the initial testing, I
noticed that memory usage on our &lt;a href="http://www.rsyslog.com"&gt;rsyslog&lt;/a&gt;
server was near 98%. Looking at &lt;code&gt;top(1)&lt;/code&gt;, I saw numbers that agreed,
though processor usage was around 99% idle, and no process appeared to
be using more than 1% of memory. It took me a minute or two to open my
eyes and see past the panic of memory usage, and finally look at the
complete output from &lt;code&gt;free(1)&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;             total       used       free     shared    buffers     cached
Mem:       8171508    8032632     138876          0     162084    7253716
-/+ buffers/cache:     616832    7554676
Swap:      4192956        152    4192804
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The pertinent part is the last column: &amp;#8220;cached&amp;#8221;. It slipped my mind that
while rsyslog is writing vast amounts of data to disk, which may or may
not ever be read back, the kernel is using free memory to cache as much
of that as it reliably can. Hence the difference between what the kernel
and userland tools call &amp;#8220;free&amp;#8221;, and what most human beings (or at least
sysadmins) would consider &amp;#8220;free&amp;#8221; - or, more correctly, &amp;#8220;available for&amp;nbsp;use&amp;#8221;.&lt;/p&gt;
&lt;p&gt;When I get a chance, maybe I&amp;#8217;ll submit patches to the Cacti Memory Usage
Percent (&lt;span class="caps"&gt;SNMP&lt;/span&gt;) template to either graph cache separately, or remove it
from the&amp;nbsp;total.&lt;/p&gt;
&lt;p&gt;Interestingly, I also found a somewhat cute page entitled &amp;#8220;Help! Linux
ate my &lt;span class="caps"&gt;RAM&lt;/span&gt;!&amp;#8221; at
&lt;a href="http://www.linuxatemyram.com/"&gt;http://www.linuxatemyram.com/&lt;/a&gt;.&lt;/p&gt;</summary><category term="linux"></category><category term="memory"></category><category term="rsyslog"></category><category term="syslog"></category></entry><entry><title>Article on theInquirer.net</title><link href="http://blog.jasonantman.com/2011/07/article-on-theinquirer-net/" rel="alternate"></link><updated>2011-07-11T15:55:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-07-11:2011/07/article-on-theinquirer-net/</id><summary type="html">&lt;p&gt;I guess it&amp;#8217;s pretty strange that I just found out about it now, three
years later, but there&amp;#8217;s an &lt;a href="http://www.theinquirer.net/inquirer/news/1026958/citibank-infuriating-customers-linux-hostile-site"&gt;article on
TheInquirer.net&lt;/a&gt;
about Citibank&amp;#8217;s website not allowing Linux, that heavily quotes &lt;a href="/2008/08/linux-choice-updates-citibank-issues/"&gt;a blog
post of mine&lt;/a&gt; about the
issue.&amp;nbsp;Cool.&lt;/p&gt;</summary><category term="citibank"></category><category term="linux"></category><category term="me"></category></entry><entry><title>A Quick Review of Mint.com - from both a user and programmer perspective</title><link href="http://blog.jasonantman.com/2011/07/a-quick-review-of-mint-com-from-both-a-user-and-programmer-perspective/" rel="alternate"></link><updated>2011-07-03T22:03:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-07-03:2011/07/a-quick-review-of-mint-com-from-both-a-user-and-programmer-perspective/</id><summary type="html">&lt;p&gt;For those of you who are unfamiliar with
&lt;a href="http://www.mint.com"&gt;Mint.com&lt;/a&gt;, it&amp;#8217;s a free online personal finance
site that allows you to track spending across all of your bank accounts
and manage budgets and financial goals. Once upon a time it was a nice
little Web 2.0 startup, now it&amp;#8217;s owned by Intuit. The service is free,
but it&amp;#8217;s ad supported, albeit in an unintrusive way - &amp;#8220;partner&amp;#8221; services
(credit cards, savings accounts, etc.) are recommended. I&amp;#8217;ve been using
it for about two weeks now, with a goal of tracking my spending,
developing a budget and getting a better handle on my present and future
finances. So here are some of my impressions, considering that the
service is still growing but has been around for a&amp;nbsp;while.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The&amp;nbsp;Good:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Account Sync&lt;/strong&gt; - Some things I&amp;#8217;ve read online suggest that Mint
    now uses the &lt;a href="http://yodlee.com"&gt;Yodlee&lt;/a&gt; service to sync
    transactions from your financial institutions. Whatever they use,
    they seem to be able to sync transactions and account balances from
    all of my accounts, even ones at a few small investment companies.
    The sync is fast, and they do push notifications (low balance, large
    deposits, etc.) very well. They even seem to support many more
    institutions than Quicken last time I used it (2010 I&amp;nbsp;think).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Budgets&lt;/strong&gt; - Mint has a very nice, clean, simple monthly budget
    implementation. You tell it how much you want to spend in a given
    category in a month, and it shows a nice horizontal bar graph of how
    far through your allotment you are. It even makes some suggestions,
    and sets baseline budgets by category based on previous spending.
    About the only problem is when my bi-weely pay checks fall on odd
    weeks in the month. Most of my bills are due near the end of the
    month, and if my pay check happens to be around the same time my
    bills are due, I&amp;#8217;ll have quite a bit less cash on hand at the
    beginning of the next month than the budgets&amp;nbsp;reflect.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Categorization&lt;/strong&gt; - they do it very well. One of their big selling
    points is their categorization engine, and it seemed to get about
    80% of my purchases right, from day one. That&amp;#8217;s much better than
    anything else I&amp;#8217;ve seen. The only down side is that they only look
    at the Vendor name, not the description - so when I use my debit
    card and the vendor name is &amp;#8220;&lt;span class="caps"&gt;NYCE&lt;/span&gt; Transaction&amp;#8221; but the store
    name/address is in the description, Mint is hopelessly lost. They
    offer rules to put transactions in category, but only exact matching
    on the vendor name, so there&amp;#8217;s no way to tell it to look at a
    description that includes &amp;#8220;123 Main St&amp;#8221;. From a programmer&amp;#8217;s
    perspective, they should allow rules based on either vendor name
    &lt;em&gt;or&lt;/em&gt; description, and maybe they should let the user highlight or
    specify the part that matches (or a&amp;nbsp;RegEx?).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Apps&lt;/strong&gt; - I haven&amp;#8217;t tried the iOS ones, but the Android app is
    pretty nice. It gives a nice quick picture of your spending and
    account balances, how you&amp;#8217;re doing with your monthly budget, and any
    alerts/messages. Transaction history isn&amp;#8217;t easily accessible and is
    per-account only, so it&amp;#8217;s hard to answer &amp;#8220;hmmm, how much did it cost
    last time I was here?&amp;#8221; or &amp;#8220;where did I get lunch last Tuesday?&amp;#8221;, but
    it&amp;#8217;s still handy enough to tell me how much I have left in my
    Entertainment budget, or whether I should put this big purchase on
    my credit or debit&amp;nbsp;card.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goals&lt;/strong&gt; - Mint has a good idea with goals - it includes a number
    of pre-configured financial goals like paying off credit card debt,
    saving for retirement, or stashing away some emergency cash. But in
    order to function correctly, you must have a specific, dedicated
    account for each goal. I guess this is where Mint makes money - they
    suggest accounts with specific attributes (high interest, high
    liquidity, whatever) from their partners. But there doesn&amp;#8217;t appear
    to be a way to set up a Goal without associating it with a dedicated
    account, and (as per some forum posts I read, I haven&amp;#8217;t tried this)
    you can&amp;#8217;t associate a cash asset account with a goal, so there&amp;#8217;s no
    way to track my progress on building the Depression fund I keep
    under my&amp;nbsp;mattress.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The Bad/Room for&amp;nbsp;Improvement:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Customer Service&lt;/strong&gt; - I don&amp;#8217;t know when Mint was bought up by
    Intuit, but to me, they have the feel of an agile Web 2.0 property
    that was bought up by a slow-moving bureaucratic company unable to
    keep up with customer demands or the amount of support requests.
    They use &lt;a href="http://getsatisfaction.com/"&gt;GetSatisfaction&lt;/a&gt;, a new-age
    forum-based customer &amp;#8220;community&amp;#8221; provider, for customer service. But
    their forums are filled with feature request threads that have
    &amp;#8220;we&amp;#8217;ll bring it up to Product Development and get back to you&amp;#8221;
    responses over half a year old. There appears to be very little
    follow-through or feedback on feature requests, and poor
    announcement/communication surrounding the one feature that was
    recently brought in to an invitation-only beta. Unfortunately, I get
    the general feeling (and I&amp;#8217;ve found this far too many times lately)
    that they were originally a cutting-edge, agile, fast-paced, &amp;#8220;cool&amp;#8221;
    service, developed by a team that probably stayed up all night
    coding a cool feature their users were asking for, that&amp;#8217;s now been
    swallowed up by a behemoth that wants a 6-month-long risk assessment
    before writing a line of&amp;nbsp;code.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cash Tracking&lt;/strong&gt; - I understand that Mint makes money from
    recommending the services of lenders, banks, etc. But if you want to
    monetize every single feature, you&amp;#8217;re bound to fail. In this
    respect, Mint&amp;#8217;s total lack of cash accounting is a serious failure
    for many of their users (and the forums are filled with threads to
    this effect). The site allows users to manually input cash
    transactions, but that&amp;#8217;s about it. You can deduct the amount from an
    automatically-synced &lt;span class="caps"&gt;ATM&lt;/span&gt; withdrawal (just your last &lt;span class="caps"&gt;ATM&lt;/span&gt; withdrawal,
    no choice if you have multiple &lt;span class="caps"&gt;ATM&lt;/span&gt; accounts, or you and your
    partner/spouse both use the same Mint account), but that just
    complicates things further. There&amp;#8217;s also no logic of tracking cash
    on hand - you can create a &amp;#8220;Asset&amp;#8221; (cash) account, but you have to
    manually update the balance. If you&amp;#8217;re like me and use cash for
    small purchases, or often get meals at local places that only accept
    cash, this becomes quite a bit of a hassle. Even more so if, like
    me, you&amp;#8217;ve ever lost an &lt;span class="caps"&gt;ATM&lt;/span&gt; card on a holiday weekend, and now keep
    some actual cash in the house. Honestly, I think this is my biggest
    complaint about Mint, and the one that&amp;#8217;s most likely to keep me
    looking for alternatives. More importantly, this has been requested
    and voted for over and over on their support forums for over a year,
    with no informational response. For a company whose developers
    aggregate and analyze data from thousands of banks, I&amp;#8217;d think that
    letting users type in a series of dollar amounts and then totaling
    it up would be pretty&amp;nbsp;easy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scheduled Transactions&lt;/strong&gt; - On the plus side, Mint parses the &amp;#8220;next
    payment due&amp;#8221; date out of credit card and loan account information,
    so it gives you nice (email, &lt;span class="caps"&gt;SMS&lt;/span&gt;, and web) alerts a configurable
    number of days before. However, it doesn&amp;#8217;t even have a feature to
    set calendar reminders for when bills are due, so I&amp;#8217;m still stuck
    opening Mint and Google Calendar if I need to figure out whether I
    can make that big purchase today or if I should wait until my next
    pay check. This was also a very commonly requested feature on their
    forums, and apparently they have an invitation-only beta running.
    But I responded to the thread a few days late, so I wasn&amp;#8217;t given an
    invitation. As far as I can tell, there was never an announcement of
    the beta, and I never got a chance to check a &amp;#8220;please let me beta
    test&amp;#8221;&amp;nbsp;box.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Forecasting&lt;/strong&gt; - This is my #2 biggest issue with Mint, after the
    lack of cash tracking. And the other one most likely to drive me
    either to another service, to write my own software (again), or to
    go back to a spreadsheet. Mint is great at tracking your transaction
    history, your account balances and net worth, and your current
    monthly budget. But it has absolutely no concept of financial
    forecasting or balance predictions. If you&amp;#8217;re on a tight budget,
    this can be a problem. At the moment, I have a spreadsheet were I
    keep a list of all of my regularly recurring expenses (in date order
    over the month), my pay dates, and the combined balance of my
    checking/savings accounts. I can easily see what (within reason, not
    counting discretionary expenses) my cash on hand will be at any time
    in the month. This seems like a no-brainer necessary feature for a
    site like Mint, and combined with its great budgeting features,
    could provide a wonderful picture of what to expect in the next
    month or two, and when I should plan on making that unusually large&amp;nbsp;purchase.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Couples/Families&lt;/strong&gt; - My girlfriend and I both use Mint, and have
    somewhat combined finances (but not accounts). It doesn&amp;#8217;t make sense
    for us to have two Mint accounts, since it would be a real pain to
    keep track of. But, on the other hand, having all of our accounts in
    one Mint isn&amp;#8217;t an ideal solution either. I can categorize
    transactions, but there&amp;#8217;s no easy way to track &lt;em&gt;who&lt;/em&gt; the purchase
    was for, short of duplicating (or triplicating - Me, Her, Both) all
    of the categories. I&amp;#8217;m trying something with tags, but it&amp;#8217;s a real
    kludge in Mint&amp;#8217;s search interface to get a list of transactions
    filtered by category &lt;em&gt;and&lt;/em&gt; tag. Also, the account name doesn&amp;#8217;t show
    up in the transactions list unless you pull down the Detail box for
    a transaction, so it&amp;#8217;s troublesome to look through a list and sort
    out whose cards everything was&amp;nbsp;on.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Miscellaneous:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Passwords.&lt;/strong&gt; In order to sync data from my banks, I have to supply
    mint.com with all of my login credentials. I understand that, until
    banks enter the 21st century (and be smart about it - even a less
    likely possibility) this is just the way it is, and I can&amp;#8217;t blame
    Mint for a system imposed by the banks. But still, I&amp;#8217;m not too happy
    about the idea of Mint storing in plain text (I assume, since they
    need to pass them on to the bank) my username and password for all
    of my banking sites. I got some comfort knowing that the site is
    owned by Intuit - a company that, if not totally security-minded, is
    at least big enough not to fold overnight after a breach. Maybe one
    day, banks and credit card companies will let me specify separate
    credentials specific to third-party software and websites, which I
    could then revoke with my &amp;#8220;master&amp;#8221; password. Until then, I guess
    this is just a risk I have to live&amp;nbsp;with.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Importing Transactions&lt;/strong&gt; - Mint only supports importing up to 3
    months of transaction data per account. Some institutions provide
    less than that. Obviously Intuit doesn&amp;#8217;t want people switching from
    their paid software, so the two &lt;span class="caps"&gt;YEARS&lt;/span&gt; of transactions I meticulously
    categorized in Quicken are now useless to me in Mint. However, I
    guess I can&amp;#8217;t really fault them too much on this one. Firstly, that
    would be a &lt;span class="caps"&gt;LOT&lt;/span&gt; of data for them to store. It would also be much more
    of a headache to try and ensure that the export formats of whatever
    software packages they support are properly&amp;nbsp;parsed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Conclusions:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Mint does a lot of things well. And it&amp;#8217;s a nice clean interface. But
there are also some key features missing, which I feel like I really
need. So, for the time being, I&amp;#8217;m going to keep using mint, but also
explore what other options are available, and look into anyone who
offers an &lt;span class="caps"&gt;API&lt;/span&gt; for pulling transaction data that might actually be
powerful enough for me to use to write my own web-based app (since my
attempts at pulling &lt;a href="http://en.wikipedia.org/wiki/OFX"&gt;&lt;span class="caps"&gt;OFX&lt;/span&gt;&lt;/a&gt; feeds only
worked for about half my accounts). If you don&amp;#8217;t care as much about
tracking cash spending/cash on hand, and are financially stable enough
that you don&amp;#8217;t need to forecast the next month or two, Mint is&amp;nbsp;wonderful.&lt;/p&gt;</summary><category term="finance"></category><category term="mint"></category><category term="review"></category></entry><entry><title>Netgear ReadyNAS 1100 Bug causes NFS Failure after reboot - workaround</title><link href="http://blog.jasonantman.com/2011/06/netgear-readynas-1100-bug-causes-nfs-failure-after-reboot-workaround/" rel="alternate"></link><updated>2011-06-28T08:40:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-06-28:2011/06/netgear-readynas-1100-bug-causes-nfs-failure-after-reboot-workaround/</id><summary type="html">&lt;p&gt;At work, we have a &lt;a href="http://www.readynas.com/?cat=23"&gt;Netgear ReadyNAS
1100&lt;/a&gt;. It&amp;#8217;s a &lt;span class="caps"&gt;4TB&lt;/span&gt; &lt;span class="caps"&gt;NAS&lt;/span&gt; appliance, a cute
little 1U half-depth Linux box with 4 &lt;span class="caps"&gt;SATA&lt;/span&gt; disks, a &lt;span class="caps"&gt;RAID&lt;/span&gt; controller, and
some firmware to do a whole bunch of fancy stuff (mainly geared towards
consumers and very small shops - all configuration is point-and-click
web &lt;span class="caps"&gt;UI&lt;/span&gt;). We&amp;#8217;ve been using it for storing archived log data and
low-priority backups. At the beginning of this problem, it was running
RAIDiator 4.1.6 firmware since December of last year (over 6 months),
and hadn&amp;#8217;t had any configuration changes in at least 4&amp;nbsp;months.&lt;/p&gt;
&lt;p&gt;Last week, I had to power off the unit and remove the power cables for
some rack maintenance. I went through the usual full shutdown procedure
in the web &lt;span class="caps"&gt;UI&lt;/span&gt;, and also told it to `fsck` the volumes, as that hadn&amp;#8217;t
been done in quite some time. Unfortunately, when the unit came back up,
even after I could log into the web &lt;span class="caps"&gt;UI&lt;/span&gt;, I couldn&amp;#8217;t mount the &lt;span class="caps"&gt;NFS&lt;/span&gt; shares
on my backup server. I kept getting messages&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[root@backup-server ~]# mount -a&lt;/span&gt;
&lt;span class="go"&gt;mount: mount to &lt;span class="caps"&gt;NFS&lt;/span&gt; server &amp;#39;css-readynas&amp;#39; failed: &lt;span class="caps"&gt;RPC&lt;/span&gt; Error: Program not registered.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;so my next step was to check &lt;span class="caps"&gt;RPC&lt;/span&gt; status of the readynas, from the
client. That was also a bit of a&amp;nbsp;surprise:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[root@backup-server ~]# rpcinfo -p css-readynas                        &lt;/span&gt;
&lt;span class="go"&gt;   program vers proto   port                                              &lt;/span&gt;
&lt;span class="go"&gt;    100000    2   tcp    111  portmapper                                  &lt;/span&gt;
&lt;span class="go"&gt;    100000    2   udp    111  portmapper                                  &lt;/span&gt;
&lt;span class="go"&gt;    100011    1   udp    620  rquotad                                     &lt;/span&gt;
&lt;span class="go"&gt;    100011    2   udp    620  rquotad                                     &lt;/span&gt;
&lt;span class="go"&gt;    100011    1   tcp    623  rquotad                                     &lt;/span&gt;
&lt;span class="go"&gt;    100011    2   tcp    623  rquotad                                     &lt;/span&gt;
&lt;span class="go"&gt;    100024    1   udp  32765  status                                      &lt;/span&gt;
&lt;span class="go"&gt;    100024    1   tcp  32765  status                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    1   udp   2051  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    1   tcp   3006  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    2   udp   2051  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    2   tcp   3006  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    3   udp   2051  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    3   tcp   3006  mountd &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Somewhere in that list is supposed to be nfsd, listening on port 2049.
Next, I did an nmap (port scan) of the&amp;nbsp;readynas:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[root@backup-server ~]# nmap -sU -p2047-2050 css-readynas             &lt;/span&gt;

&lt;span class="go"&gt;Starting Nmap 4.11 ( http://www.insecure.org/nmap/ ) at 2011-06-23 15:21 &lt;span class="caps"&gt;EDT&lt;/span&gt;&lt;/span&gt;
&lt;span class="go"&gt;Interesting ports on css-readynas.rutgers.edu (172.16.25.108):              &lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;PORT&lt;/span&gt;     &lt;span class="caps"&gt;STATE&lt;/span&gt;         &lt;span class="caps"&gt;SERVICE&lt;/span&gt;                                              &lt;/span&gt;
&lt;span class="go"&gt;2047/udp closed        dls                                                  &lt;/span&gt;
&lt;span class="go"&gt;2048/udp closed        dls-monitor                                          &lt;/span&gt;
&lt;span class="go"&gt;2049/udp open|filtered nfs                                                  &lt;/span&gt;
&lt;span class="go"&gt;2050/udp closed        unknown  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Interesting. The port scan shows that &lt;em&gt;something&lt;/em&gt; is listening on port
2049. But rpcinfo doesn&amp;#8217;t seem to recognize it as a &lt;span class="caps"&gt;NFS&lt;/span&gt;&amp;nbsp;server.&lt;/p&gt;
&lt;p&gt;At this point, through FrontView (the web &lt;span class="caps"&gt;UI&lt;/span&gt;) I backed up the
configuration and went through a few reboot cycles, with no change. I
then started tweaking everything I could that I thought would restart
the &lt;span class="caps"&gt;NFS&lt;/span&gt; server - I added and removed allowed hosts for the &lt;span class="caps"&gt;NFS&lt;/span&gt; share,
enabled and disabled sync mode, etc. I started searching the &lt;a href="http://www.readynas.com/forum/"&gt;ReadyNAS
Forum&lt;/a&gt; and found a post that reported a
very similar problem - &lt;a href="http://www.readynas.com/forum/viewtopic.php?f=20&amp;amp;t=23139"&gt;upnpd grabbing nfsd
port&lt;/a&gt;. The
user reported that he was getting the same &amp;#8220;&lt;span class="caps"&gt;RPC&lt;/span&gt; Error: Program not
registered&amp;#8221; message, and in &lt;code&gt;daemon.log&lt;/code&gt; on the ReadyNAS, found a line
including &amp;#8220;storage nfsd[1087]: nfssvc: Address already in use&amp;#8221;. I
remembered that I&amp;#8217;d setup the ReadyNAS to forward all logs to our
central syslog server and, sure enough, found an identical message that
something had already bound to &lt;span class="caps"&gt;UDP&lt;/span&gt; port 2049 when &lt;span class="caps"&gt;NFS&lt;/span&gt; was starting. I
tried confirming that upnpd was disabled and rebooting, but that didn&amp;#8217;t
help. Grepping my logs for &amp;#8220;nfs&amp;#8221;&amp;nbsp;returned:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;daemon.log:Jun 23 12:43:43 css-readynas nfsd[2331]: nfssvc: Address already in use
daemon.log:Jun 23 15:26:33 css-readynas nfsd[2724]: nfssvc: Address already in use
kern.log:Jun 23 11:35:29 css-readynas kernel: Installing knfsd (copyright (C) 1996 okir@monad.swb.de).
kern.log:Jun 23 12:43:43 css-readynas kernel: NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory
kern.log:Jun 23 12:43:43 css-readynas kernel: NFSD: starting 90-second grace period
kern.log:Jun 23 14:56:20 css-readynas kernel: Installing knfsd (copyright (C) 1996 okir@monad.swb.de).
kern.log:Jun 23 15:12:41 css-readynas kernel: NFSD: starting 90-second grace period
kern.log:Jun 23 15:26:33 css-readynas kernel: NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory
kern.log:Jun 23 15:26:33 css-readynas kernel: NFSD: starting 90-second grace period
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;My next step was a few more reboots, with no change. I then upgraded the
RAIDiator firmware to the latest, 4.1.7. Still no luck. I installed the
&lt;a href="http://www.readynas.com/?p=4203"&gt;Enable root &lt;span class="caps"&gt;SSH&lt;/span&gt;&lt;/a&gt; addon, and that&amp;#8217;s
when things became very&amp;nbsp;clear:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; netstat -unlp
&lt;span class="go"&gt;Active Internet connections (only servers)&lt;/span&gt;
&lt;span class="go"&gt;Proto Recv-Q Send-Q Local Address           Foreign Address         State       &lt;span class="caps"&gt;PID&lt;/span&gt;/Program name   &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2049            0.0.0.0:*                           794/snmpd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:514             0.0.0.0:*                           673/syslogd         &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:137       0.0.0.0:*                           1672/nmbd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:137             0.0.0.0:*                           1672/nmbd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:138       0.0.0.0:*                           1672/nmbd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:138             0.0.0.0:*                           1672/nmbd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:161             0.0.0.0:*                           794/snmpd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:162             0.0.0.0:*                           802/snmptrapd       &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2086            0.0.0.0:*                           1565/rpc.mountd     &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 127.0.0.1:22081         0.0.0.0:*                           1599/raidard        &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:22081     0.0.0.0:*                           1599/raidard        &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:22081           0.0.0.0:*                           1599/raidard        &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:988             0.0.0.0:*                           819/rpc.rquotad     &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:5353            0.0.0.0:*                           729/avahi-daemon: r &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:111             0.0.0.0:*                           666/portmap         &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:881             0.0.0.0:*                           1553/rpc.statd      &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:32765           0.0.0.0:*                           1553/rpc.statd     &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For some &lt;strong&gt;&lt;em&gt;very&lt;/em&gt;&lt;/strong&gt; strange reason, snmpd had bound to port 2049 (the
nfs port) instead of 161. That left no port for nfs to bind&amp;nbsp;to.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; /etc/init.d/snmpd stop                                                       
&lt;span class="go"&gt;Stopping network management services: snmpd snmptrapd readynas-agent.                               &lt;/span&gt;
&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; /etc/init.d/nfs-kernel-server start
&lt;span class="go"&gt;Exporting directories for &lt;span class="caps"&gt;NFS&lt;/span&gt; kernel daemon...done.&lt;/span&gt;
&lt;span class="go"&gt;Starting &lt;span class="caps"&gt;NFS&lt;/span&gt; kernel daemon:mount: nfsd already mounted or /proc/fs/nfsd/ busy&lt;/span&gt;
&lt;span class="go"&gt;mount: according to mtab, nfsd is mounted on /proc/fs/nfsd&lt;/span&gt;
&lt;span class="go"&gt; statd nfsd mountd.&lt;/span&gt;
&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; /etc/init.d/snmpd start
&lt;span class="go"&gt;Starting network management services: snmpd snmptrapd readynas-agent.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Stop snmpd, restart nfs-kernel-server so that it grabs port 2049 like it
should, and then start snmpd back up. If all went well, nfsd should now
be listening on &lt;span class="caps"&gt;UDP&lt;/span&gt; 2049, and snmpd should be listening on &lt;span class="caps"&gt;UDP&lt;/span&gt; 161 like
it should. To&amp;nbsp;confirm:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; netstat -unlp
&lt;span class="go"&gt;Active Internet connections (only servers)&lt;/span&gt;
&lt;span class="go"&gt;Proto Recv-Q Send-Q Local Address           Foreign Address         State       &lt;span class="caps"&gt;PID&lt;/span&gt;/Program name&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2049            0.0.0.0:*                           -&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:514             0.0.0.0:*                           673/syslogd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:137       0.0.0.0:*                           1672/nmbd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:137             0.0.0.0:*                           1672/nmbd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:138       0.0.0.0:*                           1672/nmbd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:138             0.0.0.0:*                           1672/nmbd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:161             0.0.0.0:*                           26161/snmpd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:162             0.0.0.0:*                           26163/snmptrapd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2086            0.0.0.0:*                           1565/rpc.mountd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 127.0.0.1:22081         0.0.0.0:*                           1599/raidard&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:22081     0.0.0.0:*                           1599/raidard&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:22081           0.0.0.0:*                           1599/raidard&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:988             0.0.0.0:*                           819/rpc.rquotad&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:5353            0.0.0.0:*                           729/avahi-daemon: r&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2158            0.0.0.0:*                           -&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:111             0.0.0.0:*                           666/portmap&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2160            0.0.0.0:*                           26161/snmpd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:881             0.0.0.0:*                           1553/rpc.statd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:32765           0.0.0.0:*                           1553/rpc.statd&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All is well. Now to confirm this from the client&amp;nbsp;machine:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[root@backup-server ~]# rpcinfo -p css-readynas&lt;/span&gt;
&lt;span class="go"&gt;   program vers proto   port&lt;/span&gt;
&lt;span class="go"&gt;    100000    2   tcp    111  portmapper&lt;/span&gt;
&lt;span class="go"&gt;    100000    2   udp    111  portmapper&lt;/span&gt;
&lt;span class="go"&gt;    100011    1   udp    988  rquotad&lt;/span&gt;
&lt;span class="go"&gt;    100011    2   udp    988  rquotad&lt;/span&gt;
&lt;span class="go"&gt;    100011    1   tcp    991  rquotad&lt;/span&gt;
&lt;span class="go"&gt;    100011    2   tcp    991  rquotad&lt;/span&gt;
&lt;span class="go"&gt;    100024    1   udp  32765  status&lt;/span&gt;
&lt;span class="go"&gt;    100024    1   tcp  32765  status&lt;/span&gt;
&lt;span class="go"&gt;    100005    1   udp   2086  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    1   tcp   3131  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    2   udp   2086  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    2   tcp   3131  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    3   udp   2086  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    3   tcp   3131  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100003    2   udp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    3   udp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    4   udp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    2   tcp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    3   tcp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    4   tcp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100021    1   udp   2158  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    3   udp   2158  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    4   udp   2158  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    1   tcp   4189  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    3   tcp   4189  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    4   tcp   4189  nlockmgr&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ok, &lt;span class="caps"&gt;NFS&lt;/span&gt; is now there. It all looks good, and re-running &lt;code&gt;mount -a&lt;/code&gt; on
the client successfully mounts the &lt;span class="caps"&gt;NFS&lt;/span&gt;&amp;nbsp;share.&lt;/p&gt;
&lt;p&gt;We&amp;#8217;ll see what happens next time I have to reboot the ReadyNAS. In the
mean time, I&amp;#8217;m going to try to bring this to the attention of Netgear
support and hope they do something about&amp;nbsp;it.&lt;/p&gt;</summary><category term="appliance"></category><category term="embedded"></category><category term="linux"></category><category term="nas"></category><category term="netgear"></category><category term="nfs"></category><category term="readynas"></category></entry><entry><title>Links for Wednesday, June 8, 2011</title><link href="http://blog.jasonantman.com/2011/06/links-for-wednesday-june-8-2011/" rel="alternate"></link><updated>2011-06-08T10:55:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-06-08:2011/06/links-for-wednesday-june-8-2011/</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href="http://it.toolbox.com/blogs/bridging-gaps/what-is-a-systems-architect-9995"&gt;What is a Systems&amp;nbsp;Architect?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Simple Diagrams of MySQL Schema</title><link href="http://blog.jasonantman.com/2011/05/simple-diagrams-of-mysql-schema/" rel="alternate"></link><updated>2011-05-04T08:47:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-05-04:2011/05/simple-diagrams-of-mysql-schema/</id><summary type="html">&lt;p&gt;Jess Robinson&amp;#8217;s
&lt;a href="http://search.cpan.org/~jrobinson/SQL-Translator/"&gt;&lt;span class="caps"&gt;SQL&lt;/span&gt;-Translator&lt;/a&gt; &lt;span class="caps"&gt;CPAN&lt;/span&gt;
module translates and parses &lt;span class="caps"&gt;SQL&lt;/span&gt; statements. The
&lt;a href="http://sqlfairy.sourceforge.net/"&gt;SQLfairy&lt;/a&gt; project has some nice
binaries that, among other things, use GraphViz or &lt;span class="caps"&gt;GD&lt;/span&gt; to draw pseudo-&lt;span class="caps"&gt;ER&lt;/span&gt;
diagrams from &lt;span class="caps"&gt;SQL&lt;/span&gt; &lt;span class="caps"&gt;CREATE&lt;/span&gt; statements. Drawing a diagram of an &lt;span class="caps"&gt;SQL&lt;/span&gt; schema
is as easy as
&lt;code&gt;sqlt-diagram --db=MySQL -o schema.png -i png -t "title" --color --gutter 100 -c 2 schema-erd.sql&lt;/code&gt;.
There are a few minor issues - the program seems to choke on the &lt;span class="caps"&gt;LOCK&lt;/span&gt;
&lt;span class="caps"&gt;TABLES&lt;/span&gt; statements in &lt;code&gt;mysqldump&lt;/code&gt; output. But overall, the results are
quite nice. The script can take (as easy as putting it in a Makefile)
mysqldump output and generate a diagram like the one below, including
foreign key constraints. I also found a simple intro and example in a
post on &lt;a href="http://nsaunders.wordpress.com/2009/01/11/easy-visualisation-of-database-schemas-using-sqlfairy/"&gt;Neil
Saunders&lt;/a&gt;&amp;#8216;&amp;nbsp;blog.&lt;/p&gt;
&lt;p&gt;&lt;img alt="sqlfairy output" src="/GFX/sqlfairy.png" /&gt;&lt;/p&gt;</summary><category term="database"></category><category term="db"></category><category term="diagram"></category><category term="mysql"></category><category term="sql"></category></entry><entry><title>Links for Thursday, April 28, 2011</title><link href="http://blog.jasonantman.com/2011/04/links-for-thursday-april-28-2011/" rel="alternate"></link><updated>2011-04-28T10:55:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-04-28:2011/04/links-for-thursday-april-28-2011/</id><summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.technologyreview.com/computing/37295/page1/#photo"&gt;Inside Facebook’s Not-So-Secret New Data Center - Technology&amp;nbsp;Review&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Using wireshark to capture packets from a remote host</title><link href="http://blog.jasonantman.com/2011/04/using-wireshark-to-capture-packets-from-a-remote-host/" rel="alternate"></link><updated>2011-04-26T10:50:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-04-26:2011/04/using-wireshark-to-capture-packets-from-a-remote-host/</id><summary type="html">&lt;p&gt;I spend a fair amount of my time debugging network and service problems
on a few racks of Linux servers. Of course, they&amp;#8217;re located in a data
center (yes, just downstairs, but still not quite as comfortable as my
office), and they&amp;#8217;re all command-line only - no sense in using up &lt;span class="caps"&gt;RAM&lt;/span&gt;
and &lt;span class="caps"&gt;CPU&lt;/span&gt; to run a graphical &lt;span class="caps"&gt;UI&lt;/span&gt; on a box that should just be serving
remote clients. I used to go through the arduous task of running a
command line &lt;a href="http://www.tcpdump.org/"&gt;&lt;code&gt;tcpdump&lt;/code&gt;&lt;/a&gt; session on the server
until I thought I had enough packets, then SCPing it over to my
workstation and opening the file in
&lt;a href="http://www.wireshark.org/"&gt;wireshark&lt;/a&gt; (formerly Ethereal). Fortunately,
thanks to a
&lt;a href="http://linuxexplore.wordpress.com/2010/05/30/remote-packet-capture-using-wireshark-tcpdump/"&gt;post&lt;/a&gt;
on Rahul Panwar&amp;#8217;s &lt;a href="http://linuxexplore.wordpress.com/"&gt;Linux Explore
blog&lt;/a&gt; (which seems to be sadly
neglected), I found a much easier way to do it. I&amp;#8217;ve summarized that
post here, added a little explanation, and also made some useful
comments for people working on Red Hat/CentOS and&amp;nbsp;OpenSuSE.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What you&amp;nbsp;need:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Source system (the server you want to capture packets on) that you
    have &lt;span class="caps"&gt;SSH&lt;/span&gt; access to, with tcpdump installed, and available to your
    user (either directly, or via sudo without&amp;nbsp;password).&lt;/li&gt;
&lt;li&gt;Destination system (where you run graphical Wireshark) with
    wireshark installed and working, and &lt;code&gt;mkfifo&lt;/code&gt; available.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Procedure:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;On the destination system, if you haven&amp;#8217;t already done&amp;nbsp;so,&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;mkfifo /tmp/packet_capture
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This creates a &lt;a href="http://en.wikipedia.org/wiki/Named_pipe"&gt;named pipe&lt;/a&gt;
where the source packet data (via ssh) will be written and Wireshark
will read it from. You can use any name or location you want, but
&lt;code&gt;/tmp/packet_capture&lt;/code&gt; is pretty&amp;nbsp;logical.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On your destination system, open up Wireshark (we do this now, since
    on many systems it required the root password to start). In the
    &amp;#8220;Capture&amp;#8221; menu, select &amp;#8220;Options&amp;#8221;. In the &amp;#8220;Interface&amp;#8221; box, type in
    the path to the &lt;span class="caps"&gt;FIFO&lt;/span&gt; you created (&lt;code&gt;/tmp/packet_capture&lt;/code&gt;). You should
    press the Start button before running the next command - I recommend
    typing the command in a terminal window, pressing start, then
    hitting enter in the terminal to run the&amp;nbsp;command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the destination system,&amp;nbsp;run&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;ssh user@source-hostname &lt;span class="s2"&gt;&amp;quot;sudo /usr/sbin/tcpdump -s 0 -U -n -w - -i eth0 not port 22&amp;quot;&lt;/span&gt; &amp;gt; /tmp/packet_capture
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will &lt;span class="caps"&gt;SSH&lt;/span&gt; to the source system (&lt;code&gt;source-hostname&lt;/code&gt;, either by
hostname or &lt;span class="caps"&gt;IP&lt;/span&gt;) as the specified user (&lt;code&gt;user&lt;/code&gt;) and execute
&lt;code&gt;sudo /usr/sbin/tcpdump&lt;/code&gt;. Omit the &amp;#8220;sudo&amp;#8221; if you don&amp;#8217;t need it,
though if you do, you&amp;#8217;ll need passwordless access. Options passed to
tcpdump are: &amp;#8220;-s 0&amp;#8221; snarf entire packets, no length limit; &amp;#8220;-U&amp;#8221;
packet-buffered output - write each complete packet to output once
it&amp;#8217;s captured, rather than waiting for a buffer to fill up; &amp;#8220;-n&amp;#8221;
don&amp;#8217;t convert addresses to hostnames; &amp;#8220;-w -&amp;#8221; write raw packets to
&lt;span class="caps"&gt;STDOUT&lt;/span&gt; (which will be passed through the &lt;span class="caps"&gt;SSH&lt;/span&gt; tunnel and become
&lt;span class="caps"&gt;STDOUT&lt;/span&gt; of the &amp;#8220;ssh&amp;#8221; command on the destination machine); &amp;#8220;-i eth0&amp;#8221;
capture on interface eth0; &amp;#8220;not port 22&amp;#8221; a tcpdump filter expression
to prevent capturing our own &lt;span class="caps"&gt;SSH&lt;/span&gt; packets (more on this below). The
final &amp;#8220;&gt; /tmp/packet_capture&amp;#8221; redirects the &lt;span class="caps"&gt;STDOUT&lt;/span&gt; of the ssh
program (the raw packets from tcpdump on the source machine) to the
&lt;code&gt;/tmp/packet_capture&lt;/code&gt; &lt;span class="caps"&gt;FIFO&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When you&amp;#8217;re ready to stop the capture, just Ctrl+C the &lt;span class="caps"&gt;SSH&lt;/span&gt; command
    in the terminal window. Wireshark will automatically stop capturing,
    and you can save the capture file or play around with it. To capture
    again, you&amp;#8217;ll need to restart the capture in Wireshark and then run
    the ssh command&amp;nbsp;again.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;A note on network usage and tcpdump&amp;nbsp;filters&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is a relatively bandwidth intensive procedure. If you use the &amp;#8220;not
port 22&amp;#8221; tcpdump filter (shown above) on the source machine, all traffic
over eth0 (other than &lt;span class="caps"&gt;SSH&lt;/span&gt;) on that machine will be duplicated within an
&lt;span class="caps"&gt;SSH&lt;/span&gt; tunnel. So you have double the traffic, plus the overhead of
tunneling all that within &lt;span class="caps"&gt;SSH&lt;/span&gt; to the destination machine. If you&amp;#8217;re
capturing data from a busy machine this way, you could easily saturate
the uplink and wreak all sorts of havoc. As a result, I&amp;#8217;d recommend
making the tcpdump filter as specific as you can while still retaining
the data you need. If you can replace it with a filter for specific
ports (i.e. &lt;code&gt;'(port 67 or port 68)'&lt;/code&gt; for &lt;span class="caps"&gt;DHCP&lt;/span&gt;) or specific hosts, that
should cut down on the amount of data you actually have to pass through
the&amp;nbsp;tunnel.&lt;/p&gt;</summary><category term="ethereal"></category><category term="linux"></category><category term="sysadmin"></category><category term="tcpdump"></category><category term="troubleshooting"></category><category term="wireshark"></category></entry><entry><title>Consolidation of nmap port scan results to HTML table</title><link href="http://blog.jasonantman.com/2011/01/consolidation-of-nmap-port-scan-results-to-html-table/" rel="alternate"></link><updated>2011-01-30T20:00:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-01-30:2011/01/consolidation-of-nmap-port-scan-results-to-html-table/</id><summary type="html">&lt;p&gt;I spent a good part of the weekend auditing the security of my
infrastructure at home, since I haven&amp;#8217;t given it much attention lately.
One of my first steps was doing a port scan with
&lt;a href="http://www.nmap.org"&gt;nmap&lt;/a&gt; of my public IPs from a remote host, both to
make sure there&amp;#8217;s nothing showing up that shouldn&amp;#8217;t be and to get an
idea of what a potential attacker might see. However, given all of
nmap&amp;#8217;s options for different &lt;span class="caps"&gt;TCP&lt;/span&gt; scans, it seemed like a lot of data to
sort through. Without finding any good solution in my cursory search, I
wrote up a little &lt;span class="caps"&gt;PHP&lt;/span&gt; script that takes any number of &lt;span class="caps"&gt;XML&lt;/span&gt; nmap scan
files on the command line, parses out the hosts and ports found in each
of them, and presents a nice table showing the result for each host/port
for each scan&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;The current version of the script can be found at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/nmap-xml-to-table.php"&gt;https://github.com/jantman/misc-scripts/blob/master/nmap-xml-to-table.php&lt;/a&gt;,
and simply called as &lt;code&gt;./nmap-xml-to-table.php file1.xml file2.xml [...]&lt;/code&gt;
and outputs &lt;span class="caps"&gt;HTML&lt;/span&gt; to&amp;nbsp;stdout.&lt;/p&gt;</summary><category term="nmap"></category><category term="security"></category></entry><entry><title>Vyatta VC5 - Snort alerts to syslog</title><link href="http://blog.jasonantman.com/2011/01/vyatta-vc5-snort-alerts-to-syslog/" rel="alternate"></link><updated>2011-01-30T19:54:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-01-30:2011/01/vyatta-vc5-snort-alerts-to-syslog/</id><summary type="html">&lt;p&gt;I&amp;#8217;m running a &lt;a href="http://www.vyatta.org"&gt;Vyatta&lt;/a&gt; vyatta router at home - in
my opinion it&amp;#8217;s pretty near &amp;#8220;enterprise grade&amp;#8221;, and I&amp;#8217;m running the
Community/Core (read: no-cost and almost all Free) on commodity hardware
with great performance. Granted, I&amp;#8217;m still on the older version (5 as
opposed to the current 6) since an upgrade will require total downtime
and a spare set of &lt;span class="caps"&gt;SCSI&lt;/span&gt; disks for the machine it&amp;#8217;s on, but it still
works quite well. Today I decided to enable the
&lt;a href="http://www.snort.org"&gt;Snort&lt;/a&gt; &lt;span class="caps"&gt;IDS&lt;/span&gt; on the box. It actually worked quite
well (albeit stuck at older rules until I upgrade to Vyatta &lt;span class="caps"&gt;VC6&lt;/span&gt;) and
didn&amp;#8217;t put much more load on the box. For the time being I decided to
just have it alert on problems and not drop anything, as I&amp;#8217;m getting
pretty high false positives and the older Vyatta version doesn&amp;#8217;t seem to
have a way to disregard&amp;nbsp;rules.&lt;/p&gt;
&lt;p&gt;My biggest complaint was that Vyatta didn&amp;#8217;t see fit to allow alerts by
syslog. I&amp;#8217;m not a big fan of keeping information like &lt;span class="caps"&gt;IDS&lt;/span&gt; logs stuck on
the router - I don&amp;#8217;t like logging in to it any more than I have to, it
doesn&amp;#8217;t have much storage, and I&amp;#8217;d also like to keep stuff like this in
a more secure location. Through a bit of digging, I found the
&lt;code&gt;/opt/vyatta/share/perl5/VyattaSnortConfig.pm&lt;/code&gt; Perl module which
generates the Snort config file from Vyatta&amp;#8217;s &lt;span class="caps"&gt;CLI&lt;/span&gt; stuff. Looking through
the Perl code, I found the definition of the snort.conf output&amp;nbsp;statements:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$output_def&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;lt;&amp;lt;&lt;span class="caps"&gt;EOD&lt;/span&gt;;&lt;/span&gt;
&lt;span class="s"&gt;  output alert_unified: alert, limit $log_limit&lt;/span&gt;
&lt;span class="s"&gt;  output log_null&lt;/span&gt;
&lt;span class="s"&gt;&lt;span class="caps"&gt;EOD&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I simply added a line &lt;code&gt;output alert_syslog: log_local3 log_notice&lt;/code&gt; after the &lt;code&gt;output alert_unified&lt;/code&gt; line.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$output_def&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;lt;&amp;lt;&lt;span class="caps"&gt;EOD&lt;/span&gt;;&lt;/span&gt;
&lt;span class="s"&gt;  output alert_unified: alert, limit $log_limit&lt;/span&gt;
&lt;span class="s"&gt;  output alert_syslog: log_local3 log_notice&lt;/span&gt;
&lt;span class="s"&gt;  output log_null&lt;/span&gt;
&lt;span class="s"&gt;&lt;span class="caps"&gt;EOD&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I then went into Vyatta configuration and changed a rule from alert to pass, committed,
changed back, committed, and &lt;code&gt;/etc/snort/snort.conf&lt;/code&gt; now had my syslog lines. I&amp;#8217;m now 
getting snort alerts to local3 in syslog, which is fed to my centralized log server. My
next project is to find or write something which will parse these logs, generate a daily
summary email, and maybe check them hourly and alert on any big changes. I also might just
cron an emailing of the output from Vyatta&amp;#8217;s show ips summary command. So far I have over 11,000 events logged in about 12&amp;nbsp;hours.&lt;/p&gt;</summary><category term="security"></category><category term="snort"></category><category term="syslog"></category><category term="vyatta"></category></entry></feed>