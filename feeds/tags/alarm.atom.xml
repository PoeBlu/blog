<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jason Antman's Blog - alarm</title><link href="https://blog.jasonantman.com/" rel="alternate"></link><link href="https://blog.jasonantman.com/feeds/tags/alarm.atom.xml" rel="self"></link><id>https://blog.jasonantman.com/</id><updated>2018-07-02T06:10:00-04:00</updated><entry><title>IP Camera, Home Security and Automation Update</title><link href="https://blog.jasonantman.com/2018/07/ip-camera-home-security-and-automation-update/" rel="alternate"></link><published>2018-07-02T06:10:00-04:00</published><updated>2018-07-02T06:10:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-07-02:/2018/07/ip-camera-home-security-and-automation-update/</id><summary type="html">&lt;p&gt;An update on my &lt;span class="caps"&gt;IP&lt;/span&gt; camera and home security project, now branching out into home automation and machine learning as&amp;nbsp;well.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#amcrest-cameras"&gt;Amcrest Cameras&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#ir-illuminator"&gt;&lt;span class="caps"&gt;IR&lt;/span&gt;&amp;nbsp;Illuminator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#surveillance-software-zoneminder"&gt;Surveillance Software - ZoneMinder&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#notifications"&gt;Notifications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image-processing-ir-switch-detection"&gt;Image Processing - &lt;span class="caps"&gt;IR&lt;/span&gt; Switch&amp;nbsp;Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#monitoring"&gt;Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#neural-network-object-detection"&gt;Neural Network Object&amp;nbsp;Detection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#homeassistant-and-z-wave"&gt;HomeAssistant and Z-Wave&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#doorwindow-and-motion-sensors"&gt;Door/Window and Motion&amp;nbsp;Sensors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#thermostat"&gt;Thermostat&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#whats-next"&gt;What&amp;#8217;s&amp;nbsp;Next&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Last month I posted about my &lt;a href="/2018/05/linux-surveillance-camera-software-evaluation/"&gt;Linux Surveillance Camera Software Evaluation&lt;/a&gt; and my plans for turning some Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; cameras into a home security system. I&amp;#8217;ve made a lot of progress and some big changes since then and decided that I had better post an update before the effort of doing so becomes overwhelming. There are a lot of changes and new information, and some really cool plans for the future (this has become my new obsession, albeit a prohibitively expensive one), so I&amp;#8217;ll break this up into a number of&amp;nbsp;sections.&lt;/p&gt;
&lt;h2 id="amcrest-cameras"&gt;&lt;a class="toclink" href="#amcrest-cameras"&gt;Amcrest&amp;nbsp;Cameras&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m extremely happy with the two Amcrest cameras I purchased, and am planning to add two more at some point in the near future to cover the rest of the exterior of my house. The one I currently have outside is an Amcrest &lt;a href="https://amcrest.com/amcrest-1-3mp-bullt-wifi-video-security-ip-camera-pt-ipm-723w.html"&gt;&lt;span class="caps"&gt;IPM&lt;/span&gt;-723W&lt;/a&gt; WiFi camera with a 1.&lt;span class="caps"&gt;3MP&lt;/span&gt; 1280x960 resolution and a 92º field of view. It&amp;#8217;s a decent camera and the resolution is perfectly adequate but I wouldn&amp;#8217;t mind a bit more, and more importantly, both sides of my house would benefit a lot from a winder field of view. I believe I&amp;#8217;ve settled on two Amcrest &lt;a href="https://amcrest.com/amcrest-prohd-outdoor-1080p-wifi-wireless-ip-security-bullet-camera-ip67-weatherproof-1080p-1920tvl-ip2m-852w-white.html"&gt;&lt;span class="caps"&gt;IP2M&lt;/span&gt;-852W&lt;/a&gt;, which are similar outdoor WiFi cameras but with 1920x1080 resolution and a super-wide 128º field of&amp;nbsp;view.&lt;/p&gt;
&lt;p&gt;I received some questions via email after writing this post about the Amcrest cameras with Linux as well as the security of them. I think I&amp;#8217;m quite happy with both, but both with some caveats. First of all, regarding security, I&amp;#8217;m skeptical of the security of any proprietary software (especially from a small vendor or one not in the software business) and generally expect all IoT devices to have abysmal security. When I originally purchased the devices, I blocked all Internet-bound traffic from them at my router before even plugging them in. For the time being at least, I&amp;#8217;m going to assume that to be enough for my needs. I certainly wouldn&amp;#8217;t expose these directly to the Internet or allow them to access both the Internet and my home network, as is the case for any consumer-oriented&amp;nbsp;devices.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve also received some questions about the Linux support for Amcrest cameras. My experience so far has been consistent with my &lt;a href="/2018/05/amcrest-ip-camera-first-impressions/"&gt;Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; Camera First Impressions - Jason Antman&amp;#8217;s Blog&lt;/a&gt;. The cameras certainly work fine under Linux in general; they can be fully controlled and configured via any browser and you can view the low-resolution &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream in any browser. Viewing the full-resolution &lt;span class="caps"&gt;RTSP&lt;/span&gt; stream requires either the Amcrest Web View Chrome app or a viewer that supports &lt;span class="caps"&gt;RTSP&lt;/span&gt; streams (&lt;span class="caps"&gt;VLC&lt;/span&gt; or any common surveillance camera software). Aside from watching the stream in &lt;span class="caps"&gt;VLC&lt;/span&gt; or Amcrest Web View while I was outside aiming the camera, I&amp;#8217;ve been using either the low-res &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream in a browser or, more recently ZoneMinder and HomeAssistant, to view it. Unless you want a closed-source native desktop app, I can&amp;#8217;t find any meaningful difference between how the cameras work on Linux vs Mac or presumably&amp;nbsp;Windows.&lt;/p&gt;
&lt;h3 id="ir-illuminator"&gt;&lt;a class="toclink" href="#ir-illuminator"&gt;&lt;span class="caps"&gt;IR&lt;/span&gt;&amp;nbsp;Illuminator&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My first step in attempting to reduce false-positive motion detection caused by flying bugs at night was purchasing an external &lt;span class="caps"&gt;IR&lt;/span&gt; illuminator. I opted for a 12V &lt;span class="caps"&gt;DC&lt;/span&gt; model on amazon that uses the same power supply as the camera (I purchased a splitter for them), the
&lt;a href="https://www.amazon.com/gp/product/B01G6EDOO2/"&gt;Univivi 850nm 12 &lt;span class="caps"&gt;LED&lt;/span&gt; Wide Angle &lt;span class="caps"&gt;IR&lt;/span&gt; Illuminator&lt;/a&gt;. It&amp;#8217;s a large-ish unit that looks much like a &lt;span class="caps"&gt;LED&lt;/span&gt; floodlight, except that when on it emits only a barely-visible red glow from the LEDs. This has helped immensely; I have it placed about a foot and a half away from the camera and it has dramatically cut down on (but not eliminated) the number of times that the motion detection is triggered at night by moths and other light-seeking insects. That being said, with some of the advances I&amp;#8217;ve made in other areas (read on) I probably won&amp;#8217;t be replicating this for my other cameras, at least not initially. I &lt;em&gt;will&lt;/em&gt; also remark that the light output from this unit isn&amp;#8217;t wide enough to cover the camera&amp;#8217;s whole field of view, and it does suffer from some definite hot&amp;nbsp;spots.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a view of the camera and &lt;span class="caps"&gt;IR&lt;/span&gt; illuminator during the&amp;nbsp;day:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/ir_illuminator_day.jpg"&gt;&lt;img alt="camera and IR illuminator as installed, during the day" src="/GFX/ir_illuminator_day_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And here&amp;#8217;s a view of it at night. Note that this was taken in almost total darkness and to the human eye the illuminator only emits a barely-visible red glow; unfortunately this photo does more to illustrate how sensitive my phone camera is to &lt;span class="caps"&gt;IR&lt;/span&gt; than what it actually looks&amp;nbsp;like.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/ir_illuminator_night.jpg"&gt;&lt;img alt="camera and IR illuminator at night" src="/GFX/ir_illuminator_night_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="surveillance-software-zoneminder"&gt;&lt;a class="toclink" href="#surveillance-software-zoneminder"&gt;Surveillance Software -&amp;nbsp;ZoneMinder&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When I last posted I&amp;#8217;d done an &lt;a href="/2018/05/linux-surveillance-camera-software-evaluation/"&gt;evaluation&lt;/a&gt; of a number of options for Linux-based video surveillance, discounted ZoneMinder mainly because of its age, resource requirements, and difficulty getting it running in Docker. I ended up settling on the &lt;a href="https://motion-project.github.io/"&gt;Motion Project&lt;/a&gt; (&lt;code&gt;motion&lt;/code&gt;) because of its simplicity and low resource requirements. Unfortunately, that path ended up being a dead&amp;nbsp;end.&lt;/p&gt;
&lt;p&gt;I spent quite a bit of time tuning motion and developing a horribly simple proof-of-concept web interface for it (the defunct project lives at &lt;a href="https://github.com/jantman/motion-pipeline"&gt;https://github.com/jantman/motion-pipeline&lt;/a&gt; if anyone is interested) and playing with masks and various values to get reliable motion detection at 1920x1080 10fps on a RaspberryPi 3B+. While I eventually got that working including notifications with images, it failed completely when I installed the camera in its final environment - the exterior of my house. No matter how hard I tried, I couldn&amp;#8217;t get the motion detection to capture legitimate events but ignore the large amounts of shadow motion when wind caught the trees around my house. I hadn&amp;#8217;t considered this relatively obvious issue when I did my initial tests at my former (and relatively tree-free) apartment complex. It&amp;#8217;s also worth noting that when running motion detection at 1920x1080 10fps, the RaspberryPi 3B+ was essentially at its limits; if I wanted to add another camera of equal resolution and frame rate I&amp;#8217;d need a Pi per&amp;nbsp;camera.&lt;/p&gt;
&lt;p&gt;After that non-starter I remembered that the motion detection algorithm in &lt;code&gt;motion&lt;/code&gt; only takes luminance into account (effectively a black-and-white image) but ZoneMinder uses full color in its motion detection. So, I decided to take another look at ZoneMinder. After some initial hiccups I decided to just install the &lt;code&gt;zoneminder&lt;/code&gt; package on the RaspberryPi 3B+ running Debian 9. After a bit of setup, I had it running and processing 1920x1080 10fps on the Pi. This taxed the system quite a bit and the web &lt;span class="caps"&gt;UI&lt;/span&gt; was almost unusably sluggish, but it was enough for me to get &lt;span class="caps"&gt;ZM&lt;/span&gt; up and running and to prove that its motion detection algorithm handles clouds and shadows &lt;em&gt;much&lt;/em&gt; better than &lt;code&gt;motion&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It was apparent that if I wanted to make use of &lt;span class="caps"&gt;ZM&lt;/span&gt; with multiple cameras and also have it be useful and reliable, I needed significantly better hardware than the RaspberryPi. After some searching on Amazon, I found a &lt;a href="https://www.amazon.com/gp/product/B01KWP82CK/"&gt;refurbished &lt;span class="caps"&gt;HP&lt;/span&gt; Elite 8200 small-form-factor desktop&lt;/a&gt; on Amazon for $300. It was quite a bit more money than I&amp;#8217;d wanted to put into this system, but with an Intel Core i7-2600 with four cores (plus hyper-threading) at 3.4GHz, &lt;span class="caps"&gt;16GB&lt;/span&gt; memory and a &lt;span class="caps"&gt;2TB&lt;/span&gt; spinning disk, I figured it would be more than adequate for four or more cameras (in fact the specs are shockingly close to my desktop computer, which was quite beefy when I built it three or four years&amp;nbsp;ago).&lt;/p&gt;
&lt;p&gt;That machine arrived two weeks ago and I installed Debian 9 on it along with the official ZoneMinder package, and it&amp;#8217;s performing amazingly well. With one camera at 1920x1080 10fps in monitor mode and another at 1280x960 10fps in motion detection (Modect) mode, the system barely breaks a sweat with half of its memory free and half or three-quarters of the &lt;span class="caps"&gt;CPU&lt;/span&gt; cores idle. &lt;span class="caps"&gt;ZM&lt;/span&gt; is performing exceedingly well, with the web &lt;span class="caps"&gt;UI&lt;/span&gt; fast and streaming working very well. I&amp;#8217;m still having some false positives from shadows when it gets very windy, but I have a plan for addressing that as well. Overall I&amp;#8217;m really glad I switched to ZoneMinder with decent hardware, and plan on further improving and expanding this set-up in the&amp;nbsp;future.&lt;/p&gt;
&lt;h3 id="notifications"&gt;&lt;a class="toclink" href="#notifications"&gt;Notifications&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;One thing that ZoneMinder completely lacks is the built-in ability to notify immediately on new events/alarms. The closest that it has are &amp;#8220;filters&amp;#8221;, which run at a configurable interval (usually 60 seconds) and can be set to send email or execute an external command for new alarms. Unfortunately there are some issues around how they&amp;#8217;re configured that result in either notification storms or severe delays when multiple short events happen in rapid succession. After using this method for a few days and researching other possibilities, I found the &lt;a href="https://github.com/pliablepixels/zmeventserver"&gt;zmeventserver&lt;/a&gt; project, a daemon written in Perl that polls the ZoneMinder shared memory map for new events at a short interval and pushes them to clients via a websocket server. After some initial experimentation, I unashamedly hacked up the Perl source, ripped out the websocket server, and modified it to execute a shell command with the event &lt;span class="caps"&gt;ID&lt;/span&gt; as an argument (backgrounded with &lt;code&gt;&amp;amp;&lt;/code&gt; so as not to tie up the Perl&amp;nbsp;code).&lt;/p&gt;
&lt;p&gt;For my event handler script I wrote something in Python that grabs the details of the event directly from ZoneMinder&amp;#8217;s database, along with the first and best (most motion) frames, and sends them to me via email and Pushover. I&amp;#8217;ve added a bit more to the script but it&amp;#8217;s still quite a hack-ish proof-of-concept and too rough to share, but there&amp;#8217;s really nothing terribly complicated about it: it gets called with ZoneMinder&amp;#8217;s EventId, looks up that event and a bunch of related stuff in the database, and then generates an email and Pushover notification. I&amp;#8217;m not sure if I&amp;#8217;m going to keep using this or try to push most of the logic into HomeAssistant (see below); if I do stick with this script, I&amp;#8217;ll make an effort to clean it up and publish the&amp;nbsp;code.&lt;/p&gt;
&lt;h3 id="image-processing-ir-switch-detection"&gt;&lt;a class="toclink" href="#image-processing-ir-switch-detection"&gt;Image Processing - &lt;span class="caps"&gt;IR&lt;/span&gt; Switch&amp;nbsp;Detection&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once I got ZoneMinder relatively well tuned for motion detection in my environment and notifications up and running, my first bit of intelligence in the alerting process was disregarding events when the camera switched from visible light to infra-red mode. This &lt;span class="caps"&gt;IR&lt;/span&gt; switch occurs twice a day - visible to &lt;span class="caps"&gt;IR&lt;/span&gt; around dusk and &lt;span class="caps"&gt;IR&lt;/span&gt; to visible around dawn - and was a bit of an annoyance to me. When the switch-over happens, virtually all pixels in the image go white for a frame or two and the image switches between color and black and white. My gut reaction was to ignore events with a massive percentage of changed pixels around dawn or dusk, but that seemed too uncertain. With a bit of thought, I realized that detecting a change from color to black-and-white (or vice-versa) should be rather&amp;nbsp;straightforward.&lt;/p&gt;
&lt;p&gt;As the script was already written in Python, I installed &lt;a href="https://pillow.readthedocs.io/"&gt;pillow&lt;/a&gt;, a modern fork of the Python Imaging Library, and came up with the following snippet to tell whether a specific Frame from ZoneMinder is color or black-and-white (note this is a partial snippet with a lot of unrelated code&amp;nbsp;removed):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;&lt;span class="caps"&gt;PIL&lt;/span&gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="c1"&gt;# lots of internals redacted here...&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frame_fmt&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FrameId&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_color&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Finding if image is color or not for &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;bands&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;histos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;histogram&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;bands&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;histos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;histos&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Loading image for &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; from: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This loads the &lt;span class="caps"&gt;JPEG&lt;/span&gt; image (frame) from ZoneMinder as a &lt;span class="caps"&gt;PIL&lt;/span&gt; &lt;code&gt;Image&lt;/code&gt;, splits the image
into its color-component bands (red, green, and blue), and then checks if the histograms
of the three color bands are identical. If so, the image is&amp;nbsp;black-and-white.&lt;/p&gt;
&lt;p&gt;My notification script simply looks at each event, checks if the first frame is color
and the last is black and white or vice-versa, and if so suppresses the notification
and renames the Event in ZoneMinder for later&amp;nbsp;cleanup.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;There is one issue with this method,&lt;/strong&gt; when ZoneMinder loses signal from a camera it
generates a completely blue frame until signal is regained. I&amp;#8217;ve only had this happen
once, but at some point I plan on modifying the above to ignore the blue &amp;#8220;loss of signal&amp;#8221;&amp;nbsp;frames.&lt;/p&gt;
&lt;h3 id="monitoring"&gt;&lt;a class="toclink" href="#monitoring"&gt;Monitoring&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;At this point I decided that I was sufficiently close to having a minimally-usable system that
I should turn my attention to monitoring it, and making sure I&amp;#8217;m alerted if it stops working.
Since I&amp;#8217;ve moved all of my personal services to &lt;span class="caps"&gt;AWS&lt;/span&gt;, I didn&amp;#8217;t have an existing monitoring
infrastructure for anything running in my home. Not wanting anything too heavy-weight or
complicated, and having an existing Lambda function to handle re-notification of CloudWatch
alarms, I hacked a &amp;#8220;monitoring system&amp;#8221; together using that Lambda function and &lt;span class="caps"&gt;API&lt;/span&gt; Gateway
in a few&amp;nbsp;hours.&lt;/p&gt;
&lt;p&gt;The functionality is relatively simple: every five minutes a Python script runs on my ZoneMinder
system that does a bunch of checks and &lt;span class="caps"&gt;POSTS&lt;/span&gt; them to &lt;span class="caps"&gt;API&lt;/span&gt; Gateway as a &lt;span class="caps"&gt;JSON&lt;/span&gt; array of results. The
POSTed data for each check includes the timestamp, a check name, a boolean &lt;code&gt;is_ok&lt;/code&gt; field, and
an optional string with additional information. &lt;span class="caps"&gt;API&lt;/span&gt; Gateway writes this information to DynamoDB,
and triggers a Lambda function if any of the &lt;code&gt;is_ok&lt;/code&gt; fields changed from true to false. The
Lambda is also run every 30 minutes, and notifies me via email or text message if any of the
check &lt;code&gt;is_ok&lt;/code&gt; fields is False &lt;em&gt;or&lt;/em&gt; if any of the timestamp values are more than 10 minutes old.
For now, this should suffice as a really simple monitoring system. I also have a quick and simple
single-page web view of the current Dynamo&amp;nbsp;contents.&lt;/p&gt;
&lt;p&gt;The checks that I&amp;#8217;m currently running&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;System load average&lt;sup&gt;1&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Disk free space as reported by&amp;nbsp;ZoneMinder&lt;/li&gt;
&lt;li&gt;ZoneMinder daemon status as reported by&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;ZoneMinder Run State (one of my custom values, not&amp;nbsp;&amp;#8220;stopped&amp;#8221;)&lt;/li&gt;
&lt;li&gt;ZoneMinder &lt;span class="caps"&gt;SHM&lt;/span&gt;&amp;nbsp;free&lt;/li&gt;
&lt;li&gt;ZoneMinder status as reported by &lt;code&gt;zmpkg.pl&lt;/code&gt; (&amp;#8220;running&amp;#8221;)&lt;/li&gt;
&lt;li&gt;ZoneMinder &lt;span class="caps"&gt;UI&lt;/span&gt; - page loads and has a link to my primary&amp;nbsp;camera&lt;/li&gt;
&lt;li&gt;zmdc process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;zmwatch process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;My custom event server process running (based on zmeventnotification.pl; see&amp;nbsp;above)&lt;/li&gt;
&lt;li&gt;For each&amp;nbsp;camera:&lt;/li&gt;
&lt;li&gt;Direct image check against the Amcrest&amp;nbsp;camera&lt;/li&gt;
&lt;li&gt;Camera&amp;nbsp;enabled&lt;/li&gt;
&lt;li&gt;Image check via&amp;nbsp;ZoneMinder&lt;/li&gt;
&lt;li&gt;zmu frame&amp;nbsp;rate&lt;/li&gt;
&lt;li&gt;zmu last frame&amp;nbsp;time&lt;/li&gt;
&lt;li&gt;zmc process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;zma process running if Monitor is set to a motion-detecting&amp;nbsp;state&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the &amp;#8220;Image check&amp;#8221; tests, I do the&amp;nbsp;following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Retrieve the binary image from the camera or&amp;nbsp;&lt;span class="caps"&gt;ZM&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Use the python &lt;code&gt;imghdr.what()&lt;/code&gt; function to ensure it&amp;#8217;s a &lt;span class="caps"&gt;JPEG&lt;/span&gt;&amp;nbsp;image&lt;/li&gt;
&lt;li&gt;Ensure that the size of the image matches what &lt;span class="caps"&gt;ZM&lt;/span&gt; thinks the monitor size&amp;nbsp;is&lt;/li&gt;
&lt;li&gt;Use the &lt;span class="caps"&gt;PIL&lt;/span&gt; &lt;code&gt;getextrema()&lt;/code&gt; function to ensure that there&amp;#8217;s more than one color in the image (i.e. fail if it&amp;#8217;s an all-blue &amp;#8220;signal lost&amp;#8221; or an all-black&amp;nbsp;image).&lt;/li&gt;
&lt;li&gt;Ensure that the histogram of the image has more than 20 distinct buckets / pixel&amp;nbsp;values.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; I&amp;#8217;ve usually found Load Average to be an often misunderstood metric, and one that people rely on much too often (generally without knowing enough about it). ZoneMinder exposes it prominently in the &lt;span class="caps"&gt;UI&lt;/span&gt; as one of the three health metrics, and while I&amp;#8217;m not sure I agree with this, it &lt;em&gt;is&lt;/em&gt; a good metric for the specific workload of this particular system of mine. If you&amp;#8217;d like to learn more about Load Average as a performance metric on modern Linux systems, system performance expert and current Senior Performance Architect at Netflix Brendan Gregg has an excellent blog post, &lt;a href="http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html"&gt;Linux Load Averages: Solving the Mystery&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="neural-network-object-detection"&gt;&lt;a class="toclink" href="#neural-network-object-detection"&gt;Neural Network Object&amp;nbsp;Detection&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When I was researching how other ZoneMinder users are attempting to reduce false positives, I came by a &lt;a href="https://forums.zoneminder.com/viewtopic.php?f=36&amp;amp;t=26222"&gt;post on the ZoneMinder Forums&lt;/a&gt; from someone who is using &lt;a href="https://pjreddie.com/darknet/yolo/"&gt;Joseph Redmon&amp;#8217;s Darknet yolo3&lt;/a&gt; neutral network object detection implementation for detecting and localizing meaningful changes in ZoneMinder&amp;#8217;s captured frames. This idea immediately appealed to me; if I could reliably tell whether a frame contains a person, for my purposes as a security system, that would completely solve the environmental false positive problem. I was also very interested in Darknet yolo3 as it is simple to build and distributes pre-trained models - my initial testing was as simple as cloning a repo, downloading a few files, running &lt;code&gt;make&lt;/code&gt;, and then running the included command-line script on a &lt;span class="caps"&gt;JPEG&lt;/span&gt; image. I was pretty amazed at how accurately it recognized the person, car, and dogs in the image I selected. There is also a Python wrapper around yolo3, &lt;a href="https://github.com/madhawav/YOLO3-4-Py"&gt;yolo34py&lt;/a&gt;, which I found quite easy to&amp;nbsp;use.&lt;/p&gt;
&lt;p&gt;Using yolo34py I was able to relatively quickly add object detection to my Python-based ZoneMinder event notification script. Over three or four days of testing, I found yolo3 using the pre-trained model to be &lt;em&gt;extremely&lt;/em&gt; accurate across all of the events my camera captured. The one down side was that, running on my Intel i7-2600 at 3.4GHz, it was taking a full &lt;em&gt;ten to fifteen seconds per frame&lt;/em&gt; to run the object detection. That&amp;#8217;s fine for testing, but if I were to rely on this as an alarm system, I&amp;#8217;d want something considerably&amp;nbsp;faster.&lt;/p&gt;
&lt;p&gt;A cursory glance at the Darknet documentation told me what I already knew - though I have no prior experience with the subject - that running neural network image processing with any reasonable speed requires a &lt;span class="caps"&gt;GPU&lt;/span&gt;. I decided that I could allocate around $100 to speeding up the detection given the Darknet documentation&amp;#8217;s claim of a 10x or better speedup on a &lt;span class="caps"&gt;GPU&lt;/span&gt;. I found that about the best $100 &lt;span class="caps"&gt;GPU&lt;/span&gt; I could get on Amazon was a &lt;span class="caps"&gt;1GB&lt;/span&gt; Nvidia Quadro K600, so I purchased &lt;a href="https://www.amazon.com/gp/product/B00BLTE8HK/"&gt;this&lt;/a&gt; &lt;span class="caps"&gt;PNY&lt;/span&gt;&amp;nbsp;card.&lt;/p&gt;
&lt;p&gt;When I got the card and requisite software installed and recompiled Darknet with &lt;span class="caps"&gt;CUDA&lt;/span&gt; support and attempted to run detection on an image, I was rather dismayed to be greeted with an error&amp;nbsp;message:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;0 &lt;span class="caps"&gt;CUDA&lt;/span&gt; Error: out of&amp;nbsp;memory&lt;/p&gt;
&lt;p&gt;darknet: ./src/cuda.c:36: check_error: Assertion &lt;code&gt;0&lt;/code&gt; failed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Unfortunately, after just googling that error for Darknet, I found quite a few GitHub issues and mailing list threads explaining that Darknet Yolo3&amp;#8217;s default (and most accurate) model requires about 3.&lt;span class="caps"&gt;6GB&lt;/span&gt; of &lt;span class="caps"&gt;GPU&lt;/span&gt; memory, far too much for my &lt;span class="caps"&gt;1GB&lt;/span&gt; card (at the moment, &lt;span class="caps"&gt;4GB&lt;/span&gt; GPUs start at&amp;nbsp;$&lt;span class="caps"&gt;500USD&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Luckily for the fate of my project, Darknet also has a pre-trained &amp;#8220;tiny&amp;#8221; model designed to work for low-memory GPUs - like the apparently-puny one I just bought. The project states that its accuracy is only about 2-3% lower, though the results I&amp;#8217;ve seen are noticeably inferior especially when two objects are in close proximity or overlap. For the time being, I&amp;#8217;m still getting notified by my Python script for every motion detection event, along with the &lt;span class="caps"&gt;YOLO&lt;/span&gt; object detection results. I&amp;#8217;m saving every event that has questionable results for later comparison against the full (albeit slow, running on &lt;span class="caps"&gt;CPU&lt;/span&gt;) model and possibly other object detection&amp;nbsp;tools.&lt;/p&gt;
&lt;h2 id="homeassistant-and-z-wave"&gt;&lt;a class="toclink" href="#homeassistant-and-z-wave"&gt;HomeAssistant and&amp;nbsp;Z-Wave&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Just before I began experimenting with Darknet object detection, I decided that the number of false positive motion detection events I was receiving merited investigation into a more classic alarm system approach. I also received a coupon for the &lt;a href="https://simplisafe.com/"&gt;SimpliSafe&lt;/a&gt; home security system in my address change packet from the &lt;span class="caps"&gt;USPS&lt;/span&gt;. After a fair amount of investigation I decided that there weren&amp;#8217;t any off-the-shelf wireless home alarm systems that seemed attractive to me (I don&amp;#8217;t really need central monitoring, but I do need to be able to access the system and status programmatically) but this did get me doing some research, and I found there is a wide array of alarm system components using the &lt;a href="http://www.z-wave.com/"&gt;Z-Wave&lt;/a&gt; radio technology that seemed suitable for a &lt;span class="caps"&gt;DIY&lt;/span&gt;&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;One of my colleagues speaks quite highly of &lt;a href="https://www.home-assistant.io/"&gt;HomeAssistant&lt;/a&gt;, an open source (though Apache licensed) home automation suite written in Python3. Browsing through the project&amp;#8217;s website and documentation, I became reasonably confident that it could handle my needs for an alarm system (it has a fair amount of built-in logic for this use case, and other people actively use it for this) and that it also integrates natively with Z-Wave. Even better, it also has a native integration with ZoneMinder to tie the two systems&amp;nbsp;together.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m really, &lt;em&gt;really&lt;/em&gt; liking HomeAssistant so far, but I&amp;#8217;ll leave the details of that for a future&amp;nbsp;post.&lt;/p&gt;
&lt;h3 id="doorwindow-and-motion-sensors"&gt;&lt;a class="toclink" href="#doorwindow-and-motion-sensors"&gt;Door/Window and Motion&amp;nbsp;Sensors&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After a bit of research, I determined that I wanted Z-Wave Plus components for their better (than none) security and advanced features and purchased some initial Z-Wave components to test from Amazon: a &lt;span class="caps"&gt;USB&lt;/span&gt; &lt;a href="https://www.amazon.com/gp/product/B00X0AWA6E/"&gt;Aeotec Gen5 Z-Stick&lt;/a&gt; Z-Wave controller for $45, an &lt;a href="https://www.amazon.com/gp/product/B01N5HB4U5/"&gt;Ecolink Z-Wave Plus magnetic Door/Window sensor&lt;/a&gt; for $30, and an &lt;a href="https://www.amazon.com/gp/product/B01MQXXG0I/"&gt;Ecolink Z-Wave Plus &lt;span class="caps"&gt;PIR&lt;/span&gt; Motion Sensor&lt;/a&gt; for $40. I figured that was a reasonable enough price to test the system and determine how well it works, and either move forward or return the&amp;nbsp;items.&lt;/p&gt;
&lt;p&gt;So far I&amp;#8217;ve had the Z-Wave components running via HomeAssistant for seven days, with the door sensor on my front door and the motion sensor placed atop the adjacent window. I&amp;#8217;ve configured HomeAssistant to do nothing more than notify me via Pushover when the door opens or motion is sensed. So far in a week, I&amp;#8217;ve received zero false-positive alarms and zero false-negative alarms, so I&amp;#8217;m quite happy. The motion or door opening signals make it from the sensors to HomeAssistant, out to Pushover, and to my phone within one to three seconds, which seems quite reasonable to me. The &amp;#8220;pet immunity&amp;#8221; on the motion sensor &lt;em&gt;is&lt;/em&gt; still triggered by my two dogs walking around, but that&amp;#8217;s rather expected since they&amp;#8217;re fifty-five and seventy pounds, respectively, and not a problem since they&amp;#8217;re crated whenever I&amp;#8217;m not home. I&amp;#8217;m quite happy with the performance of both of these sensors so&amp;nbsp;far.&lt;/p&gt;
&lt;h3 id="thermostat"&gt;&lt;a class="toclink" href="#thermostat"&gt;Thermostat&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Last weekend, after unpacking and enabling my two &lt;a href="https://github.com/jantman/pi2graphite"&gt;RaspberryPi-to-Graphite temperature sensors&lt;/a&gt;, I finally determined that I&amp;#8217;m not going crazy but the thermostat in my house was. It was wildly inaccurate, and letting the house overheat during the day and then over-cooling at night. I knew I had to replace it and, having seen that HomeAssistant supports climate control systems, immediately remembered my dream of having a computer-controlled thermostat that I briefly &lt;a href="https://github.com/jantman/RPyMostat"&gt;explored&lt;/a&gt; since I first built a &lt;a href="https://github.com/jantman/tuxostat"&gt;crude solution&lt;/a&gt; back &lt;a href="http://blog.jasonantman.com/2008/06/new-project/"&gt;in 2008&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After a short search on Amazon, I found the &lt;a href="https://www.amazon.com/gp/product/B0095P7B80/"&gt;Iris &lt;span class="caps"&gt;CT&lt;/span&gt;-101 Z-Wave thermostat&lt;/a&gt;. It&amp;#8217;s a touchscreen 7-day programmable thermostat with Z-Wave, essentially the same unit as the &lt;a href="http://www.radiothermostat.com/products/"&gt;Radio Thermostat &lt;span class="caps"&gt;CT&lt;/span&gt;-101&lt;/a&gt; but intended to work with the Lowes Iris home automation system. A number of the positive reviews mentioned it working with HomeAssistant or other F/&lt;span class="caps"&gt;OSS&lt;/span&gt; home automation systems, and the $40 price was well below most networked thermostats and about the same as a normal &amp;#8220;dumb&amp;#8221; 7-day thermostat at local&amp;nbsp;stores.&lt;/p&gt;
&lt;p&gt;So far I&amp;#8217;m quite happy with it. I had some initial concerns - even though the device is constantly powered and even a Z-Wave repeater, I had to configure HomeAssistant to explicitly poll it on a regular interval for up-to-date information - but now that I&amp;#8217;ve figured it out, the thermostat seems to be working quite well. I can view the current and target temperatures, the operational/power status of my &lt;span class="caps"&gt;HVAC&lt;/span&gt; system&amp;#8217;s fan and compressor, and set the target temperature and on/off controls. The unit &lt;em&gt;does&lt;/em&gt; show up as two separate controls - heating and cooling - but that seems to be the standard for Z-Wave climate controls and logically matches up with the physical thermostat&amp;#8217;s &amp;#8220;heat/off/cool&amp;#8221; controls. I haven&amp;#8217;t done any automation with it yet, but at a minimum this should make it easy for me to control heating and cooling based on different temperature sensors throughout the house at different times of&amp;nbsp;day.&lt;/p&gt;
&lt;h2 id="whats-next"&gt;&lt;a class="toclink" href="#whats-next"&gt;What&amp;#8217;s&amp;nbsp;Next&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This past weekend I purchased two more outdoor Amcrest WiFi cameras - this time the &lt;a href="https://amcrest.com/amcrest-prohd-outdoor-1080p-wifi-wireless-ip-security-bullet-camera-ip67-weatherproof-1080p-1920tvl-ip2m-852w-white.html"&gt;&lt;span class="caps"&gt;IP2M&lt;/span&gt;-852W&lt;/a&gt; 1080P models with an impressive 128º field of view - to complete my camera coverage, as well as a few more of the same &lt;a href="https://www.amazon.com/gp/product/B01N5HB4U5/"&gt;Z-Wave door/window sensors&lt;/a&gt;, a pair of Z-Wave lightbulbs to try, and some well-reviewed &lt;a href="https://www.amazon.com/gp/product/B01AKSO80O/"&gt;&lt;span class="caps"&gt;ZOOZ&lt;/span&gt; Z-Wave 4-in-1 sensors&lt;/a&gt; that combine motion sensors with light level, temperature, and humidity. Over the next week or two I&amp;#8217;ll be installing all of that to finally finish the system, and also spending quite a bit of time customizing HomeAssistant to be the heart of it all. I&amp;#8217;ll share my experiences in follow-up posts, but some of the things I have planned&amp;nbsp;include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Experimenting with some other machine-learning-based object detection&amp;nbsp;implementations&lt;/li&gt;
&lt;li&gt;Localizing detected objects to a ZoneMinder zone in the image, and using that to determine whether to alarm or&amp;nbsp;not&lt;/li&gt;
&lt;li&gt;Modifying the ZoneMinder HomeAssistant integration to know about run&amp;nbsp;states&lt;/li&gt;
&lt;li&gt;Using HomeAssistant&amp;#8217;s alarm control panel component to implement real alarm system logic, with notifications to my&amp;nbsp;phone&lt;/li&gt;
&lt;li&gt;Having my Amcrest ProHD pan/tilt camera, which has clear line of sight to both front and back doors, pan to a door and capture a snapshot when the door sensor&amp;nbsp;activates.&lt;/li&gt;
&lt;/ul&gt;</content><category term="amcrest"></category><category term="camera"></category><category term="security"></category><category term="surveillance"></category><category term="video"></category><category term="linux"></category><category term="IP camera"></category><category term="evaluation"></category><category term="alarm"></category><category term="IR"></category><category term="homeassistant"></category><category term="hass"></category><category term="automation"></category><category term="z-wave"></category><category term="darknet"></category><category term="yolo"></category><category term="machine learning"></category><category term="neural network"></category><category term="object detection"></category></entry><entry><title>Raspberry Pi Security System</title><link href="https://blog.jasonantman.com/2016/01/raspberry-pi-security-system/" rel="alternate"></link><published>2016-01-16T10:00:00-05:00</published><updated>2016-01-16T10:00:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2016-01-16:/2016/01/raspberry-pi-security-system/</id><summary type="html">&lt;p&gt;A Raspberry Pi and webcam security&amp;nbsp;system.&lt;/p&gt;</summary><content type="html">&lt;p&gt;It seems that crime is on the rise in the area where I live, and in my &amp;#8220;gated&amp;#8221; (when they actually close)
apartment complex. I&amp;#8217;m going out of town for a while to visit family, and was a bit wary of leaving my
apartment - and all of my posessions, and most importantly my cats, unattended for too long. I&amp;#8217;m having
some family in the area check on the cats every few days, but that doesn&amp;#8217;t do a lot for my peace of mind
in a complex that&amp;#8217;s had a few break-ins this&amp;nbsp;year.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve played around on previous trips with with &lt;a href="http://www.lavrsen.dk/foswiki/bin/view/Motion/WebHome"&gt;motion&lt;/a&gt;, a motion-activated video recording tool,
and a &lt;a href="http://www.amazon.com/Logitech-960-000585-HD-Webcam-C310/dp/B003LVZO8S/ref=sr_1_1?ie=UTF8&amp;amp;qid=1450663461&amp;amp;sr=8-1&amp;amp;keywords=logitech+c310"&gt;Logitech C310 webcam&lt;/a&gt;,
but with four cats, it&amp;#8217;s far from a tool to detect a human in my apartment. So, the weekend before my trip,
I decided to do some&amp;nbsp;tinkering.&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s an &amp;#8220;alarm system&amp;#8221; control panel next to the entry to my apartment, but it appears to be a no-name system that probably
cost $20 and doesn&amp;#8217;t actually do anything other than sound a chime when the door opens. I turned it off the day I moved in,
and hadn&amp;#8217;t given it a second thought since. However, it occurred to me that the useless panel next to the washing machine
probably had magnetic contact switches for the doors. Sure enough, after a few minutes with a multimeter, I found that both
the entry door and the sliding balcony door have normally-closed magnetic contacts wired back to the panel. After thinking
over the options for a few minutes, I remembered that I had a &lt;a href="https://www.raspberrypi.org/"&gt;Raspberry Pi&lt;/a&gt; (the original)
sitting unused under my &lt;span class="caps"&gt;TV&lt;/span&gt;, and a &lt;a href="https://www.sparkfun.com/products/11772"&gt;PiFace I/O card&lt;/a&gt; that I&amp;#8217;d never&amp;nbsp;used.&lt;/p&gt;
&lt;p&gt;After about an hour of connecting some wires and playing around with the wonderfully-simple &lt;a href="http://piface.github.io/pifacedigitalio/"&gt;pifacedigitalio&lt;/a&gt;
Python package &lt;a href="https://pypi.python.org/pypi/pifacedigitalio/3.0.5"&gt;available on PyPi&lt;/a&gt;, I was able to successfully read
inputs for when either door was open. I figured that this would provide the perfect squelch for motion recording from the
webcam, as the cats aren&amp;#8217;t able to operate the deadbolt on my front door (I had to replace all of the interior door handles
with cat-proof&amp;nbsp;models).&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/rpi_alarm_1_large.jpg"&gt;&lt;img alt="Photograph of RPi in alarm enclosure" src="/GFX/rpi_alarm_1_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/rpi_alarm_2_large.jpg"&gt;&lt;img alt="Photograph of alarm enclosure closed, showing wires to RPi" src="/GFX/rpi_alarm_2_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The system that I&amp;#8217;ve come up with is rather rough around the edges&amp;#8230; to put it lightly. It&amp;#8217;s pretty obvious that it was written
in a few days, and at this point, it&amp;#8217;s not really intended to be used by anyone who doesn&amp;#8217;t have a good understanding of the
components (and Python). But I&amp;#8217;m hoping that someone else might find it interesting, or perhaps improve on it. It&amp;#8217;s not terribly
robust, but it seems to be working acceptably well for my&amp;nbsp;needs.&lt;/p&gt;
&lt;h2 id="components"&gt;&lt;a class="toclink" href="#components"&gt;Components&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The system is split into a number of components, with some of them running on the Raspberry Pi and some on my desktop&amp;nbsp;computer.&lt;/p&gt;
&lt;p&gt;The Pi is running my &lt;a href="https://github.com/jantman/piface-webhooks"&gt;piface-webhooks&lt;/a&gt; project (everything needed to set it up on
&lt;a href="https://www.raspbian.org/"&gt;Raspbian&lt;/a&gt; or &lt;a href="https://osmc.tv/"&gt;&lt;span class="caps"&gt;OSMC&lt;/span&gt;&lt;/a&gt; is available in the repo), which is made up of two Python&amp;nbsp;services:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;piface-listener&lt;/strong&gt; Is the code that actually polls the PiFace inputs. When the state of an input changes, it writes out
a file (under &lt;code&gt;/var/spool/piface-webhooks&lt;/code&gt; by default) with the input number, state, and&amp;nbsp;timestamp.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;piface-worker&lt;/strong&gt; Polls this directory for files; when one is found, it takes some action and then removes the file. The
current actions are sending an &lt;span class="caps"&gt;HTTP&lt;/span&gt; webhook, sending a message via &lt;a href="https://pushover.net/"&gt;Pushover&lt;/a&gt;, and sending an email
via Gmail. I currently use all of these, mainly for redudnancy. The webhook feature is used to &lt;span class="caps"&gt;POST&lt;/span&gt; data to &lt;code&gt;motion_piface_handler.py&lt;/code&gt;,
a Flask app running on my&amp;nbsp;desktop.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My desktop computer is the heart of the system, handling the webcam and most of the &amp;#8220;alarm&amp;#8221;&amp;nbsp;logic:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.lavrsen.dk/foswiki/bin/view/Motion/WebHome"&gt;motion&lt;/a&gt; monitors the webcam feed for motion above a certain number of
pixels. When motion is detected, it saves both &lt;span class="caps"&gt;JPEG&lt;/span&gt; images and &lt;span class="caps"&gt;AVI&lt;/span&gt; files to disk, logs the event in a MySQL database, and
executes a Python script. It also saves a snapshot from the webcam every 30&amp;nbsp;seconds.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/misc-scripts/blob/master/s3sync_inotify.py"&gt;s3sync_inotify.py&lt;/a&gt; is a quick Python script I wrote that
uses Linux inotify to monitor &lt;code&gt;motion&lt;/code&gt;&amp;#8216;s output directory for new files (only when they&amp;#8217;ve been closed, and are finished being
written) and syncs them to an S3 bucket set up for static website hosting. It also generates an &lt;code&gt;index.html&lt;/code&gt; file for the bucket,
with links to all uploaded files. At startup, any files that aren&amp;#8217;t yet synced are uploaded, so it &lt;em&gt;should&lt;/em&gt; handle crashes relatively&amp;nbsp;well.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;handle_motion.py&lt;/strong&gt; is the command executed by &lt;code&gt;motion&lt;/code&gt; when an event is detected; it POSTs data to &lt;code&gt;motion_piface_handler.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;motion_piface_handler.py&lt;/strong&gt; is the heart of the system, explained&amp;nbsp;below.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="motion_piface_handlerpy-pulling-it-all-together"&gt;&lt;a class="toclink" href="#motion_piface_handlerpy-pulling-it-all-together"&gt;motion_piface_handler.py - Pulling it all&amp;nbsp;together&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Webhooks from both the Raspberry Pi door sensor and &lt;code&gt;motion&lt;/code&gt;&amp;#8216;s command execution go to a Python &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; app
running on my desktop. This app accepts the incoming data, and also connects to the MySQL database used by Motion. When a &lt;span class="caps"&gt;POST&lt;/span&gt; from
&lt;code&gt;piface-worker&lt;/code&gt; comes in showing that a door has been opened, it adds a record to the MySQL database with information on the input
pin (which door) and state (open/closed), and&amp;nbsp;timestamp.&lt;/p&gt;
&lt;p&gt;When a &lt;span class="caps"&gt;POST&lt;/span&gt; comes in from &lt;code&gt;handle_motion.py&lt;/code&gt;, the command executed by &lt;code&gt;motion&lt;/code&gt; when a file is written, the app checks to see if
a door has been opened in the past few minutes. If not, the event is ignored (and logged, of course). However, if a door has been
opened, the real fun starts. First, the database is queried for the last time a notification was sent out. If one has been sent
in the past few minutes, the current event is ignored (and a rate-limiting message is logged). If it hasn&amp;#8217;t sent out a message
recently, the database is queried for the last door event (which door, and if it was opened or closed) as well as the last &lt;span class="caps"&gt;AVI&lt;/span&gt;
and last five JPEGs saved by &lt;code&gt;motion&lt;/code&gt;. This information is all formatted into a message and sent to my GMail account, and a
shortened version (with just the door event information, and that motion was detected) is sent to my phone via Pushover, with
the highest priority and a custom notification&amp;nbsp;sound.&lt;/p&gt;
&lt;p&gt;So far - at least as far as taking my dogs out is concerned - it appears to be working relatively well. There&amp;#8217;s a bit of
latency in the S3 uploads, especially when AVIs are written, so the files linked in the notification emails may not be
uploaded before the message goes out. That&amp;#8217;s a bit annying, but something that I think I can live&amp;nbsp;with.&lt;/p&gt;
&lt;p&gt;The use of disk queueing probably isn&amp;#8217;t the best, especially with the Pi&amp;#8217;s &lt;span class="caps"&gt;SD&lt;/span&gt; card, but I wanted something that was simple
and didn&amp;#8217;t introduce any additional service dependencies. Each of the components runs as a systemd service, configured to
always restart, so it should tolerate internal failures relatively well. The Python code has a &lt;em&gt;lot&lt;/em&gt; of bare excepts;
I&amp;#8217;m not sure this was the right way to approach it, but my initial theory was that in the event of an error, I&amp;#8217;m more
concerned about keeping the system running than getting an individual message through. The point of the system is to let
me know if my home - and more importantly, my four-legged children - are in danger. I figured that I&amp;#8217;d rather get a delayed
notification than none at&amp;nbsp;all.&lt;/p&gt;
&lt;h2 id="results"&gt;&lt;a class="toclink" href="#results"&gt;Results&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After two weeks away, the system worked quite well. It triggered correctly, and quickly, when my family came to check on the cats.
On average, it took about 3-5 seconds for me to receive the PushOver and GMail notifications for a door open event, and about 30 seconds
for an alarm (motion after door state change)&amp;nbsp;event.&lt;/p&gt;
&lt;p&gt;However, I did have a few&amp;nbsp;issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Late one night, I got a door open alert when I hadn&amp;#8217;t been expecting anyone. After about half an hour of panic checking the webcam feed
and watching the logs remotely, I determined that it was a false positive. All was well, there wasn&amp;#8217;t any sign of anyone in the apartment,
the cats were all wandering (or lounging) around as normal, and the door never registered as closed. A day or two later, the door registered
as closing. I&amp;#8217;m not sure if this was an issue with the door sensor triggering because of wind or vibration, or an issue with the PiFace itself
having internal issues reading an input over such a long time, or something with induced current in the long unshielded sensor wire in the wall
(and possibly compounded by my naive debounce&amp;nbsp;logic).&lt;/li&gt;
&lt;li&gt;Having &lt;code&gt;motion&lt;/code&gt; store everything in one directory, and then &lt;code&gt;s3sync_inotify.py&lt;/code&gt; sync that to S3 and create an &lt;code&gt;index.html&lt;/code&gt; file was a
bad idea. &lt;code&gt;motion&lt;/code&gt; was triggered quite often by the cats; after about a week away, I had ~&lt;span class="caps"&gt;10GB&lt;/span&gt; of photos and videos in the S3 bucket, and the
&lt;code&gt;index.html&lt;/code&gt; file was over &lt;span class="caps"&gt;7MB&lt;/span&gt;. Not only did the index page take a painfully long amount of time to load, but generation of it introduced enough
latency in the upload process that &lt;code&gt;s3sync_inotify.py&lt;/code&gt; ended up missing a large number of&amp;nbsp;files.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="next-steps"&gt;&lt;a class="toclink" href="#next-steps"&gt;Next&amp;nbsp;Steps&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m not sure if I&amp;#8217;ll do much more work on this - we don&amp;#8217;t travel often - but if I do, the next things that I want to tackle&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Queueing of outgoing messages, so that network outages won&amp;#8217;t result in completely-lost&amp;nbsp;communication.&lt;/li&gt;
&lt;li&gt;Some sort of heartbeat - ideally to an off-premesis system, such as my &lt;span class="caps"&gt;EC2&lt;/span&gt; instance - from every process involved, to
confirm that all of the components (a) are running correctly, and (b) have&amp;nbsp;connectivity.&lt;/li&gt;
&lt;li&gt;Modify the &lt;code&gt;motion&lt;/code&gt; output directory structure and &lt;code&gt;s3sync_inotify.py&lt;/code&gt; to write into per-day (or per-hour) directories
and write &lt;code&gt;index.html&lt;/code&gt; files for each of&amp;nbsp;them.&lt;/li&gt;
&lt;li&gt;See if there&amp;#8217;s a straightforward way to use systemd&amp;#8217;s &lt;a href="http://www.freedesktop.org/software/systemd/man/sd_notify.html"&gt;sd_notify&lt;/a&gt;
from Python, to build a watchdog into the processes and have systemd restart them if they&amp;nbsp;hang.&lt;/li&gt;
&lt;li&gt;Packaging this all together into one or more real repositories, so maybe it can be used by&amp;nbsp;others.&lt;/li&gt;
&lt;li&gt;Cleaning up &lt;code&gt;handle_motion.py&lt;/code&gt; and &lt;code&gt;motion_piface_handler.py&lt;/code&gt; and releasing them along with everything&amp;nbsp;else.&lt;/li&gt;
&lt;/ul&gt;</content><category term="rpi"></category><category term="pi"></category><category term="raspberrypi"></category><category term="security"></category><category term="alarm"></category><category term="motion"></category><category term="camera"></category></entry></feed>