<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jason Antman's Blog</title><link>http://blog.jasonantman.com/</link><description></description><atom:link href="http://blog.jasonantman.com/feeds/tags/terraform.rss.xml" rel="self"></atom:link><lastBuildDate>Sat, 06 Aug 2016 21:38:00 -0400</lastBuildDate><item><title>Tooling for AWS - webhooks to SQS via API Gateway and Lambda</title><link>http://blog.jasonantman.com/2016/08/tooling-for-aws-webhooks-to-sqs-via-api-gateway-and-lambda/</link><description>&lt;p&gt;A few weeks ago at work, I was party to two discussions about possible tooling needs, both very low-priority. One was the possible need to sync MarkDown documentation
from GitHub repositories to&amp;#8230; another thing that can hold docs. The other was relating to the new Version 2 Docker Registry, &lt;a href="https://github.com/docker/distribution"&gt;distribution&lt;/a&gt;.
We have some Jenkins jobs that dynamically populate dropdown fields for build parameters with Docker image names and tags, using the &lt;a href="https://wiki.jenkins-ci.org/display/JENKINS/Active+Choices+Plugin"&gt;Active Choices Plugin&lt;/a&gt;.
Right now we&amp;#8217;re directly querying the Docker Registry &lt;span class="caps"&gt;API&lt;/span&gt; from Groovy, every time the Build With Parameters page is loaded. With the original version 1 Docker Registry,
images were often missing from the results (eek!) but the performance was good. With the switch to the v2 Registry, it takes almost two minutes to load the page.
While brainstorming solutions, we decided that caching the list of images and tags in the Registry was the solution. For bonus points, it would also be nice to
be able to query based on image labels - something that&amp;#8217;s not exposed in the Registry &lt;span class="caps"&gt;API&lt;/span&gt; at all. Luckily, the Registry has an option to fire a webhook every time
a new image is&amp;nbsp;pushed.&lt;/p&gt;
&lt;p&gt;Both of these problems have solutions that involve webhooks, from GitHub and Docker Distribution, respectively. They also both involve doing time-consuming things in custom code with the
data in those hooks - transforming MarkDown to another markup and pushing the result to an on-premesis system in the case of GitHub, and &lt;code&gt;pull&lt;/code&gt;ing and inspecting Docker
images in the case of the Registry. As such, the &amp;#8220;typical&amp;#8221; webhook things like &lt;a href="https://zapier.com/"&gt;Zapier&lt;/a&gt; won&amp;#8217;t fit the bill. All I really needed was something to receive webhooks
and push the content of them into a queue. Ideally, it would also be something that would utilize existing services we have, namely&amp;nbsp;&lt;span class="caps"&gt;AWS&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;After working a bunch of nights and the good part of a weekend, I have a solution: my new &lt;a href="https://pypi.python.org/pypi/webhook2lambda2sqs"&gt;webhook2lambda2sqs&lt;/a&gt; Python&amp;nbsp;package.&lt;/p&gt;
&lt;p&gt;This implements what I think is the cheapest and lowest-overhead solution for anyone with an existing &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;nbsp;account:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup an &lt;a href="https://aws.amazon.com/api-gateway/"&gt;&lt;span class="caps"&gt;API&lt;/span&gt; Gateway&lt;/a&gt; that receives json &lt;span class="caps"&gt;POST&lt;/span&gt; and &lt;span class="caps"&gt;GET&lt;/span&gt;&amp;nbsp;requests.&lt;/li&gt;
&lt;li&gt;It passes them to a &lt;a href="https://aws.amazon.com/lambda/"&gt;Lambda Function&lt;/a&gt; which pushes the content to one or more &lt;a href="https://aws.amazon.com/sqs/"&gt;&lt;span class="caps"&gt;SQS&lt;/span&gt;&lt;/a&gt; queues, for consumption by an&amp;nbsp;application.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The tooling is written in Python, but leverages &lt;a href="https://www.terraform.io/"&gt;HashiCorp&amp;#8217;s Terraform&lt;/a&gt; to actually manage the &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;nbsp;resources.&lt;/p&gt;
&lt;p&gt;From a &lt;span class="caps"&gt;JSON&lt;/span&gt; configuration file as simple&amp;nbsp;as:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;{
  &amp;quot;endpoints&amp;quot;: {
    &amp;quot;some_resource_name&amp;quot;: {
      &amp;quot;method&amp;quot;: &amp;quot;POST&amp;quot;,
      &amp;quot;queues&amp;quot;: [&amp;quot;myqueue&amp;quot;]
    },
  },
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and a single command (&lt;code&gt;webhook2lambda2sqs genapply&lt;/code&gt;), you&amp;#8217;ll have the complete system up and running, receiving &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;POST&lt;/span&gt; requests
at an &lt;span class="caps"&gt;AWS&lt;/span&gt;-generated &lt;span class="caps"&gt;URL&lt;/span&gt; and pushing them into the &lt;code&gt;myqueue&lt;/code&gt; &lt;span class="caps"&gt;SQS&lt;/span&gt; queue. Best of all, going by my testing (this is based on the time
the Lambda function takes to run, which can vary quite a bit), the whole thing is &lt;strong&gt;free for the first 1 million requests per month&lt;/strong&gt;
if your account is still on the Free Tier, and otherwise is less than $4/month for the first million&amp;nbsp;requests.&lt;/p&gt;
&lt;p&gt;The configuration can handle setting up multiple distinct endpoint paths in the same &lt;span class="caps"&gt;API&lt;/span&gt; Gateway, each
sending the data to one or more &lt;span class="caps"&gt;SQS&lt;/span&gt; queues. It also has options for enabling logging (to CloudWatch Logs) both in the function
and on the &lt;span class="caps"&gt;API&lt;/span&gt; Gateway, pushing &lt;span class="caps"&gt;API&lt;/span&gt; Gateway metrics to CloudWatch, and configuring rate&amp;nbsp;limiting.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;webhook2lambda2sqs&lt;/code&gt; program generates the Python code for the lambda function and packages it correctly for Lambda, and
then generates a Terraform configuration to manage all required &lt;span class="caps"&gt;AWS&lt;/span&gt; resources. Separate commands are available that wrap Terraform
(mainly to deal with some issues with its &lt;span class="caps"&gt;API&lt;/span&gt; Gateway implementation) to run &lt;code&gt;plan&lt;/code&gt;, &lt;code&gt;apply&lt;/code&gt; and &lt;code&gt;destroy&lt;/code&gt;. There are
also helper commands to view the Lambda Function and &lt;span class="caps"&gt;API&lt;/span&gt; Gateway logs from CloudWatch, view messages in the queue(s) and
&lt;span class="caps"&gt;GET&lt;/span&gt; or &lt;span class="caps"&gt;POST&lt;/span&gt; a test message to one or all of the&amp;nbsp;endpoints.&lt;/p&gt;
&lt;p&gt;Full documentation is available at &lt;a href="http://webhook2lambda2sqs.readthedocs.io/en/latest/"&gt;http://webhook2lambda2sqs.readthedocs.io/en/latest/&lt;/a&gt;
and the package (Python 2.7, 3.3-3.5) can be downloaded &lt;a href="https://pypi.python.org/pypi/webhook2lambda2sqs"&gt;from PyPI&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Sat, 06 Aug 2016 21:38:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2016-08-06:2016/08/tooling-for-aws-webhooks-to-sqs-via-api-gateway-and-lambda/</guid><category>aws</category><category>webhook</category><category>lambda</category><category>github</category><category>api-gateway</category><category>sqs</category><category>queue</category><category>python</category><category>terraform</category></item><item><title>Terraform Shortcomings - No Interpolated Default Values, No Functions, No Conditionals, Local State Storage</title><link>http://blog.jasonantman.com/2016/04/terraform-shortcomings-no-interpolated-default-values-no-functions/</link><description>&lt;p&gt;Lately I&amp;#8217;ve been using HashiCorp&amp;#8217;s &lt;a href="https://www.terraform.io/"&gt;Terraform&lt;/a&gt; a lot to manage infrastructure. It certainly has some big things going for it; it supports a whole bunch of providers (including on-prem, non-cloud stuff like VMWare and Docker) as well as some database engines and &lt;span class="caps"&gt;DNS&lt;/span&gt; providers and can even manage GitHub teams, it can plan changes before committing them (which CloudFormation only &lt;a href="https://aws.amazon.com/blogs/aws/new-change-sets-for-aws-cloudformation/"&gt;very recently&lt;/a&gt; learned), and it can store the current state of your infrastructure in &lt;a href="https://www.consul.io/"&gt;Consul&lt;/a&gt;. Also a big step past CloudFormation, it has &lt;a href="https://www.terraform.io/docs/provisioners/index.html"&gt;provisioners&lt;/a&gt; including local execution, remote execution, file copying and Chef (strangely no built-in support for Puppet, but the remote-exec can do that) that can reach out to your newly-created instances and take actions on&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;Terraform also has a &lt;a href="https://www.terraform.io/docs/providers/template/index.html"&gt;template provider&lt;/a&gt; that&amp;#8217;s used any time you need a templated file, such as &lt;span class="caps"&gt;EC2&lt;/span&gt; instance user-data or dynamically generated scripts to place on hosts. Terraform uses a &lt;span class="caps"&gt;DSL&lt;/span&gt; for its &lt;a href="https://www.terraform.io/docs/configuration/index.html"&gt;configuration&lt;/a&gt;, either the &lt;span class="caps"&gt;JSON&lt;/span&gt;-like but slightly-more-human-readable &lt;a href="https://github.com/hashicorp/hcl"&gt;Hashicorp Configuration Language (&lt;span class="caps"&gt;HCL&lt;/span&gt;)&lt;/a&gt; or the same information conveyed in pure &lt;span class="caps"&gt;JSON&lt;/span&gt;. The configuration language supports variables (passed in at the command line or in a file) and is based on &lt;a href="https://www.terraform.io/docs/configuration/interpolation.html"&gt;string interpolation&lt;/a&gt; with a handful of functions defined. It&amp;#8217;s also worth noting that Terraform is written in Go; it has a &lt;a href="https://www.terraform.io/docs/plugins/index.html"&gt;plugin system&lt;/a&gt; but only for Providers and Provisioners; there&amp;#8217;s no way to add core functionality (I suppose I&amp;#8217;ve been spolied by Puppet having such good support for adding core functionality via Ruby, or HashiCorp&amp;#8217;s Vagrant having a config file that itself is&amp;nbsp;Ruby).&lt;/p&gt;
&lt;p&gt;Now that I&amp;#8217;ve been nice and said some great things about Terraform (and it really is; at least for the way my current job is managing infrastructure, I&amp;#8217;ve fallen in love with it, and it certainly does fix some shortcomings that I found in CloudFormation, specifically with pre-execution plans and ability to interact with resources), on to my complaints of the&amp;nbsp;day.&lt;/p&gt;
&lt;h2 id="local-state-storage"&gt;Local State&amp;nbsp;Storage&lt;/h2&gt;
&lt;p&gt;My first complaint is that by default, Terraform stores the state of your infrastrucutre in a file in your current working directory. It uses this to attempt to figure out the already-existing resources you&amp;#8217;ve created, and only make the required changes. The first time I used terraform, I completely destroyed one of our (luckily non-production) services; coworkers of mine have brought down production services because of&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s say that we have a Terraform configuration which takes one variable, &lt;code&gt;environment&lt;/code&gt;. That variable determines the &lt;span class="caps"&gt;VPC&lt;/span&gt; and subnets we deploy into, our &lt;span class="caps"&gt;DNS&lt;/span&gt; names, and also gets passed to &lt;span class="caps"&gt;EC2&lt;/span&gt; instances via user-data. We build our infrastructure with &lt;code&gt;environment = "prod"&lt;/code&gt;, and everything works right - we now have a production cluster of our service. Then we want to test some changes, so we run again with &lt;code&gt;environment = "dev"&lt;/code&gt;. The naive - and logical - assumption would be that we get a second &amp;#8220;dev&amp;#8221; cluster of our service. Nope. Terraform finds the &lt;code&gt;terraform.tfstate&lt;/code&gt; file in our current directory, reads it, and takes it to be the current state of our infrastructure. It sees that we &lt;strong&gt;changed&lt;/strong&gt; &lt;code&gt;environment&lt;/code&gt; from &amp;#8220;prod&amp;#8221; to &amp;#8220;dev&amp;#8221;&amp;#8230; so it destroys our &lt;span class="caps"&gt;EC2&lt;/span&gt; instances and &lt;span class="caps"&gt;DNS&lt;/span&gt; record, and creates new ones for &amp;#8220;dev&amp;#8221; (applying the requested&amp;nbsp;changes).&lt;/p&gt;
&lt;p&gt;This teaches us two important&amp;nbsp;points:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Always&lt;/strong&gt; run &lt;code&gt;terraform plan&lt;/code&gt;. Even if you think your changes are trivial, examine what Terraform will do before running &lt;code&gt;apply&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Always&lt;/strong&gt; run &lt;code&gt;terraform&lt;/code&gt; through a wrapper. We have a simple Rake task in an internal rubygem that ensures that Terraform will always store state in Consul, so it won&amp;#8217;t be locked to one person&amp;#8217;s local machine, and also removes any local state files before running so they won&amp;#8217;t pollute the run or result in changes intended for one isolated instance of our Terraform configuration from being applied to&amp;nbsp;another.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="functions"&gt;Functions&lt;/h2&gt;
&lt;p&gt;Terraform&amp;#8217;s &lt;a href="https://www.terraform.io/docs/configuration/interpolation.html"&gt;configuration interpolation&lt;/a&gt; has a bunch of built-in functions for working with variables. They&amp;#8217;re a subset of what you&amp;#8217;d expect in a language that is mainly based around strings, arrays and maps/hashes: split, join, concat, lookup (get a hash item by key), index (find the index of an item in a list), element (return the n&amp;#8217;th element of a list), format (sprintf-like), etc. However, there&amp;#8217;s no function to retrieve only unique elements from a list. This becomes a problem especially when dealing with multi-&lt;span class="caps"&gt;AZ&lt;/span&gt;/multi-subnet &lt;span class="caps"&gt;AWS&lt;/span&gt; resources, as some of them (e.g. managing a set number individual &lt;span class="caps"&gt;EC2&lt;/span&gt; instances outside of an &lt;span class="caps"&gt;ASG&lt;/span&gt;, such as when assigning static IPs) require a list of subnets matching the number of resources, and others (cross-&lt;span class="caps"&gt;AZ&lt;/span&gt; ELBs) require a list of unique&amp;nbsp;subnets.&lt;/p&gt;
&lt;p&gt;Terraform and its language have no way to add this functionality (&lt;em&gt;see note below&lt;/em&gt;); the only option that I&amp;#8217;ve found is to wrap Terraform in some sort of runner (I use &lt;a href="https://github.com/ruby/rake"&gt;Rake&lt;/a&gt; but you could use any scripting or Make-like language) that does whatever manipulation and calculation is needed, and passes in the necessary values distinct variable values (i.e. the full subnet list, and the unique subnet list, as separate variables). To make this even more difficult, though Terraform supports loading built-time variables from a &lt;span class="caps"&gt;JSON&lt;/span&gt; or &lt;span class="caps"&gt;HCL&lt;/span&gt; file instead of the command line, it only supports taking in variables as strings (even in &lt;span class="caps"&gt;JSON&lt;/span&gt;). So in our subnet example, our wrapper script needs to join the list of subnets into a string (i.e. &lt;span class="caps"&gt;CSV&lt;/span&gt;) and then whenever we use the variable in Terraform, we need to &lt;code&gt;split()&lt;/code&gt; it on our separator character (because Terraform doesn&amp;#8217;t support variable setting or&amp;nbsp;manipulation).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Terraform [has] no way to add this functionality&amp;#8221;&lt;/em&gt; - I&amp;#8217;m aware that I could fork Terraform, learn Go, and submit pull requests for all of the features I think would be useful; and if I had maybe half a dozen less unfinished projects, I&amp;#8217;d probably do that. However, this still means that HashiCorp would need to accept and merge my PRs and release a new version, or else I&amp;#8217;d need to build and distribute my forked version. Terraform supports &lt;a href="https://www.terraform.io/docs/plugins/index.html"&gt;plugins&lt;/a&gt;, but only for Providers and Provisioners, not language internals. What I&amp;#8217;d really like is a way to define plugin functions that could be distributed without having to rebuild all of&amp;nbsp;Terraform.&lt;/p&gt;
&lt;h2 id="no-interpolated-default-variable-values"&gt;No Interpolated Default Variable&amp;nbsp;Values&lt;/h2&gt;
&lt;p&gt;Terraform variables can have default values defined for them. However, these default values have no way of using other variables. This means that even for relatively common use cases - like a service that has a name and a &lt;span class="caps"&gt;DNS&lt;/span&gt; record, both of which can be overridden but with the &lt;span class="caps"&gt;DNS&lt;/span&gt; record defaulting to &amp;#8220;SERVICE_NAME.example.com&amp;#8221;, you can&amp;#8217;t do that. The only options that I&amp;#8217;ve been able to figure out are to either do it in your wrapper script (which means the Terraform configs can&amp;#8217;t be run without the wrapper) or use the &lt;code&gt;coalesce&lt;/code&gt; function to give your variable an empty default value, and then choose a second interpolated string if the variable is&amp;nbsp;empty.&lt;/p&gt;
&lt;h2 id="no-conditionals"&gt;No&amp;nbsp;Conditionals&lt;/h2&gt;
&lt;p&gt;Terraform&amp;#8217;s configuration language also lacks conditional statements such as &lt;code&gt;if&lt;/code&gt;. This poses a problem with all but the simplest applications, and is certainly likely to be an issue for anyone who wants to do the right thing and use the same tooling to deploy multiple environments. It seems that the only options are to either pass in the necessary information as variables from a wrapper script, or generate Terraform configurations with other tooling. The former works only if the desired result is a variable in your configuration; there&amp;#8217;s simply no way that I&amp;#8217;ve found to have a conditional around resource(s). The only obvious option for that is to take advantage of Terraform&amp;#8217;s ability to read configurations as &lt;span class="caps"&gt;JSON&lt;/span&gt;, and simply generate your entire terraform configuration with another&amp;nbsp;tool.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Tue, 19 Apr 2016 07:40:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2016-04-19:2016/04/terraform-shortcomings-no-interpolated-default-values-no-functions/</guid><category>terraform</category><category>hashicorp</category><category>AWS</category><category>go</category></item></channel></rss>