<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jason Antman's Blog</title><link href="http://blog.jasonantman.com/" rel="alternate"></link><link href="http://blog.jasonantman.com/feeds/categories/tech-howtos.atom.xml" rel="self"></link><id>http://blog.jasonantman.com/</id><updated>2015-03-22T19:36:00-04:00</updated><entry><title>My New-found Love of Trello and a Helpful GreaseMonkey Script</title><link href="http://blog.jasonantman.com/2015/03/my-new-found-love-of-trello-and-a-helpful-greasemonkey-script/" rel="alternate"></link><updated>2015-03-22T19:36:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-03-22:2015/03/my-new-found-love-of-trello-and-a-helpful-greasemonkey-script/</id><summary type="html">&lt;p&gt;When I started at my current job two and a half years ago, we were just really getting into &lt;a href="http://en.wikipedia.org/wiki/Kanban_%28development%29"&gt;Kanban&lt;/a&gt;.
We used a web-based Kanban board (&lt;a href="https://github.com/cmheisel/kardboard"&gt;Kardboard&lt;/a&gt;, written by our director of development at the time), and each team had
their daily stand-up status meetings in the middle of the office in front of a projector screen, with their board filling the entire wall (and remotes on Skype). It took me a while
to get used to it, having always worked in very ticket-and-emergency-driven ops roles. But once it clicked, it was like an epiphany. Suddenly I could see all
of the (non-breakfix or unforeseen) work headed to our team, its priority and due dates, and what everyone (including myself) was working on at a given moment.
Even though work-in-progress (&lt;span class="caps"&gt;WIP&lt;/span&gt;) limits never made it to the ops team, it reduced my stress level amazingly. Instead of dealing with a massive queue of tickets
assigned to me - some of which were such low priority I&amp;#8217;d probably never get around to them - suddenly all I had to concern myself with was my &lt;span class="caps"&gt;WIP&lt;/span&gt; and what was
next up for&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;Over the past year we&amp;#8217;ve had a major (almost complete) changeover of management, and many of the old ways have disappeared. Some might even say that, as a technical
company, we&amp;#8217;ve regressed quite a bit. Either way, we haven&amp;#8217;t been using Kanban for over six months. Our development teams are moving to &lt;a href="http://en.wikipedia.org/wiki/Scrum_%28software_development%29"&gt;Scrum&lt;/a&gt;,
and our more ops-y teams (I&amp;#8217;m now on our Automation and Tooling team, straddling the awkward line between the two) are trying to figure out what&amp;#8217;s right for us.
And I haven&amp;#8217;t been this stressed since I started work here; my team is both busier than ever and understaffed by almost 50%. We stopped using the Kanban board in our
stand-ups, our new manager stopped referring to it, so (even with mostly-working synchronization with Jira) it stopped being useful, and I stopped using it. Without thinking,
I went back to my old &amp;#8220;page showing &lt;em&gt;everything&lt;/em&gt; assigned to me&amp;#8221; view in our ticketing system, and grew increasingly frustrated by managing my &lt;span class="caps"&gt;WIP&lt;/span&gt; and deciding what
needed to be worked&amp;nbsp;next.&lt;/p&gt;
&lt;p&gt;So, after discussing this with the rest of my team, last week two of us came to the same conclusion, independently, on the same day: use &lt;a href="https://trello.com/"&gt;Trello&lt;/a&gt; to
run our own personal Kanban boards. I&amp;#8217;ve been doing so for about a week now, and all I&amp;#8217;m horribly embarrassed that I didn&amp;#8217;t think of this sooner. It&amp;#8217;s absolutely wonderful -
I can keep managing my own work in a Kanban-like form (albeit without formal &lt;span class="caps"&gt;WIP&lt;/span&gt; limits) without needing management endorsement. Sure, it only works for things that I know
are coming and takes some manual curation time, but so far, it&amp;#8217;s been amazingly refreshing and calming. The best part is being able to (once again) visually see
both my &lt;span class="caps"&gt;WIP&lt;/span&gt;, and my recently-complete&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;Someone else on my team mentioned that they use Trello for their personal tasks; I created two more boards, one for my personal development work, and another for my general
around-the-house tasks and to-do&amp;#8217;s (my wife connected with her inner manager once I shared my board with her and she figured out that she could re-order by backlog&amp;#8230;).
It&amp;#8217;s 8 &lt;span class="caps"&gt;PM&lt;/span&gt; on Sunday night, and I can confidently say that I&amp;#8217;ve had one of the most productive weekends in ages. And one of the most relaxing. Instead of spending
lots of time trying to figure out what I have to do this weekend and what the priorities are, I just used the same Kanban method that I loved from work. And it
paid&amp;nbsp;off.&lt;/p&gt;
&lt;h2 id="the-greasemonkey-script"&gt;The GreaseMonkey&amp;nbsp;Script&lt;/h2&gt;
&lt;p&gt;The one thing that initially bothered me about Trello was the time it took to add cards. At work every task I have is in either our ticketing system or
a GitHub Issue. Our previous official tool, &lt;a href="https://github.com/cmheisel/kardboard"&gt;Kardboard&lt;/a&gt;, synchronized with Jira so everything was always
up-to-date and on the right board. At first I was adding cards manually, but I figured there had to be a better way. A quick Google search turned up
a &lt;a href="https://github.com/danlec/Trello-Bookmarklet"&gt;Bookmarklet&lt;/a&gt; by &lt;a href="https://github.com/danlec"&gt;Daniel LeCheminant&lt;/a&gt; of Trello, to add a Trello card for the current
page. It does some really cool stuff, like parsing Jira and GitHub issues and setting the card title nicely for them, as well as some other ticketing
systems. I also found a &lt;a href="https://gist.github.com/aggieben/5811685"&gt;GreaseMonkey script&lt;/a&gt; from &lt;a href="https://github.com/aggieben"&gt;Benjamin Collins&lt;/a&gt; of StackExchange
that adds a link to create Trello cards from StackExchange meta&amp;nbsp;posts.&lt;/p&gt;
&lt;p&gt;So, I took things a bit further and whipped up a GreaseMonkey script, &lt;a href="https://github.com/jantman/userscripts#trellocontextmenu"&gt;TrelloContextMenu&lt;/a&gt;. It
uses Daniel&amp;#8217;s card naming code (plus fixing the GitHub format a bit and adding support for &lt;a href="https://www.reviewboard.org/"&gt;ReviewBoard&lt;/a&gt; code reviews) and
the GreaseMonkey/Trello logic from Benjamin&amp;#8217;s script. Once installed and authenticated with Trello, the script retrieves a list of all of your boards
and cards, and adds an &amp;#8220;Add to Trello&amp;#8221; right-click context menu in Firefox, allowing you to add the current page to any list on any of your&amp;nbsp;boards.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/TrelloContextMenu_large.png"&gt;&lt;img alt="screenshot of TrelloContextMenu context menu popup in Firefox" src="/GFX/TrelloContextMenu_sm.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The script is &lt;a href="https://github.com/jantman/userscripts#trellocontextmenu"&gt;available on GitHub&lt;/a&gt; (the link in the &lt;span class="caps"&gt;README&lt;/span&gt; will go to an installable raw
version of the script), and uses GreaseMonkey&amp;#8217;s versioning capabilities. At the moment I&amp;#8217;ve only tested it with GreaseMonkey in Firefox, and I don&amp;#8217;t
expect it to work elsewhere as it uses a few GreaseMonkey-specific features, such as &lt;code&gt;GM_xmlhttpRequest&lt;/code&gt; and GreaseMoneky&amp;#8217;s browser-wide SQLite
persistent storage (to store your boards and lists, and authentication credentials, until you manually refresh). I&amp;#8217;d be happy to accept pull requests
from anyone who can get it working in other&amp;nbsp;browsers.&lt;/p&gt;</summary><category term="Trello"></category><category term="kanban"></category><category term="tickets"></category><category term="organization"></category><category term="work"></category></entry><entry><title>RSpec Matcher For Hash Item Value</title><link href="http://blog.jasonantman.com/2015/02/rspec-matcher-for-hash-item-value/" rel="alternate"></link><updated>2015-02-21T10:33:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-02-21:2015/02/rspec-matcher-for-hash-item-value/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Well, this is embarassing. &lt;em&gt;After&lt;/em&gt; I posted this, I received a
&lt;a href="http://blog.jasonantman.com/2015/02/rspec-matcher-for-hash-item-value/#comment-1868422853"&gt;comment&lt;/a&gt;
within a few hours from &lt;a href="https://twitter.com/myronmarston"&gt;@myronmarston&lt;/a&gt;. I&amp;#8217;d originally
written this matcher for RSpec2, and then had to convert my project to use
RSpec3. I just blindly converted this matcher over. Myron pointed out that with
RSpec3&amp;#8217;s &lt;a href="http://rspec.info/blog/2014/01/new-in-rspec-3-composable-matchers/"&gt;composable matchers&lt;/a&gt;,
the functionality of this gem is built-in. It can be done as simply&amp;nbsp;as:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="n"&gt;its&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:headers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;should&lt;/span&gt; &lt;span class="kp"&gt;include&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;server&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="sr"&gt;/nginx\/1\./&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;As such, I&amp;#8217;ve yanked them gem and am leaving the code and blog post here just for posterity.&lt;/strong&gt;
This should probably not be&amp;nbsp;used.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve been working on a project to move my &lt;a href="http://linode.com"&gt;Linode&lt;/a&gt; &lt;span class="caps"&gt;VM&lt;/span&gt; to an
Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt; instance; the entire instance is a &amp;#8220;baked&amp;#8221; &lt;span class="caps"&gt;AMI&lt;/span&gt; built by Puppet. Since
I&amp;#8217;d like to be able to rebuild this quickly, I&amp;#8217;m using &lt;a href="http://serverspec.org/"&gt;ServerSpec&lt;/a&gt;
(which I have some non-technical issues with, but that&amp;#8217;s a long story) to run full
integration tests of the whole system - check that packages are installed, services
are running, and even make live &lt;span class="caps"&gt;HTTP&lt;/span&gt; requests agsinst&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;One part of this was making live &lt;span class="caps"&gt;HTTP&lt;/span&gt; requests (from inside ServerSpec / &lt;a href="http://rspec.info/"&gt;rspec&lt;/a&gt;)
and checking &lt;span class="caps"&gt;HTTP&lt;/span&gt; response headers. Unfortunately, RSpec doesn&amp;#8217;t have a nice, clean way to make
assertions about a hash&amp;nbsp;item.&lt;/p&gt;
&lt;p&gt;So, I wrote a little Ruby Gem to do this, &lt;a href="https://github.com/jantman/rspec-matcher-hash-item"&gt;rspec-matcher-hash-item&lt;/a&gt;. At the moment it just
has one matcher, &lt;code&gt;have_hash_item_matching&lt;/code&gt;. This operates on a hash, and takes two arguments,
a key and a regex for the value. It allows me to do simple but useful things&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;  &lt;span class="n"&gt;describe&lt;/span&gt; &lt;span class="n"&gt;http_get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;testapp1.jasonantman.com&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/testapp1234&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="n"&gt;its&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:headers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;should&lt;/span&gt; &lt;span class="n"&gt;have_hash_item_matching&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;server&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sr"&gt;/nginx\/1\./&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(The &lt;code&gt;http_get&lt;/code&gt; serverspec matcher is coming in a future gem and blog&amp;nbsp;post)&lt;/p&gt;
&lt;p&gt;Among other things, it prints diffs on&amp;nbsp;failure:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;  2) privatepuppet::ec2::vhosts::testapp1 Http_get &amp;quot;&amp;quot; headers should include key &amp;#39;server&amp;#39; matching /badvalue/
     On host `54.149.198.147&amp;#39;
     Failure/Error: its(:headers) { should have_hash_item_matching(&amp;#39;server&amp;#39;, /badvalue/) }
       expected that hash[server] would match /badvalue/
       Diff:
       @@ -1,2 +1,6 @@
       -[&amp;quot;server&amp;quot;, /badvalue/]
       +&amp;quot;connection&amp;quot; =&amp;gt; &amp;quot;close&amp;quot;,
       +&amp;quot;content-type&amp;quot; =&amp;gt; &amp;quot;text/plain&amp;quot;,
       +&amp;quot;date&amp;quot; =&amp;gt; &amp;quot;Sat, 21 Feb 2015 16:07:42 GMT&amp;quot;,
       +&amp;quot;server&amp;quot; =&amp;gt; &amp;quot;nginx/1.6.2&amp;quot;,
       +&amp;quot;transfer-encoding&amp;quot; =&amp;gt; &amp;quot;chunked&amp;quot;,
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using the gem is as simple as including it in your &lt;code&gt;Gemfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;gem &amp;quot;rspec-matcher-hash-item&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And adding a line to your &lt;code&gt;spec_helper.rb&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;require &amp;#39;rspec_matcher_hash_item&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that the gem is written for&amp;nbsp;RSpec3.&lt;/p&gt;
&lt;p&gt;This is available at &lt;a href="https://rubygems.org/gems/rspec-matcher-hash-item"&gt;rubygems.org&lt;/a&gt; or from
&lt;a href="https://github.com/jantman/rspec-matcher-hash-item"&gt;GitHub&lt;/a&gt;. See GitHub for the&amp;nbsp;documentation.&lt;/p&gt;</summary><category term="ruby"></category><category term="rspec"></category><category term="spec"></category><category term="testing"></category></entry><entry><title>AWS CloudFormation and RDS Snapshots</title><link href="http://blog.jasonantman.com/2014/12/aws-cloudformation-and-rds-snapshots/" rel="alternate"></link><updated>2014-12-15T09:29:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-12-15:2014/12/aws-cloudformation-and-rds-snapshots/</id><summary type="html">&lt;p&gt;For the past few weeks, I&amp;#8217;ve been working on spinning up a WordPress stack on Amazon &lt;span class="caps"&gt;AWS&lt;/span&gt;. It&amp;#8217;s intended to be a production application,
so it uses Multi-&lt;span class="caps"&gt;AZ&lt;/span&gt; and a few other tricks to try to achieve relatively high fault tolerance (nothing insane, still in one region). It uses
&lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;#8217;s &lt;a href="https://aws.amazon.com/rds/"&gt;&lt;span class="caps"&gt;RDS&lt;/span&gt;&lt;/a&gt; hosted MySQL service for the database, and the stacks are created with &lt;a href="https://aws.amazon.com/cloudformation/"&gt;CloudFormation&lt;/a&gt;.
Using CloudFormation has been an utterly wonderful experience and being able to spin up an entire stack - multiple autoscaling web server
instances, a database, memcache, etc. with the click of a button in ~20 minutes - is as close to operations nirvana as I&amp;#8217;ve ever&amp;nbsp;gotten.&lt;/p&gt;
&lt;p&gt;One of the last steps for me was to work on database backups and restoration; both restoring the production application&amp;#8217;s database to a
previous snapshot, and restoring a production database snapshot to a test or development stack. This took a few days of testing, and I
wasn&amp;#8217;t able to find much complete information on the nuances of it; there are also some pieces that are not intuitive and (&lt;span class="caps"&gt;IMO&lt;/span&gt;) not
documented well enough in the &lt;span class="caps"&gt;AWS&lt;/span&gt; docs. In short, it&amp;#8217;s horribly easy to blow away your entire database. So, I&amp;#8217;m going to attempt to document
some of what I learned, in the hope that it will benefit&amp;nbsp;others.&lt;/p&gt;
&lt;p&gt;At the bottom of this post I&amp;#8217;ve included some snippets from my CloudFormation template, which I make reference to. It&amp;#8217;s probably worth looking
through that, as I make reference to some of the names used in it. Also, to make sense of this, you should be familiar with the nomenclature used by CloudFormation,
such as the &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html"&gt;template anatomy&lt;/a&gt; and the difference between
parameters and properties, and resources and&amp;nbsp;instances.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I&amp;#8217;m writing this in mid-December 2014. I&amp;#8217;ll make every effort to keep this updated as I continue working with &lt;span class="caps"&gt;AWS&lt;/span&gt;, but it&amp;#8217;s possible
that some of the problems described herein will be fixed by &lt;span class="caps"&gt;AWS&lt;/span&gt; in the&amp;nbsp;future.&lt;/p&gt;
&lt;h2 id="deletionpolicy-snapshot"&gt;DeletionPolicy&amp;nbsp;Snapshot&lt;/h2&gt;
&lt;p&gt;CloudFormation resources support a &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html"&gt;DeletionPolicy&lt;/a&gt;
attribute that says what to do to a resource when deleted. For &lt;span class="caps"&gt;RDS&lt;/span&gt; instances, &amp;#8220;Snapshot&amp;#8221; is an option, which takes a manual snapshot when the resource
is deleted (manual snapshots, unlike the automated daily ones, live on even after the instance is deleted). Be warned, this only takes effect when you
delete the &lt;strong&gt;entire stack&lt;/strong&gt;. If you make a change to one of the &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-rds-database-instance.html"&gt;DBInstance properties&lt;/a&gt;
that requires a &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks.html#update-replacement"&gt;resource replacement&lt;/a&gt; to
take effect, the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance will be replaced with a new one, and all of the data and automatic snapshots from the old one will be deleted.
That last part deserves repeating: automatic snapshots (the daily ones created by &lt;span class="caps"&gt;RDS&lt;/span&gt;) are tied to the instance; if the instance is replaced
by CloudFormation, you lose all automatic (backup) snapshots with&amp;nbsp;it.&lt;/p&gt;
&lt;h2 id="stack-policy-to-prevent-updates"&gt;Stack Policy to Prevent&amp;nbsp;Updates&lt;/h2&gt;
&lt;p&gt;To prevent &lt;span class="caps"&gt;RDS&lt;/span&gt; data loss from accidentally changing a property of the instance, it&amp;#8217;s wise to add a
&lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html"&gt;stack policy to prevent updates to &lt;span class="caps"&gt;RDS&lt;/span&gt; resources&lt;/a&gt;.
This will prevent CloudFormation from making any changes to the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance at all. Once the stack policy
is in place, in order to make changes to the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance you would either need to set a temporary stack policy
to allow the update (see the &amp;#8220;Updating Protected Resources&amp;#8221; section of the &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html"&gt;stack policy documentation&lt;/a&gt;)
or simply delete and re-create the stack (the recommended method, if it&amp;#8217;s feasible for&amp;nbsp;you).&lt;/p&gt;
&lt;p&gt;Setting a proper stack policy should prevent many of the pitfalls I describe below; however, for completeness,
I&amp;#8217;ve described how &lt;span class="caps"&gt;RDS&lt;/span&gt; resources behave currently without a stack policy protecting them. The
&lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-rds-database-instance.html"&gt;&lt;span class="caps"&gt;AWS&lt;/span&gt;::&lt;span class="caps"&gt;RDS&lt;/span&gt;::DBInstance resource documentation&lt;/a&gt;
describes which properties can be updated in-place (&amp;#8220;Update requires: No interruption&amp;#8221; or &amp;#8220;some interruptions&amp;#8221;)
and which trigger complete replacement of the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance (&amp;#8220;Update requires:&amp;nbsp;replacement&amp;#8221;).&lt;/p&gt;
&lt;p&gt;When you try to update a protected resource through the &lt;code&gt;aws&lt;/code&gt; &lt;span class="caps"&gt;CLI&lt;/span&gt; tools, the update will appear to have worked, but the event
log on the stack will show the update denied and the update will be rolled&amp;nbsp;back.&lt;/p&gt;
&lt;h2 id="restoring-snapshots-and-dbname"&gt;Restoring Snapshots and&amp;nbsp;DBName&lt;/h2&gt;
&lt;p&gt;The DBSnapshotIdentifier property on a MySQL &lt;span class="caps"&gt;RDS&lt;/span&gt; instance specifies a &lt;span class="caps"&gt;RDS&lt;/span&gt; snapshot to restore into the instance. The DBName
property will create a new &lt;span class="caps"&gt;RDS&lt;/span&gt; instance with a single blank database of that name. This bears repeating again; if the DBName
property ever changes, your &lt;span class="caps"&gt;RDS&lt;/span&gt; instance will be replaced with one with a new, blank database of that name.
When creating a MySQL &lt;span class="caps"&gt;RDS&lt;/span&gt; instance, you can specify either the &lt;code&gt;DBName&lt;/code&gt; or &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; property, but not both;
if you attempt to specify both, you&amp;#8217;ll get an error, &amp;#8220;DBName must be null when Restoring for this&amp;nbsp;Engine.&amp;#8221;&lt;/p&gt;
&lt;p&gt;If you want to restore a snapshot to a new &lt;span class="caps"&gt;RDS&lt;/span&gt; instance, you&amp;#8217;ll need to ensure that &lt;code&gt;DBName&lt;/code&gt; is null (either not specified at all, or the special &lt;code&gt;AWS::NoValue&lt;/code&gt;
&lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/pseudo-parameter-reference.html"&gt;pseudo parameter&lt;/a&gt;). In order
to do this automatically (and since NoValue/null can&amp;#8217;t be passed in as a template parameter), in the template snippet below I&amp;#8217;ve defined a
&lt;code&gt;UseDbSnapshot&lt;/code&gt; &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/conditions-section-structure.html"&gt;condition&lt;/a&gt;
that evaluates to true if the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; parameter is not empty. In my &lt;code&gt;RDS::DBInstance&lt;/code&gt; resource,
I conditionally set (using &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-conditions.html#d0e42982"&gt;&lt;code&gt;Fn::If&lt;/code&gt;&lt;/a&gt;)
the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; and &lt;code&gt;DBName&lt;/code&gt; properties depending on the value of &lt;code&gt;UseDbSnapshot&lt;/code&gt;. The end result is that if the
&lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; parameter is not empty, it is passed in as the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; property of the resource and
the &lt;code&gt;DBName&lt;/code&gt; property is set to &lt;code&gt;AWS::NoValue&lt;/code&gt;. Otherwise, the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; property is set to &lt;code&gt;AWS::NoValue&lt;/code&gt;
and the &lt;code&gt;DBName&lt;/code&gt; parameter is passed in to the corresponding property on the resource (indicating to create a new blank database
of that&amp;nbsp;name).&lt;/p&gt;
&lt;p&gt;To explain this a bit more, CloudFormation seems to have no introspection into &lt;span class="caps"&gt;RDS&lt;/span&gt; instances. The &lt;code&gt;DBName&lt;/code&gt; parameter
exists only in CloudFormation itself, and is only evaluated as a diff from the previous template; if it changes,
CloudFormation spins up a completely new &lt;span class="caps"&gt;RDS&lt;/span&gt; instance with a single blank database of that name. Whether or not
the value of &lt;code&gt;DBName&lt;/code&gt; matches the database currently in the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance (say, restored from a snapshot)
is not known by CloudFormation. In short, if you create an &lt;span class="caps"&gt;RDS&lt;/span&gt; instance from a snapshot of a &amp;#8220;foo&amp;#8221; database
and then change the template to have a &lt;code&gt;DBName&lt;/code&gt; of &amp;#8220;foo&amp;#8221;, CloudFormation will spin up a new &lt;span class="caps"&gt;RDS&lt;/span&gt; instance
with an empty &amp;#8220;foo&amp;#8221;&amp;nbsp;database.&lt;/p&gt;
&lt;h2 id="restoring-to-a-new-stack"&gt;Restoring to a New&amp;nbsp;Stack&lt;/h2&gt;
&lt;p&gt;When restoring to a new stack (stack creation), specify the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; and make sure &lt;code&gt;DBName&lt;/code&gt; is set
to &lt;code&gt;AWS::NoValue&lt;/code&gt; per the previous paragraph (condition in the template). Note that for the life of the stack, you
must continue specifying these parameters (or the &amp;#8220;use previous value&amp;#8221; option for them). Using my example template
below, if you restored into a new stack using the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; parameter and then later updated the stack
and omitted that parameter (which, because of the condition, would set it to &lt;code&gt;NoValue&lt;/code&gt; and set the &lt;code&gt;DBName&lt;/code&gt; parameter
to its default value) the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance would be replaced with a new one with a blank&amp;nbsp;database.&lt;/p&gt;
&lt;p&gt;Because of this, stack updates should always use the previous value for the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; parameter; this can
be done through the &lt;span class="caps"&gt;AWS&lt;/span&gt; Console, or using the &lt;code&gt;aws&lt;/code&gt; command line tools and a parameter like: &lt;code&gt;--parameters ParameterKey=DBSnapshotIdentifier,UsePreviousValue=true&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="restoring-to-an-existing-stack"&gt;Restoring to an Existing&amp;nbsp;Stack&lt;/h2&gt;
&lt;p&gt;Restoring a snapshot to an existing stack is a bit more nuanced. You can&amp;#8217;t restore a snapshot to an existing &lt;span class="caps"&gt;RDS&lt;/span&gt; instance,
you can only restore to a new instance. If you do this through the &lt;span class="caps"&gt;AWS&lt;/span&gt; Console, you&amp;#8217;ll end up with an &lt;span class="caps"&gt;RDS&lt;/span&gt; instance disconnected
from your CloudFormation stack. So the way to do this is more or less the same as restoring to a new stack - specify
the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; parameter for your template, and it will create a new &lt;span class="caps"&gt;RDS&lt;/span&gt; instance with the snapshot. The same
rules about using previous values for the parameters hold true. If you used a stack policy to prevent updates to the &lt;span class="caps"&gt;RDS&lt;/span&gt;
instance, you&amp;#8217;ll need to override that with a temporary policy when doing the&amp;nbsp;restore.&lt;/p&gt;
&lt;p&gt;There are a few caveats to keep in mind with this procedure. The first, obviously, is that there may be some application downtime
when the existing database is replaced with the new (restored) one, and any writes will obviously be lost. Also, this only
works on &lt;span class="caps"&gt;RDS&lt;/span&gt; instances that were created with DBName or a &lt;strong&gt;different&lt;/strong&gt; snapshot. In order to restore the same snapshot to
an &lt;span class="caps"&gt;RDS&lt;/span&gt; resource a second time, you need to first update with the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; parameter removed and have the &lt;span class="caps"&gt;RDS&lt;/span&gt;
instance re-created with an empty database, and then update again with the &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt; in order to do the restore.
This is because CloudFormation doesn&amp;#8217;t reconcile the current state of instances to determine which actions to take, it only diffs
the updated template against the existing one. If the existing template and the updated one have the same value for the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance&amp;#8217;s
properties (specifically &lt;code&gt;DBSnapshotIdentifier&lt;/code&gt;), CloudFormation determines there are no changes, and does&amp;nbsp;nothing.&lt;/p&gt;
&lt;h2 id="launchconfig-metadata-issues"&gt;LaunchConfig Metadata&amp;nbsp;Issues&lt;/h2&gt;
&lt;p&gt;The &lt;span class="caps"&gt;EC2&lt;/span&gt; instances I&amp;#8217;m using for this project are &amp;#8220;baked&amp;#8221; AMIs (built with &lt;a href="https://packer.io/"&gt;packer.io&lt;/a&gt;) in an Auto-Scaling Group (&lt;span class="caps"&gt;ASG&lt;/span&gt;).
They use a &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-launchconfig.html"&gt;LaunchConfig&lt;/a&gt; to write
out a file on disk with the database connection information for the application. In addition, my &lt;span class="caps"&gt;ASG&lt;/span&gt; has an &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatepolicy.html"&gt;UpdatePolicy&lt;/a&gt;
designed to perform rolling updates (termination and replacement) of &lt;span class="caps"&gt;EC2&lt;/span&gt; instances when their properties&amp;nbsp;change.&lt;/p&gt;
&lt;p&gt;In my testing, I noticed a number of times where updates to the &lt;span class="caps"&gt;RDS&lt;/span&gt; resource that triggered creation of a new &lt;span class="caps"&gt;RDS&lt;/span&gt; instance - such as restoring from
a snapshot in an existing stack, or changing the DBName - properly triggered an update of the LaunchConfig, but failed to trigger
the rolling update of the &lt;span class="caps"&gt;EC2&lt;/span&gt; instances. This left the application in a state where one or more (sometimes all) of the &lt;span class="caps"&gt;EC2&lt;/span&gt;
instances couldn&amp;#8217;t connect to the database, because the file written out by the LaunchConfig still contained the old &lt;span class="caps"&gt;DB&lt;/span&gt; connection
information. For non-production stacks where the entire stack can be deleted and recreated instead of updating the &lt;span class="caps"&gt;RDS&lt;/span&gt; resource,
this shouldn&amp;#8217;t be an issue. Otherwise, if changes are made that replace the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance, I&amp;#8217;d recommend watching for the
LaunchConfig update completion, and manually terminating instances (or increasing the size of the &lt;span class="caps"&gt;ASG&lt;/span&gt; to add instances)
to ensure that the running &lt;span class="caps"&gt;EC2&lt;/span&gt; instances have the updated&amp;nbsp;LaunchConfig.&lt;/p&gt;
&lt;p&gt;Another option would be to use the &lt;a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-hup.html"&gt;cfn-hup daemon&lt;/a&gt; to
listen for stack updates that cause changes in resource metadata, and perform the required actions without needing the rolling update
to replace the&amp;nbsp;instances.&lt;/p&gt;
&lt;h2 id="how-to-do-things-using-the-template-below"&gt;How to Do Things Using the Template&amp;nbsp;Below&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m currently using the &lt;code&gt;aws&lt;/code&gt; command line tools to perform stack creation and updates,
wrapped in a Rakefile (I plan on changing this to use &lt;a href="https://github.com/boto/boto"&gt;boto&lt;/a&gt;
inside a &lt;a href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; job). What follows is a quick high-level guide
on how to accomplish various &lt;span class="caps"&gt;RDS&lt;/span&gt;-related tasks, using the template snippet&amp;nbsp;below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Build a new stack using a &lt;span class="caps"&gt;RDS&lt;/span&gt; snapshot and a stack policy to prevent updates&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;cat /tmp/stack_policy.json
&lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="s2"&gt;&amp;quot;Statement&amp;quot;&lt;/span&gt; : &lt;span class="o"&gt;[&lt;/span&gt;
    &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="s2"&gt;&amp;quot;Effect&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;Deny&amp;quot;&lt;/span&gt;,
      &lt;span class="s2"&gt;&amp;quot;Action&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;Update:*&amp;quot;&lt;/span&gt;,
      &lt;span class="s2"&gt;&amp;quot;Principal&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt;,
      &lt;span class="s2"&gt;&amp;quot;Resource&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;LogicalResourceId/DBInstance&amp;quot;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;,
    &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="s2"&gt;&amp;quot;Effect&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;Allow&amp;quot;&lt;/span&gt;,
      &lt;span class="s2"&gt;&amp;quot;Action&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;Update:*&amp;quot;&lt;/span&gt;,
      &lt;span class="s2"&gt;&amp;quot;Principal&amp;quot;&lt;/span&gt;: &lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt;,
      &lt;span class="s2"&gt;&amp;quot;Resource&amp;quot;&lt;/span&gt; : &lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
  &lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;aws cloudformation create-stack --stack-name mystack --stack-policy-body file:///tmp/stack_policy.json --template-body file:///home/myuser/cloudformation_template.json --parameters &lt;span class="nv"&gt;ParameterKey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;DBSnapshotIdentifier,ParameterValue&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;my-snapshot-identifier&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Temporarily override stack policy to allow updates&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a file with the following contents (we&amp;#8217;ll assume it&amp;#8217;s at &lt;code&gt;/home/myuser/allow_all_updates.json&lt;/code&gt;):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;Statement&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Effect&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Allow&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Action&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Update:*&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Principal&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Resource&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the following &lt;code&gt;aws&lt;/code&gt; commands, append &lt;code&gt;--stack-policy-during-update-body file:///home/myuser/allow_all_updates.json&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Update a stack (built using a &lt;span class="caps"&gt;RDS&lt;/span&gt; snapshot), without losing data&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;aws cloudformation update-stack --stack-name mystack --template-body file:///home/myuser/cloudformation_template.json --parameters &lt;span class="nv"&gt;ParameterKey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;DBSnapshotIdentifier,UsePreviousValue&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Load a &lt;span class="caps"&gt;RDS&lt;/span&gt; snapshot into an existing stack&lt;/strong&gt; (that isn&amp;#8217;t already using this&amp;nbsp;snapshot):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;aws cloudformation update-stack --stack-name mystack --template-body file:///home/myuser/cloudformation_template.json --parameters &lt;span class="nv"&gt;ParameterKey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;DBSnapshotIdentifier,ParameterValue&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;my-snapshot-identifier&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Load a &lt;span class="caps"&gt;RDS&lt;/span&gt; snapshot into an existing stack again&lt;/strong&gt; (i.e. restore from the same snapshot a second time; this one is a&amp;nbsp;kludge):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="c"&gt;# re-create the &lt;span class="caps"&gt;RDS&lt;/span&gt; instance with a blank &lt;span class="caps"&gt;DB&lt;/span&gt; (DBName)&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;aws cloudformation update-stack --stack-name mystack --template-body file:///home/myuser/cloudformation_template.json --parameters &lt;span class="nv"&gt;ParameterKey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;DBSnapshotIdentifier,ParameterValue&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="c"&gt;# then load the snapshot again&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;aws cloudformation update-stack --stack-name mystack --template-body file:///home/myuser/cloudformation_template.json --parameters &lt;span class="nv"&gt;ParameterKey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;DBSnapshotIdentifier,ParameterValue&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;my-snapshot-identifier&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cloudformation-template-snippet"&gt;CloudFormation Template&amp;nbsp;Snippet&lt;/h2&gt;
&lt;p&gt;This is by no means complete, but just includes the parameters, conditions, and resources which I make reference&amp;nbsp;to.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;Parameters&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;DBName&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Default&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;wordpress&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Description&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;The WordPress database name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;String&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;MinLength&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;MaxLength&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;64&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;AllowedPattern&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[a-zA-Z][a-zA-Z0-9]*&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;ConstraintDescription&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;must begin with a letter and contain only alphanumeric characters.&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;DBSnapshotIdentifier&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Description&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; The &lt;span class="caps"&gt;RDS&lt;/span&gt; MySQL snapshot name to restore to the new &lt;span class="caps"&gt;DB&lt;/span&gt; instance.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;String&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Default&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;quot;Conditions&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;UseDbSnapshot&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Fn::Not&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;Fn::Equals&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBSnapshotIdentifier&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
          &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="p"&gt;]&lt;/span&gt;
      &lt;span class="p"&gt;}]&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;

  &lt;span class="nt"&gt;&amp;quot;Resources&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;DBInstance&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;AWS&lt;/span&gt;::&lt;span class="caps"&gt;RDS&lt;/span&gt;::DBInstance&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Properties&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;DBName&amp;quot;&lt;/span&gt;            &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;Fn::If&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;UseDbSnapshot&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;AWS&lt;/span&gt;::NoValue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBName&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
          &lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="p"&gt;},&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;Engine&amp;quot;&lt;/span&gt;            &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;MySQL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;MasterUsername&amp;quot;&lt;/span&gt;    &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBUsername&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;DBInstanceClass&amp;quot;&lt;/span&gt;   &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBClass&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;DBSecurityGroups&amp;quot;&lt;/span&gt;  &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBSecurityGroup&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;}],&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;DBSubnetGroupName&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBSubnetGroup&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;AllocatedStorage&amp;quot;&lt;/span&gt;  &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBAllocatedStorage&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;MasterUserPassword&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBPassword&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;DBSnapshotIdentifier&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;Fn::If&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;UseDbSnapshot&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBSnapshotIdentifier&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;AWS&lt;/span&gt;::NoValue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
          &lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="p"&gt;},&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;MultiAZ&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
      &lt;span class="p"&gt;},&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;DeletionPolicy&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Snapshot&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;WebServerGroup&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Type&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;AWS&lt;/span&gt;::AutoScaling::AutoScalingGroup&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Properties&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;LaunchConfigurationName&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;LaunchConfig&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt;
      &lt;span class="p"&gt;},&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;UpdatePolicy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;AutoScalingRollingUpdate&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;MinInstancesInService&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;MaxBatchSize&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;WaitOnResourceSignals&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;true&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;PauseTime&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;PT10M&lt;/span&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="p"&gt;},&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;AutoScalingScheduledAction&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;IgnoreUnmodifiedGroupSizeProperties&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="p"&gt;},&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;CreationPolicy&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;ResourceSignal&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;Timeout&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;PT10M&lt;/span&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;Count&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;2&amp;quot;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;LaunchConfig&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Type&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;AWS&lt;/span&gt;::AutoScaling::LaunchConfiguration&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nt"&gt;&amp;quot;Metadata&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;&lt;span class="caps"&gt;AWS&lt;/span&gt;::CloudFormation::Init&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
          &lt;span class="nt"&gt;&amp;quot;config&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;quot;files&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
              &lt;span class="nt"&gt;&amp;quot;/opt/wordpress/cloudformation_db.php&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;quot;content&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nt"&gt;&amp;quot;Fn::Join&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
                  &lt;span class="s2"&gt;&amp;quot;&amp;lt;?php\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="s2"&gt;&amp;quot;define(&amp;#39;DB_NAME&amp;#39;,          &amp;#39;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBName&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;#39;);\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="s2"&gt;&amp;quot;define(&amp;#39;DB_USER&amp;#39;,          &amp;#39;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBUsername&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;#39;);\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="s2"&gt;&amp;quot;define(&amp;#39;DB_PASSWORD&amp;#39;,      &amp;#39;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;Ref&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DBPassword&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;#39;);\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="s2"&gt;&amp;quot;define(&amp;#39;DB_HOST&amp;#39;,          &amp;#39;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;Fn::GetAtt&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;DBInstance&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Endpoint.Address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;#39;);\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="p"&gt;},&lt;/span&gt;
              &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
          &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="aws"></category><category term="cloudformation"></category><category term="rds"></category><category term="mysql"></category><category term="snapshot"></category></entry><entry><title>Watching Jenkins Jobs and CloudFormation Updates with Pushover Notification</title><link href="http://blog.jasonantman.com/2014/12/watching-jenkins-jobs-and-cloudformation-updates-with-pushover-notification/" rel="alternate"></link><updated>2014-12-14T19:22:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-12-14:2014/12/watching-jenkins-jobs-and-cloudformation-updates-with-pushover-notification/</id><summary type="html">&lt;p&gt;A few months ago I &lt;a href="http://blog.jasonantman.com/2014/09/pushover-notifications-for-shell-command-completion-and-status/"&gt;posted&lt;/a&gt;
about a script I wrote to send &lt;a href="https://pushover.net/"&gt;Pushover&lt;/a&gt; notifications for shell command&amp;nbsp;completion.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve been doing quite a bit of work lately both with testing some &lt;a href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; jobs, and spinning up
&lt;span class="caps"&gt;AWS&lt;/span&gt; stacks using &lt;a href="https://aws.amazon.com/cloudformation/"&gt;CloudFormation&lt;/a&gt;. Last week I wrote two python scripts to aid in&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/jantman/misc-scripts/blob/master/watch_cloudformation.py"&gt;watch_cloudformation.py&lt;/a&gt; uses the popular &lt;a href="https://github.com/boto/boto"&gt;boto&lt;/a&gt;
Python &lt;span class="caps"&gt;AWS&lt;/span&gt; interface to list (and display) the events on a specified CloudFormation stack, and exit 0 or 1 when it finds a (&lt;span class="caps"&gt;CREATE&lt;/span&gt;|&lt;span class="caps"&gt;UPDATE&lt;/span&gt;)_(&lt;span class="caps"&gt;FAILED&lt;/span&gt;|&lt;span class="caps"&gt;COMPLETE&lt;/span&gt;) event.
It also optionally uses &lt;a href="https://pypi.python.org/pypi/python-pushover"&gt;python-pushover&lt;/a&gt; to send the notification to your devices via&amp;nbsp;Pushover.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/jantman/misc-scripts/blob/master/watch_jenkins.py"&gt;watch_jenkins.py&lt;/a&gt; takes the &lt;span class="caps"&gt;URL&lt;/span&gt; to a Jenkins job or build, and uses
&lt;a href="https://pypi.python.org/pypi/python-jenkins"&gt;python-jenkins&lt;/a&gt; to poll the status of the build (or the latest build, if given a Job url)
and display the result when the build finishes, also optionally using python-pushover to send notifications to your&amp;nbsp;device.&lt;/p&gt;
&lt;p&gt;They&amp;#8217;re really quick-and-dirty scripts and might not be suitable for everyone&amp;#8217;s use case, but I took the time to write them,
so hopefully they&amp;#8217;ll be useful to someone&amp;nbsp;else.&lt;/p&gt;</summary><category term="script"></category><category term="pushover"></category><category term="jenkins"></category><category term="hudson"></category><category term="aws"></category><category term="cloudformation"></category></entry><entry><title>Managing EC2 SSH Keys - An Idea</title><link href="http://blog.jasonantman.com/2014/10/managing-ec2-ssh-keys-an-idea/" rel="alternate"></link><updated>2014-10-04T11:59:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-10-04:2014/10/managing-ec2-ssh-keys-an-idea/</id><summary type="html">&lt;p&gt;At work, we have a bunch of &lt;span class="caps"&gt;EC2&lt;/span&gt; instances (currently hundreds, and growing quickly). We also have a bunch
(probably now around 100, counting contractors) of users. Some users - mainly engineers - need &lt;span class="caps"&gt;SSH&lt;/span&gt; access to all
of the &lt;span class="caps"&gt;EC2&lt;/span&gt; instances; many others only need access to their team&amp;#8217;s instances. While I usually advocate sanity checks
and training over access control for employees, many teams have expressed legitimate concern that they don&amp;#8217;t want
others on their instances; commands that are safe to run in dev/test (like loading test data) might be disastrous
on production instances. So, as part of our automation and tooling team, I&amp;#8217;ve been trying to come up with a way to manage
access to all these instances. Right now we have a single &amp;#8220;bastion&amp;#8221; (a.k.a. jump box / ssh gateway / keyhole) instance, with a single
shared used keyed to access every &lt;span class="caps"&gt;EC2&lt;/span&gt; instance; that doesn&amp;#8217;t scale and doesn&amp;#8217;t meet the security&amp;nbsp;requirements.&lt;/p&gt;
&lt;p&gt;What follows is one theory of mine on how to solve this problem. I&amp;#8217;ve been thinking about this for the past
day; this might not be the Right answer, and it&amp;#8217;s just a theory at this point, but I think it&amp;nbsp;works.&lt;/p&gt;
&lt;h1 id="requirements-and-assumptions"&gt;Requirements and&amp;nbsp;Assumptions&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;We have Active Directory as the one source of authentication/authorization truth, but it&amp;#8217;s only in the corporate
  network. For various reasons both technical and political, accessing it from &lt;span class="caps"&gt;AWS&lt;/span&gt; (whether directly, over &lt;span class="caps"&gt;VPN&lt;/span&gt;,
  via replication, or via data feeds to a separate &lt;span class="caps"&gt;LDAP&lt;/span&gt; infrastructure in &lt;span class="caps"&gt;EC2&lt;/span&gt;) is simply not&amp;nbsp;possible.&lt;/li&gt;
&lt;li&gt;We want to control &lt;span class="caps"&gt;SSH&lt;/span&gt; access to a bunch of instances. Some of them are persistent and some are ephemeral. Some
  are pre-baked AMIs in auto-scaling groups, with &lt;em&gt;no&lt;/em&gt; changes made outside the &lt;span class="caps"&gt;AMI&lt;/span&gt;. Some of them are persistent
  or semi-persistent instances that run Puppet every 30 minutes. Some of them are somewhat special, and can&amp;#8217;t be
  trivially torn&amp;nbsp;down.&lt;/li&gt;
&lt;li&gt;Most of our instances are in a &lt;span class="caps"&gt;VPC&lt;/span&gt;, and have proper security controls which include &lt;span class="caps"&gt;SSH&lt;/span&gt; access from only a specifically
  white-listed range of IPs. However, some instances are in &amp;#8220;&lt;span class="caps"&gt;EC2&lt;/span&gt; Classic&amp;#8221; and have &lt;span class="caps"&gt;SSH&lt;/span&gt; open to the world. We want a
  solution that also protects these&amp;nbsp;instances.&lt;/li&gt;
&lt;li&gt;We&amp;#8217;re mainly concerned with securing access from (a) users inadvertently accessing an instance they shouldn&amp;#8217;t be
  on, (b) outside/untrusted parties, and (c) former employees. We trust our employees within reason, and accept that,
  within our security stance, if an employee &lt;em&gt;really&lt;/em&gt; wants privilege escalation, they&amp;#8217;re going to get it. We&amp;#8217;re not
  overly concerned with protecting against determined, malicious users who already have some access but want&amp;nbsp;more.&lt;/li&gt;
&lt;li&gt;Our current process for security cleanup for former employees is largely based on corporate &lt;span class="caps"&gt;IT&lt;/span&gt; (or is it &lt;span class="caps"&gt;HR&lt;/span&gt;?) turning
  off their &lt;span class="caps"&gt;AD&lt;/span&gt; account. We want to minimize additional steps that need to be completed when someone has access&amp;nbsp;revoked.&lt;/li&gt;
&lt;li&gt;Any solution that we choose needs to be usable with self-service &lt;span class="caps"&gt;AWS&lt;/span&gt;; i.e. any user can spin up their own instances
  or stacks, provided that they use an &lt;span class="caps"&gt;AMI&lt;/span&gt; that is either built by our automation team, or follows guidelines on what
  must be included in all&amp;nbsp;AMIs.&lt;/li&gt;
&lt;li&gt;We have some administrative accounts (Jenkins, as well as some shared privileged accounts on select machines) that need
  unrestricted access to&amp;nbsp;everything.&lt;/li&gt;
&lt;li&gt;Local user accounts aren&amp;#8217;t an option. This would mean running Puppet constantly on every image and/or rebuilding
  every image each time we gain or lose an employee. That would be especially difficult when we occasionally have
  project-based&amp;nbsp;contractors.&lt;/li&gt;
&lt;li&gt;We&amp;#8217;re &lt;span class="caps"&gt;OK&lt;/span&gt; with having a bastion/keyhole server in &lt;span class="caps"&gt;AWS&lt;/span&gt;, we just don&amp;#8217;t want everyone to be able to access&amp;nbsp;everything.&lt;/li&gt;
&lt;li&gt;Our intended network security stance is to have bastion/keyhole servers in &lt;span class="caps"&gt;AWS&lt;/span&gt; (ideally one per &lt;span class="caps"&gt;AZ&lt;/span&gt;), which are only
  reachable via &lt;span class="caps"&gt;SSH&lt;/span&gt; from selected public addresses on our corporate network (which can only be reached by current
  employees with valid, working access). All other instances should only allow &lt;span class="caps"&gt;SSH&lt;/span&gt; from these selected&amp;nbsp;hosts.&lt;/li&gt;
&lt;li&gt;Despite the above, we don&amp;#8217;t want to rely on an instance being properly configured as our only security measure;
  if an instance is incorrectly configured to accept &lt;span class="caps"&gt;SSH&lt;/span&gt; from 0.0.0.0/0, we still want to prevent users whose
  access has been revoked from logging in to the&amp;nbsp;instance.&lt;/li&gt;
&lt;li&gt;We don&amp;#8217;t need access to be granted and revoked immediately. We&amp;#8217;ll assume that in normal operating conditions,
  thirty (30) minutes is a reasonable amount of time to either grant or revoke a user&amp;#8217;s&amp;nbsp;access.&lt;/li&gt;
&lt;li&gt;We want to minimize reliance on our existing corporate infrastructure, so that &lt;span class="caps"&gt;AWS&lt;/span&gt; can be used for business
  continuity&amp;nbsp;purposes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="main-goals"&gt;Main&amp;nbsp;Goals&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Provide users with &lt;span class="caps"&gt;SSH&lt;/span&gt; access to &lt;span class="caps"&gt;EC2&lt;/span&gt; servers; privilege should be able to be granted to a subset of users and/or groups
  for each &amp;#8220;application&amp;#8221;. Users should not be able to access other&amp;nbsp;instances.&lt;/li&gt;
&lt;li&gt;Allow a fixed list of users access to every&amp;nbsp;instance.&lt;/li&gt;
&lt;li&gt;Be able to revoke a user&amp;#8217;s access without rebuilding instances or ssh-in-a-loop&amp;#8217;ing to all of&amp;nbsp;them.&lt;/li&gt;
&lt;li&gt;Many instances are not going to be running Puppet after initial provisioning/&lt;span class="caps"&gt;AMI&lt;/span&gt; creation, so as much as we love Puppet,
  it&amp;#8217;s not an option to solve this&amp;nbsp;problem.&lt;/li&gt;
&lt;li&gt;This should involve a minimum of administrative overhead when a user leaves the&amp;nbsp;company.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="proposed-solution"&gt;Proposed&amp;nbsp;Solution&lt;/h1&gt;
&lt;p&gt;My solution relies on &lt;span class="caps"&gt;SSH&lt;/span&gt; agent forwarding and the &lt;code&gt;AuthorizedKeysCommand&lt;/code&gt; introduced in OpenSSH 6.2 (see &amp;#8220;Limitations&amp;#8221;, below, for more information),
most likely inspired by (or maybe literally the same code)
as the patch formerly used by GitHub. This allows sshd to execute an arbitrary command, passing it the login username, which returns output identical to what would
be in the &lt;code&gt;authorized_keys&lt;/code&gt; file. If none of the keys successfully authenticate the user, authentication continues using the usual &lt;code&gt;AuthorizedKeysFile&lt;/code&gt;. We take
advantage of this feature, in addition to &lt;span class="caps"&gt;SSH&lt;/span&gt; agent forwarding, to provide our granular access control. Public keys are pulled from a central location &lt;em&gt;at login time&lt;/em&gt;
(and cached for a set amount of time); each user has control over their own public keys, and a central process builds sets of public keys authorized to access a given
group of&amp;nbsp;instances.&lt;/p&gt;
&lt;h2 id="infrastructure"&gt;Infrastructure&lt;/h2&gt;
&lt;p&gt;Each &lt;span class="caps"&gt;EC2&lt;/span&gt; instance will be a member of an Access Group, which is a unique identifier for the set of users authorized to access instances
in the group. In implementation, Access Groups will likely just be a tag on &lt;span class="caps"&gt;EC2&lt;/span&gt; instances that maps to a set of predefined values
(see below for&amp;nbsp;more).&lt;/p&gt;
&lt;p&gt;We will have a number of &amp;#8220;bastion&amp;#8221; (keyhole/jump box/&lt;span class="caps"&gt;SSH&lt;/span&gt; gateway) hosts, ideally one in each Availability Zone where we have instances.
These bastion hosts will only be reachable from within our corporate network (or our &lt;span class="caps"&gt;VPN&lt;/span&gt;); therefore, users must have
current access to our corporate network (where we can rely on Active Directory and other systems to handle authorization) in order to
gain access to &lt;span class="caps"&gt;AWS&lt;/span&gt;. All other &lt;span class="caps"&gt;EC2&lt;/span&gt; instances will only be reachable over &lt;span class="caps"&gt;SSH&lt;/span&gt; from one of these bastion hosts. The bastion hosts themselves
will not have &lt;span class="caps"&gt;SSH&lt;/span&gt; keys to access other instances; they will, however, have &lt;span class="caps"&gt;SSH&lt;/span&gt; agent forwarding&amp;nbsp;enabled.&lt;/p&gt;
&lt;p&gt;Users reach &lt;span class="caps"&gt;AWS&lt;/span&gt; instances by SSHing from a host attached to our corporate network (including &lt;span class="caps"&gt;VPN&lt;/span&gt; hosts) to a bastion host in &lt;span class="caps"&gt;EC2&lt;/span&gt;. From there,
they &lt;span class="caps"&gt;SSH&lt;/span&gt; to the destination instance, making use of &lt;span class="caps"&gt;SSH&lt;/span&gt; agent forwarding to use their local key to authenticate to the instance. We get both
a restricted entry point to &lt;span class="caps"&gt;AWS&lt;/span&gt; (the bastion host, which can enforce further security and logging methods) and the ability to authenticate users
using their own personal public keys on the destination&amp;nbsp;instances.&lt;/p&gt;
&lt;p&gt;To make it easier for end-users, we could develop a wrapper script like &lt;a href="https://pypi.python.org/pypi/ec2-ssh"&gt;Instagram&amp;#8217;s ec2-ssh&lt;/a&gt; that
checks for a valid, running ssh agent with keys in it, and then crafts the correct &lt;span class="caps"&gt;SSH&lt;/span&gt; command to land the user on the desired end
host - i.e. something like &lt;code&gt;ec2ssh instance_id&lt;/code&gt; would generate and execute a command like &lt;code&gt;ssh -At bastion_hostname 'ssh instance_ip'&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="on-the-servers-instances"&gt;On the Servers&amp;nbsp;(Instances)&lt;/h2&gt;
&lt;p&gt;Each instance, when initially built/provisioned, is given a &lt;code&gt;get_authorized_keys&lt;/code&gt; script, which is configured to be run by sshd as the
&lt;code&gt;AuthorizedKeysCommand&lt;/code&gt;. This script uses one of the following three public key distribution services to retrieve the authorized public keys
for that instance, which are then echoed on &lt;span class="caps"&gt;STDOUT&lt;/span&gt; and used to authenticate the user. For the sake of simplicity, we&amp;#8217;ll assume (which is
currently the case in our infrastructure) that this script will only run for a single non-root user that is used for logins; it will exit
without returning any output for any other users on the system, effectively preventing logins to&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;The script will first check for authorized keys cached locally (either on disk or in memory, to be determined). If they&amp;#8217;re found and less
than some age threshold (we&amp;#8217;ll say five minutes), the cached version is returned. This is intended to both reduce latency when performing
multiple sequential logins, and to allow logins to continue functioning through short periods of degraded network connectivity. If no recent
keys are found cached on disk, the script will retrieve them from the configured public key distribution service. If the service does not
return an appropriate response within an acceptable time limit, or is unreachable, the script will exit with no output. This will prevent
logins from users authorized with this method, but will fall through to the standard &lt;code&gt;AuthorizedKeysFile&lt;/code&gt; method. A number of permanent
authorized public keys will be included in each instance, to allow emergency administrative access in the event that the key distribution
service&amp;nbsp;fails.&lt;/p&gt;
&lt;p&gt;If we&amp;#8217;re willing to assume that the instances themselves are trusted (which I think is a valid assumption), the key retrieval script on
each instance will determine the Access Group that the instance belongs to, and then request the authorized keys for that Access Group.
Determination of Access Group will likely be made via user data passed into the instance at provisioning time, or via retrieval of a
tag value for the&amp;nbsp;instance.&lt;/p&gt;
&lt;p&gt;If assuming trust locally on the instance is not sufficient, then the burden of identifying the instance&amp;#8217;s access group is shifted
to the key distribution service (likely by identifying the &lt;span class="caps"&gt;IP&lt;/span&gt; address of the requesting instance, and then using the &lt;span class="caps"&gt;EC2&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; to
determine which group that instance belongs to). With this solution, only the second alternative key distribution service is&amp;nbsp;feasible.&lt;/p&gt;
&lt;p&gt;If a shorter delay to authorization changes is needed, it would be feasible for instances to also run a separate process
(cronjob, daemon, etc.) that polls the key distribution service at a regular interval to check for updates (i.e.
&lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;HEAD&lt;/span&gt;, something &lt;span class="caps"&gt;SQS&lt;/span&gt;-based, etc.) and updates the local cache when they&amp;nbsp;occur.&lt;/p&gt;
&lt;h1 id="public-key-distribution-service"&gt;Public Key Distribution&amp;nbsp;Service&lt;/h1&gt;
&lt;p&gt;Instances will retrieve their authorized public keys from a key distribution service. Three examples&amp;nbsp;follow:&lt;/p&gt;
&lt;h2 id="alternative-1-scalable-architecture-aws-and-local"&gt;Alternative 1 - Scalable Architecture - &lt;span class="caps"&gt;AWS&lt;/span&gt; and&amp;nbsp;Local&lt;/h2&gt;
&lt;p&gt;Keys will be managed by a web-based application (with a complete and documented &lt;span class="caps"&gt;API&lt;/span&gt;) living in the corporate data center.
The application will provide facilities for authorized users (managers, operations) to define new Access Groups and modify
the list of users allowed to access them. Individual end-users will be able to manage their public keys. At a set interval,
a standalone script will retrieve a list of all users defined in the application and check the status of their corporate Active
Directory accounts. Any users whose accounts have been deactivated or locked will be flagged as such in the application. Whenever
a change is made in the application (including a user being flagged as deactivated), all Access Groups that include that user
will have their authorized_keys file (composed of the authorized_keys files of all users with access) written to an S3 bucket
that&amp;#8217;s only writable by the privileged
user running the application. All instances will have &lt;span class="caps"&gt;IAM&lt;/span&gt; roles that allow them to read the&amp;nbsp;bucket.&lt;/p&gt;
&lt;p&gt;This method allows us to provide self-service to users and application administrators, and keeps all data about users within
the corporate network. It provides automatic revocation of access for disabled Active Directory accounts. It does introduce
a delay in revocation of access for disabled &lt;span class="caps"&gt;AD&lt;/span&gt; accounts, but a delay of ~10 minutes is certainly not a concern in our&amp;nbsp;environment.&lt;/p&gt;
&lt;h2 id="alternative-2-scalable-architecture-entirely-in-aws"&gt;Alternative 2 - Scalable Architecture Entirely in&amp;nbsp;&lt;span class="caps"&gt;AWS&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;A similar application exists, but lives entirely in &lt;span class="caps"&gt;AWS&lt;/span&gt;, utilizing its native high availability technologies (i.e. multi-&lt;span class="caps"&gt;AZ&lt;/span&gt;
&lt;span class="caps"&gt;RDS&lt;/span&gt; as a data store). A script still runs in the corporate data center, but all it does is query the &lt;span class="caps"&gt;API&lt;/span&gt; for a list of all
active users, check &lt;span class="caps"&gt;AD&lt;/span&gt; account status, and deactivate any users that no longer have a valid account. Instead of writing the
authorized key files to an S3 bucket, the application serves them directly in real-time. The application could
store keys and data in a &lt;span class="caps"&gt;RDBMS&lt;/span&gt;, or perhaps something like OpenLDAP, depending on which technologies are best known and
what the performance requirements&amp;nbsp;are.&lt;/p&gt;
&lt;p&gt;This is more of an infrastructure challenge and introduces additional points for failure; if the application above (1)
fails, it will only impact &lt;em&gt;changes&lt;/em&gt; to access, whereas if this application fails, all user access (aside from the static
emergency keys) will break. However, this method allows us to control access at a level finer than Access Groups; rules
could be developed based on any attributes of the requesting instance, including (if the latency was allowable) queries
to the &lt;span class="caps"&gt;EC2&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; for instance-specific&amp;nbsp;data.&lt;/p&gt;
&lt;h2 id="alternative-3-simple-architecture"&gt;Alternative 3 - Simple&amp;nbsp;Architecture&lt;/h2&gt;
&lt;p&gt;A text file stores mappings of Access Groups to the Active Directory users and groups authorized for them. The text file
is manually maintained, stored in version control, and all changes must comply with an access policy and be peer-reviewed.
A script runs at a set interval (let&amp;#8217;s say cron every 5-10 minutes) that reads the user/group mapping, translates groups
to their membership list, and checks the &lt;span class="caps"&gt;AD&lt;/span&gt; account status of every listed user. Users without valid/current/enabled accounts
are removed from the lists in memory. For the remaining (active) users for each Access Group, their &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt;
file is read. All user&amp;#8217;s authorized_keys files are concatenated together per Access Group, and the result is written to
an S3&amp;nbsp;bucket.&lt;/p&gt;
&lt;p&gt;This is by far the simplest method, and relies on our &lt;span class="caps"&gt;NFS&lt;/span&gt; shared home directories to allow users to manage their public
keys by simply using the standard file. This keeps all user-related data in our corporate data center, and means that we
have only one script and its&amp;#8217; cron job to maintain, rather than a whole application. The text-file-based method of access
control isn&amp;#8217;t terribly scalable, but it should work for the ~100 users that we have to deal with. Checking &lt;span class="caps"&gt;AD&lt;/span&gt; account status
when generating the file should provide a feasible safeguard for users whose corporate accounts are locked/revoked without
requiring someone to remember to also remove them from the &lt;span class="caps"&gt;AWS&lt;/span&gt; user&amp;nbsp;list.&lt;/p&gt;
&lt;h2 id="advantages-over-other-solutions"&gt;Advantages Over Other&amp;nbsp;Solutions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Self-service for users and for managers/administrators of&amp;nbsp;applications.&lt;/li&gt;
&lt;li&gt;No manual intervention when a user leaves the company; users automatically deactivated when their &lt;span class="caps"&gt;AD&lt;/span&gt; account&amp;nbsp;is.&lt;/li&gt;
&lt;li&gt;No cron job or daemon to run on instances, and no centralized process to break key distribution; each instance
  automatically pulls the current authorized keys when a login is&amp;nbsp;attempted.&lt;/li&gt;
&lt;li&gt;Doesn&amp;#8217;t depend on Puppet, so it allows individual applications to use Puppet as they desire, without complication
  or&amp;nbsp;confusion.&lt;/li&gt;
&lt;li&gt;Only depends on centralized (corporate data center) infrastructure for key updates (at most). Failure of connectivity
  between &lt;span class="caps"&gt;AWS&lt;/span&gt; and the corporate data center can be worked around assuming there is an alternate path of access (such as
  a bastion host that allows logins from engineers/managers from a trusted outside&amp;nbsp;host).&lt;/li&gt;
&lt;li&gt;Management of access can be delegated to application owners/managers, while still allowing engineers full&amp;nbsp;access.&lt;/li&gt;
&lt;li&gt;Uses the strength of public key authentication; no passwords to&amp;nbsp;change.&lt;/li&gt;
&lt;li&gt;Ensures that select static trusted keys always have access to instances, even during a failure of the key distribution&amp;nbsp;system.&lt;/li&gt;
&lt;li&gt;In emergencies, keys could be distributed directly to the authorized_keys file, bypassing the distribution system,
  or key file cache lifetime could be&amp;nbsp;increased.&lt;/li&gt;
&lt;li&gt;Can be easily audited by having a scheduled job add a key for all instances, wait ~15 minutes, and then attempt &lt;span class="caps"&gt;SSH&lt;/span&gt;
  connections to all&amp;nbsp;instances.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="trade-offs"&gt;Trade-Offs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Delay between user access addition/removal and updates (though this can be minimized by a shorter cache&amp;nbsp;time).&lt;/li&gt;
&lt;li&gt;Latency during initial login with a cold&amp;nbsp;cache.&lt;/li&gt;
&lt;li&gt;Addition of another system that could&amp;nbsp;break.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="limitations"&gt;Limitations&lt;/h2&gt;
&lt;p&gt;My company is a CentOS shop. The &lt;code&gt;AuthorizedKeysCommand&lt;/code&gt; feature of OpenSSH itself was only released in &lt;a href="http://www.openssh.com/txt/release-6.2"&gt;OpenSSH 6.2&lt;/a&gt;,
on March 22, 2013. A patch for it was backported to the 5.3p1 version of openssh-server in &lt;span class="caps"&gt;RHEL&lt;/span&gt; and CentOS 6. However,
this method will certainly not work on CentOS 5, which is still running OpenSSH 4.3. Be aware that when the new &lt;code&gt;AuthorizedKeysCommand&lt;/code&gt;
feature was backported, the man page was not updated; &lt;code&gt;man sshd_config&lt;/code&gt; is still conspicuously missing these options, and I couldn&amp;#8217;t
find anything in the &lt;span class="caps"&gt;RPM&lt;/span&gt; changelog about it, but the &lt;code&gt;openssh-5.3p1-authorized-keys-command.patch&lt;/code&gt; file is clearly there in the
5.3p1 &lt;span class="caps"&gt;SRPM&lt;/span&gt;, and the options are there but commented out in the &lt;code&gt;sshd_config&lt;/code&gt; it provides. I actually thought this would be near-impossible
to do on CentOS 6 until I found the &lt;code&gt;openssh-ldap&lt;/code&gt; package (in the default repos) and discovered that it uses this&amp;nbsp;feature.&lt;/p&gt;
&lt;p&gt;Also, this solution requires (depending on which alternative is chosen) working access to either S3 or instances serving an application.
Assuming proper configuration (and distribution across AZs) this should be a&amp;nbsp;non-issue.&lt;/p&gt;
&lt;h2 id="accountability"&gt;Accountability&lt;/h2&gt;
&lt;p&gt;If accountability is a concern, we will handle this through detailed logging in every step of the key creation, authorization, distribution
and retrieval process. In addition, all instances will run sshd with &lt;code&gt;LogLevel VERBOSE&lt;/code&gt;, which will log the fingerprint of all public keys
used to connect to the instance. Logs will be written to a secure, append-only&amp;nbsp;medium.&lt;/p&gt;
&lt;h1 id="references-and-further-details"&gt;References and Further&amp;nbsp;Details&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;There is an existing &lt;code&gt;openssh-ldap&lt;/code&gt; package in CentOS that provides instructions on setting up public key storage in an &lt;span class="caps"&gt;LDAP&lt;/span&gt; backend,
  using &lt;code&gt;AuthorizedKeysCommand&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://andriigrytsenko.net/2013/05/authorizedkeyscommand-support-and-centosrhel-5-x/"&gt;Someone said&lt;/a&gt; they successfully built the current
  6.2 OpenSSH for &lt;span class="caps"&gt;RHEL&lt;/span&gt;/Cent&amp;nbsp;5.&lt;/li&gt;
&lt;li&gt;An &lt;span class="caps"&gt;EC2&lt;/span&gt; instance can retrieve its own tags using tools such as &lt;code&gt;awscli&lt;/code&gt; or &lt;code&gt;ec2-api-tools&lt;/code&gt; and an appropriate &lt;span class="caps"&gt;IAM&lt;/span&gt; role set on the&amp;nbsp;instance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="rejected-ideas"&gt;Rejected&amp;nbsp;Ideas&lt;/h1&gt;
&lt;p&gt;While thinking through this I considered and rejected a number of alternate methods. Here are some of&amp;nbsp;them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;While &lt;span class="caps"&gt;SSH&lt;/span&gt;&amp;#8217;s relatively new Certificate support (&lt;span class="caps"&gt;CA&lt;/span&gt;-based) sounds nice, it doesn&amp;#8217;t solve the problem; according to
  &lt;a href="http://neocri.me/documentation/using-ssh-certificate-authentication/"&gt;this blog post&lt;/a&gt; it uses a &lt;span class="caps"&gt;CA&lt;/span&gt; to sign keys,
  but doesn&amp;#8217;t do a &lt;span class="caps"&gt;CRL&lt;/span&gt; lookup, it relies on a RevokedKeys file manually sync&amp;#8217;ed to all servers. So, this poses the
  same problem as managing authorized_keys as a file distributed to&amp;nbsp;instances.&lt;/li&gt;
&lt;li&gt;Managing per-application users or groups on the &lt;span class="caps"&gt;AWS&lt;/span&gt; bastion hosts requires a lot of administrative overhead, and isn&amp;#8217;t really an option for us.
  Though this would be a simple implementation using either groups for each application with private keys group-readable,
  or using per-application users and the proper sudo&amp;nbsp;configuration.&lt;/li&gt;
&lt;li&gt;Prior to finding out about &lt;code&gt;AuthorizedKeysCommand&lt;/code&gt;, my top idea was essentially this same implementation on the
  key distribution server side, but writing it to an S3 bucket, and running a cronjob on each &lt;span class="caps"&gt;EC2&lt;/span&gt; instance to pull
  down the authorized_keys&amp;nbsp;file.&lt;/li&gt;
&lt;li&gt;Just Don&amp;#8217;t - See &lt;a href="https://wblinks.com/notes/aws-tips-i-wish-id-known-before-i-started/"&gt;this blog post&lt;/a&gt;
  as a reference. But the gist is, &amp;#8220;If you have to &lt;span class="caps"&gt;SSH&lt;/span&gt; into your servers, then your automation has failed&amp;#8221;.
  Sure, development and test stacks will be spun up, probably with either a single user&amp;#8217;s key, or a shared
  key. But after that (i.e. in prod), instances are cattle. Logs should be shipped to a central store, CloudWatch
  and/or other monitoring technologies (i.e. NewRelic, Diamond to graphite) should get most of the data that&amp;#8217;s
  needed. I&amp;#8217;m not seriously agreeing to &lt;strong&gt;disable&lt;/strong&gt; &lt;span class="caps"&gt;SSH&lt;/span&gt; access, but to put in place the tools that it&amp;#8217;s needed
  so rarely (on non-dev instances) that it&amp;#8217;s feasible to ask one of a small group of privileged people to
  perform the&amp;nbsp;task.&lt;/li&gt;
&lt;li&gt;Trust our users - If someone can push to master, full control of our systems is just a backtick (or popen) away.
  Recognize that if someone wasn&amp;#8217;t trustworthy, we wouldn&amp;#8217;t hire them. Let everyone access a single bastion host.
  Discourage unauthorized use via strong password policies and other standard security measures
  (perhaps &lt;span class="caps"&gt;OTP&lt;/span&gt;-based two-factor authentication). Discourage malicious use via detailed audit logging, with logs
  shipped to an append-only secure storage&amp;nbsp;location.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;SUID&lt;/span&gt; wrapper script - All users have &lt;span class="caps"&gt;SSH&lt;/span&gt; access to a bastion host as their normal
  active directory user. They run a &lt;span class="caps"&gt;SUID&lt;/span&gt; wrapper script that has a list of which users are allowed to access
  which &lt;span class="caps"&gt;EC2&lt;/span&gt; instances (or security groups, subnets, etc). When the user calls this script, it checks if the
  specified host is in a group they&amp;#8217;re allowed to access, and if so, SSHes to that host using a key only readable
  by the owner of the script. This is somewhat complex; there&amp;#8217;s a good possibility of security issues with the
  script itself, and it means that we&amp;#8217;re probably only allowing interactive logins - we&amp;#8217;re limited by the
  capabilities of the wrapper script, it&amp;#8217;s not just a normal &lt;span class="caps"&gt;SSH&lt;/span&gt;&amp;nbsp;client.&lt;/li&gt;
&lt;li&gt;Key Pushing- A script runs in one central location. It has a mapping of which users/groups are allowed
  to access which &lt;span class="caps"&gt;EC2&lt;/span&gt; instances. Every X minutes the script runs. It grabs &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; for all
  users that are allowed &lt;span class="caps"&gt;EC2&lt;/span&gt; access, and then generates an authorized_keys file for each group of instances.
  The script checks a cache, and if the file has changed for a group of instances since the last run, it queries
  the &lt;span class="caps"&gt;AWS&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; to determine which instances are in that group, and distributes the authorized_keys file to them.
  The &amp;#8220;distributes&amp;#8221; part would, unfortunately, probably have to be&amp;nbsp;scp.&lt;/li&gt;
&lt;li&gt;Bastion host per application. Users are allowed access to this host either via authorized_keys managed by Puppet,
  or via sudoers rules on a bastion host in the corporate network. But yeah, we&amp;#8217;d end up with a &lt;strong&gt;lot&lt;/strong&gt; of&amp;nbsp;these.&lt;/li&gt;
&lt;li&gt;Various thoughts around &lt;span class="caps"&gt;AD&lt;/span&gt; in the cloud, replicated &lt;span class="caps"&gt;AD&lt;/span&gt; in the cloud, OpenLDAP in the cloud pulling from &lt;span class="caps"&gt;AD&lt;/span&gt;, or
  &lt;span class="caps"&gt;AD&lt;/span&gt; over &lt;span class="caps"&gt;VPN&lt;/span&gt;. These were all rejected either because of corporate security policies, or because relying on internal
  &lt;span class="caps"&gt;AD&lt;/span&gt; for authentication would mean that a data center or connectivity failure also affects&amp;nbsp;&lt;span class="caps"&gt;AWS&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Puppet - We actually &lt;em&gt;run&lt;/em&gt; puppet on every instance. Maybe against our master, maybe masterless with a script
  to deploy some modules before every run. At a minimum, it manages ssh authorized keys for ec2_user. We implement
  some method where each user has a manifest with their own public keys, that they can maintain. Managers can add users
  to the group(s) for their applications, and that users&amp;#8217; keys are automatically deployed. Revoking keys, on the other
  hand, is a bigger problem. This requires some sort of &amp;#8220;this person is going away&amp;#8221; procedure, which currently doesn&amp;#8217;t
  exist (or involve the groups who maintain &lt;span class="caps"&gt;AWS&lt;/span&gt; infrastructure), and would be one more thing for a human to forget.
  There are also instances that have &amp;#8220;special stuff&amp;#8221; going on with Puppet that would complicate&amp;nbsp;this.&lt;/li&gt;
&lt;li&gt;Generate a list of authorized keys, turn it into a manifest, and run puppet masterless on it via a cronjob (pulling
  the manifest from S3). This involves most of the same problems as above, plus means that we have Puppet running
  in two different ways on some instances (triggered via mco against a master, and cron&amp;#8217;ed in apply&amp;nbsp;mode).&lt;/li&gt;
&lt;/ul&gt;</summary><category term="ssh"></category><category term="ec2"></category><category term="aws"></category><category term="keys"></category><category term="public key"></category><category term="pubkey"></category></entry><entry><title>Pushover Notifications for Shell Command Completion and Status</title><link href="http://blog.jasonantman.com/2014/09/pushover-notifications-for-shell-command-completion-and-status/" rel="alternate"></link><updated>2014-09-27T21:20:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-09-27:2014/09/pushover-notifications-for-shell-command-completion-and-status/</id><summary type="html">&lt;p&gt;Lately I&amp;#8217;ve been doing a bunch of work with &lt;a href="http://www.packer.io/"&gt;packer&lt;/a&gt; building &lt;a href="http://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;
machine images, and using &lt;a href="http://serverspec.org/"&gt;serverspec&lt;/a&gt; to run automated acceptance tests on the images. Unfortunately,
this ends up being a ~40-minute cycle time for the full image to provision and test. So, lots of watching text slowly scroll
down a screen, and finding something else to do. It&amp;#8217;s the weekend; I want to get this project finished, but I&amp;#8217;ve got other
things to&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;So, I wrote a little bash wrapper around &lt;a href="https://github.com/jnwatts"&gt;jnwatts&amp;#8217;&lt;/a&gt;
&lt;a href="https://raw.githubusercontent.com/jnwatts/pushover.sh/master/pushover.sh"&gt;pushover.sh&lt;/a&gt;. Assuming wherever you put this
is in your path, simply prefix any command with &lt;code&gt;pushover&lt;/code&gt;, and you&amp;#8217;ll get a handy &lt;a href="https://pushover.net/"&gt;Pushover&lt;/a&gt;
notification when it completes, along with the exit status and some other useful&amp;nbsp;information.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;
&lt;span class="c"&gt;# Notify command completion and exit status via pushover&lt;/span&gt;
&lt;span class="c"&gt;# uses pushover.sh from https://raw.githubusercontent.com/jnwatts/pushover.sh/master/pushover.sh&lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;APIKEY&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Your Pushover &lt;span class="caps"&gt;API&lt;/span&gt; Key Here&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;USERKEY&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Your Pushover User Key Here&amp;quot;&lt;/span&gt;

&lt;span class="nv"&gt;stime&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;date &lt;span class="s1"&gt;&amp;#39;+%s&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;$@&lt;/span&gt;
&lt;span class="nv"&gt;exitcode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$?&lt;/span&gt;
&lt;span class="c"&gt;# timer&lt;/span&gt;
&lt;span class="nv"&gt;etime&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;date &lt;span class="s1"&gt;&amp;#39;+%s&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;etime &lt;span class="o"&gt;-&lt;/span&gt; stime&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;ds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;dt &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="m"&gt;60&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;dm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;dt &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="m"&gt;60&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="m"&gt;60&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;dh&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;dt &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="m"&gt;3600&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;times&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;printf&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%d:%02d:%02d&amp;#39;&lt;/span&gt; &lt;span class="nv"&gt;$dh&lt;/span&gt; &lt;span class="nv"&gt;$dm&lt;/span&gt; &lt;span class="nv"&gt;$ds&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# end timer&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$exitcode&amp;quot;&lt;/span&gt; -eq 0 &lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;pushover.sh -p 0 -t &lt;span class="s2"&gt;&amp;quot;Command Succeeded&amp;quot;&lt;/span&gt; -T &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;APIKEY&lt;/span&gt;&amp;quot;&lt;/span&gt; -U &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;USERKEY&lt;/span&gt;&amp;quot;&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;succeeded in ${times} on $(hostname): $@ (in $(pwd))&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;(sent pushover success notification)&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;pushover.sh -p 0 -s falling -t &lt;span class="s2"&gt;&amp;quot;Command Failed&amp;quot;&lt;/span&gt; -T &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;APIKEY&lt;/span&gt;&amp;quot;&lt;/span&gt; -U &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;USERKEY&lt;/span&gt;&amp;quot;&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;failed in ${times} (exit $exitcode) on $(hostname): $@ (in $(pwd))&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;(sent pushover failure notification)&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So, for example, a failing spec&amp;nbsp;test:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;jantman@phoenix:pts/4:~/CMG/git/puppet-cm (AUTO-415=)$ pushover bundle exec rake spec
&amp;lt;lots of failing spec output that exits non-0 after 1 minute 10 seconds&amp;gt;
(sent pushover failure notification)
jantman@phoenix:pts/4:~/CMG/git/puppet-cm (AUTO-415=)$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Would send me a handy pushover message when it&amp;nbsp;finishes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Command Failed
failed in 0:01:10 (exit 1) on phoenix: bundle exec rake spec (in /home/jantman/CMG/git/puppet-cm)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopefully this is useful to someone else as&amp;nbsp;well&amp;#8230;&lt;/p&gt;</summary><category term="pushover"></category><category term="shell"></category><category term="notifications"></category></entry><entry><title>Session Save and Restore with Bash and GNU Screen</title><link href="http://blog.jasonantman.com/2014/07/session-save-and-restore-with-bash-and-gnu-screen/" rel="alternate"></link><updated>2014-07-25T10:09:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-07-25:2014/07/session-save-and-restore-with-bash-and-gnu-screen/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been using &lt;a href="http://www.gnu.org/software/screen/"&gt;&lt;span class="caps"&gt;GNU&lt;/span&gt; Screen&lt;/a&gt; for a very long time; I pretty much do &lt;em&gt;all&lt;/em&gt; of my
daily work in it. I have long-lived screen sessions pretty much everywhere; at any given time, I&amp;#8217;ve got a session running
on my desktop (that probably has 19 windows open and active) and a few on various remote hosts. I also have a really
bad habit of using screen windows to hold work in progress, things that I need to revisit, and what I want to do
next. This isn&amp;#8217;t as big of a deal on boxes in a datacenter that rarely go down, but my home desktop ends up getting
rebooted every few weeks (and not always at planned&amp;nbsp;times).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt; - what I&amp;#8217;m about to describe is, really, a fragile and somewhat ugly hack. I&amp;#8217;m pretty sure that if I took
the time to learn and switch to zsh (or another, more modern shell) and tmux, I could probably do this easier. But my
shell environment is something I&amp;#8217;m pretty stuck in. So, if this is useful to anyone else, cool. But caveat&amp;nbsp;emptor.&lt;/p&gt;
&lt;p&gt;screen 4.2.0 introduced some extensions to the &lt;code&gt;-Q&lt;/code&gt; remote querying capabilities, including the ability to retrieve a
list of current windows and their titles via &lt;code&gt;screen -Q windows&lt;/code&gt;. A few months ago, I wrapped a python script around
this that reads the currently open windows along with their title and window number, and writes out &lt;code&gt;~/.screenrc.save&lt;/code&gt;
that&amp;#8217;s &lt;code&gt;~/.screenrc&lt;/code&gt; with &lt;code&gt;screen -t&lt;/code&gt; lines to recreate my currently open windows with their titles. After a system
crash or reboot, I could &lt;code&gt;screen -c ~/.screenrc.save&lt;/code&gt; and get all of my windows and their titles back. So, that&amp;#8217;s
a slightly better reminder of what I was working on assuming I keep my titles relevant. But each window just dumped
me into &lt;code&gt;~/&lt;/code&gt; like usual, so I&amp;#8217;d just have the window title to remind me what I was working&amp;nbsp;on. &lt;/p&gt;
&lt;p&gt;I ran this script for a few months; you can see the original version &lt;a href="https://github.com/jantman/misc-scripts/blob/ab6a14774d5dd6250aac98f804c33d3dc26a32eb/savescreen.py"&gt;here&lt;/a&gt;.
However, this still really isn&amp;#8217;t what I&amp;#8217;d call &amp;#8220;session restore&amp;#8221;. I had window titles as &amp;#8220;hints&amp;#8221; to what I was doing,
but everything else was left to my&amp;nbsp;memory.&lt;/p&gt;
&lt;p&gt;Enter some awful &lt;code&gt;bashrc&lt;/code&gt; hackery. Please note that my bashrc is a bit complicated, mainly due to git completion
and getting a proper prompt for python virtualenvs, but here&amp;#8217;s the magic&amp;nbsp;portion:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# git prompt - make it work everywhere&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -e /usr/share/git/completion/git-prompt.sh &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt; /usr/share/git/completion/git-prompt.sh
&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -e /usr/share/git-core/contrib/completion/git-prompt.sh &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt; /usr/share/git-core/contrib/completion/git-prompt.sh
&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -e ~/bin/git-prompt.sh &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt; ~/bin/git-prompt.sh
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="c"&gt;#set the &lt;span class="caps"&gt;PROMPT&lt;/span&gt;&lt;/span&gt;
&lt;span class="nv"&gt;cur_tty&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;tty&lt;span class="k"&gt;)&lt;/span&gt; ; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;5&lt;/span&gt;&lt;span class="k"&gt;})&lt;/span&gt;;
&lt;span class="c"&gt;# git prompt configutation&lt;/span&gt;
&lt;span class="nv"&gt;GIT_PS1_SHOWDIRTYSTATE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
&lt;span class="nv"&gt;GIT_PS1_SHOWUNTRACKEDFILES&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
&lt;span class="nv"&gt;GIT_PS1_SHOWUPSTREAM&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;auto&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;GIT_PS1_SHOWCOLORHINTS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1

&lt;span class="c"&gt;# for screen session-saving hack, set per-window history file if in screen&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;STY&lt;/span&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;HISTFILE&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;readlink -f ~/.screenhist/&lt;span class="nv"&gt;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;shopt&lt;/span&gt; -s histappend

&lt;span class="c"&gt;# make sure our screen session-saving hack directories exist&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt; -d ~/.screenhist &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; mkdir ~/.screenhist
&lt;span class="o"&gt;[[&lt;/span&gt; -d ~/.screendirs &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; mkdir ~/.screendirs

__wrap_git_ps1 &lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="c"&gt;# commands here now get executed every time bash constructs a prompt&lt;/span&gt;
    &lt;span class="c"&gt;# for screen pwd saving&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;STY&lt;/span&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
    &lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;SCREENLINKDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;readlink -f ~/.screendirs&lt;span class="k"&gt;)&lt;/span&gt;
        rm -f &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SCREENLINKDIR&lt;/span&gt;&lt;/span&gt;/&lt;span class="nv"&gt;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&lt;/span&gt;
        ln -sf &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;/ &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SCREENLINKDIR&lt;/span&gt;&lt;/span&gt;/&lt;span class="nv"&gt;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&lt;/span&gt;
    &lt;span class="k"&gt;fi&lt;/span&gt;
    &lt;span class="c"&gt;# virtualenv stuff for prompt&lt;/span&gt;
    &lt;span class="nv"&gt;venv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="o"&gt;[[&lt;/span&gt; &lt;span class="nv"&gt;$VIRTUAL_ENV&lt;/span&gt; !&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nv"&gt;venv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;\[\033[31m\](${VIRTUAL_ENV##*/})\e[0m&amp;quot;&lt;/span&gt;
    __git_ps1 &lt;span class="s2"&gt;&amp;quot;$venv\u@\h:$cur_tty:\w&amp;quot;&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;\\\$ &amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;history&lt;/span&gt; -a
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="nv"&gt;PROMPT_COMMAND&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;__wrap_git_ps1&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;PS2&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;gt; &amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So&amp;#8230; the hack. First we source the git prompt scripts that come with git (trying the
locations they should be at on all of the machines I commonly use, and if it can&amp;#8217;t find
any of them, falling back to a copy in my homedir) and set some configuration variables
for them (as well as capturing the current tty). We then (conditionally on being inside
a screen window) set our history file to a per-screen-window path, and have history append.
At this point we also make sure some directories we&amp;#8217;ll use&amp;nbsp;exist.&lt;/p&gt;
&lt;p&gt;Now the real fun. &lt;code&gt;PROMPT_COMMAND&lt;/code&gt; specifies a function for bash to execute to build the
prompt string; this is called every time bash needs to display the prompt (so, effectively,
every time a command completes in the shell). We set it to &lt;code&gt;__wrap_git_ps1&lt;/code&gt;, a function we
just defined. The magic happens in this function. Screen sets some environment variables
inside each window, including &lt;code&gt;STY&lt;/code&gt; (the name of the screen session you&amp;#8217;re in) and
&lt;code&gt;WINDOW&lt;/code&gt;, the current window number. If both of these are set, we symlink our current
&lt;code&gt;pwd&lt;/code&gt; to &lt;code&gt;~/.screendirs/$WINDOW&lt;/code&gt; (note some hackery, explicitly removing the link if it
already exists, to get this to work correctly). We then throw in some python virtualenv-specific
prompt settings, and pass on the strings we&amp;#8217;ve constructed to &lt;code&gt;__git_ps1&lt;/code&gt; which adds the
git-specific information, and then sets &lt;code&gt;PS1&lt;/code&gt; correctly. Finally, we explicitly append to
current history, to make sure the history on disk is always accurate and&amp;nbsp;up-to-date.&lt;/p&gt;
&lt;p&gt;This works in combination with the &lt;a href="https://github.com/jantman/misc-scripts/blob/master/savescreen.py"&gt;latest version&lt;/a&gt;
of savescreen.py, which has some minor changes. The line to create each window,&amp;nbsp;formerly:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="n"&gt;fh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;screen -t &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;{name}&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s"&gt; {num}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;windows&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;becomes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="n"&gt;fh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;screen -t &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;{name}&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s"&gt; {num} sh -c &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s"&gt;cd $(readlink -fn {dirpath}/{num}); bash&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;windows&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dirpath&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dirpath&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When each window is created at startup, we &lt;code&gt;cd&lt;/code&gt; into the previous &lt;code&gt;pwd&lt;/code&gt; (the path
that the &lt;code&gt;~/.screendirs/$WINDOW&lt;/code&gt; symlink, created by bashrc, points to) and then
call our shell. When this is combined with the &lt;code&gt;HISTFILE&lt;/code&gt; change, the effect is that
&lt;code&gt;screen -c ~/.screenrc.save&lt;/code&gt; brings us back into a screen session that has not only
all of our previous windows and their titles, but also a shell in each window&amp;#8217;s previous
working directory, and that window&amp;#8217;s&amp;nbsp;history.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Limitations&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I should&amp;#8217;ve also used &lt;code&gt;$STY&lt;/code&gt; in each of the paths, so this would be multi-session-safe.
   I didn&amp;#8217;t, so this has undefined behavior if more than one screen session is running as
   your&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;A lot of this is lost, obviously, if you &lt;code&gt;sudo su&lt;/code&gt; or &lt;code&gt;ssh&lt;/code&gt;, or in any other way end up
   as a different&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;I&amp;#8217;m thinking about rolling in some method of automatic &lt;code&gt;virtualenv&lt;/code&gt; activation (since it,
   unfortunately, doesn&amp;#8217;t have anything like &lt;code&gt;.rvmrc&lt;/code&gt;). Maybe in the next&amp;nbsp;version.&lt;/li&gt;
&lt;/ol&gt;</summary><category term="bash"></category><category term="screen"></category><category term="restore"></category><category term="bashrc"></category></entry><entry><title>bashrc Vagrant / VirtualBox reminder</title><link href="http://blog.jasonantman.com/2014/07/bashrc-vagrant-virtualbox-reminder/" rel="alternate"></link><updated>2014-07-10T06:45:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-07-10:2014/07/bashrc-vagrant-virtualbox-reminder/</id><summary type="html">&lt;p&gt;Lately I&amp;#8217;ve been using VirtualBox VMs, both managed by Vagrant and otherwise, quite a lot.
I&amp;#8217;ve also been doing a bunch of development work with them. And inevitably, I close a screen
window and fo on with my work and end up with a few &amp;#8220;orphaned&amp;#8221; virtualbox VMs running that
I&amp;#8217;ve forgotten&amp;nbsp;about.&lt;/p&gt;
&lt;p&gt;Below is the snippet I&amp;#8217;ve added to my &lt;code&gt;~/.bashrc&lt;/code&gt; to keep me aware of this situation. Unfortunately
the &lt;code&gt;vagrant global-status&lt;/code&gt; command is relatively slow, so this adds (on my machine) about
1.5 seconds of wall-clock time to my &lt;code&gt;.bashrc&lt;/code&gt; (hence the process check&amp;nbsp;first).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# Vagrant/VirtualBox reminder&lt;/span&gt;
&lt;span class="k"&gt;if &lt;/span&gt;pgrep VBoxHeadless &amp;amp;&amp;gt;/dev/null; &lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;vblist&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;VBoxManage list runningvms&lt;span class="k"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;[&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;${vblist}&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;\e[1;31mRunning VirtualBox VMs:\e[0m\n${vblist}\n&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if &lt;/span&gt;which vagrant &amp;amp;&amp;gt; /dev/null &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; vagrant &lt;span class="nb"&gt;help&lt;/span&gt; | grep -q global-status; &lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;vagrantstatus&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;vagrant global-status | sed &lt;span class="s1"&gt;&amp;#39;/^\s*$/q&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
        &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$vagrantstatus&amp;quot;&lt;/span&gt; | grep -q running &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;\e[1;31mRunning Vagrant Machines:\e[0m&amp;quot;&lt;/span&gt; ; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$vagrantstatus&amp;quot;&lt;/span&gt; | head -2; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$vagrantstatus&amp;quot;&lt;/span&gt; | grep running; &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="vagrant"></category><category term="bashrc"></category><category term="profile"></category><category term="virtualbox"></category></entry><entry><title>Remotely-controlled deck.js slide presentations</title><link href="http://blog.jasonantman.com/2014/05/remotely-controlled-deckjs-slide-presentations/" rel="alternate"></link><updated>2014-05-12T09:34:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-05-12:2014/05/remotely-controlled-deckjs-slide-presentations/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been struggling to find a good, cross-platform remote meeting solution. We&amp;#8217;re using &lt;a href="http://www.imeet.com"&gt;iMeet&lt;/a&gt;
at work at the moment, but there&amp;#8217;s no way to present or screen share from a Linux machine. For most of our ops and
automation team daily and weekly meetings, we use &lt;a href="http://www.teamspeak.com/"&gt;TeamSpeak&lt;/a&gt; - sure it&amp;#8217;s not open source,
but it&amp;#8217;s simple, supports all OSes that matter to us (Mac, Linux, Windows, Android and iOS), can be self-hosted,
and has the holy grail, functional push-to-talk. But it&amp;#8217;s audio&amp;nbsp;only.&lt;/p&gt;
&lt;p&gt;On Friday I was running two short elaboration meetings, and had quick little slide decks done up in &lt;a href="http://imakewebthings.com/deck.js/"&gt;deck.js&lt;/a&gt;
to keep us on track. I couldn&amp;#8217;t help but think, gee, it sure would be nice if instead of switching to Mac or a &lt;span class="caps"&gt;VM&lt;/span&gt; and sharing my screen,
we could just use the audio communication mediums that we already do, and I could simply control the slides in a&amp;nbsp;browser.&lt;/p&gt;
&lt;p&gt;Well this morning I stumbled on &lt;a href="http://cleverchris.com/"&gt;Chris Jaure&lt;/a&gt;&amp;#8216;s &lt;a href="https://github.com/chrisjaure/deckjs-remote"&gt;deckjs-remote&lt;/a&gt;
project that does exactly that. It&amp;#8217;s a nodejs npm module that runs a websocket server, and allows people to join a session and follow
along as the presenter changes&amp;nbsp;slides.&lt;/p&gt;
&lt;p&gt;I did have a few hiccups getting it working - mainly some issues with &lt;span class="caps"&gt;CORS&lt;/span&gt;. The &lt;span class="caps"&gt;README&lt;/span&gt;.md has a large block of markup to be added to
the slide deck html to support &amp;#8220;older browsers that don&amp;#8217;t support &lt;span class="caps"&gt;CORS&lt;/span&gt;.&amp;#8221; I&amp;#8217;m running Firefox 28.0 (Firefox has supported &lt;span class="caps"&gt;CORS&lt;/span&gt; since
3.0, quite a few years back) and still needed to add this to get everything working. I also needed to manually add a script tag
for socket.io coming from the nodejs server in order to get everything&amp;nbsp;working.&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s a bit of a delay for the socket connection to come up after initially loading the page, but once that&amp;#8217;s done, the presenter
(&amp;#8220;master&amp;#8221; session) should get the password prompt, and any guests should get a prompt asking if they want to join the current
session. Perhaps the best part is that the nodejs server interally stores each deck by &lt;span class="caps"&gt;URL&lt;/span&gt;, so it seems to work perfectly fine
when running one instance for N presenters (i.e. a single instance running persistently on a shared&amp;nbsp;server).&lt;/p&gt;</summary><category term="slide"></category><category term="presentation"></category><category term="deck.js"></category><category term="deckjs"></category><category term="javascript"></category></entry><entry><title>Python script to backup Disqus comments</title><link href="http://blog.jasonantman.com/2014/03/python-script-to-backup-disqus-comments/" rel="alternate"></link><updated>2014-03-01T19:01:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-03-01:2014/03/python-script-to-backup-disqus-comments/</id><summary type="html">&lt;p&gt;Since I just &lt;a href="/2014/03/wordpress-to-pelican-with-disqus-comments"&gt;switched this blog to using Disqus for commenting&lt;/a&gt;,
I wanted a way to back up comments in case something goes wrong (like,
Disqus going the way of del.icio.us&amp;nbsp;bookmarking).&lt;/p&gt;
&lt;p&gt;I whipped up a quick &lt;a href="https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py"&gt;Python script&lt;/a&gt;
using the official &lt;a href="https://github.com/disqus/disqus-python"&gt;Disqus Python &lt;span class="caps"&gt;API&lt;/span&gt; client&lt;/a&gt;. It grabs the forum details,
threads list and posts (comments) list, and writes them out to a &lt;span class="caps"&gt;JSON&lt;/span&gt;&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;It doesn&amp;#8217;t have any restore feature, but it captures all of the&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;My first test made it look like there &lt;em&gt;may&lt;/em&gt; be some posts and theads missing (my import from
wordpress showed 56 threads and 146 comments, but this script only grabbed 52 and 125 respectively),
so exercise some caution until I verify what the problem is. If you happen to figure it out,
please submit a&amp;nbsp;&lt;span class="caps"&gt;PR&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The script is available on GitHub at &lt;a href="https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py"&gt;https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py&lt;/a&gt;.&lt;/p&gt;</summary><category term="pelican"></category><category term="disqus"></category><category term="python"></category></entry><entry><title>Wordpress to Pelican with Disqus comments</title><link href="http://blog.jasonantman.com/2014/03/wordpress-to-pelican-with-disqus-comments/" rel="alternate"></link><updated>2014-03-01T09:09:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-03-01:2014/03/wordpress-to-pelican-with-disqus-comments/</id><summary type="html">&lt;p&gt;This is the second part of my WordPress to &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt; conversion saga.
In the &lt;a href="/2014/03/converting-wordpress-posts-to-pelican-markdown/"&gt;last post&lt;/a&gt; I ran through some
of the issues that I faced when converting the posts themselves, setting up my theme and settings,
etc. In this post, I&amp;#8217;ll discuss the saga of moving from WordPress comments to Disqus&amp;nbsp;comments.&lt;/p&gt;
&lt;p&gt;Be sure to read &lt;strong&gt;all&lt;/strong&gt; of this before trying it yourself, as I had some serious problems with my
first&amp;nbsp;attempt.&lt;/p&gt;
&lt;h2 id="initial-import-to-disqus"&gt;Initial Import to&amp;nbsp;Disqus&lt;/h2&gt;
&lt;p&gt;Initially, I installed the Disqus WordPress plugin as instructed in
&lt;a href="http://help.disqus.com/customer/portal/articles/466255-importing-comments-from-wordpress"&gt;Disqus&amp;#8217; Import from WordPress documentation&lt;/a&gt;.
The automatic import imported three of 134 comments, and froze there,
even though the status said it was 100% complete. I emailed Disqus&amp;#8217; support,
and was told that this meant the import failed (even though there was no explicit
notification, their admin &lt;span class="caps"&gt;UI&lt;/span&gt; said the import was successful) and I had to manually
import my comments. I did this, as instructed in the same docs, by disabling all
plugins except for Disqus and generating an &lt;span class="caps"&gt;XML&lt;/span&gt; export from WordPress, then re-enabling
the plugins, and uploading the export to Disqus. This time, I ended up with all 134
comments in Disqus, so I assumed that all went&amp;nbsp;well.&lt;/p&gt;
&lt;h2 id="previewing-comments-in-pelican"&gt;Previewing Comments in&amp;nbsp;Pelican&lt;/h2&gt;
&lt;p&gt;I added my Disqus &lt;code&gt;shortname&lt;/code&gt; to the &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; field in &lt;code&gt;pelicanconf.py&lt;/code&gt; and
re-built. I ended up having an issue with &lt;code&gt;SITE_URL&lt;/code&gt; being set incorrectly for some testing
that I did, so that killed 10 minutes. I rebuilt locally with &lt;code&gt;SITE_URL&lt;/code&gt; not defined, and
then used &lt;code&gt;fab serve&lt;/code&gt; to serve locally. I was using my
&lt;a href="/2014/01/planning-migration-from-wordpress-to-static-site/"&gt;Planning Migration from Wordpress to Static Site&lt;/a&gt;
post to test, as it was both the most recent post, and had a five comments in WordPress, which imported
correctly into Disqus and were visible both in the Disqus moderation tool and on the now-Disqus-powered
WordPress&amp;nbsp;blog.&lt;/p&gt;
&lt;p&gt;Once I rebuilt with &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; set and served locally with SimpleHTTPServer (&lt;code&gt;fab serve&lt;/code&gt;),
I checked the post and saw only a &amp;#8220;We were unable to load Disqus&amp;#8221; message below the post. It contained
a &lt;a href="http://help.disqus.com/customer/portal/articles/472007-i-m-receiving-the-message-%22we-were-unable-to-load-disqus-%22"&gt;link to their help article for that problem&lt;/a&gt;,
which pointed me at a domain mismatch/different origin problem. As indicated on that page,
I went to Settings -&amp;gt; Advanced in the Disqus admin, found the &amp;#8220;Trusted Domains&amp;#8221; box, and added
both my test domain (newblog.jasonantman.com - pointing at GitHub pages until I was ready to
shut WordPress down and actually move the live site) and &amp;#8220;localhost&amp;#8221; for testing, and&amp;nbsp;saved.&lt;/p&gt;
&lt;p&gt;I refreshed the page I was looking at, and now could see the Disqus commenting below my post,
but it wasn&amp;#8217;t showing any of the comments&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Disqus commenting with no comments" src="/GFX/disqus_wrong_url.png" /&gt;&lt;/p&gt;
&lt;p&gt;I pulled up the source of the page, and saw in the Disqus javascript just below the post&amp;nbsp;content:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_shortname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;jasonantman&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// required: replace example with your forum shortname&lt;/span&gt;
            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_identifier&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;planning-migration-from-wordpress-to-static-site&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;../../../2014/01/planning-migration-from-wordpress-to-static-site/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Everything looked &lt;span class="caps"&gt;OK&lt;/span&gt; to me except for &lt;code&gt;disqus_url&lt;/code&gt;, which I&amp;#8217;d seen mention of on the
&lt;a href="http://help.disqus.com/customer/portal/articles/472007-i-m-receiving-the-message-%22we-were-unable-to-load-disqus-%22"&gt;help page&lt;/a&gt;
I&amp;#8217;d just been looking at. Sure enough, it indicated that the &lt;code&gt;disqus_url&lt;/code&gt; var must be
an absolute &lt;span class="caps"&gt;URL&lt;/span&gt; to the post, not a relative path. I assume this was because I&amp;#8217;d generated
the content without having &lt;code&gt;SITE_URL&lt;/code&gt; set, so I hand-edited the generated page to change this
to the correct &lt;span class="caps"&gt;URL&lt;/span&gt;, http://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/,
and tested again. Unfortunately, still zero&amp;nbsp;comments.&lt;/p&gt;
&lt;h2 id="wordpress-disqus-plugin-permalinks"&gt;WordPress Disqus Plugin&amp;nbsp;Permalinks&lt;/h2&gt;
&lt;p&gt;Fearing the worst, I pulled up the same post on my now-Disqus-powered WordPress blog,
and took a peek at the source. The javascript over there revealed a&amp;nbsp;problem:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_identifier&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;1546 http://blog.jasonantman.com/?p=1546&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_container_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;disqus_thread&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_domain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;disqus.com&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_shortname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;jasonantman&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Planning Migration from WordPress to Static Site&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While the &lt;span class="caps"&gt;URL&lt;/span&gt; is correct, the Disqus WordPress plugin uses the WordPress
post &lt;span class="caps"&gt;ID&lt;/span&gt; and permalink for the &amp;#8220;identifier&amp;#8221;, but the Pelican plugin uses the slug.
That&amp;#8217;s a problem, as my Pelican site will have the same URLs, but the WordPress
post-&lt;span class="caps"&gt;ID&lt;/span&gt;-based permalinks are gone (since it&amp;#8217;s a static site, and there&amp;#8217;s no easy
way of replicating things that are query param based). The WordPress post IDs
are thrown out by Pelican, so there&amp;#8217;s no way to connect the&amp;nbsp;two.&lt;/p&gt;
&lt;p&gt;Even worse, I remembered that Disqus&amp;#8217;
&lt;a href="http://help.disqus.com/customer/portal/articles/466255-importing-comments-from-wordpress"&gt;Importing Comments from WordPress help page&lt;/a&gt;
clearly&amp;nbsp;stated:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Imported comments can&amp;#8217;t be permanently deleted. Consider following our &lt;a href="http://help.disqus.com/customer/portal/articles/1053796-best-practices-for-staging-development-and-preview-sites"&gt;guidelines for development sites&lt;/a&gt; to make sure the data you&amp;#8217;re importing is correct. You can &lt;a href="http://disqus.com/register"&gt;register a new forum&lt;/a&gt; if you have imported the wrong&amp;nbsp;comments.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="solution-to-permalink-issue"&gt;Solution to Permalink&amp;nbsp;Issue&lt;/h2&gt;
&lt;p&gt;Not seeing any way around it, I figured it was time to &amp;#8220;bite the bullet&amp;#8221;. I disabled the Disqus plugin
in WordPress and then installed and activated the
&lt;a href="http://wordpress.org/extend/plugins/code-freeze/"&gt;WordPress Code Freeze Plugin&lt;/a&gt;
to disable comments. (&lt;em&gt;Note&lt;/em&gt; ironically, this plugin also uses JavaScript to disable your ability to
deactivate plugins, including itself. So before you activate it, copy the &amp;#8220;Activate&amp;#8221; link and save it
somewhere; changing &lt;code&gt;action=activate&lt;/code&gt; to &lt;code&gt;action=deactivate&lt;/code&gt; will let you get rid of it if you&amp;nbsp;want).&lt;/p&gt;
&lt;p&gt;Disqus has some documentation on &lt;a href="http://help.disqus.com/customer/portal/articles/1104797-importing-exporting"&gt;Importing and Exporting&lt;/a&gt;
which includes &lt;a href="http://help.disqus.com/customer/portal/articles/472150"&gt;Custom &lt;span class="caps"&gt;XML&lt;/span&gt; Imports&lt;/a&gt; based on the
WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export format. So, I figured that I just had to decide that WordPress commenting would be
turned off, and do a point-in-time migration to Disqus (maybe circling back to hack the Disqus &lt;span class="caps"&gt;WP&lt;/span&gt; plugin
to keep comments working there for the time&amp;nbsp;being).&lt;/p&gt;
&lt;p&gt;Before anything else, I decided to actually set up a test forum/site in Disqus like they suggested.
I updated the &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; in &lt;code&gt;pelicanconf.py&lt;/code&gt;, and then started in on the &lt;span class="caps"&gt;XML&lt;/span&gt; munging. The
&lt;a href="http://help.disqus.com/customer/portal/articles/472150"&gt;Custom &lt;span class="caps"&gt;XML&lt;/span&gt; Imports&lt;/a&gt; documentation implies
that the import engine recognizes a &lt;code&gt;dsq:thread_identifier&lt;/code&gt; &lt;span class="caps"&gt;XML&lt;/span&gt; element that holds the thread identifier,
but that element wasn&amp;#8217;t present in my WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export. It appeared that Disqus was concatenating the
&lt;code&gt;wp:post_id&lt;/code&gt; and &lt;code&gt;guid&lt;/code&gt; fields (with a space in between) to come up with the&amp;nbsp;identifier.&lt;/p&gt;
&lt;p&gt;So, I wrote a script (&lt;a href="https://github.com/jantman/blog/blob/master/dev/wp-move/wp_comment_xml_munge.py"&gt;wp_comment_xml_munge.py&lt;/a&gt;)
using &lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt; that adds the &lt;code&gt;dsq:&lt;/code&gt; namespace to the WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export (unfortunately using
string replacement and a temp file, due to a &lt;a href="https://bugs.launchpad.net/lxml/+bug/555602"&gt;bug in lxml&lt;/a&gt;)
and then adds the &lt;code&gt;dsq:thread_identifier&lt;/code&gt; tag to each post item, setting its value to the same
string as &lt;code&gt;wp:post_name&lt;/code&gt;, the &lt;span class="caps"&gt;URL&lt;/span&gt; slug (and post identifier in&amp;nbsp;Pelican).&lt;/p&gt;
&lt;p&gt;I imported the &lt;span class="caps"&gt;XML&lt;/span&gt; written by the script into my test forum in Disqus and rebuilt the Pelican content.
Magically, the first time I looked, the comments were&amp;nbsp;there.&lt;/p&gt;
&lt;p&gt;Now, time to see if I could get the same effect with the existing Disqus&amp;nbsp;site/forum:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In the Disqus moderation interface, delete all comments. You&amp;#8217;ll have to do this in batches of 10, as that&amp;#8217;s
   how they&amp;#8217;re paged in the interface. The comments don&amp;#8217;t seem to be permanently deleted, but do show as&amp;nbsp;&amp;#8220;deleted&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Go to &lt;a href="http://import.disqus.com"&gt;import.disqus.com&lt;/a&gt; and select your &amp;#8220;forum&amp;#8221; (site). You should see your existing
   (previous) import, as 100% complete, with the correct count of threads and comments. Do another import with the
   &lt;code&gt;_disqus.xml&lt;/code&gt; munged &lt;span class="caps"&gt;XML&lt;/span&gt;&amp;nbsp;export.&lt;/li&gt;
&lt;li&gt;Comments should now be linked to the correct post in&amp;nbsp;Pelican.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, Pelican seemed to be working, but WordPress was still left with only the old internal commenting,
and that was disabled by the Code Freeze plugin. I probably could have manually patched the Disqus plugin to
reflect the new thread identifiers, but instead, I chose to just push forward with the switch from WordPress to&amp;nbsp;Pelican.&lt;/p&gt;
&lt;p&gt;That only took a few hours, and I&amp;#8217;m happy to say that I&amp;#8217;m now up and running with a Pelican blog, hosted for free
by GitHub&amp;nbsp;Pages.&lt;/p&gt;</summary><category term="wordpress"></category><category term="pelican"></category><category term="blog"></category><category term="disqus"></category><category term="comments"></category></entry><entry><title>Converting WordPress Posts to Pelican MarkDown</title><link href="http://blog.jasonantman.com/2014/02/converting-wordpress-posts-to-pelican-markdown/" rel="alternate"></link><updated>2014-02-28T22:21:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-02-28:2014/02/converting-wordpress-posts-to-pelican-markdown/</id><summary type="html">&lt;p&gt;A few weeks ago, I
&lt;a href="/2014/01/planning-migration-from-wordpress-to-static-site/"&gt;posted&lt;/a&gt; about my
plans to convert my self-hosted WordPress blog to a static site using a static
blog generator. Since then, I&amp;#8217;ve decided to stop working on my exhaustive
&lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AnHh-ye5DNiNdF9DWkJrT2kzSkNsNVp6cjMzLXJ6VEE&amp;amp;usp=sharing"&gt;static blog generator comparison spreadsheet&lt;/a&gt;
and just try &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt; - mainly because it&amp;#8217;s written in
Python which is my current strongest language, comes highly recommended, seems
to have most of the features I want, and seems to be easily&amp;nbsp;extensible.&lt;/p&gt;
&lt;p&gt;So, I walked through the documentation for the latest version (3.3.0), started
a &lt;a href="https://github.com/jantman/blog"&gt;GitHub repo&lt;/a&gt;, and tweaked a bunch of
settings. The repo is public, so if you want to take a look behind the scenes,
see my &lt;a href="https://github.com/jantman/blog/blob/master/fabfile.py"&gt;fabfile&lt;/a&gt;,
etc. feel&amp;nbsp;free. &lt;/p&gt;
&lt;h2 id="initial-wordpress-import-attempt"&gt;Initial WordPress Import&amp;nbsp;Attempt&lt;/h2&gt;
&lt;p&gt;I used the WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; Export tool, as instructed in the &lt;a href="http://docs.getpelican.com/en/latest/importer.html"&gt;Pelican Importer documentation&lt;/a&gt;.
At first, I attempted to do a more-or-less default import from WordPress using
the &lt;code&gt;pelican-import&lt;/code&gt; tool, which writes rST, and then build the blog. What I
ended up with was thousands of errors complaining about &amp;#8220;Inline interpreted
text or phrase reference start-string without end-string&amp;#8221;, &amp;#8220;Explicit markup
ends without a blank line; unexpected uninden&amp;#8221;, &amp;#8220;malformed hyperlink target&amp;#8221;,
&amp;#8220;Unknown target name&amp;#8221; on all of my links, and a bevy of other Docutils
errors. It was so utterly awful that I gave&amp;nbsp;up.&lt;/p&gt;
&lt;h2 id="wordpress-import-as-markdown"&gt;WordPress Import as&amp;nbsp;MarkDown&lt;/h2&gt;
&lt;p&gt;Next I tried importing as MarkDown instead of rST,&amp;nbsp;using:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;pelican-import --markup markdown --wpfile -o content/ --dir-page jasonantman039sblog.wordpress.2014-01-11.xml
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That built without errors, and the posts looked somewhat right out of the
box, without any of the previous thousands of errors. And the links looked
mostly right - even the captions for images. Though I&amp;#8217;m working at a Python
shop and writing a lot of Python these days, my knowledge of MarkDown is still
much better than rST, so this is fine for me. (I even wrote a &lt;code&gt;fab post&lt;/code&gt; task
that prompts for a title, generates all of the post metadata, writes it to the
right file, and opens up an editor on&amp;nbsp;it.)&lt;/p&gt;
&lt;p&gt;The first problem was that the import script gave me one &amp;#8220;content&amp;#8221; directory
with 346 &amp;#8220;.md&amp;#8221; files in it - not exactly easy to work with. Luckily the
metadata was right, so a quick little
&lt;a href="https://github.com/jantman/blog/blob/master/move_wordpress.sh"&gt;bash script&lt;/a&gt;
moved the posts into a &lt;span class="caps"&gt;YYYY&lt;/span&gt;/&lt;span class="caps"&gt;MM&lt;/span&gt; directory&amp;nbsp;hierarchy.&lt;/p&gt;
&lt;h2 id="obvious-problems-with-imported-posts"&gt;Obvious Problems with Imported&amp;nbsp;Posts&lt;/h2&gt;
&lt;p&gt;After getting the MarkDown import working, and the posts moved to the proper
paths, I was still having some&amp;nbsp;issues&amp;#8230;&lt;/p&gt;
&lt;h3 id="syntax-hilighting-gone"&gt;Syntax Hilighting&amp;nbsp;Gone&lt;/h3&gt;
&lt;p&gt;In WordPress, I was using the
&lt;a href="http://wordpress.org/extend/plugins/wp-syntax/"&gt;&lt;span class="caps"&gt;WP&lt;/span&gt;-Syntax&lt;/a&gt; plugin to perform
syntax hilighting via &lt;a href="http://qbnz.com/highlighter/"&gt;GeSHi&lt;/a&gt;. The plugin uses
pre tags with a &lt;code&gt;lang=&lt;/code&gt; attribute to specify the language,&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&amp;lt;pre lang=&amp;quot;bash&amp;quot;&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, these translated to some really ugly MarkDown fenced blocks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;~~~~ {lang=&amp;quot;bash&amp;quot;}
cp /boot/efi/EFI/fedora/grub.cfg /boot/efi/EFI/fedora/grub.cfg.bak
echo &amp;#39;GRUB_DISABLE_OS_PROBER=&amp;quot;true&amp;quot;&amp;#39; &amp;gt;&amp;gt; /etc/default/grub
grub2-mkconfig &amp;gt; /boot/efi/EFI/fedora/grub.cfg
~~~~
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;that seem to be just a bit off from what MarkDown/Pygments can handle. The
places where I just used bare &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; blocks translated&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;http://blog.gastove.com/2013-09-17_enabling_line_numbers_for_pygments.html&lt;/p&gt;
&lt;p&gt;Fixed this by using fenced blocks with the &amp;#8216;lang=&amp;#8217; stuff removed, and in class
syntax like the MarkDown docs suggest. Some four-tab-indents with
:::identifier&amp;nbsp;work.&lt;/p&gt;
&lt;h3 id="broken-links"&gt;Broken&amp;nbsp;Links&lt;/h3&gt;
&lt;p&gt;It seems that something in the conversion process introduced line wraps (could
it really be Pandoc itself???) Unfortunately, this wreaks havoc with any
explicit reference links
that use long (long enough to break across lines) titles, depending on where
they are in the line. It seems that in some places they end up breaking
differently in the link in the text and in the link definition, which MarkDown misses, and
then renders broken links and plain text of the link table at the bottom of
the page. Manually removing the line breaks and any extraneous spaces seems to
fix&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;So, yes, Pandoc was doing this because of the &lt;code&gt;--reference-links&lt;/code&gt; parameter
that &lt;code&gt;pelican-import&lt;/code&gt; was calling it with. There was an
&lt;a href="https://github.com/getpelican/pelican/issues/348"&gt;issue&lt;/a&gt; and
&lt;a href="https://github.com/getpelican/pelican/pull/642"&gt;pull request&lt;/a&gt; to fix this,
but when I started with Pelican the last release was 3.3.0 (4 months ago) and
the &lt;span class="caps"&gt;PR&lt;/span&gt; was merged after that. So, if you&amp;#8217;re having the same problem and the
latest release of Pelican is still 3.3.0, you might as well just apply
&lt;a href="https://github.com/getpelican/pelican/commit/83e4d35b44a422ee8d4b077f505970d03e555f45"&gt;the patch&lt;/a&gt;
yourself - it&amp;#8217;s just a very simple removal of a parameter in
&lt;code&gt;pelican_import.py&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="overall-results"&gt;Overall&amp;nbsp;Results&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m quite happy with the overall results. I also spent a &lt;em&gt;lot&lt;/em&gt; of time manually fixing
markup issues that didn&amp;#8217;t translate well through Pandoc, but I suppose that&amp;#8217;s to be
expected given that many of my older blog posts had &lt;span class="caps"&gt;HTML&lt;/span&gt;&amp;nbsp;issues.&lt;/p&gt;</summary><category term="pelican"></category><category term="wordpress"></category><category term="blog"></category><category term="markdown"></category></entry><entry><title>Testing GPG Key Passphrases</title><link href="http://blog.jasonantman.com/2013/08/testing-gpg-key-passphrases/" rel="alternate"></link><updated>2013-08-26T06:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-08-26:2013/08/testing-gpg-key-passphrases/</id><summary type="html">&lt;p&gt;So hypothetically, you have a &lt;span class="caps"&gt;GPG&lt;/span&gt; public/private keypair (from a backup
or old computer), but you don&amp;#8217;t remember the passphrase. Here&amp;#8217;s a
relatively simple way to find it from a number of possible options. This
&lt;em&gt;requires&lt;/em&gt; that you have a computer secure enough to store the possible
options in a text file. I&amp;#8217;d recommend storing that file on a
ramdisk/tmpfs, and using a temporary &lt;span class="caps"&gt;VM&lt;/span&gt; for this, which you&amp;#8217;ll wipe away
when you&amp;#8217;re&amp;nbsp;done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preparation:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You have an appropriately secure place to do this with &lt;span class="caps"&gt;GPG&lt;/span&gt;
    installed, and a safe place to store a text file of sample
    passphrases (i.e. a&amp;nbsp;ramdisk).&lt;/li&gt;
&lt;li&gt;Copy your backed up public and private keys to &lt;code&gt;~/.gnupg&lt;/code&gt; on that
    host. Let&amp;#8217;s assume they&amp;#8217;re called &lt;code&gt;TestUser_public.key&lt;/code&gt; and
    &lt;code&gt;TestUser_private.key&lt;/code&gt;. We&amp;#8217;re assuming that you &lt;span class="caps"&gt;KNOW&lt;/span&gt;, &lt;span class="caps"&gt;BEYOND&lt;/span&gt; A &lt;span class="caps"&gt;DOUBT&lt;/span&gt;
    that these are your keys (i.e. you got them from a secure offline
    backup medium, you&amp;#8217;ve verified against a printed key fingerprint,
    you&amp;#8217;ve verified the fingerprints against a
    &lt;a href="http://pgp.mit.edu/"&gt;keyserver&lt;/a&gt; that you know is authoritative for
    your keys,&amp;nbsp;etc.).&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;First, we import the public and private keys to&amp;nbsp;&lt;span class="caps"&gt;GPG&lt;/span&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~$&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; .gnupg
&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --import TestUser_public.key 
&lt;span class="go"&gt;gpg: keyring `/home/testuser/.gnupg/secring.gpg` created&lt;/span&gt;
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: public key &amp;quot;Test User (Test User) &amp;quot; imported&lt;/span&gt;
&lt;span class="go"&gt;gpg: Total number processed: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:               imported: 1  (&lt;span class="caps"&gt;RSA&lt;/span&gt;: 1)&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --allow-secret-key-import --import TestUser_secret.key 
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: secret key imported&lt;/span&gt;
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: &amp;quot;Test User (Test User) &amp;quot; not changed&lt;/span&gt;
&lt;span class="go"&gt;gpg: Total number processed: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:              unchanged: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:       secret keys read: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:   secret keys imported: 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check that the keys are&amp;nbsp;there:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --list-keys
&lt;span class="go"&gt;/home/testuser/.gnupg/pubring.gpg&lt;/span&gt;
&lt;span class="go"&gt;--------------------------------&lt;/span&gt;
&lt;span class="go"&gt;pub   2048R/&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; 2013-08-24&lt;/span&gt;
&lt;span class="go"&gt;uid                  Test User (Test User) &lt;/span&gt;
&lt;span class="go"&gt;sub   2048R/&lt;span class="caps"&gt;40D9F35E&lt;/span&gt; 2013-08-24&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --list-secret-keys
&lt;span class="go"&gt;/home/testuser/.gnupg/secring.gpg&lt;/span&gt;
&lt;span class="go"&gt;--------------------------------&lt;/span&gt;
&lt;span class="go"&gt;sec   2048R/&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; 2013-08-24&lt;/span&gt;
&lt;span class="go"&gt;uid                  Test User (Test User) &lt;/span&gt;
&lt;span class="go"&gt;ssb   2048R/&lt;span class="caps"&gt;40D9F35E&lt;/span&gt; 2013-08-24&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Note the fingerprint of the key which is, in this case, &lt;code&gt;17AD8D3D&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Testing&amp;nbsp;Passphrases:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Now that we have the keys imported, we&amp;#8217;re ready to test some
    passphrases. Enter your passphrases, one per line, in a text file.
    We&amp;#8217;re assuming that we&amp;#8217;re working on a totally secured host
    (ideally, a &lt;span class="caps"&gt;VM&lt;/span&gt; running on a standalone, non-networked machine) that
    will be destroyed when we&amp;#8217;re done. For added security, I&amp;#8217;d put this
    file on a ramdisk. In this example, the actual passphrase for the
    key is &amp;#8220;test&amp;#8221;. Here&amp;#8217;s our text&amp;nbsp;file:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; cat /tmp/passphrases 
&lt;span class="go"&gt;bad&lt;/span&gt;
&lt;span class="go"&gt;notgood&lt;/span&gt;
&lt;span class="go"&gt;notright&lt;/span&gt;
&lt;span class="go"&gt;test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, create a test data file to try to&amp;nbsp;sign/encrypt:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;test input&amp;quot;&lt;/span&gt; &amp;gt; /tmp/test.in
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now we run the actual test (see below for more&amp;nbsp;information&amp;#8230;)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; &lt;span class="k"&gt;for &lt;/span&gt;p in &lt;span class="sb"&gt;`&lt;/span&gt;cat /tmp/passphrases&lt;span class="sb"&gt;`&lt;/span&gt;; &lt;span class="k"&gt;do &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$p&amp;quot;&lt;/span&gt; | gpg -q --sign --local-user &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; --passphrase-fd 0 --output /dev/null --yes /tmp/test.in &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: $p&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;break&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;; &lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0&lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0&lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0&lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0&lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: test&lt;/span&gt;
&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And there we have it, the working passphrase. I&amp;#8217;m sure there&amp;#8217;s a
    more efficient way to do this, and probably a more secure way, but
    I&amp;#8217;m not trying to brute-force someone&amp;#8217;s &lt;span class="caps"&gt;GPG&lt;/span&gt; key, I&amp;#8217;m trying to
    remember which one of my (many, many) passwords I used for a &lt;span class="caps"&gt;GPG&lt;/span&gt; key
    that I generated a decade&amp;nbsp;ago.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The actual command that we ran, rewritten with some linebreaks for
legibility,&amp;nbsp;is:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;for &lt;/span&gt;p in &lt;span class="sb"&gt;`&lt;/span&gt;cat /tmp/passphrases&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$p&amp;quot;&lt;/span&gt; | gpg -q --sign --local-user &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; --passphrase-fd 0 --output /dev/null --yes /tmp/test.in &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: $p&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;break&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This loops over each line in the passphrases file (each passphrase that
we want to try), and for each one, echoes the password and pipes it to
&lt;span class="caps"&gt;STDIN&lt;/span&gt; of &lt;code&gt;gpg&lt;/code&gt;, which tries to sign /tmp/test.in (sending the output
to /dev/null) using the key with &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;code&gt;17AD8D3D&lt;/code&gt; (from #5 in the
Preparation steps above) and a password provided on &lt;span class="caps"&gt;STDIN&lt;/span&gt;. If the &lt;span class="caps"&gt;GPG&lt;/span&gt;
command succeeds, we echo the passphrase and stop looping through the
passphrases&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;I hope I wouldn&amp;#8217;t have to say this for anyone who&amp;#8217;s reading my blog, but
this information (as easy as it is to be figured out), is not to be used
for unethical&amp;nbsp;purposes.&lt;/p&gt;</summary><category term="encryption"></category><category term="gnupg"></category><category term="gpg"></category><category term="key"></category><category term="passphrase"></category><category term="pgp"></category></entry><entry><title>Quick Tip: Timestamping bash history</title><link href="http://blog.jasonantman.com/2013/06/quick-tip-timestamping-bash-history/" rel="alternate"></link><updated>2013-06-11T07:09:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-11:2013/06/quick-tip-timestamping-bash-history/</id><summary type="html">&lt;p&gt;Here&amp;#8217;s a tiny little snippet that I have in my &lt;code&gt;.bashrc&lt;/code&gt; which really
comes in handy when trying to figure out what I did on a system when.
One of the first things I do when (eek) building out or working on a
one-off machine (or setting up a new laptop/desktop, as I am right now)
is set this in bashrc for my user and root, so I can go back and
document the setup process with a little more ease and sanity. Just add
this (it&amp;#8217;s just a &lt;a href="http://linux.die.net/man/3/strftime"&gt;strftime (3)&lt;/a&gt;
format string &lt;a href="http://www.gnu.org/software/bash/manual/bashref.html#index-HISTTIMEFORMAT"&gt;according to the
docs&lt;/a&gt;,
so adjust as desired) to &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;HISTTIMEFORMAT&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;%F %T &amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and bash will store commented-out integer timestamps before each line in
&lt;code&gt;.bash_history&lt;/code&gt; like&amp;nbsp;so:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt;1370950005
&lt;span class="go"&gt;less .bashrc&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950017
&lt;span class="go"&gt;history &lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950279
&lt;span class="go"&gt;tail -30 .bash_history &lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950293
&lt;span class="go"&gt;exit&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;the output of &lt;code&gt;history&lt;/code&gt; now uses the specified time&amp;nbsp;format:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt; 997  2013-06-11 07:26:45 less .bashrc
 998  2013-06-11 07:26:57 history 
 999  2013-06-11 07:31:19 tail -30 .bash_history 
1000  2013-06-11 07:31:33 exit
&lt;/pre&gt;&lt;/div&gt;</summary><category term="bash"></category><category term="history"></category><category term="shell"></category><category term="timestamp"></category></entry><entry><title>Modern (0.10.x+) NodeJS RPMs on CentOS/REHL 5 and 6</title><link href="http://blog.jasonantman.com/2013/06/modern-0-10-x-nodejs-rpms-on-centosrehl-5-and-6/" rel="alternate"></link><updated>2013-06-06T20:47:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-06:2013/06/modern-0-10-x-nodejs-rpms-on-centosrehl-5-and-6/</id><summary type="html">&lt;p&gt;I posted back in January about &lt;a href="/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt; Spec Files for nodejs 0.9.5 and v8
on CentOS
6&lt;/a&gt;. In
that post I also said that I was unable to get recent NodeJS to build on
CentOS 5 because of a long chain of dependencies including node-gyp, v8,
http-parser, glibc, etc. I said I couldn&amp;#8217;t get it to build. Well, I have
good news for both distro&amp;nbsp;versions.&lt;/p&gt;
&lt;p&gt;On the CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; 6 side, thanks to a lot of work by &lt;span class="caps"&gt;T. C.
&lt;/span&gt;Hollingsworth and others, NodeJS 0.10.5 is currently in the official
&lt;a href="http://fedoraproject.org/wiki/EPEL"&gt;&lt;span class="caps"&gt;EPEL&lt;/span&gt;&lt;/a&gt; repositories. They seem to be
keeping the packages pretty current, but if you need newer, you can
always grab the SRPMs from &lt;span class="caps"&gt;EPEL&lt;/span&gt; and build the newer versions. This is
great, because it means I no longer need to maintain the spec files and
do my own builds. I don&amp;#8217;t think I really did anything to help get this
package in &lt;span class="caps"&gt;EPEL&lt;/span&gt;, other than ping a few people and comment on a few&amp;nbsp;tickets.&lt;/p&gt;
&lt;p&gt;For CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; 5, I finally have packages, but they&amp;#8217;re not exactly
pretty. The dependency solving issues still stand; they&amp;#8217;re rooted at the
dependency of node-gyp which requires the v8 C++ JavaScript library, and
is required to compile shared object addons. The best solution that I
(and a few others) could find is simply not to build node-gyp, and not
to have support for addons or package any addons; we just have the
binaries that NodeJS&amp;#8217;s Makefile creates, and everything else is
interpreted. A &lt;a href="https://twitter.com/toxigenicpoem"&gt;coworker&lt;/a&gt; found
&lt;a href="https://github.com/kazuhisya/nodejs-rpm"&gt;https://github.com/kazuhisya/nodejs-rpm&lt;/a&gt;
which contains a configure patch and specfile for a dead-simple CentOS
5/6 &lt;span class="caps"&gt;RPM&lt;/span&gt; of NodeJS 0.10.9, which essentially just uses &lt;span class="caps"&gt;EPEL&lt;/span&gt;&amp;#8217;s python26
packages to power the NodeJS build process, configures and uses the
Makefile&amp;#8217;s &lt;code&gt;make binary&lt;/code&gt; command to spit out a NodeJS binary tarball,
and then packages that. That whole process way out of line from the
&lt;a href="http://fedoraproject.org/wiki/Packaging:Guidelines"&gt;Fedora Packaging
Guidelines&lt;/a&gt;, and
also only dumps out nodejs, nodejs-binary and nodejs-debuginfo packages,
so I also can&amp;#8217;t just substitute in a different package name in my puppet
manifests (which install nodejs, nodejs-devel and npm packages). So I
&lt;a href="https://github.com/jantman/nodejs-rpm-centos5"&gt;forked that repository&lt;/a&gt;
and made some changes to the specfile: I gave the package name a prefix
(&amp;#8220;cmgd_&amp;#8221;, since that&amp;#8217;s where I work these days) and some warnings in
the description, to make it abundantly clear that these packages are
very far from what you find in &lt;span class="caps"&gt;EPEL&lt;/span&gt; and other repositories, and broke
npm and the devel files out into their own subpackages. Hopefully this
spec file will be of use to someone else who also has the unfortunate
need of supporting recent NodeJS on CentOS 5. If there&amp;#8217;s enough
interest, I&amp;#8217;ll consider building the packages and putting them in a
repository&amp;nbsp;somewhere.&lt;/p&gt;
&lt;p&gt;You can see the NodeJS 0.10.9 on CentOS 5 spec file, a patch, and the
READMEs at
&lt;a href="https://github.com/jantman/nodejs-rpm-centos5"&gt;https://github.com/jantman/nodejs-rpm-centos5&lt;/a&gt;.
Patches and/or pull requests are greatly appreciated, especially from
anyone who wants to make the spec file more Fedora guidelines&amp;nbsp;compliant.&lt;/p&gt;</summary><category term="build"></category><category term="centos"></category><category term="EPEL"></category><category term="node"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="redhat"></category><category term="RHEL"></category><category term="rpm"></category><category term="specfile"></category></entry><entry><title>Script to easily rebuild a SRPM</title><link href="http://blog.jasonantman.com/2013/05/script-to-easily-rebuild-a-srpm/" rel="alternate"></link><updated>2013-05-28T10:26:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-28:2013/05/script-to-easily-rebuild-a-srpm/</id><summary type="html">&lt;p&gt;Between &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 and 6 the default &lt;span class="caps"&gt;RPM&lt;/span&gt; compression format was
changed to xz. As such, trying to build a recent Fedora or Cent6 &lt;span class="caps"&gt;SRPM&lt;/span&gt; on
Cent5 will error out with a message like
&lt;code&gt;error: unpacking of archive failed on file foo;51a4c2a5: cpio: MD5 sum mismatch&lt;/code&gt;
because tar on CentOS 5 doesn&amp;#8217;t support&amp;nbsp;xz.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a quick and dirty little script to use &lt;code&gt;rpm2cpio&lt;/code&gt; to rebuild a
&lt;span class="caps"&gt;SRPM&lt;/span&gt; using the host&amp;#8217;s native &lt;span class="caps"&gt;RPM&lt;/span&gt; compression. The latest version will
live at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/rebuild_srpm.sh"&gt;https://github.com/jantman/misc-scripts/blob/master/rebuild_srpm.sh&lt;/a&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;
&lt;span class="c"&gt;# Script to rebuild a &lt;span class="caps"&gt;SRPM&lt;/span&gt; 1:1, useful when you want to build a &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 6&lt;/span&gt;
&lt;span class="c"&gt;# &lt;span class="caps"&gt;SRPM&lt;/span&gt; on a &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 system that doesn&amp;#39;t support newer compression (cpio: &lt;span class="caps"&gt;MD5&lt;/span&gt; sum mismatch)&lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;
&lt;span class="c"&gt;# by Jason Antman &lt;/span&gt;
&lt;span class="c"&gt;# The latest version of this script will always live at:&lt;/span&gt;
&lt;span class="c"&gt;# &lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-h&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--help&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: rebuild_srpm.sh  &amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; ! -e &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: &lt;span class="caps"&gt;SRPM&lt;/span&gt; file not found: $1&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; ! which rpmbuild &amp;amp;&amp;gt; /dev/null
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rpmbuild could not be found. please install. (sudo yum install rpm-build)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; ! which rpm2cpio &amp;amp;&amp;gt; /dev/null
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rpm2cpio could not be found. please install. (sudo yum install rpm)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;dirname &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;basename &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;mktemp -d&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;STARTPWD&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Rebuilding $&lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;

&lt;span class="c"&gt;# copy srpm into tempdir&lt;/span&gt;
cp &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;

&lt;span class="nb"&gt;pushd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt; &amp;amp;&amp;gt;/dev/null

&lt;span class="c"&gt;# setup local build dir structure&lt;/span&gt;
mkdir -p rpm rpm/&lt;span class="caps"&gt;BUILD&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt; rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt; rpm/&lt;span class="caps"&gt;SPECS&lt;/span&gt; rpm/&lt;span class="caps"&gt;SRPMS&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/athlon rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/i&lt;span class="se"&gt;\[&lt;/span&gt;3456&lt;span class="se"&gt;\]&lt;/span&gt;86 rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/i386 rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/noarch rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/x86_64

&lt;span class="c"&gt;# setup rpmmacros file&lt;/span&gt;
cat /dev/null &amp;gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/.rpmmacros
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%_topdir        $&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;/rpm&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.rpmmacros

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Extracting &lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;pushd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt;/ &amp;amp;&amp;gt;/dev/null
rpm2cpio &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt; | cpio -idmv &amp;amp;&amp;gt;/dev/null
&lt;span class="nb"&gt;popd&lt;/span&gt; &amp;amp;&amp;gt;/dev/null

&lt;span class="c"&gt;# build the &lt;span class="caps"&gt;SRPM&lt;/span&gt; from the spec and sources&lt;/span&gt;
&lt;span class="c"&gt;# we&amp;#39;re just building a &lt;span class="caps"&gt;SRPM&lt;/span&gt; so we can ignore dependencies&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Rebuilding &lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;NEW_SRPM&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;rpmbuild -bs --nodeps --macros&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/.rpmmacros &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt;/*.spec | grep &lt;span class="s2"&gt;&amp;quot;^Wrote: &amp;quot;&lt;/span&gt; | awk &lt;span class="s1"&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Copying to $&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&amp;quot;&lt;/span&gt;
cp &lt;span class="nv"&gt;$NEW_SRPM&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;/

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Wrote file to $&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;/`basename $NEW_SRPM`&amp;quot;&lt;/span&gt;

&lt;span class="c"&gt;# cleanup&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;STARTPWD&lt;/span&gt;&lt;/span&gt;
rm -Rf &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="lzma"></category><category term="packaging"></category><category term="rpm"></category><category term="rpm2cpio"></category><category term="rpmbuild"></category><category term="srpm"></category><category term="xz"></category></entry><entry><title>Git Cheat Sheet</title><link href="http://blog.jasonantman.com/2013/05/git-cheat-sheet/" rel="alternate"></link><updated>2013-05-14T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-14:2013/05/git-cheat-sheet/</id><summary type="html">&lt;p&gt;I use &lt;a href="http://git-scm.com/"&gt;git&lt;/a&gt; quite a bit these days, both with an
internal server at work and with a bunch of my projects and random code
that now live on &lt;a href="https://github.com/jantman/"&gt;my github account&lt;/a&gt;. The
transition from &lt;span class="caps"&gt;SVN&lt;/span&gt; hasn&amp;#8217;t always been easy. Here&amp;#8217;s a quick cheat sheet
of some of the things that I usually&amp;nbsp;forget.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Show diff of the last&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git diff HEAD^..HEAD
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Roll back to version xyz of a specific file &lt;em&gt;(where xyz is a &lt;span class="caps"&gt;SHA1&lt;/span&gt;
    commit ref)&lt;/em&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout xyz path/to/file
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Undo any &lt;em&gt;unstaged&lt;/em&gt; changes to your&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -f
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Undo any staged and working directory&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git reset --hard
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update submodules after cloning a&amp;nbsp;repository:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git submodule update --init
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebase on current master to pull in new&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebase on current master, but for files that changed, take our
    version &lt;em&gt;(for some reason, a plain rebase seems to sometimes show
    conflicts on files that haven&amp;#8217;t changed in ages on master)&lt;/em&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase -s recursive -Xtheirs master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete a local&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git branch -d BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete a remote branch from&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin --delete BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Roll back your branch to the same state as the branch in&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git reset --hard origin/BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Revert a specific&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git revert COMMIT_HASH
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Track an upstream branch (i.e. in a project you&amp;nbsp;forked):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add --track master upstream https://github.com/user/project.git
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pull in upstream&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout master &amp;amp;&amp;amp; git fetch upstream &amp;amp;&amp;amp; git merge upstream/master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Merge &amp;#8220;stuff&amp;#8221; from someone else&amp;#8217;s fork into&amp;nbsp;yours:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add other-guys-repo URL_TO_REPO
git fetch other-guys-repo
git checkout my_new_branch
git merge other-guys-repo/master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prune local branches that have been deleted in the remote&amp;nbsp;(origin):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote prune origin
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;</summary><category term="git"></category></entry><entry><title>Search for a small-scale but automated RPM build system</title><link href="http://blog.jasonantman.com/2013/05/search-for-a-small-scale-but-automated-rpm-build-system/" rel="alternate"></link><updated>2013-05-13T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-13:2013/05/search-for-a-small-scale-but-automated-rpm-build-system/</id><summary type="html">&lt;p&gt;&lt;strong&gt;This post is part of a series of older draft posts from a few months
ago that I&amp;#8217;m just getting around to publishing. Unfortunately, I have
yet to find a build system that meets my requirements (see the last&amp;nbsp;paragraph).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At work, we have a handful - currently a really small number - of &lt;span class="caps"&gt;RPM&lt;/span&gt;
packages that we need to build and deploy internally for our CentOS
server infrastructure. A number of them are just pulled down from
specific third-party repositories and rebuilt to have the vendor set as
us, and some are internally patched or developed software. We run
websites, and on the product side, we&amp;#8217;re a
Python/&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; shop (in fact, probably
one of the largest Django apps out there). We don&amp;#8217;t deploy our Django
apps via &lt;span class="caps"&gt;RPM&lt;/span&gt;, so building and distributing RPMs is definitely not one of
our core competencies. In fact, we really only want to do it when we&amp;#8217;re
testing/deploying a new distro, or when an upstream package is&amp;nbsp;updated.&lt;/p&gt;
&lt;p&gt;Last week I pulled a ticket to deploy &lt;a href="http://nodejs.org/"&gt;node.js&lt;/a&gt; to
one of our build hosts, and we&amp;#8217;ve got a few things in the pipeline that
also rely on it. I found the
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module on Github that&amp;#8217;s supposed to install it on &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS, but it
pulls packages from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;,
and the newest version of nodejs there is 0.6.18, which is quite old. I
can&amp;#8217;t find any actively maintained sources of newer nodejs packages for
&lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS (yeah, I know, that&amp;#8217;s one down side to the
distributions&amp;#8230;). However, I did find that nodejs 0.9.5 is being &lt;a href="http://koji.fedoraproject.org/koji/packageinfo?packageID=15154"&gt;built
for Fedora 18/19 in the Fedora build
system&lt;/a&gt;,
is already in the Fedora 18 Testing and Fedora Rawhide repos, but is
failing its &lt;span class="caps"&gt;EL6&lt;/span&gt; builds in their system. The decision I&amp;#8217;ve come to is to
use the puppetlabs-nodejs module to install it, but try and rebuild the
Fedora 18 RPMs under CentOS 5 and&amp;nbsp;6.&lt;/p&gt;
&lt;p&gt;So that&amp;#8217;s the background. Now, my current task: to search for an &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system for my current job. My core requirements, in no specific
order,&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be relatively easy and quick to use for people who have a specfile
    or &lt;span class="caps"&gt;SRPM&lt;/span&gt; and want to be able to &amp;#8220;ensure =&gt; present&amp;#8221; the finished &lt;span class="caps"&gt;RPM&lt;/span&gt;
    on a system. i.e., require as little per-package configuration as&amp;nbsp;possible.&lt;/li&gt;
&lt;li&gt;Be able to handle rebuilding &amp;#8220;all&amp;#8221; of our RPMs when we roll out a
    new distro version. Doesn&amp;#8217;t necessarily need to be automatic, but
    should be relatively&amp;nbsp;simple.&lt;/li&gt;
&lt;li&gt;Ideally, not need to be running constantly - i.e. something that
    will cope well with build hosts being VMs that are shut down when
    they&amp;#8217;re not&amp;nbsp;needed.&lt;/li&gt;
&lt;li&gt;Handle automatically putting successfully built packages into a
    repository, ideally with some sort of (manual) promotion process
    from staging to&amp;nbsp;stable.&lt;/li&gt;
&lt;li&gt;Have minimal external (infrastructure) dependencies that we can&amp;#8217;t
    satisfy with existing&amp;nbsp;systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the first step was to research existing &lt;span class="caps"&gt;RPM&lt;/span&gt; build systems and how
others do this. Here&amp;#8217;s a list of what I could find online, though most
of these are from distributions and software vendors/projects, not
end-user companies that are only building for internal&amp;nbsp;use.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://fedorahosted.org/koji/wiki"&gt;Koji&lt;/a&gt; is the build system used
    by &lt;a href="http://fedoraproject.org/wiki/Koji"&gt;Fedora&lt;/a&gt; and RedHat. It&amp;#8217;s
    about as full-featured as any can be, and I&amp;#8217;m familiar with it from
    my time at &lt;a href="http://koji.rutgers.edu/koji/"&gt;Rutgers University&lt;/a&gt;, as
    it&amp;#8217;s used to maintain their CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; packages. It&amp;#8217;s based largely
    on Mock. However, &lt;a href="http://fedoraproject.org/wiki/Koji/ServerHowTo"&gt;setting up the build
    server&lt;/a&gt; is no
    trivial task; there are few installations outside of Fedora/RedHat,
    and it relies on either Kerberos or an &lt;span class="caps"&gt;SSL&lt;/span&gt; &lt;span class="caps"&gt;CA&lt;/span&gt; infrastructure to
    authenticate machines and clients. So, it&amp;#8217;s designed for too large a
    scale and too much infrastructure for&amp;nbsp;me.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux has a &lt;a href="https://www.pld-linux.org/developingpld/builderscript"&gt;builder
    script&lt;/a&gt; that
    seems to automate &lt;code&gt;rpmbuild&lt;/code&gt; as well as fetching sources and
    resolving/building dependencies. I haven&amp;#8217;t looked at the script yet,
    but apparently it&amp;#8217;s in &lt;span class="caps"&gt;PLD&lt;/span&gt;&amp;#8217;s &amp;#8220;rpm-build-tools&amp;#8221;&amp;nbsp;package.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux also has a &lt;span class="caps"&gt;CVS&lt;/span&gt; repository for something called
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new"&gt;pld-builder.new&lt;/a&gt;.
    The
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/README?rev=1.5"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;
    and
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/ARCHITECTURE?rev=1.6"&gt;&lt;span class="caps"&gt;ARCHITECTURE&lt;/span&gt;&lt;/a&gt;
    files make it sound like a relatively simple mainly-Python system
    that builds &lt;span class="caps"&gt;SRPMS&lt;/span&gt; and binary packages when requested, and most
    importantly, seems like a simple system that uses little more than
    shared filesystem access for communication and&amp;nbsp;coordination.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;ALT&lt;/span&gt; Linux has &lt;a href="http://en.altlinux.org/Sisyphus"&gt;Sisyphus&lt;/a&gt;, which
    combines repository management and web interface tools, package
    building and testing tools, and&amp;nbsp;more.&lt;/li&gt;
&lt;li&gt;The Dries &lt;span class="caps"&gt;RPM&lt;/span&gt; repository uses (or at least used&amp;#8230; my reference is
    quite old) &lt;a href="http://dries.ulyssis.org/rpm/pydar2/index.html"&gt;pydar2&lt;/a&gt;,
    &amp;#8220;a distributed client/server program which allows you to build
    multiple spec files on multiple distribution/architecture
    combinations automatically.&amp;#8221; That sounds like it could be what I
    need, but the last update says that it isn&amp;#8217;t finished yet, and that
    was in &lt;strong&gt;2005&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Mandriva Linux has pretty extensive information on their build
    system &lt;a href="http://wiki.mandriva.com/en/Category:Build_System"&gt;on their
    wiki&lt;/a&gt; and a
    &lt;a href="http://wiki.mandriva.com/en/Development/Packaging/BuildSystem/Theory"&gt;build system theory
    page&lt;/a&gt;,
    but it seems to be largely a hodgepodge of shell scripts and
    cronjobs, and is likely not a candidate for use by anyone other than
    its&amp;nbsp;designers.&lt;/li&gt;
&lt;li&gt;Argeo provides the &lt;a href="https://www.argeo.org/wiki/SLC"&gt;&lt;span class="caps"&gt;SLC&lt;/span&gt; framework&lt;/a&gt;
    which has a &amp;#8220;&lt;span class="caps"&gt;RPM&lt;/span&gt; Factory&amp;#8221; component, but I can&amp;#8217;t seem to find much
    more than a wiki page, and can&amp;#8217;t tell if it&amp;#8217;s a build automation
    system or just handles mocking packages and putting them in a repo
    on a single&amp;nbsp;host.&lt;/li&gt;
&lt;li&gt;Dag Wieers&amp;#8217; repositories use (or used) a set of python scripts
    called &lt;a href="http://dag.wieers.com/home-made/dar/"&gt;&lt;span class="caps"&gt;DAR&lt;/span&gt;, &amp;#8220;Dynamic Apt Repository
    builder&amp;#8221;&lt;/a&gt;. They&amp;#8217;re on
    &lt;a href="https://github.com/dagwieers/dar"&gt;github&lt;/a&gt; but are listed as &amp;#8220;old&amp;#8221;
    and haven&amp;#8217;t been updated in at least 2 years. The features sound
    quite interesting, and though it&amp;#8217;s based on the Apt repo format, it
    might provide some good ideas for implementing a similar&amp;nbsp;system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Update four months later:&lt;/strong&gt; I&amp;#8217;ve yet to find a build system that meets
my requirements above. For the moment I&amp;#8217;m only managing \~20 packages,
so my &amp;#8220;build system&amp;#8221; is a single shell script that reads in some
environment variables and runs through using
&lt;a href="http://fedoraproject.org/wiki/Projects/Mock"&gt;mock&lt;/a&gt; to build them in the
correct order (including pushing the finished RPMs back into the local
repository that mock reads from) and then pushing the finished packages
to our internal repository. Maybe when I have some spare time, I&amp;#8217;ll
consider a project to either make a slightly better (but simple) &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system based on Python, or get our
&lt;a href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; install to handle this for&amp;nbsp;me.&lt;/p&gt;</summary><category term="build"></category><category term="linux"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="repository"></category><category term="rpm"></category><category term="rpmbuild"></category><category term="software"></category><category term="sysadmin"></category><category term="yum"></category></entry><entry><title>Environment Variable Substitution in Apache httpd Configs</title><link href="http://blog.jasonantman.com/2013/05/environment-variable-substitution-in-apache-httpd-configs/" rel="alternate"></link><updated>2013-05-11T12:01:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-11:2013/05/environment-variable-substitution-in-apache-httpd-configs/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been configuring Apache httpd for over a decade, from a single
personal web server to web farms running thousands of vhosts. In most of
the &amp;#8220;real&amp;#8221; environments I&amp;#8217;ve worked in, we&amp;#8217;ve had some variation of
production, stage/test/&lt;span class="caps"&gt;QA&lt;/span&gt; and development hosts; and usually some method
of managing configurations between them, whether it&amp;#8217;s source control or
generating them from template. And in all of these environments, there
has invariably been drift between the configurations in the various
environments, whether it&amp;#8217;s because of poor tools to maintain a unified
configuration or many of those emergency redirect requests that make it
into production but are never backported. This is made all the worse
because everywhere I&amp;#8217;ve worked, the real difference between what
production and other environments &lt;em&gt;should&lt;/em&gt; be is really just a string
replacement in Apache configurations - &lt;code&gt;/prod/&lt;/code&gt; to &lt;code&gt;/test/&lt;/code&gt; or
&lt;code&gt;www.example.com&lt;/code&gt; to &lt;code&gt;www.dev.example.com&lt;/code&gt; or something along those&amp;nbsp;lines.&lt;/p&gt;
&lt;p&gt;Well a few days ago I was having a discussion with some co-workers that
dovetailed into this topic, and when I started some research, I found
(&lt;em&gt;finally after using httpd for years&lt;/em&gt;) that the &lt;a href="http://httpd.apache.org/docs/2.2/configuring.html#syntax"&gt;Apache httpd 2.2
configuration file syntax
documentation&lt;/a&gt;
states that httpd supports environment variable interpolation anywhere
in the config files (and &lt;a href="http://httpd.apache.org/docs/2.4/configuring.html#syntax"&gt;httpd
2.4&lt;/a&gt; supports
it with Defines as&amp;nbsp;well).&lt;/p&gt;
&lt;p&gt;Yup, that&amp;#8217;s right. All those different Apache configs I&amp;#8217;ve worked with
for years that define separate vhosts, document roots, rewrite targets,
ServerAliases, etc. for &lt;code&gt;www.example.com&lt;/code&gt; and &lt;code&gt;www.qa.example.com&lt;/code&gt; and
&lt;code&gt;www.dev.example.com&lt;/code&gt; really only had to be
&lt;code&gt;www.${ENV_URL_PART}example.com&lt;/code&gt;, and set &lt;code&gt;ENV_URL_PART&lt;/code&gt; in the init
script or sysconfig file. (Of course this all assumes that you have your
different environments served by different httpd instances, which you
do, of&amp;nbsp;course&amp;#8230;)&lt;/p&gt;
&lt;p&gt;For me, this is a very big deal. It means that finally, instead of
maintaining separate sets of configs for different environments which
are (theoretically, except for those emergencies) kept identical by
hand, or updating templates and then re-generating each environment&amp;#8217;s
configs, we can finally follow the same
commit/merge/promotion-between-environments workflow that we use for
other production code and Puppet configuration. It also means that those
pesky little rewrites and other minor tweaks will make it all the way
back to development&amp;nbsp;environments.&lt;/p&gt;
&lt;p&gt;So, here&amp;#8217;s a little example of how this would work in reality. Let&amp;#8217;s
assume that we have 3 main environments, &lt;code&gt;prod&lt;/code&gt;, &lt;code&gt;qa&lt;/code&gt; and &lt;code&gt;dev&lt;/code&gt; (though
this should work for N environments) and that domains are prefixed with
&amp;#8220;qa.&amp;#8221; or &amp;#8220;dev.&amp;#8221; for the respective internal environments. We set
environment variables before httpd is started, on a per-host basis,
depending on what environment that host is in. On RedHat based systems,
we&amp;#8217;d add the variables to &lt;code&gt;/etc/sysconfig/httpd&lt;/code&gt; for&amp;nbsp;production:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;HTTPD_ENV_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;prod&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;HTTPD_ENV_URL_PART&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;or for&amp;nbsp;&lt;span class="caps"&gt;QA&lt;/span&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;HTTPD_ENV_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;qa&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;HTTPD_ENV_URL_PART&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;qa.&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Those variables will now be available to httpd within the configurations
(and also to any applications or scripts that have access to the web
server&amp;#8217;s environment&amp;nbsp;variables).&lt;/p&gt;
&lt;p&gt;Now let&amp;#8217;s look at an example vhost configuration file that uses the
environment&amp;nbsp;variables:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;ServerName&lt;/span&gt; example.com
&lt;span class="nb"&gt;ServerAlias&lt;/span&gt; www.example.com
&lt;span class="c"&gt;# Aliases including proper environment name&lt;/span&gt;
&lt;span class="nb"&gt;ServerAlias&lt;/span&gt; www.${HTTPD_ENV_NAME}.example.com ${HTTPD_ENV_NAME}.example.com

&lt;span class="nb"&gt;ErrorLog&lt;/span&gt; &lt;span class="sx"&gt;/var/log/httpd/example.com-error_log&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; &lt;span class="sx"&gt;/var/log/httpd/example.com-access_log&lt;/span&gt; combined

&lt;span class="nb"&gt;DocumentRoot&lt;/span&gt; &lt;span class="sx"&gt;/sites/example.com/&lt;/span&gt;${HTTPD_ENV_NAME}/

&lt;span class="c"&gt;# Environment-specific configuration, if we absolutely need it:&lt;/span&gt;
&lt;span class="nb"&gt;Include&lt;/span&gt; &lt;span class="sx"&gt;/etc/httpd/sites/&lt;/span&gt;${HTTPD_ENV_NAME}/env.conf


&lt;span class="nb"&gt;RewriteEngine&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt;
&lt;span class="nb"&gt;RewriteRule&lt;/span&gt; &lt;span class="sx"&gt;/foobar/.&lt;/span&gt;* http://www.${HTTPD_ENV_URL_PART}example.com/baz/ [R=302,L]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Every instance of &lt;code&gt;${HTTPD_ENV_NAME}&lt;/code&gt; will be replaced with the value
set in the sysconfig file, and likewise with every instance of
&lt;code&gt;${HTTPD_ENV_URL_PART}&lt;/code&gt;. This way, we can have one set of configurations
and use our normal source control branch/promotion process to both test
and promote changes through the environments along with application
code, and ensure that any straight-to-production emergency changes
(everyone has customer-ordered rewrites like that, right?) make it back
to development and&amp;nbsp;qa.&lt;/p&gt;
&lt;p&gt;One caveat is that, if the environment variable is not defined, the
&lt;code&gt;${VAR_NAME}&lt;/code&gt; will be left as a literal string in the configuration
file. There doesn&amp;#8217;t seem to be any way to protect against this in httpd
2.2, other than making sure the variables are set before the server
starts (and maybe setting logical default values, like an empty string,
in your init script which should be overridden by the sysconfig&amp;nbsp;file).&lt;/p&gt;
&lt;p&gt;If you&amp;#8217;re running httpd 2.4+, you can turn on
&lt;a href="http://httpd.apache.org/docs/2.4/mod/mod_info.html"&gt;mod_info&lt;/a&gt; and
browse to &lt;code&gt;http://servername/server-info?config&lt;/code&gt; to dump the current
configuration, which will show the variable&amp;nbsp;substitution.&lt;/p&gt;</summary><category term="apache"></category><category term="environment"></category><category term="httpd"></category><category term="variable"></category></entry><entry><title>RPM Spec Files for nodejs 0.9.5 and v8 on CentOS 6</title><link href="http://blog.jasonantman.com/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/" rel="alternate"></link><updated>2013-01-31T14:13:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-01-31:2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/</id><summary type="html">&lt;p&gt;The latest version of nodejs that I could find as an &lt;span class="caps"&gt;RPM&lt;/span&gt; for CentOS was
0.6.16, from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;.
That&amp;#8217;s the one that puppetlabs currently uses in their
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module. There is, however, a nodejs 0.9.5 &lt;span class="caps"&gt;RPM&lt;/span&gt; in the Fedora Rawhide (19)
repository. Below are some patches to that specfile, and the specfile
for its v8 dependency, to get them to build on CentOS 6. You can also
find the full specfiles on my &lt;a href="https://github.com/jantman/specfiles"&gt;github specfile
repository&lt;/a&gt;. I had originally
wanted to get them built on CentOS 5 as well, but after following the
dependency tree from nodejs to http-parser to gyp, and then finding
issues in the gyp source that are incompatible with CentOS 5&amp;#8217;s python
2.4, I gave up on that&amp;nbsp;target.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nodejs.spec&lt;/strong&gt;, diff from Fedora Rawhide nodejs-0.9.5-9.fc18.src.rpm,
buildID=377755 (&lt;a href="https://raw.github.com/jantman/specfiles/master/nodejs.spec"&gt;full
specfile&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff --git a/nodejs.spec b/nodejs.spec&lt;/span&gt;
&lt;span class="gh"&gt;index 050ed86..86c0f4b 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/nodejs.spec&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/nodejs.spec&lt;/span&gt;
&lt;span class="gu"&gt;@@ -1,6 +1,6 @@&lt;/span&gt;
 Name: nodejs
 Version: 0.9.5
&lt;span class="gd"&gt;-Release: 9%{?dist}&lt;/span&gt;
&lt;span class="gi"&gt;+Release: 10%{?dist}&lt;/span&gt;
 Summary: JavaScript runtime
 License: &lt;span class="caps"&gt;MIT&lt;/span&gt; and &lt;span class="caps"&gt;ASL&lt;/span&gt; 2.0 and &lt;span class="caps"&gt;ISC&lt;/span&gt; and &lt;span class="caps"&gt;BSD&lt;/span&gt;
 Group: Development/Languages
&lt;span class="gu"&gt;@@ -25,7 +25,7 @@ Source6: nodejs-fixdep&lt;/span&gt;
 BuildRequires: v8-devel &amp;gt;= %{v8_ge}
 BuildRequires: http-parser-devel &amp;gt;= 2.0
 BuildRequires: libuv-devel
&lt;span class="gd"&gt;-BuildRequires: c-ares-devel&lt;/span&gt;
&lt;span class="gi"&gt;+BuildRequires: c-ares-devel &amp;gt;= 1.9.0&lt;/span&gt;
 BuildRequires: zlib-devel
 # Node.js requires some features from openssl 1.0.1 for &lt;span class="caps"&gt;SPDY&lt;/span&gt; support
 BuildRequires: openssl-devel &amp;gt;= 1:1.0.1
&lt;span class="gu"&gt;@@ -165,9 +165,13 @@ cp -p common.gypi %{buildroot}%{_datadir}/node&lt;/span&gt;

 %files docs
 %{_defaultdocdir}/%{name}-docs-%{version}
&lt;span class="gd"&gt;-%doc &lt;span class="caps"&gt;LICENSE&lt;/span&gt;&lt;/span&gt;

 %changelog
&lt;span class="gi"&gt;+* Thu Jan 31 2013 Jason Antman  - 0.9.5-10&lt;/span&gt;
&lt;span class="gi"&gt;+- specify build requirement of c-ares-devel &amp;gt;= 1.9.0&lt;/span&gt;
&lt;span class="gi"&gt;+- specify build requirement of libuv-devel 0.9.4&lt;/span&gt;
&lt;span class="gi"&gt;+- remove duplicate %doc &lt;span class="caps"&gt;LICENSE&lt;/span&gt; that was causing cpio &amp;#39;Bad magic&amp;#39; error on CentOS6&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
 * Sat Jan 12 2013 &lt;span class="caps"&gt;T.C.&lt;/span&gt; Hollingsworth  - 0.9.5-9
 - fix brown paper bag bug in requires generation script
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;v8.spec&lt;/strong&gt;, diff from Fedora Rawhide 3.13.7.5-2 (&lt;a href="https://raw.github.com/jantman/specfiles/master/v8.spec"&gt;full
specfile&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gd"&gt;--- v8.spec.orig       2013-01-26 16:03:18.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ v8.spec     2013-01-31 09:04:51.068029459 -0500&lt;/span&gt;
&lt;span class="gu"&gt;@@ -21,9 +21,11 @@&lt;/span&gt;

 # %%global svnver 20110721svn8716

&lt;span class="gi"&gt;+%{!?python_sitelib: %define python_sitelib %(%{__python} -c &amp;quot;import distutils.sysconfig as d; print d.get_python_lib()&amp;quot;)}&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
 Name:          v8
 Version:       %{somajor}.%{sominor}.%{sobuild}.%{sotiny}
&lt;span class="gd"&gt;-Release:       2%{?dist}&lt;/span&gt;
&lt;span class="gi"&gt;+Release:       5%{?dist}&lt;/span&gt;
 Epoch:         1
 Summary:       JavaScript Engine
 Group:         System Environment/Libraries
&lt;span class="gu"&gt;@@ -32,7 +34,7 @@&lt;/span&gt;
 Source0:       http://commondatastorage.googleapis.com/chromium-browser-official/v8-%{version}.tar.bz2
 BuildRoot:     %{_tmppath}/%{name}-%{version}-%{release}-root-%(%{__id_u} -n)
 ExclusiveArch: %{ix86} x86_64 %{arm}
&lt;span class="gd"&gt;-BuildRequires: scons, readline-devel, libicu-devel&lt;/span&gt;
&lt;span class="gi"&gt;+BuildRequires: scons, readline-devel, libicu-devel, ncurses-devel&lt;/span&gt;

 %description
 V8 is Google&amp;#39;s open source JavaScript engine. V8 is written in C++ and is used 
&lt;span class="gu"&gt;@@ -51,8 +53,13 @@&lt;/span&gt;
 %setup -q -n %{name}-%{version}

 # -fno-strict-aliasing is needed with gcc 4.4 to get past some ugly code
&lt;span class="gd"&gt;-PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -Wno-error=strict-overflow -Wno-error=unused-local-typedefs -Wno-unused-but-set-variable\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
&lt;span class="gi"&gt;+%if 0%{?el5}&lt;/span&gt;
&lt;span class="gi"&gt;+PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -lncurses\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
&lt;span class="gi"&gt;+sed -i &amp;quot;s|&amp;#39;-O3&amp;#39;,|$PARSED_OPT_FLAGS,|g&amp;quot; SConstruct&lt;/span&gt;
&lt;span class="gi"&gt;+%else&lt;/span&gt;
&lt;span class="gi"&gt;+PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -Wno-error=strict-overflow -Wno-unused-but-set-variable\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
 sed -i &amp;quot;s|&amp;#39;-O3&amp;#39;,|$PARSED_OPT_FLAGS,|g&amp;quot; SConstruct
&lt;span class="gi"&gt;+%endif&lt;/span&gt;

 # clear spurious executable bits
 find . \( -name \*.cc -o -name \*.h -o -name \*.py \) -a -executable   
&lt;span class="gu"&gt;@@ -198,6 +205,17 @@&lt;/span&gt;
 %{python_sitelib}/j*.py*

 %changelog
&lt;span class="gi"&gt;+* Thu Jan 31 2013 Jason Antman  - 1:3.13.7.5-5&lt;/span&gt;
&lt;span class="gi"&gt;+- remove -Werror=unused-local-typedefs on cent6&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+* Wed Jan 30 2013 Jason Antman  - 1:3.13.7.5-4&lt;/span&gt;
&lt;span class="gi"&gt;+- define python_sitelib if it isn&amp;#39;t already (CentOS 5)&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+* Wed Jan 30 2013 Jason Antman  - 1:3.13.7.5-3&lt;/span&gt;
&lt;span class="gi"&gt;+- pull 3.13.7.5-2 &lt;span class="caps"&gt;SRPM&lt;/span&gt; from Fedora 19 Koji most recent build&lt;/span&gt;
&lt;span class="gi"&gt;+- add ncurses-devel BuildRequires&lt;/span&gt;
&lt;span class="gi"&gt;+- modify PARSED_OPT_FLAGS to work with g++ 4.1.2 on CentOS 5&lt;/span&gt;
&lt;span class="gi"&gt;+ &lt;/span&gt;
 * Sat Jan 26 2013 &lt;span class="caps"&gt;T.C.&lt;/span&gt; Hollingsworth  - 1:3.13.7.5-2
 - rebuild for icu-50
 - ignore new &lt;span class="caps"&gt;GCC&lt;/span&gt; 4.8 warning
&lt;/pre&gt;&lt;/div&gt;</summary><category term="build"></category><category term="centos"></category><category term="node"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="redhat"></category><category term="RHEL"></category><category term="rpm"></category><category term="specfile"></category></entry><entry><title>Fedora Linux and OSX Dual Boot on Mid-2010 (6,2) 15” MacBook Pro Laptop</title><link href="http://blog.jasonantman.com/2013/01/fedora-linux-and-osx-dual-boot-on-mid-2010-62-15-macbook-pro-laptop/" rel="alternate"></link><updated>2013-01-21T12:13:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-01-21:2013/01/fedora-linux-and-osx-dual-boot-on-mid-2010-62-15-macbook-pro-laptop/</id><summary type="html">&lt;p&gt;As part of the transition from a contractor to a full-time employee of
&lt;a href="http://www.cmgdigital.com"&gt;Cox Media Group Digital &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Strategy&lt;/a&gt; (check
out our &lt;a href="https://github.com/cmgdigital"&gt;github&lt;/a&gt;), I&amp;#8217;ve been issued a
&lt;a href="http://support.apple.com/kb/SP582"&gt;Mid-2010 (6,2)&lt;/a&gt; 15&amp;#8221; &lt;a href="http://en.wikipedia.org/wiki/Macbook_pro#Technical_specifications_2"&gt;MacBook
Pro&lt;/a&gt;
laptop, to replace my current &lt;a href="http://support.apple.com/kb/SP11"&gt;Early-2008
(3,1)&lt;/a&gt; MacPro desktop. The desktop is
currently running &lt;a href="http://fedoraproject.org/"&gt;Fedora&lt;/a&gt; 17, dual-boot with
with Mac &lt;span class="caps"&gt;OS&lt;/span&gt; X (left in place for firmware updates and emergencies) using
the &lt;a href="http://www.rodsbooks.com/refind/index.html"&gt;rEFInd boot manager&lt;/a&gt; to
choose between the two OSes. It took me two days to get this working
right on my desktop, but it had been my plan to duplicate this setup on
my laptop. I found a lot of conflicting information online, but I
decided to give it a&amp;nbsp;try.&lt;/p&gt;
&lt;p&gt;Well, I have Fedora 18 and &lt;span class="caps"&gt;OS&lt;/span&gt; X 10.8 dual-booting on the laptop, but not
as planned. After a day and a half of research, troubleshooting and
re-installs, here&amp;#8217;s what I found to actually work, in the hope that
nobody else will go through the ordeal I went through. Following that
are some notes about the new Fedora 18 installer (Anaconda 18),
especially important for anyone who&amp;#8217;s used Linux for a while. To those
who are new to Linux, don&amp;#8217;t be dissuaded by the above. Most of the
frustration I experienced is because I&amp;#8217;ve been using Linux for a
relatively long time (about 10 years), had my own ideas about exactly
how I wanted things setup (which are decidedly &lt;em&gt;not&lt;/em&gt; supported by
Fedora), and had some assumptions about the installation process based
on earlier&amp;nbsp;versions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to get it&amp;nbsp;working:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Forget about rEFInd. This had been the original advice from &lt;a href="http://mjg59.dreamwidth.org/"&gt;Matthew
Garrett&lt;/a&gt;,
&lt;a href="https://twitter.com/mjg59"&gt;@mjg59&lt;/a&gt;, kernel coder, contributor to the
Anaconda project, and all-around authority on booting Linux on &lt;span class="caps"&gt;EFI&lt;/span&gt;/&lt;span class="caps"&gt;UEFI&lt;/span&gt;
hardware. My advice, and the method that worked for&amp;nbsp;me:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shrink your Mac partitions and leave as much free space as you want
    for Fedora. using the Disk Utility tool in &lt;span class="caps"&gt;OS&lt;/span&gt; X (I also created an
    &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;VFAT&lt;/span&gt; partition that both OSes can read/write&amp;nbsp;to).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://fedoraproject.org/en/get-fedora"&gt;Download Fedora 18&lt;/a&gt; 64-bit
    &lt;span class="caps"&gt;DVD&lt;/span&gt; image, I chose the &lt;span class="caps"&gt;KDE&lt;/span&gt; version. Verify the sha256 sum if you
    want (they don&amp;#8217;t have a readily visible link to the checksum file.
    Copy the download link, paste it into your address bar and remove
    the filename. You should get a directory index that includes a
    &lt;code&gt;-CHECKSUM&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Per the Installation Guide&amp;#8217;s &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/Making_USB_Media-UNIX_Linux.html"&gt;Making Fedora &lt;span class="caps"&gt;USB&lt;/span&gt; Media
    page&lt;/a&gt;,
    use &lt;code&gt;liveusb-creator&lt;/code&gt; to setup the installation image on the &lt;span class="caps"&gt;USB&lt;/span&gt;
    flash drive (I needed to start it with the &lt;code&gt;--reset-mbr&lt;/code&gt; option).
    You can also use other tools (dd if you&amp;#8217;re not on a Fedora-based
    distro), or a &lt;span class="caps"&gt;DVD&lt;/span&gt;, but this is the method I&amp;nbsp;chose.&lt;/li&gt;
&lt;li&gt;Due to a &lt;a href="https://fedorahosted.org/liveusb-creator/ticket/810"&gt;bug in
    liveusb-creator&lt;/a&gt;,
    you may need to manually edit &lt;code&gt;/EFI/boot/grub.cfg&lt;/code&gt; on the created
    &lt;span class="caps"&gt;USB&lt;/span&gt; stick if grub gives you a file not found error. If that happens,
    please see my bug report above for the action to take (in short, you
    need to mount the &lt;span class="caps"&gt;USB&lt;/span&gt; stick, &lt;code&gt;chmod u+w /EFI/boot/grub.cfg&lt;/code&gt; then
    edit that file and replace every occurrence of &amp;#8220;isolinux&amp;#8221; with
    &amp;#8220;syslinux&amp;#8221; and every occurrence of
    &amp;#8220;root=live:&lt;span class="caps"&gt;LABEL&lt;/span&gt;=Fedora-18-x86_64-Live-&lt;span class="caps"&gt;KDE&lt;/span&gt;.iso&amp;#8221; with&amp;nbsp;&amp;#8220;root=live:&lt;span class="caps"&gt;LABEL&lt;/span&gt;=&lt;span class="caps"&gt;LIVE&lt;/span&gt;&amp;#8221;).&lt;/li&gt;
&lt;li&gt;Boot the &lt;span class="caps"&gt;USB&lt;/span&gt; drive (use the alt key when you turn on the laptop to
    select the &lt;span class="caps"&gt;USB&lt;/span&gt; drive) and just install Fedora normally, letting it
    do its thing. Select a boot disk and let it put &lt;span class="caps"&gt;GRUB2&lt;/span&gt; on the &lt;span class="caps"&gt;EFI&lt;/span&gt;&amp;nbsp;partition.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When you boot, it will boot to &lt;span class="caps"&gt;GRUB&lt;/span&gt;. There will be some options for Mac
&lt;span class="caps"&gt;OS&lt;/span&gt; there, but they don&amp;#8217;t work (more on that below). If you want to boot
Mac, hold down the alt/option key when you power on the laptop, which
will bring you to the boot disk selector and you can pick the Mac disk.
I know it&amp;#8217;s not pretty or ideal, but it&amp;#8217;s the best option right&amp;nbsp;now.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Making it&amp;nbsp;Better:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;GRUB2&lt;/span&gt; tries to automatically detect other OSes and configure them in the
boot loader (this is done through &lt;code&gt;/etc/grub.d/30_os-prober&lt;/code&gt;, commonly
just referred to as &lt;code&gt;os-prober&lt;/code&gt;). It tries to boot Mac directly through
the xnu_kernel64 module, which not only isn&amp;#8217;t installed on the boot
partition by default, but just doesn&amp;#8217;t work with at least Mountain Lion
(10.8). So getting &lt;span class="caps"&gt;GRUB&lt;/span&gt; to boot Mac means either having the bugs in the
xnu module fixed, or figuring out how to setup a chainloader to boot
from &lt;span class="caps"&gt;GRUB&lt;/span&gt; to Mac. The latter is probably the method I&amp;#8217;ll investigate,
but for now, since I rarely use Mac, I&amp;#8217;m happy having to use the alt key
at boot to get there. To remove the annoying, broken Mac &lt;span class="caps"&gt;OS&lt;/span&gt; options from
the grub screen, run the following commands as root (they assume you
have your &lt;span class="caps"&gt;EFI&lt;/span&gt; partition mounted at &lt;code&gt;/boot/efi&lt;/code&gt; which I believe Fedora
should do by&amp;nbsp;default:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;cp /boot/efi/EFI/fedora/grub.cfg /boot/efi/EFI/fedora/grub.cfg.bak
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;GRUB_DISABLE_OS_PROBER=&amp;quot;true&amp;quot;&amp;#39;&lt;/span&gt; &amp;gt;&amp;gt; /etc/default/grub
grub2-mkconfig &amp;gt; /boot/efi/&lt;span class="caps"&gt;EFI&lt;/span&gt;/fedora/grub.cfg
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Thoughts on the Fedora 18 Anaconda&amp;nbsp;Installer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I found a couple of issues with the new Anaconda 18 installer that were
either unweildy or confusing for someone who&amp;#8217;s been installing Linux for
a long time. Overall, the new installer is very nice. It has a clean,
even elegant &lt;span class="caps"&gt;UI&lt;/span&gt;, a relatively nice flow from start to completion, and is
certainly beginner-friendly. It has fewer options than any Linux
installer I&amp;#8217;ve ever used before - not even options for package
selection, firewall or SELinux configuration, etc. - but I guess this is
in line with the goal of making Fedora a desktop &lt;span class="caps"&gt;OS&lt;/span&gt; for the masses. I
would have appreciated an &amp;#8220;advanced mode&amp;#8221; installer that was more like
Fedora 17 (or even much older versions), but I guess I&amp;#8217;m an edge case,
at least in the Fedora community. However, I did find two things
especially difficult, both related to the fact that my laptop has two
main drives (a &lt;span class="caps"&gt;500GB&lt;/span&gt; hard drive and a &lt;span class="caps"&gt;120GB&lt;/span&gt;&amp;nbsp;&lt;span class="caps"&gt;SSD&lt;/span&gt;):&lt;/p&gt;
&lt;p&gt;First, the installer prompted me to select a &amp;#8220;boot disk&amp;#8221;. I guess I
should have read the installation guide, but I assumed that nomenclature
translated to either &amp;#8220;which disk should the automatic partitiioning put
yout &lt;code&gt;/boot&lt;/code&gt; partition on&amp;#8221; or &amp;#8220;which disk should I set the bootable flag
on in the partition table&amp;#8221;. In fact, it means &amp;#8220;which disk should I put
&lt;span class="caps"&gt;GRUB&lt;/span&gt; on the &lt;span class="caps"&gt;EFI&lt;/span&gt; partition of&amp;#8221;. I installed, rebooted, and was shocked -
and somewhat distressed - to boot directly to &lt;span class="caps"&gt;GRUB2&lt;/span&gt; instead of the
rEFInd installation I had setup. The installer didn&amp;#8217;t have any of the
previously-customary &amp;#8220;warning: this will overwrite your &lt;span class="caps"&gt;MBR&lt;/span&gt;/&lt;span class="caps"&gt;EFI&lt;/span&gt; boot
partition&amp;#8221; notices, so I felt safe letting it continue. It turned out
that this was the way I ended up going, and it also turns out that
there&amp;#8217;s a bug in Anaconda that makes it fail installation if you tell it
not to write a bootloader to disk (though it&amp;#8217;s patched by one line of
Python code). But I was deeply distressed that - contrary to the
experience of every, admittedly more complicated, Linux installer I&amp;#8217;d
used before - the Fedora 18 installer overwrote my &lt;span class="caps"&gt;EFI&lt;/span&gt; bootloader
(analogous to overwriting the &lt;span class="caps"&gt;MBR&lt;/span&gt; on a &lt;span class="caps"&gt;BIOS&lt;/span&gt; boot machine) without ever
warning me or asking for a&amp;nbsp;confirmation.&lt;/p&gt;
&lt;p&gt;Secondly, the partitioning tool is clearly designed for only one
destination disk. The overview screen lists configured partitions by
label and mount point, but not by physical device, so figuring out which
partitions are on which physical disks takes a click on each and every
partition to view that information in the detail panel. When you create
a new partition, it&amp;#8217;s automatically put in a &lt;span class="caps"&gt;LVM&lt;/span&gt; volume group spanning
all disks. Changing the target of the automatically created volume group
requires a few clicks, as does changing the physical disks backing any
new volume groups. To assign a newly created partition to a specific
disk, you have to click on an unlabeled &amp;#8220;tool&amp;#8221; icon under the list of
partitions, far away from the information on the partition in question.
It&amp;#8217;s a nice interface for someone who clicks the &amp;#8220;partition
automatically&amp;#8221; button, or who just knows they want to add &amp;#8220;an extra
partition&amp;#8221;, but for anyone who has a specific layout in mind (like
having &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/boot&lt;/code&gt; and &lt;code&gt;/var&lt;/code&gt;, specifically sized, on the &lt;span class="caps"&gt;SSD&lt;/span&gt; and
&lt;code&gt;/home&lt;/code&gt; on the rotating disk) it takes about 4-5 more clicks and dialogs
to add a partition than the last Fedora installer did. Mainly, it&amp;#8217;s
lacking any sort of Advanced Mode for partitioning that allows the user
to quickly and accurately layout a more complex partitioning&amp;nbsp;scheme.&lt;/p&gt;
&lt;p&gt;Below are some screenshots from the Fedora 17 and Fedora 18 Installation
Guides, which contrast both the overview of all partitions and the
individual partition&amp;nbsp;settings:&lt;/p&gt;
&lt;p&gt;Fedora 18 Overview, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/s1-diskpartitioning-x86.html"&gt;9.13. Creating a Custom Partition
Layout&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://www.dedoimedo.com/images/computers_years/2013_1/fedora-18-installer-configure-partitions.jpg" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 17 Overview, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/s1-diskpartitioning-x86.html"&gt;9.14. Creating a Custom Layout or Modifying
the Default
Layout&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/images/diskpartitioning/ddmain.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 18 Partition Creation/Editing, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/Create_LVM-x86.html"&gt;9.13.3. Create &lt;span class="caps"&gt;LVM&lt;/span&gt; Logical
Volume&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/images/diskpartitioning/lvm-pv.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 17 Partition Creation/Editing, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/Adding_Partitions-x86.html"&gt;9.14.2. Adding
Partitions&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/images/diskpartitioning/part-add.png" /&gt;&lt;/p&gt;</summary><category term="bootloader"></category><category term="efi"></category><category term="fedora"></category><category term="gpt"></category><category term="grub"></category><category term="installation"></category><category term="laptop"></category><category term="mac"></category><category term="macbook"></category><category term="os x"></category></entry><entry><title>Pretty-Print a JSON response at the command line</title><link href="http://blog.jasonantman.com/2012/10/pretty-print-a-json-response-at-the-command-line/" rel="alternate"></link><updated>2012-10-09T14:44:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-09:2012/10/pretty-print-a-json-response-at-the-command-line/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been doing some work with &lt;a href="http://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;
lately, and have been doing some testing against its &lt;span class="caps"&gt;HTTP&lt;/span&gt;-based &lt;span class="caps"&gt;API&lt;/span&gt;,
which returns results in &lt;span class="caps"&gt;JSON&lt;/span&gt;. If you&amp;#8217;re looking to pretty-print a &lt;span class="caps"&gt;JSON&lt;/span&gt;
response for easier viewing, here&amp;#8217;s a nice way to do it at the command
line using Python and
&lt;a href="http://docs.python.org/library/json.html"&gt;json.tool&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl http://username:pass@hostname:55672/api/overview | python -m json.tool&lt;/code&gt;&lt;/p&gt;</summary><category term="curl"></category><category term="json"></category><category term="python"></category><category term="rabbitmq"></category></entry><entry><title>Nagstamon on Fedora 17</title><link href="http://blog.jasonantman.com/2012/10/nagstamon-on-fedora-17/" rel="alternate"></link><updated>2012-10-05T07:37:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-05:2012/10/nagstamon-on-fedora-17/</id><summary type="html">&lt;p&gt;Since I started my last job, I&amp;#8217;ve been using
&lt;a href="http://nagstamon.ifw-dresden.de/"&gt;Nagstamon&lt;/a&gt; on my workstation; it&amp;#8217;s a
really handy little system tray application that monitors a
Nagios/Icinga instance and shows status updates/summary in a handy
fashion, including flashing and (optionally) a sound alert when
something changes. Unfortunately, there doesn&amp;#8217;t seem to be a Fedora 17
package for it, though there is an entry on the &lt;a href="http://fedoraproject.org/wiki/Package_maintainers_wishlist#N-O"&gt;Fedora package
maintainers
wishlist&lt;/a&gt;.
The closest I was able to find is a
&lt;a href="http://pkgs.org/centos-6-rhel-6/repoforge-i386/nagstamon-0.9.7.1-2.el6.rf.noarch.rpm.html"&gt;repoforge/RPMforge&lt;/a&gt;
package of Nagstamon 0.9.7.1, along with a &lt;a href="http://apt.sw.be/source/nagstamon-0.9.7.1-2.rf.src.rpm"&gt;source
&lt;span class="caps"&gt;RPM&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are the steps to build that package on&amp;nbsp;F17:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download and install
    &lt;a href="http://apt.sw.be/source/rpm-macros-rpmforge-0-6.rf.src.rpm"&gt;rpm-macros-rpmforge&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;As root, edit &lt;code&gt;/etc/rpm/macros.rpmforge&lt;/code&gt; and comment out the &lt;code&gt;%dist&lt;/code&gt;
    macro, so we&amp;#8217;ll still have the default &amp;#8220;fc17&amp;#8221; dist&amp;nbsp;tag.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wget http://apt.sw.be/source/nagstamon-0.9.7.1-2.rf.src.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rpmbuild &amp;#8212;rebuild&amp;nbsp;nagstamon-0.9.7.1-2.rf.src.rpm&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hopefully this will help someone else as well. At the moment, Nagstamon
is actually up to version 0.9.9, so hopefully I&amp;#8217;ll build a newer package
sometime&amp;nbsp;soon.&lt;/p&gt;</summary><category term="fedora"></category><category term="nagios. icinga"></category><category term="nagstamon"></category><category term="package"></category><category term="rpm"></category></entry><entry><title>Getting oVirt up and running</title><link href="http://blog.jasonantman.com/2012/09/getting-ovirt-up-and-running/" rel="alternate"></link><updated>2012-09-07T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-07:2012/09/getting-ovirt-up-and-running/</id><summary type="html">&lt;p&gt;The bulk of this post was written way back in April 2012. If you&amp;#8217;re just
coming here, and looking to setup oVirt, you should probably &lt;a href="#postscript"&gt;skip down
to the postscript&lt;/a&gt; for an update, and ignore most of the
content here (as it&amp;#8217;s applicable to an older oVirt&amp;nbsp;version).&lt;/p&gt;
&lt;p&gt;I recently started setting up &lt;a href="http://www.ovirt.org"&gt;oVirt&lt;/a&gt;, the
community version of Red Hat Enterprise Virtualization, at work for some
testing (mainly a &amp;#8220;sandbox&amp;#8221; &lt;span class="caps"&gt;VM&lt;/span&gt; environment, and because
&lt;a href="http://theforeman.org/"&gt;Foreman&lt;/a&gt;
&lt;a href="http://blog.theforeman.org/2012/03/vnc-support-built-in-foreman.html"&gt;supports&lt;/a&gt;
it). To start with, I had two nodes, each with two dual-core Xeon
processors (&lt;span class="caps"&gt;VT&lt;/span&gt;-x capable) with &lt;span class="caps"&gt;20GB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;, one with &lt;span class="caps"&gt;600GB&lt;/span&gt; internal storage
and one with &lt;span class="caps"&gt;140GB&lt;/span&gt; internal. While oVirt&amp;#8217;s documentation isn&amp;#8217;t exactly
wonderful, I found a blgo post by Jason Brooks, &lt;a href="http://blog.jebpages.com/archives/how-to-get-up-and-running-with-ovirt/"&gt;How to Get Up and
Running with
oVirt&lt;/a&gt;,
which gives a great walkthrough of getting the oVirt Engine setup on a
machine, and also setting up that same machine as a &lt;span class="caps"&gt;VM&lt;/span&gt; host. As oVirt is
still fairly young, this is all done on Fedora. I performed my
installation via Cobbler, though I&amp;#8217;m afraid to admit it was an entirely
manual, interactive&amp;nbsp;install.&lt;/p&gt;
&lt;p&gt;I did run into a few bumps during Jason&amp;#8217;s tutorial. In step 15, adding
the data &lt;span class="caps"&gt;NFS&lt;/span&gt; export as a Storage Domain, I was unable to add the &lt;span class="caps"&gt;NFS&lt;/span&gt;
export. I found the &lt;a href="http://www.ovirt.org/wiki/Troubleshooting_NFS_Storage_Issues"&gt;Troubleshooting &lt;span class="caps"&gt;NFS&lt;/span&gt; Storage Issues page on the
oVirt
wiki&lt;/a&gt;,
ensured that SELinux was disabled and that the export had the correct
permissions, confirmed that &lt;code&gt;/etc/nfsmount.conf&lt;/code&gt; specified &lt;code&gt;Nfsvers=3&lt;/code&gt;,
rebooted, and then ran the &lt;code&gt;nfs-check.py&lt;/code&gt; script. At this point, I was
able to add the other storage domains in steps 15 and&amp;nbsp;16.&lt;/p&gt;
&lt;p&gt;My second issue was that even on Fedora 16, I simply can&amp;#8217;t get the spice
client (through the &lt;code&gt;spice-xpi&lt;/code&gt; browser plugin) to work. As far as I can
tell from the logs, it looks like &lt;code&gt;spicec&lt;/code&gt; is being sent a value of
&amp;#8220;None&amp;#8221; for the secured port parameter, instead of the correct port
number. I assume this is a bug in oVirt, but I&amp;#8217;ll revisit this problem
when I have time. In the mean time, I changed my test &lt;span class="caps"&gt;VM&lt;/span&gt; to use &lt;span class="caps"&gt;VNC&lt;/span&gt;,
which is launched by installing the &lt;code&gt;ovirt-engine-cli&lt;/code&gt; package (see
below) on your client computer, connecting to the oVirt &lt;span class="caps"&gt;API&lt;/span&gt; with&amp;nbsp;ovirt-shell:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;ovirt-shell --connect --url=https://ovirt-engine.example.com:8443/api --user=admin@internal --password adminpassword&lt;/code&gt;&lt;br /&gt;
and then running &lt;code&gt;console vm_name&lt;/code&gt;. This launches the &lt;code&gt;vncviewer&lt;/code&gt;
binary, which is in the &amp;#8220;tigervnc&amp;#8221; package on&amp;nbsp;Fedora.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing&amp;nbsp;ovirt-engine-cli&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To run &lt;code&gt;ovirt-shell&lt;/code&gt; on your workstation (Fedora 16, of course&amp;#8230;)
you&amp;#8217;ll need the ovirt-engine-cli and ovirt-engine-sdk packages. I
manually downloaded them from
&lt;a href="http://www.ovirt.org/releases/nightly/fedora/16/"&gt;http://www.ovirt.org/releases/nightly/fedora/16/&lt;/a&gt;,
versions 2.1.3 and 1.6.2, respecitively. The &lt;span class="caps"&gt;SDK&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; are python
based, so there are a few Python dependencies, all of which were
automatically solved by yum. I know there are &lt;span class="caps"&gt;SDK&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; packages out
there for other distros, but haven&amp;#8217;t tried them&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Linux&amp;nbsp;Guests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Installing a CentOS 6.2 x86_64 guest was relatively straightforward,
and my usual kickstart infrastructure worked fine. The only catch was
the VirtIO storage interface, which shows up as &lt;code&gt;/dev/vdx&lt;/code&gt; instead of
&lt;code&gt;/dev/sdx&lt;/code&gt;; I just added another kickstart metadata option in Cobbler
that allows me to use &lt;code&gt;sdx&lt;/code&gt; by specifying &amp;#8220;virtual=yes&amp;#8221; (for our VMWare
hosts), or &lt;code&gt;vdx&lt;/code&gt; by specifying&amp;nbsp;&amp;#8220;virtual=ovirt&amp;#8221;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setting up&amp;nbsp;Authentication&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As installed, oVirt only has one user, &amp;#8220;admin@internal&amp;#8221;; it requires an
external directory service for user authentication. Currently, it
supports &lt;span class="caps"&gt;IPA&lt;/span&gt;, Red Hat&amp;#8217;s Enterprise Identity Management tool (combines
&lt;span class="caps"&gt;RHEL&lt;/span&gt;, oVirt Directory Server, Kerberos and &lt;span class="caps"&gt;NTP&lt;/span&gt;; perhaps
&lt;a href="http://freeipa.org"&gt;FreeIPA&lt;/a&gt; would work as well?) and Microsoft Active
Directory. As much as I&amp;#8217;d like to give &lt;span class="caps"&gt;IPA&lt;/span&gt; or FreeIPA a try, my company
already has an &lt;span class="caps"&gt;AD&lt;/span&gt; infrastructure, so I opted to go that route.
Documentation is given in the &lt;a href="http://www.ovirt.org/wiki/File:OVirt-3.0-Installation_Guide-en-US.pdf"&gt;oVirt 3.0 Installation
Guide&lt;/a&gt;,
starting on page 96. Unfortunately, I was never about to get &lt;span class="caps"&gt;AD&lt;/span&gt; auth
working correctly, so I just worked with the one admin&amp;nbsp;user.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adding a&amp;nbsp;Node&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The biggest issue I had was adding the second node to oVirt. I attempted
to use the &lt;span class="caps"&gt;DVD&lt;/span&gt; Import feature of Cobbler on the &lt;a href="http://www.ovirt.org/get-ovirt/"&gt;oVirt Node Image
&lt;span class="caps"&gt;ISO&lt;/span&gt;&lt;/a&gt;, but that failed. I then found the
image&amp;#8217;s &lt;code&gt;LiveOS/livecd-iso-to-pxeboot&lt;/code&gt; script and used that to make a
kernerl and initrd, and kernel parameters, for Cobbler. &lt;span class="caps"&gt;PXE&lt;/span&gt; works&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;&lt;a name="postscript"&gt;&lt;/a&gt;&lt;strong&gt;Postscript:&lt;/strong&gt; I ended up blowing away my
oVirt installation in favor of testing other things. At some point, the
engine install got corrupted in a way that I just couldn&amp;#8217;t fix; even
though I spent all day one Saturday working on it, it took more time
than I could allocate to a personal project. So this post is really
semi-complete at best. However, there is some good news. Jason Brooks&amp;#8217;
original post, &lt;a href="http://blog.jebpages.com/archives/how-to-get-up-and-running-with-ovirt/"&gt;How to Get Up and Running with
oVirt&lt;/a&gt;,
was written for oVirt 3.0, as was this post. Since then, there has been
a new release, &lt;a href="http://wiki.ovirt.org/wiki/OVirt_3.1_release_notes"&gt;oVirt
3.1&lt;/a&gt;, which
apparently has a better &lt;span class="caps"&gt;UI&lt;/span&gt; and a better installer. Jason Brooks has a
new post, &lt;a href="http://blog.jebpages.com/archives/up-and-running-with-ovirt-3-1-edition/"&gt;Up and Running with oVirt, 3.1
Edition&lt;/a&gt;,
which covers installation and configuration of both an all-in-one
machine and a separate node. If you&amp;#8217;re looking to try oVirt, I&amp;#8217;d
recommend you give that a shot. Unfortunately (and strangely, given that
this is supposed to be the &amp;#8220;upstream&amp;#8221; of RedHat&amp;#8217;s proprietary &lt;span class="caps"&gt;RHEV&lt;/span&gt;) it&amp;#8217;s
still all based on&amp;nbsp;Fedora.&lt;/p&gt;</summary><category term="fedora"></category><category term="kvm"></category><category term="ovirt"></category><category term="qemu"></category><category term="redhat"></category><category term="rhev"></category><category term="spice"></category><category term="virtualization"></category></entry><entry><title>Wordpress - Automatically publish a pending post each weekday morning from a PHP script</title><link href="http://blog.jasonantman.com/2012/09/wordpress-automatically-publish-a-pending-post-each-weekday-morning-from-a-php-script/" rel="alternate"></link><updated>2012-09-04T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-04:2012/09/wordpress-automatically-publish-a-pending-post-each-weekday-morning-from-a-php-script/</id><summary type="html">&lt;p&gt;In an earlier post, &lt;a href="/2012/08/piwik-web-analytics-and-some-unfortunate-stats-about-my-blog/"&gt;Piwik Web Analytics, and some unfortunate stats
about my
blog&lt;/a&gt;,
I mentioned that the &lt;a href="http://feedburner.google.com/"&gt;Feedburner&lt;/a&gt; stats
for this blog show a relatively high subscribe/unsubscribe rate for this
blog. I think a large part of that is my tendency to blog in spurts, and
even worse, my tendency to write drafts and not publish them. In an
effort to combat this, I&amp;#8217;ve been trying to finish blog posts and then
set them to &amp;#8220;Pending&amp;#8221; status, and go back and publish one every day
(well, every day that I have some still sitting unpublished). Of course,
that counts on me logging in to Wordpress every day, which isn&amp;#8217;t
something I do. The following script is, at least for now, the answer
for&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;This script (a standalone &lt;span class="caps"&gt;PHP&lt;/span&gt; script) uses
&lt;a href="http://core.trac.wordpress.org/browser/trunk/wp-load.php"&gt;&lt;code&gt;wp-load.php&lt;/code&gt;&lt;/a&gt;
to load the wordpress environment, and then finds the oldest post with a
given status (&amp;#8220;pending&amp;#8221; in my case) and attempts to publish it. It only
does this if there has not been another post published in the last 24
hours. The following script can be found in Git at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/wordpress_daily_post.php"&gt;https://github.com/jantman/misc-scripts/blob/master/wordpress_daily_post.php&lt;/a&gt;&lt;/p&gt;
&lt;!---
sourceinclude
---&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;#!/usr/bin/php&lt;/span&gt;
&lt;span class="cp"&gt;&amp;lt;?php&lt;/span&gt;
&lt;span class="sd"&gt;/**&lt;/span&gt;
&lt;span class="sd"&gt; * wordpress_daily_post.php&lt;/span&gt;
&lt;span class="sd"&gt; * Script to publish the oldest post with a given status, if no&lt;/span&gt;
&lt;span class="sd"&gt; * other post has been published in 24 hours. Intended to be run&lt;/span&gt;
&lt;span class="sd"&gt; * via cron on weekdays.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Copyright 2012 Jason Antman &lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Licensed under the Apache License, Version 2.0 &lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * use it anywhere you want, however you want, provided that this header is left intact,&lt;/span&gt;
&lt;span class="sd"&gt; * and that if redistributed, credit is given to me.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * It is strongly requested, but not technically required, that any changes/improvements&lt;/span&gt;
&lt;span class="sd"&gt; * be emailed to the above address.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * The latest version of this script will always be available at:&lt;/span&gt;
&lt;span class="sd"&gt; * $HeadURL: http://svn.jasonantman.com/misc-scripts/wordpress_daily_post.php $&lt;/span&gt;
&lt;span class="sd"&gt; * $LastChangedRevision: 40 $&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Changelog:&lt;/span&gt;
&lt;span class="sd"&gt; * 2012-09-03 Jason Antman  - 1.0&lt;/span&gt;
&lt;span class="sd"&gt; *  - first version&lt;/span&gt;
&lt;span class="sd"&gt; */&lt;/span&gt;

&lt;span class="c1"&gt;# &lt;span class="caps"&gt;BEGIN&lt;/span&gt; &lt;span class="caps"&gt;CONFIGURATION&lt;/span&gt;&lt;/span&gt;
&lt;span class="nb"&gt;define&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;WP_LOAD_LOC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/var/www/vhosts/blog.jasonantman.com/wp-load.php&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// Configure this to the full path of your Wordpress wp-load.php&lt;/span&gt;
&lt;span class="nb"&gt;define&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SOURCE_POST_STATUS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// post status to publish&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;END&lt;/span&gt; &lt;span class="caps"&gt;CONFIGURATION&lt;/span&gt;&lt;/span&gt;

&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;array_shift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;isset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-d&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--dry-run&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;DRY&lt;/span&gt; &lt;span class="caps"&gt;RUN&lt;/span&gt; &lt;span class="caps"&gt;ONLY&lt;/span&gt; - &lt;span class="caps"&gt;NOT&lt;/span&gt; &lt;span class="caps"&gt;ACTUALLY&lt;/span&gt; &lt;span class="caps"&gt;PUBLISHING&lt;/span&gt;.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;isset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-v&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--verbose&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;WP_LOAD_LOC=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;WP_LOAD_LOC&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;SOURCE_POST_STATUS=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;SOURCE_POST_STATUS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nb"&gt;array_shift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nv"&gt;$_SERVER&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;HTTP_HOST&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// needed for wp-includes/ms-settings.php:100&lt;/span&gt;
&lt;span class="k"&gt;require_once&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;WP_LOAD_LOC&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;# check that we&amp;#39;re running on a weekday&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="c1"&gt;#  if($&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;){ fwrite(&lt;span class="caps"&gt;STDERR&lt;/span&gt;, &amp;quot;today is a saturday or sunday, dieing.\n&amp;quot;); }&lt;/span&gt;
&lt;span class="c1"&gt;#  exit(1);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# find the publish date/time of the last published post&lt;/span&gt;
&lt;span class="nv"&gt;$published&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;DESC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="nv"&gt;$post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$published&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="nv"&gt;$pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;strtotime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$pub_date&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;86400&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;last post (&lt;span class="caps"&gt;ID&lt;/span&gt; &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt;) within last day (&lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="s2"&gt;). Nothing to do. Exiting.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Found last post (&lt;span class="caps"&gt;ID&lt;/span&gt; &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt;) with post date &lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="s2"&gt;.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="c1"&gt;# find the earliest post of status SOURCE_POST_STATUS, if there is one.&lt;/span&gt;
&lt;span class="nv"&gt;$to_post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;ASC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;SOURCE_POST_STATUS&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$to_post&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nx"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$to_pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$to_pub_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;time&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="nv"&gt;$new_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y-m-d H:i:s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$now&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nv"&gt;$new_date_gmt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;gmdate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y-m-d H:i:s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$now&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Post to publish: &lt;span class="caps"&gt;ID&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_id&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;DATE&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_date&lt;/span&gt;&lt;span class="s2"&gt; NEW_DATE=&lt;/span&gt;&lt;span class="si"&gt;$new_date&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;TITLE&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_title&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# actually publish it&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="nv"&gt;$arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;ID&lt;/span&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$to_pub_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$new_date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date_gmt&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$new_date_gmt&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="nv"&gt;$ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;wp_update_post&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$arr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// publish the post&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$ret&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: Post &lt;/span&gt;&lt;span class="si"&gt;$to_pub_id&lt;/span&gt;&lt;span class="s2"&gt; was not successfully published.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Published post. New &lt;span class="caps"&gt;ID&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;$ret&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Dry run only, not publishing post.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# check that the post really was published&lt;/span&gt;
&lt;span class="nv"&gt;$published&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;DESC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="nv"&gt;$post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$published&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="nv"&gt;$pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_guid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;guid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$pub_title&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="nv"&gt;$to_pub_title&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: title of most recent post does not match title of what we wanted to post.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Published post &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt; at &lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Title: &lt;/span&gt;&lt;span class="si"&gt;$pub_title&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n\n\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;GUID&lt;/span&gt;/Link: &lt;/span&gt;&lt;span class="si"&gt;$pub_guid&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="k"&gt;__FILE__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; on &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;trim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;shell_exec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hostname --fqdn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; running as &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;get_current_user&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="cp"&gt;?&amp;gt;&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You&amp;#8217;ll need to set &lt;code&gt;WP_LOAD_LOC&lt;/code&gt; (line 29) to the full path of your
Wordpress installation&amp;#8217;s &lt;code&gt;wp-load.php&lt;/code&gt; (it should be in the top-level
directory of your Wordpress installation. I run this script from cron&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;0 6 * * 1-5 /home/jantman/bin/wordpress_daily_post.php --verbose # publish WP pending posts daily
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;so that it runs at &lt;span class="caps"&gt;6AM&lt;/span&gt; (local time) each weekday. Assuming you have cron
setup to send you mail, you&amp;#8217;ll get a daily message saying what was (or
wasn&amp;#8217;t)&amp;nbsp;done.&lt;/p&gt;</summary><category term="cron"></category><category term="PHP"></category><category term="wordpress"></category></entry><entry><title>RVM and Ruby 1.9 to test logstash grok patterns on Fedora/CentOS</title><link href="http://blog.jasonantman.com/2012/09/rvm-and-ruby-1-9-to-test-logstash-grok-patterns-on-fedoracentos/" rel="alternate"></link><updated>2012-09-03T08:37:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-03:2012/09/rvm-and-ruby-1-9-to-test-logstash-grok-patterns-on-fedoracentos/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been working on a personal project with
&lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; lately, and it relies relatively
heavily on &lt;a href="https://github.com/jordansissel/grok"&gt;grok&lt;/a&gt; filters for
matching text and extracting matched parts. Today, I&amp;#8217;ve been parsing
syslog from &lt;a href="http://puppetlabs.com/puppet/puppet-open-source/"&gt;Puppet&lt;/a&gt;
to extract various metrics and timings, which will then be passed on
from Logstash to &lt;a href="https://github.com/etsy/statsd"&gt;Etsy&amp;#8217;s statsd&lt;/a&gt; and
then to &lt;a href="http://graphite.wikidot.com/"&gt;graphite&lt;/a&gt; for display.
Unfortunately, a few of my patterns are showing the &amp;#8220;_grokparsefailure&amp;#8221;
tag and I just can&amp;#8217;t seem to find the&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;The logstash wiki provides a page on &lt;a href="https://github.com/logstash/logstash/wiki/Testing-your-Grok-patterns-(--logstash-1.1.0-and-above-)"&gt;Testing your Grok
patterns&lt;/a&gt;,
as does Sean Laurent on his blog: &lt;a href="http://blog.bealetech.com/content/testing-logstash-grok-filters"&gt;Testing Logstash grok
filters&lt;/a&gt;.
Unfortunately, I work in a CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; shop, and we&amp;#8217;re decidedly &lt;em&gt;not&lt;/em&gt; a
Ruby shop. Our Logstash install is using the monolithic/standalone Java
&lt;span class="caps"&gt;JAR&lt;/span&gt;. We run Puppet, which is currently under ruby 1.8.7, and the
&lt;a href="http://rubygems.org/gems/jls-grok"&gt;jls-grok rubygem&lt;/a&gt; requires ruby 1.9.
There&amp;#8217;s no way I&amp;#8217;d feel safe installing 1.9 on any of our machines, as
they all run (and require) Puppet. So, I found out about
&lt;a href="https://rvm.io/"&gt;&lt;span class="caps"&gt;RVM&lt;/span&gt;&lt;/a&gt;, the Ruby Version Manager, which allows you to
run and switch between multiple ruby versions, and all of it is
installed on a per-user basis. So, I created a new user on my Fedora 16
desktop called &amp;#8220;rvmtest&amp;#8221; and went about the process of setting up what&amp;#8217;s
needed to test grok patterns in the user&amp;#8217;s local environment. I imagine
this would work similarly under CentOS or &lt;span class="caps"&gt;RHEL&lt;/span&gt;, but the following is
only tested on Fedora 16. If you have any issues, you should probably
refer back to the &lt;span class="caps"&gt;RVM&lt;/span&gt;&amp;nbsp;documentation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create the isolated user, just to be extra careful. Login as that&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As per &lt;a href="https://rvm.io/rvm/install/"&gt;Installing &lt;span class="caps"&gt;RVM&lt;/span&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl https://raw.github.com/wayneeseguin/rvm/master/binscripts/rvm-installer | bash -s stable
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;edit your &lt;code&gt;~/.bashrc&lt;/code&gt; and&amp;nbsp;add:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="o"&gt;[[&lt;/span&gt; -s &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;HOME&lt;/span&gt;/.rvm/scripts/rvm&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;HOME&lt;/span&gt;/.rvm/scripts/rvm&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt; -r &lt;span class="nv"&gt;$rvm_path&lt;/span&gt;/scripts/completion &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span class="nv"&gt;$rvm_path&lt;/span&gt;/scripts/completion
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first line sets up &lt;span class="caps"&gt;RVM&lt;/span&gt; for your sessions, and the second sources
in tab-completion for the &lt;code&gt;rvm&lt;/code&gt; command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;source .bashrc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;If you&amp;#8217;re interested, you can see a list of all known rubies with:
    &lt;code&gt;rvm list known&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install Ruby (&lt;span class="caps"&gt;MRI&lt;/span&gt;) 1.9.2: &lt;code&gt;rvm install 1.9.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;switch&amp;#8221; to that ruby: &lt;code&gt;rvm use 1.9.2&lt;/code&gt; and confirm it by running
    &lt;code&gt;ruby -v&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Make it the default ruby for us: &lt;code&gt;rvm use 1.9.2 --default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create a &amp;#8220;gemset&amp;#8221; (set of rubygems for our environment):
    &lt;code&gt;rvm gemset create groktest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use it, and set it as default: &lt;code&gt;rvm use 1.9.2@groktest --default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;for grok testing, &lt;code&gt;gem install jls-grok&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;check that it&amp;#8217;s there: &lt;code&gt;gem list&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download Logstash&amp;#8217;s default grok patterns &lt;a href="https://raw.github.com/logstash/logstash/master/patterns/grok-patterns"&gt;from&amp;nbsp;github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;You should now be ready to test some grok&amp;nbsp;patterns.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While the two howto&amp;#8217;s linked above use &lt;code&gt;irb&lt;/code&gt; to interactively test the
patterns, I prefer something easier to move to production, more
reliable, and more repeatable. The following quick little ruby script
takes test to match against on &lt;span class="caps"&gt;STDIN&lt;/span&gt; (log files, messages, etc.) and
prints the matches to &lt;span class="caps"&gt;STDOUT&lt;/span&gt;. The script is based on
&lt;a href="https://github.com/jordansissel/ruby-grok/blob/master/examples/test.rb"&gt;test.rb&lt;/a&gt;
from &lt;a href="https://github.com/jordansissel/ruby-grok"&gt;jordansissel&amp;#8217;s
ruby-grok&lt;/a&gt;. Note one
important thing here, I couldn&amp;#8217;t get the shebang (&lt;code&gt;#!&lt;/code&gt;) to work with
anything other than the explicit path to my &lt;span class="caps"&gt;RVM&lt;/span&gt; ruby install
(&lt;code&gt;which ruby&lt;/code&gt;) so you&amp;#8217;ll need to manually update this&amp;nbsp;yourself.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!.rvm/rubies/ruby-1.9.2-320bin/ruby&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;rubygems&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;grok-pure&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pp&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;grok&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;
&lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_patterns_from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;grok-patterns&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;your_grok_pattern_here&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;PATTERN&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;gets&lt;/span&gt;
  &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;IN&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;pp&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;captures&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;No Match.&amp;quot;&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&amp;#8217;s an example using a pattern to capture information from custom
syslog messages triggered by updating puppet configs. Here&amp;#8217;s some sample&amp;nbsp;messages:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[rvmtest@jantmanwork ~]$ cat puppet.log&lt;/span&gt;
&lt;span class="go"&gt;Updated 2 files in puppet svn (environment prod) to revision 754&lt;/span&gt;
&lt;span class="go"&gt;Updated 3 files in puppet svn (environment prod) to revision 756&lt;/span&gt;
&lt;span class="go"&gt;Updated 1 files in puppet svn (environment prod) to revision 757&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the pattern that I&amp;nbsp;use:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Updated%{SPACE}%{NUMBER:puppet_svn_num_files}%{SPACE}files%{SPACE}in%{SPACE}puppet%{SPACE}svn%{SPACE}\(environment%{SPACE}%{WORD:puppet_svn_env}\)%{SPACE}to%{SPACE}revision%{SPACE}%{NUMBER:puppet_svn_revision}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the output of the&amp;nbsp;script:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[rvmtest@jantmanwork ~]$ cat puppet.log | ./puppet-update-test.rb &lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;PATTERN&lt;/span&gt;: Updated%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files}%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}files%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}in%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}puppet%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}svn%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}\(environment%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env}\)%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}to%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}revision%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 2 files in puppet svn (environment prod) to revision 754&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;2&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;2&amp;quot;, &amp;quot;754&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;754&amp;quot;]}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 3 files in puppet svn (environment prod) to revision 756&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;3&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;3&amp;quot;, &amp;quot;756&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;756&amp;quot;]}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 1 files in puppet svn (environment prod) to revision 757&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;1&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;1&amp;quot;, &amp;quot;757&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;757&amp;quot;]}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopefully this will make the process a bit simpler for someone&amp;nbsp;else&amp;#8230;&lt;/p&gt;</summary><category term="grok"></category><category term="grokparsefailure"></category><category term="jruby"></category><category term="kibana"></category><category term="logstash"></category><category term="ruby"></category><category term="rvm"></category></entry><entry><title>Setting emacs zone-mode based on path</title><link href="http://blog.jasonantman.com/2012/08/setting-emacs-zone-mode-based-on-path/" rel="alternate"></link><updated>2012-08-15T08:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-15:2012/08/setting-emacs-zone-mode-based-on-path/</id><summary type="html">&lt;p&gt;At work, we do a fair amount of &lt;span class="caps"&gt;DNS&lt;/span&gt; updates. Our zone files are stored
in subversion, and are named according to the domain (with no .zone
extension). It&amp;#8217;s a real pain when updating a few (or a few dozen) zones
in Emacs, since I have to remember to &amp;#8220;M-x zone-mode&amp;#8221; so the serial gets
automatically updated. Here&amp;#8217;s a lisp snippet to put in your &lt;code&gt;.emacs&lt;/code&gt;
file that will set zone-mode for all files in any path matching the
regex &lt;code&gt;svn/named/zones-internal&lt;/code&gt;. I deliberately made it a relative path
(or, really, any path containing that) so it would work for all of my
team&amp;#8217;s workstations, no matter where we have the svn repo checked&amp;nbsp;out:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;add-to-list&lt;/span&gt; &lt;span class="ss"&gt;&amp;#39;auto-mode-alist&lt;/span&gt; &lt;span class="o"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;svn/named/zones-internal/&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="nv"&gt;zone-mode&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Many thanks to &lt;code&gt;taylanub&lt;/code&gt; on #emacs on irc.freenode.net for helping
with&amp;nbsp;this.&lt;/p&gt;</summary><category term="bind"></category><category term="emacs"></category><category term="lisp"></category><category term="named"></category><category term="zone-mode"></category></entry><entry><title>Workflow for contributing to GitHub projects</title><link href="http://blog.jasonantman.com/2012/08/workflow-for-contributing-to-github-projects/" rel="alternate"></link><updated>2012-08-11T09:35:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-11:2012/08/workflow-for-contributing-to-github-projects/</id><summary type="html">&lt;p&gt;Lately I&amp;#8217;ve been contributing to some open source projects hosted on
&lt;a href="http://github.com"&gt;github&lt;/a&gt;. I&amp;#8217;m pretty new to git, and the process is a
bit confusing for beginners. So, here&amp;#8217;s a sample workflow, based on the
&lt;a href="http://theforeman.org"&gt;The Foreman&lt;/a&gt;&amp;#8216;s &lt;a href="https://github.com/theforeman/foreman"&gt;foreman github
repository&lt;/a&gt;. Note that I&amp;#8217;m
developing against the &amp;#8220;develop&amp;#8221; branch of that repository, not the
master, so that throws in a little difference that isn&amp;#8217;t documented in
most introductions. To throw in another wrench, I maintan a branch with
the code that I&amp;#8217;m currently actually using (i.e. the application code
that I have checked out on the production server), called &amp;#8220;jantman&amp;#8221;.
This is more or less composed of the upstream &amp;#8220;develop&amp;#8221; branch, with all
of my finished (but not yet merged in the upstream) topic branches. I&amp;#8217;m
pretty sure all this is correct, but honestly, I&amp;#8217;m still new enough at
git that I can&amp;#8217;t make any promises. Unfortunatelty, I haven&amp;#8217;t had the
time to &lt;em&gt;really&lt;/em&gt; learn git, and I also can&amp;#8217;t find a simple enough
tutorial that covers all&amp;nbsp;this&amp;#8230;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fork the original repository through the GitHub&amp;nbsp;interface.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On your machine, clone your&amp;nbsp;fork:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git clone git@github.com:username/reponame.git &amp;amp;&amp;amp; cd reponame
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure you&amp;#8217;ve&amp;nbsp;setup&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git config --global branch.autosetupmerge true
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add your upstream&amp;nbsp;repo:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add upstream git://github.com/upstream_user/upstream_repo.git
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fetch it and initialize any&amp;nbsp;submodules:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git fetch upstream &amp;amp;&amp;amp; git submodule update --init
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the current branch (&lt;code&gt;git branch&lt;/code&gt;, let&amp;#8217;s assume it&amp;#8217;s called
    &amp;#8220;develop&amp;#8221;) and rebase to its&amp;nbsp;upstream:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase upstream/develop develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create my &amp;#8220;jantman&amp;#8221; branch, which will be the upstream &amp;#8220;develop&amp;#8221;,
    plus my finished work merged into&amp;nbsp;it:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -b jantman origin/develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a topic branch to do some&amp;nbsp;work:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -b NewBranchName jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Periodically, push the topic branch to&amp;nbsp;github:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin NewBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you commit to this branch from another computer (or someone else
    commits to it), periodically update your local tracking&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git pull origin NewBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Periodically, you want to pull in the upstream&amp;nbsp;changes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;switch to the develop&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;grab the latest version of the upstream git&amp;nbsp;repo:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git fetch upstream
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;rebase develop to mirror the upstream develop&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase upstream/develop develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;switch to our personal&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;rebase our personal branch onto develop (pull all the new
    commits from develop into our personal&amp;nbsp;branch):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase develop jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we want those new upstream changes to continue down to our
    topic&amp;nbsp;branches:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase develop topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When we&amp;#8217;re done with a topic branch, we want to merge it into our
    &amp;#8220;personal&amp;#8221;&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    git checkout jantman; git merge --squash node-table-facts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and then&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    git commit
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;--squash&lt;/code&gt; will squash all the history of that branch down to
one commit. This is generally easier for integration into upstream,
and assuming the topic branch was created for a single feature or
bug, should be&amp;nbsp;logical.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we&amp;#8217;re sure we don&amp;#8217;t need it anymore, delete the topic branch from
    our local&amp;nbsp;machine:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git branch -d topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and from&amp;nbsp;github:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin --delete topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, make sure we push our &amp;#8220;personal&amp;#8221; branch back to&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assuming all went well, you&amp;#8217;ll see the new commit on github, and
    have a nice pull request&amp;nbsp;button.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;References:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.doctrine-project.org/contribute.html"&gt;Contribute -&amp;nbsp;Doctrine-Project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://qsapp.com/wiki/Github"&gt;Github - Quicksilver&amp;nbsp;Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/carmaa/inception/wiki/Contributor-Workflow-with-Github"&gt;Contributor Workflow with Github · carmaa/inception&amp;nbsp;Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://help.github.com/fork-a-repo/"&gt;Help.GitHub - Fork A&amp;nbsp;Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</summary><category term="foreman"></category><category term="git"></category><category term="github"></category><category term="workflow"></category></entry><entry><title>Easily comparing a bunch of files in one directory</title><link href="http://blog.jasonantman.com/2012/08/easily-comparing-a-bunch-of-files-in-one-directory/" rel="alternate"></link><updated>2012-08-10T09:50:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-10:2012/08/easily-comparing-a-bunch-of-files-in-one-directory/</id><summary type="html">&lt;p&gt;So I pulled a specific configuration file (rsyslog.conf) off of a &lt;span class="caps"&gt;LOT&lt;/span&gt; of
hosts. I&amp;#8217;m going to be managing it with &lt;a href=""&gt;Puppet&lt;/a&gt;, but before I do, I
need to know what&amp;#8217;s out there already lest it get overwritten. I used
&lt;a href="http://code.google.com/p/parallel-ssh/"&gt;pssh&lt;/a&gt; with &lt;code&gt;cat&lt;/code&gt; and an output
directory to grab the file from all 30 servers in question. Now, I&amp;#8217;ve
got a directory with 30 files in it, and I need to figure out how many
different files (by contents) there are, and which ones&amp;nbsp;differ.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;find . -type f -exec md5sum &lt;span class="s1"&gt;&amp;#39;{}&amp;#39;&lt;/span&gt; &lt;span class="se"&gt;\;&lt;/span&gt; | sort | uniq -d -w 36
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will check the contents of each file by &lt;span class="caps"&gt;MD5&lt;/span&gt; checksum, and print out
the (lexographically) first file in each group, along with its &lt;span class="caps"&gt;MD5&lt;/span&gt; sum.
You can also strip off the uniq command, and see the list sorted by&amp;nbsp;md5.&lt;/p&gt;
&lt;p&gt;A &lt;span class="caps"&gt;GUI&lt;/span&gt; alternative would be to use
&lt;a href="http://www.pixelbeat.org/fslint/"&gt;fslint&lt;/a&gt;, which is a graphical tool
that can (among other things) display a list of the duplicate files
within a path or set of&amp;nbsp;paths.&lt;/p&gt;</summary><category term="compare"></category><category term="diff"></category></entry><entry><title>Logging OpenSSH SFTP Transactions</title><link href="http://blog.jasonantman.com/2012/07/logging-openssh-sftp-transactions/" rel="alternate"></link><updated>2012-07-16T08:47:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-07-16:2012/07/logging-openssh-sftp-transactions/</id><summary type="html">&lt;p&gt;I just came across a really handy post on &lt;a href="https://plus.google.com/117561367404774597588/posts"&gt;David
Busby&lt;/a&gt;&amp;#8216;s blog:
&lt;a href="http://blog.oneiroi.co.uk/linux/enable-logging-in-the-sftp-subsystem/"&gt;Enable logging in the &lt;span class="caps"&gt;SFTP&lt;/span&gt; subsystem -
Oneiroi&lt;/a&gt;.
From OpenSSH 4.4 on, you can pass arguments to Subsystem calls, and the
sftp subsystem supports logging to an aribtrary syslog facility and
priority. Simply adding a line&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Subsystem       sftp    /usr/libexec/openssh/sftp-server -f LOCAL5 -l INFO
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and the appropriate lines to your syslog config will give you a handy
transfer log&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Jul 16 09:22:25 hostname sftp-server[2058]: session opened for local user jantman from [A.B.C.D]
Jul 16 09:22:26 hostname sftp-server[2058]: open &amp;quot;/home/jantman/temp/sftp_test&amp;quot; flags WRITE,CREATE,TRUNCATE mode 0666
Jul 16 09:22:45 hostname sftp-server[2058]: close &amp;quot;/home/jantman/temp/sftp_test&amp;quot; bytes read 0 written 1464813
Jul 16 09:23:08 hostname sftp-server[2058]: session closed for local user jantman from [A.B.C.D]
Jul 16 09:27:50 hostname sftp-server[2309]: session opened for local user jantman from [A.B.C.D]
Jul 16 09:27:50 hostname sftp-server[2309]: open &amp;quot;/home/jantman/temp/sftp_test&amp;quot; flags READ mode 0666
Jul 16 09:27:54 hostname sftp-server[2309]: close &amp;quot;/home/jantman/temp/sftp_test&amp;quot; bytes read 1464813 written 0
Jul 16 09:27:54 hostname sftp-server[2309]: session closed for local user jantman from [A.B.C.D]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you have syslog write these logs to their own file, remember to setup
log rotation for&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;Unfortunately, I&amp;#8217;m not aware of any way to log &lt;span class="caps"&gt;SCP&lt;/span&gt; file&amp;nbsp;transfers.&lt;/p&gt;</summary><category term="logging"></category><category term="openssh"></category><category term="sftp"></category><category term="ssh"></category></entry><entry><title>Tools for watching apache httpd and memcached</title><link href="http://blog.jasonantman.com/2012/06/tools-for-watching-apache-httpd-and-memcached/" rel="alternate"></link><updated>2012-06-26T13:46:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-06-26:2012/06/tools-for-watching-apache-httpd-and-memcached/</id><summary type="html">&lt;p&gt;Recently I was working on a code release on a site running &lt;span class="caps"&gt;PHP&lt;/span&gt; on
&lt;a href="http://httpd.apache.org/"&gt;Apache httpd&lt;/a&gt;, and using
&lt;a href="http://memcached.org/"&gt;memcached&lt;/a&gt;. Without getting into specifics, we
had a number of issues that were both Apache and memcached problems, and
little visibility into them as it was running on an older server without
much monitoring in place. I started looking around for simple tools that
could provide a bit more insight, without many dependencies (as the
machine is a relatively minimalist install). Here are some of the
options I&amp;nbsp;found:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://code.google.com/p/memcache-top/"&gt;memcache-top&lt;/a&gt; - A top-like
    script that pulls stats from memcached instances and can show both
    per-instance, total and average usage %, hit rate, number of
    connections, time to run the stats query, evictions, gets, sets, and
    read and write amounts. Best of all, it&amp;#8217;s a very small perl script
    that requires only &lt;span class="caps"&gt;IO&lt;/span&gt;::Socket and Time::HiRes. Here&amp;#8217;s a small
    example of the&amp;nbsp;output:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;memcache-top v0.6       (default port: 11211, color: on, refresh: 3 seconds)

INSTANCE                USAGE   HIT %   CONN    TIME    EVICT   GETS    SETS    READ    WRITE
127.0.0.1:11211         86.6%   99.4%   115     0.6ms   0.0     4114    1669    1.3M    24.2M
127.0.0.1:11212         85.5%   59.9%   2       0.4ms   0.0     0       0       90      8055

AVERAGE:                86.0%   79.6%   58      0.5ms   0.0     2057    834     682.4K  12.1M

TOTAL:          0.9GB/  1.0GB           117     1.0ms   0.0     4114    1669    1.3M    24.2M
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/dormando/damemtop"&gt;damemtop&lt;/a&gt; is also a nice
    top-like memcached tool. On the positive side, you can specify any
    column from &amp;#8220;stats&amp;#8221;, &amp;#8220;stats items&amp;#8221; or &amp;#8220;stats slabs&amp;#8221; in the
    configuration file, and can choose between average or one-second
    snapshots for each column. On the down side, it requires the &lt;span class="caps"&gt;YAML&lt;/span&gt;
    and AnyEvent Perl modules, so it has some uncommon&amp;nbsp;dependencies.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;damemtop: Tue Jun 26 14:02:24 2012 [sort: hostname asc] [delay: 3s]
hostname           all_version  all_fill_rate  hit_rate  evictions  curr_items  curr_connections   cmd_get  cmd_set  bytes_written  bytes_read  get_hits  get_misses  
TOTAL:             
NA                 NA           NA             NA        NA         NA          NA                 87       32       491,735        30,894      86        1           
AVERAGE:           
NA                 NA           86.00%         99.00%    NA         NA          NA                 43       16       122,933        7,723       43        1           
10.200.1.78:11211  1.2.6        86.63%         98.04%    0          0           -1.00204024880524  51       19       386,492        21,613      50        1           
10.200.1.78:11212  1.2.6        85.46%         NA        0          0           0                  0        0        11,373         31          0         0           
10.200.1.79:11211  1.2.6        87.31%         100.00%   0          0           -1.00204024880524  36       13       82,479         9,219       36        0           
10.200.1.79:11212  1.2.6        85.08%         NA        0          0           0                  0        0        11,389         31          0         0           
loop took: 0.305617094039917
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;#8217;m still looking around for something for apache that uses mod_status
and isn&amp;#8217;t too verbose; ideally I&amp;#8217;d like to be able to watch memcached,
apache response codes/times, and apache mod_status all in the same
terminal&amp;nbsp;window.&lt;/p&gt;</summary><category term="apache"></category><category term="memcached"></category><category term="perl"></category><category term="top"></category><category term="troubleshooting"></category></entry><entry><title>Emacs Mode Variable for HTML</title><link href="http://blog.jasonantman.com/2012/06/emacs-mode-variable-for-html/" rel="alternate"></link><updated>2012-06-26T08:43:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-06-26:2012/06/emacs-mode-variable-for-html/</id><summary type="html">&lt;p&gt;Unfortunately, I often find myself editing files that are mixed &lt;span class="caps"&gt;PHP&lt;/span&gt; and
&lt;span class="caps"&gt;HTML&lt;/span&gt;, and ending with a &amp;#8220;.php&amp;#8221; extension. For most smaller
projects/tasks, I use &lt;a href="http://www.gnu.org/software/emacs/"&gt;emacs&lt;/a&gt; at the
command line (nox) and my .emacs settings for
&lt;a href="http://php-mode.sourceforge.net/"&gt;php-mode&lt;/a&gt; will latch onto the &amp;#8220;.php&amp;#8221;
extension and open it with &lt;span class="caps"&gt;PHP&lt;/span&gt; mode. Unfortunately, &lt;span class="caps"&gt;PHP&lt;/span&gt; mode really
doesn&amp;#8217;t like embedded &lt;span class="caps"&gt;HTML&lt;/span&gt; (let alone mostly &lt;span class="caps"&gt;HTML&lt;/span&gt; with some inline &lt;span class="caps"&gt;PHP&lt;/span&gt;),
and the indentation gets very messy, among other&amp;nbsp;problems.&lt;/p&gt;
&lt;p&gt;The simple solution is to add the following (&lt;span class="caps"&gt;XHTML&lt;/span&gt; 1.0
Transitional-compliant) comment to the first line of the file, which
tells emacs to load&amp;nbsp;html-mode:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;&amp;lt;!-- -*- mode: html; -*- --&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can also get emacs to do this for you, as per the &lt;a href="http://www.gnu.org/software/emacs/manual/html_node/emacs/Specifying-File-Variables.html"&gt;Specifying File
Variables&lt;/a&gt;
documentation page. Once in html-mode, simply &lt;code&gt;M-x
add-file-local-variable-prop-line&lt;/code&gt;, enter &amp;#8220;mode&amp;#8221; for the variable
name and use the default of the current&amp;nbsp;mode.&lt;/p&gt;</summary><category term="emacs"></category><category term="html. php"></category></entry><entry><title>Apache httpd - logging for sites with and without load balancing</title><link href="http://blog.jasonantman.com/2012/05/apache-httpd-logging-for-sites-with-and-without-load-balancing/" rel="alternate"></link><updated>2012-05-30T09:46:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-05-30:2012/05/apache-httpd-logging-for-sites-with-and-without-load-balancing/</id><summary type="html">&lt;p&gt;There are a few unfortunate places where I have an Apache httpd server
serving multiple vhosts, some behind a F5 BigIp load balancer and some
with direct traffic. For sites behind the &lt;span class="caps"&gt;LB&lt;/span&gt;, the remote &lt;span class="caps"&gt;IP&lt;/span&gt;/host will
always show up as the &lt;span class="caps"&gt;LB&lt;/span&gt;&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;/host, not that of the actual client. Using
the default configuration with LogFormat directives in &lt;code&gt;httpd.conf&lt;/code&gt;,
this means that either we need to define log formats per-vhost or lose
the client &lt;span class="caps"&gt;IP&lt;/span&gt; in one of our scenarios (&lt;span class="caps"&gt;LB&lt;/span&gt; or no&amp;nbsp;&lt;span class="caps"&gt;LB&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;I came by a simple solution to this on &lt;a href="http://www.maretmanu.org/homepage/inform/apache-forwarded.php"&gt;Emmanuel
Chantréau&lt;/a&gt;&amp;#8216;s
blog, and here is my condensed version of it. It sets an environment
variable (&amp;#8220;bigip-request&amp;#8221;) if the BIOrigClientAddr request header is set
(this header holds the client&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;; it&amp;#8217;s the BigIp proprietary version
of the X-Forwarded-For header. You could easily substitute that more
standard header in the following snippet) and then sets the &amp;#8220;combined&amp;#8221;
LogFormat based on that variable - a version using BIOrigClientAddr if
it is set, and a version using the normal &amp;#8220;%h&amp;#8221; remote host&amp;nbsp;otherwise.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;httpd.conf:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# set the &amp;quot;bigip-request&amp;quot; env variable to &amp;quot;1&amp;quot; if there is a BIOrigClientAddr header in the request                                                                                                   &lt;/span&gt;
&lt;span class="nb"&gt;SetEnvIf&lt;/span&gt; BIOrigClientAddr . bigip-request
&lt;span class="c"&gt;# we&amp;#39;ll use this following LogFormat (BIOrigClientAddr in place of remote host) as &amp;quot;combined&amp;quot; &lt;span class="caps"&gt;IF&lt;/span&gt; the bigip-request env variable is set                                                                     &lt;/span&gt;
&lt;span class="nb"&gt;LogFormat&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%{BIOrigClientAddr}i %l %u %t %v \&amp;quot;%r\&amp;quot; %&amp;gt;s %b \&amp;quot;%{Referer}i\&amp;quot; \&amp;quot;%{User-Agent}i\&amp;quot;&amp;quot;&lt;/span&gt; combined_lb
&lt;span class="c"&gt;# else we&amp;#39;ll use this one (remote host &lt;span class="caps"&gt;IP&lt;/span&gt; address) as &amp;quot;combined&amp;quot; &lt;span class="caps"&gt;IF&lt;/span&gt; the bigip-request env variable is &lt;span class="caps"&gt;NOT&lt;/span&gt; set                                                                                   &lt;/span&gt;
&lt;span class="nb"&gt;LogFormat&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%h %l %u %t %v \&amp;quot;%r\&amp;quot; %&amp;gt;s %b \&amp;quot;%{Referer}i\&amp;quot; \&amp;quot;%{User-Agent}i\&amp;quot;&amp;quot;&lt;/span&gt; combined
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then in our vhost&amp;nbsp;configuration:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# use this log format if we&amp;#39;re behind an &lt;span class="caps"&gt;LB&lt;/span&gt;&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; logs/&amp;lt;%= domain %&amp;gt;_access_log combined env=!bigip-request
&lt;span class="c"&gt;# or this format if we&amp;#39;re not&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; logs/&amp;lt;%= domain %&amp;gt;_access_log combined_lb env=bigip-request
&lt;/pre&gt;&lt;/div&gt;</summary><category term="apache"></category><category term="bigip"></category><category term="f5"></category><category term="httpd"></category><category term="load balancer"></category><category term="logging"></category></entry><entry><title>Creating RPMs from Perl CPAN Modules</title><link href="http://blog.jasonantman.com/2012/05/creating-rpms-from-perl-cpan-modules/" rel="alternate"></link><updated>2012-05-15T15:01:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-05-15:2012/05/creating-rpms-from-perl-cpan-modules/</id><summary type="html">&lt;p&gt;I try my absolute best to always install software on my Linux boxes as
&lt;a href="http://en.wikipedia.org/wiki/RPM_Package_Manager"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt;&lt;/a&gt;s, installed
through &lt;a href="http://yum.baseurl.org/"&gt;Yum&lt;/a&gt; (yes, I use
&lt;a href="http://www.centos.org"&gt;CentOS&lt;/a&gt; on servers and
&lt;a href="http://fedoraproject.org/"&gt;Fedora&lt;/a&gt; on my desktops/laptops). Not only is
this more-or-less required to sanely manage configuration through
Puppet, but it also lets me recreate a machine, or install dependencies
for something, in one simple command line. Unfortunately, I run quite a
bit of Perl code, and there are a lot of &lt;a href="http://www.cpan.org/"&gt;&lt;span class="caps"&gt;CPAN&lt;/span&gt;&lt;/a&gt;
Perl modules that aren&amp;#8217;t in any of the usual CentOS/Fedora&amp;nbsp;repositories.&lt;/p&gt;
&lt;p&gt;Enter cpan2rpm: a Perl script that, in its simplest invocation,
downloads a specified &lt;span class="caps"&gt;CPAN&lt;/span&gt; module and automatically builds RPMs and
SRPMs for it. The &lt;a href="http://perl.arix.com/cpan2rpm/"&gt;original version&lt;/a&gt; by
&lt;a href="http://www.arix.com/ec/"&gt;Erick Calder&lt;/a&gt; hasn&amp;#8217;t been touched since 2005,
but there&amp;#8217;s &lt;a href="http://www.mediaburst.co.uk/blog/creating-perl-module-rpms/"&gt;a newer version from
Mediaburst&lt;/a&gt;,
&lt;a href="http://www2.mbstatic.co.uk/wp-content/uploads/2009/09/cpan2rpmmb"&gt;cpan2rpmmb&lt;/a&gt;,
that seems to incorporate some nice improvements and worked quite well
for&amp;nbsp;me.&lt;/p&gt;</summary><category term="cpan"></category><category term="cpan2rpm"></category><category term="perl"></category><category term="rpm"></category><category term="yum"></category></entry><entry><title>Adjusting the VirtualBox F12 BIOS Boot Prompt Timeout</title><link href="http://blog.jasonantman.com/2012/04/adjusting-the-virtualbox-f12-bios-boot-prompt-timeout/" rel="alternate"></link><updated>2012-04-09T13:52:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-09:2012/04/adjusting-the-virtualbox-f12-bios-boot-prompt-timeout/</id><summary type="html">&lt;p&gt;I&amp;#8217;m working from home today, connected by &lt;span class="caps"&gt;VPN&lt;/span&gt;. I&amp;#8217;m in the process of
testing a bunch of Puppet stuff, and needed to re-image a bunch of
&lt;a href="https://www.virtualbox.org/"&gt;VirtualBox&lt;/a&gt; VMs on my desktop at work,
using &lt;span class="caps"&gt;PXE&lt;/span&gt; boot to &lt;a href="https://fedorahosted.org/cobbler/"&gt;Cobbler&lt;/a&gt;. I&amp;#8217;m only
connected to the desktop by &lt;span class="caps"&gt;SSH&lt;/span&gt;, and running the VMs with &lt;code&gt;VBoxHeadless&lt;/code&gt;
and connecting to them via &lt;span class="caps"&gt;RDP&lt;/span&gt; (well, &lt;span class="caps"&gt;VRDP&lt;/span&gt;). The problem with this is
that if I start a &lt;span class="caps"&gt;VM&lt;/span&gt; on my console window, then switch to my &lt;span class="caps"&gt;RDP&lt;/span&gt; client
and connect, by the time the &lt;span class="caps"&gt;VM&lt;/span&gt; gets keyboard focus, it&amp;#8217;s already past
the VBox &amp;#8220;Press F12 to select boot device&amp;#8221; prompt and booting from disk.
I could modify the boot order on the &lt;span class="caps"&gt;VM&lt;/span&gt;, but then that becomes a pain
when it reboots after the&amp;nbsp;install.&lt;/p&gt;
&lt;p&gt;Thanks to some of the guys on the &lt;a href="https://www.virtualbox.org/wiki/IRC"&gt;VirtualBox &lt;span class="caps"&gt;IRC&lt;/span&gt;
channel&lt;/a&gt;, I found out about the
&lt;code&gt;--bioslogodisplaytime&lt;/code&gt; option for VMs, which controls the length of
time (in milliseconds) that the boot splash screen is shown (the default
value seems to be 0). It&amp;#8217;s included in the &lt;a href="http://www.virtualbox.org/manual/ch08.html#vboxmanage-modifyvm"&gt;reference guide to
VBoxManage&lt;/a&gt;
in the modifyvm section. Setting this to a value of 10 seconds or so, as
shown below, is more than enough for me to start the &lt;span class="caps"&gt;VM&lt;/span&gt;, Alt-Tab to my
&lt;span class="caps"&gt;RDP&lt;/span&gt; client, connect to the &lt;span class="caps"&gt;VM&lt;/span&gt;, and hit &amp;#8216;F12&amp;#8217; to select a one-time
network&amp;nbsp;boot:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;VBoxManage modifyvm VMNAME --bioslogodisplaytime 10000
&lt;/pre&gt;&lt;/div&gt;</summary><category term="provisioning"></category><category term="pxe"></category><category term="rdp"></category><category term="sysadmin"></category><category term="vbox"></category><category term="virtualbox"></category><category term="virtualization"></category><category term="vm"></category></entry><entry><title>Adding Piwik Web Analytics Integration to ViewVC</title><link href="http://blog.jasonantman.com/2012/03/adding-piwik-web-analytics-integration-to-viewvc/" rel="alternate"></link><updated>2012-03-23T21:15:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-23:2012/03/adding-piwik-web-analytics-integration-to-viewvc/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update February 2014:&lt;/strong&gt; Give up the analytics, and just host your code
on &lt;a href="https://github.com"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All of my public &lt;a href="http://viewvc.jasonantman.com"&gt;subversion
repositories&lt;/a&gt; and &lt;a href="http://cvs.jasonantman.com"&gt;&lt;span class="caps"&gt;CVS&lt;/span&gt;
repositories&lt;/a&gt; are available online through a
great Python application called &lt;a href="http://viewvc.org/"&gt;ViewVC&lt;/a&gt;, which
provides a web-based interface to &lt;span class="caps"&gt;CVS&lt;/span&gt; and &lt;span class="caps"&gt;SVN&lt;/span&gt; repositories, as well as
history browsing, graphical diffs, etc. An amazingly large amount of the
traffic to my web server is for the vhosts that serve this, so I decided
that I should add some analytics to it. I&amp;#8217;m in the process of trying out
&lt;a href="http://piwik.org"&gt;Piwik&lt;/a&gt;, a full-featured, &lt;span class="caps"&gt;GPL&lt;/span&gt;-licensed, self-hosted
alternative to &lt;a href="http://www.google.com/analytics/"&gt;Google Analytics&lt;/a&gt;. It
gives lots of useful information like number of visits and unique visits
per page, search engine keywords, referrers, average time on page,
bounce rate (number of one-page visits),&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;I have ViewVC installed from the &lt;a href="http://pkgs.repoforge.org/viewvc/"&gt;RPMforge
packages&lt;/a&gt;, so there&amp;#8217;s one code base
for both of my vhosts. This means that I can&amp;#8217;t simply slap the tracking
code at the bottom of the templates and call it a day. I opted to go for
a nicer solution, and what follows is a patch (diff -u) to the current
(1.1.13) version of ViewVC that adds a &amp;#8220;piwik&amp;#8221; section to viewvc.conf,
and adds the piwik tracking code with the specified base &lt;span class="caps"&gt;URL&lt;/span&gt; and site &lt;span class="caps"&gt;ID&lt;/span&gt;
into all ViewVC pages.&amp;nbsp;Enjoy.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/lib/config.py viewvc/lib/config.py&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/lib/config.py   2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/lib/config.py    2012-03-23 21:57:08.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -108,6 +108,7 @@&lt;/span&gt;
     &amp;#39;query&amp;#39;,
     &amp;#39;templates&amp;#39;,
     &amp;#39;utilities&amp;#39;,
&lt;span class="gi"&gt;+    &amp;#39;piwik&amp;#39;,&lt;/span&gt;
     )
   _force_multi_value = (
     # Configuration values with multiple, comma-separated values.
&lt;span class="gu"&gt;@@ -127,6 +128,7 @@&lt;/span&gt;
                &amp;#39;options&amp;#39;,
                &amp;#39;templates&amp;#39;,
                &amp;#39;utilities&amp;#39;,
&lt;span class="gi"&gt;+               &amp;#39;piwik&amp;#39;,&lt;/span&gt;
                ),
     &amp;#39;root&amp;#39;  : (&amp;#39;authz-*&amp;#39;,
                &amp;#39;options&amp;#39;,
&lt;span class="gu"&gt;@@ -461,7 +463,14 @@&lt;/span&gt;
     self.cvsdb.check_database_for_root = 0

     self.query.viewvc_base_url = None
&lt;span class="gd"&gt;-    &lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+    # begin  patch for piwik integration&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.use_piwik = 0&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.base_url = &amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.site_id = &amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.use_jsindex = 0&lt;/span&gt;
&lt;span class="gi"&gt;+    # end  patch for piwik integration&lt;/span&gt;
&lt;span class="gi"&gt;+   &lt;/span&gt;
 def _startswith(somestr, substr):
   return somestr[:len(substr)] == substr

&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include/footer.ezt viewvc/templates/include/footer.ezt&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include/footer.ezt    2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/templates/include/footer.ezt 2012-03-23 22:03:04.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -13,5 +13,17 @@&lt;/span&gt;



&lt;span class="gi"&gt;+[is cfg.piwik.use_piwik &amp;quot;1&amp;quot;]&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+var pkBaseURL = ((&amp;quot;https:&amp;quot; == document.location.protocol) ? &amp;quot;https://[cfg.piwik.base_url]/&amp;quot; : &amp;quot;http://[cfg.piwik.base_url]/&amp;quot;);&lt;/span&gt;
&lt;span class="gi"&gt;+document.write(unescape(&amp;quot;%3Cscript src=&amp;#39;&amp;quot; + pkBaseURL + &amp;quot;[is cfg.piwik.use_jsindex &amp;quot;1&amp;quot;]js/[else]piwik.js[end]&amp;#39; type=&amp;#39;text/javascript&amp;#39;%3E%3C/script%3E&amp;quot;));&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+try {&lt;/span&gt;
&lt;span class="gi"&gt;+var piwikTracker = Piwik.getTracker(pkBaseURL + &amp;quot;piwik.php&amp;quot;, [cfg.piwik.site_id]);&lt;/span&gt;
&lt;span class="gi"&gt;+piwikTracker.trackPageView();&lt;/span&gt;
&lt;span class="gi"&gt;+piwikTracker.enableLinkTracking();&lt;/span&gt;
&lt;span class="gi"&gt;+} catch( err ) {}&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+[else][end]&lt;/span&gt;


Only in viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include: header.ezt~
&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/viewvc.conf.dist viewvc/viewvc.conf.dist&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/viewvc.conf.dist    2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/viewvc.conf.dist 2012-03-23 21:44:02.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -1131,3 +1131,29 @@&lt;/span&gt;
 #viewvc_base_url =

 ##---------------------------------------------------------------------------
&lt;span class="gi"&gt;+[piwik]&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+## This section enables Piwik  web analytics tracking.&lt;/span&gt;
&lt;span class="gi"&gt;+## If piwik is enabled (use_piwik = 1) all other options must be specified.&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## This is based on a patch by Jason Antman  &lt;/span&gt;
&lt;span class="gi"&gt;+## to ViewVC 1.1.13, written 2012-03-23.&lt;/span&gt;
&lt;span class="gi"&gt;+## The latest version of the patch, and information on it, can always be found at:&lt;/span&gt;
&lt;span class="gi"&gt;+## &lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## To enable piwik, change use_piwik to 1. Set to 0 to disable&lt;/span&gt;
&lt;span class="gi"&gt;+use_piwik = 1&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set base_url to the hostname and path to your piwik installation, with no trailing slash.&lt;/span&gt;
&lt;span class="gi"&gt;+## i.e. piwik.example.com or www.example.com/piwik&lt;/span&gt;
&lt;span class="gi"&gt;+base_url = piwik.example.com&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set to the numeric id of your website in Piwik&lt;/span&gt;
&lt;span class="gi"&gt;+site_id = 5&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set to 1 if you want to use js/index.php to serve the tracking code, &lt;/span&gt;
&lt;span class="gi"&gt;+## or leave at 0 if you want to call piwik.js directly&lt;/span&gt;
&lt;span class="gi"&gt;+use_jsindex = 0&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+##---------------------------------------------------------------------------&lt;/span&gt;
\ No newline at end of file
&lt;/pre&gt;&lt;/div&gt;</summary><category term="analytics"></category><category term="piwik"></category><category term="python"></category><category term="subversion"></category><category term="svn"></category><category term="tracking"></category><category term="viewvc"></category></entry><entry><title>MediaWiki - Preformatted Text within Lists</title><link href="http://blog.jasonantman.com/2012/03/mediawiki-preformatted-text-within-lists/" rel="alternate"></link><updated>2012-03-15T18:10:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-15:2012/03/mediawiki-preformatted-text-within-lists/</id><summary type="html">&lt;p&gt;As I discovered this morning, with &lt;a href="http://www.mediawiki.org"&gt;MediaWiki&lt;/a&gt;
1.5.7+, if you attempt to put a &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; wraped block of code within a
numbered list, the indentation breaks and the numbering starts over
after the &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; block. This was pretty annoying, as I was trying to
document a procedure including the commands to be run and their
explanation. It took a few minutes, but I found the solution in the
&lt;a href="http://meta.wikimedia.org/wiki/Help:Editing_FAQ#Q:_Can_I_put_preformatted_text_inside_a_numbered_list.3F"&gt;wikimedia Help:Editing
&lt;span class="caps"&gt;FAQ&lt;/span&gt;&lt;/a&gt;
page, thanks to &lt;a href="http://meta.wikimedia.org/wiki/User:Rompe"&gt;Ulf Rompe&lt;/a&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# one
# two
#:
#:here are a couple lines
#:of preformatted text
#:
# and the numbering
# continues
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code lines are indented a bit more than what looks right, but it&amp;nbsp;works.&lt;/p&gt;</summary><category term="formatting"></category><category term="mediawiki"></category><category term="wiki"></category></entry><entry><title>Meld - Graphical Diff Tool for SVN Directories</title><link href="http://blog.jasonantman.com/2012/03/meld-graphical-diff-tool-for-svn-directories/" rel="alternate"></link><updated>2012-03-12T09:48:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-12:2012/03/meld-graphical-diff-tool-for-svn-directories/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been in the process of manually merging two directories in a
subversion repo. The second started out as a &amp;#8220;development&amp;#8221; copy of the
first (without branching, unfortunately). Since there&amp;#8217;s quite a few
files, I decided that a graphical diff program is a must. I usually use
&lt;a href="http://kdiff3.sourceforge.net"&gt;kdiff3&lt;/a&gt;, but my requirements for this
are a bit more stringent than usual: it has to handle recursive diffs on
two directories, and it has to be able to ignore &lt;span class="caps"&gt;SVN&lt;/span&gt; keywords (or an
arbitrary regex) since all of the files have keyword substitution on
LastChangedRevision and HeadURL. Kdiff3 supports &lt;a href="http://kdiff3.sourceforge.net/doc/preprocessors.html"&gt;preprocessor
commands&lt;/a&gt; which
can include filtering the text through sed before performing the diff
(so I modified their regex to ignore version control keywords), but for
some reason (perhaps either bimary differences, or metadata differences)
I couldn&amp;#8217;t get the file difference indicator in the diretory tree view
to reflect this; even when ignoring keyword lines and whitespace, it
still showed every pair of files as&amp;nbsp;different.&lt;/p&gt;
&lt;p&gt;Enter &lt;a href="http://meldmerge.org/"&gt;Meld&lt;/a&gt;, a graphical diff project. I&amp;#8217;ve only
used it for half an hour or so, but it seems wonderful. It&amp;#8217;s easy to
use, has a pleasing interface similar to
&lt;a href="http://www.caffeinated.me.uk/kompare/"&gt;Kompare&lt;/a&gt;, and even has simple
check boxes in the options menu to ignore whitespace and &lt;span class="caps"&gt;SVN&lt;/span&gt; keywords -
and they work! So far, I&amp;#8217;m about half way through my 300+ file tree, and
the merge is going&amp;nbsp;wonderfully.&lt;/p&gt;</summary><category term="diff"></category><category term="kde"></category><category term="kdiff"></category><category term="meld"></category><category term="merge"></category><category term="subversion"></category><category term="svn"></category></entry><entry><title>Using VirtualBox Remotely</title><link href="http://blog.jasonantman.com/2012/03/using-virtualbox-remotely/" rel="alternate"></link><updated>2012-03-09T12:00:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-09:2012/03/using-virtualbox-remotely/</id><summary type="html">&lt;p&gt;At work, I have a pretty beefy workstation (a Dell OptiPlex 990 with a
3.4GHz Intel Core i7-2600 and &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt; running Fedora 16) that I usually
run a few VMs on as my test/development environment. I usually reboot my
machine every other week or so, and start VirtualBox and my VMs once the
system boots. All of the VMs are Linux boxes, running test-only, so I
never really cared about &lt;span class="caps"&gt;RDP&lt;/span&gt; or anything like that. Today I&amp;#8217;m working
from home and need to setup a new development environment, so here&amp;#8217;s how
to get VirtualBox working nicely assuming you&amp;#8217;ve never set it up for
&lt;span class="caps"&gt;VRDP&lt;/span&gt; (its Virtual Remote Desktop Protocol) before, and have a network
connection (&lt;span class="caps"&gt;LAN&lt;/span&gt; or &lt;span class="caps"&gt;VPN&lt;/span&gt; or something) to the machine running VirtualBox.
I currently have VirtualBox &lt;span class="caps"&gt;OSE&lt;/span&gt; 4.1.8 installed from
&lt;a href="http://nonfree.rpmfusion.org/"&gt;rpmfusion&lt;/a&gt; &lt;span class="caps"&gt;RPM&lt;/span&gt;. Most of this can be
found in &lt;a href="http://www.virtualbox.org/manual/ch07.html"&gt;Chapter 7 of the VirtualBox
manual&lt;/a&gt;, but here&amp;#8217;s a
step-by-step&amp;nbsp;method.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First, download the Oracle (non-free) Oracle VirtualBox &lt;span class="caps"&gt;VM&lt;/span&gt; Extension
Pack tarball from the &lt;a href="https://www.virtualbox.org/wiki/Downloads"&gt;VirtualBox Downloads
Page&lt;/a&gt;, which provides &lt;span class="caps"&gt;VRDP&lt;/span&gt;
support (as well as support for the virtual &lt;span class="caps"&gt;USB&lt;/span&gt; 2.0 device, Intel &lt;span class="caps"&gt;PXE&lt;/span&gt;
Boot &lt;span class="caps"&gt;ROM&lt;/span&gt; support for the E1000 &lt;span class="caps"&gt;NIC&lt;/span&gt; driver, and experimental Linux host
&lt;span class="caps"&gt;PCI&lt;/span&gt; passthrough suport). Then install it&amp;nbsp;using:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;sudo VBoxManage extpack install Oracle_VM_VirtualBox_Extension_Pack-4.1.8-75467.vbox-extpack
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assuming you have an existing &lt;span class="caps"&gt;VM&lt;/span&gt; (you can list them using &lt;code&gt;VBoxManage list vms&lt;/code&gt;), enable &lt;span class="caps"&gt;VRDP&lt;/span&gt; support on&amp;nbsp;it:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;VBoxManage modifyvm &amp;quot;VM name&amp;quot; --vrde on
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I like to assign specific ports to &lt;span class="caps"&gt;VRDP&lt;/span&gt; on each &lt;span class="caps"&gt;VM&lt;/span&gt; so I can &amp;#8220;bookmark&amp;#8221;
them in my &lt;a href="http://kde.org/applications/internet/krdc/"&gt;&lt;span class="caps"&gt;KRDC&lt;/span&gt;&lt;/a&gt; client by
&lt;span class="caps"&gt;VM&lt;/span&gt; name. I generally start with 10011, as the 10011-10049 range is both
unassigned and doesn&amp;#8217;t appear in my &lt;code&gt;/etc/services&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;VBoxManage modifyvm &amp;quot;VM name&amp;quot; --vrdeport 10011
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the &lt;span class="caps"&gt;VM&lt;/span&gt;, using VBoxHeadless (shows more debugging/errors, but also
stays in the foreground, so you&amp;#8217;ll want to use
&lt;a href="http://www.gnu.org/software/screen/"&gt;screen&lt;/a&gt; or something like&amp;nbsp;it):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;VBoxHeadless --startvm &amp;quot;VM name&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If all went well, it should show some output including a confirmation
that the &lt;span class="caps"&gt;VRDE&lt;/span&gt; server is running on the correct&amp;nbsp;port:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Oracle VM VirtualBox Headless Interface 4.1.8_OSE
(C) 2008-2012 Oracle Corporation
All rights reserved.

VRDE server is listening on port 3389.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That&amp;#8217;s it. Assuming you&amp;#8217;re using something like
&lt;a href="http://www.gnu.org/software/screen/"&gt;screen&lt;/a&gt;, you can start a whole
bunch of new VMs, and still keep the VBoxHeadless output in case of an&amp;nbsp;error.&lt;/p&gt;</summary><category term="rdp"></category><category term="virtualbox"></category><category term="virtualization"></category><category term="vm"></category></entry><entry><title>VMWare vSphere CLI and Perl SDK as an RPM</title><link href="http://blog.jasonantman.com/2012/02/vmware-vsphere-cli-and-perl-sdk-as-an-rpm/" rel="alternate"></link><updated>2012-02-28T19:01:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-28:2012/02/vmware-vsphere-cli-and-perl-sdk-as-an-rpm/</id><summary type="html">&lt;p&gt;Lately I&amp;#8217;ve been playing around with the VMWare &lt;a href="http://www.vmware.com/support/developer/viperltoolkit/"&gt;vSphere &lt;span class="caps"&gt;SDK&lt;/span&gt; for
Perl&lt;/a&gt;, since the
new job uses a bunch of VMWare stuff (and I&amp;#8217;ve been starting my foray
into Perl as a new language, and am amazed by the &lt;a href="http://www.cpan.org/"&gt;massive
number&lt;/a&gt; of modules out there). As much as I find
&lt;a href="http://yum.baseurl.org/"&gt;&lt;code&gt;yum&lt;/code&gt;&lt;/a&gt; limiting having used
&lt;a href="http://en.opensuse.org/Portal:Zypper"&gt;&lt;code&gt;zypper&lt;/code&gt;&lt;/a&gt; on OpenSuSE, I&amp;#8217;m not
much of a fan of non-natively-packaged software. Not only is it more
difficult to maintain and upgrade a system and nearly impossible to
nicely automate when building from source (or a proprietary installer
script), it&amp;#8217;s also much more difficult to transition from a development
environment to&amp;nbsp;production.&lt;/p&gt;
&lt;p&gt;In a quick search, I found a perfectly working spec file and some
&lt;span class="caps"&gt;RHEL&lt;/span&gt;/Cent-specific patches (and even beginner-level &lt;code&gt;rpmbuild&lt;/code&gt;
instructions) for the current 5.0.0-422456 VMWare &lt;span class="caps"&gt;CLI&lt;/span&gt; and Perl &lt;span class="caps"&gt;SDK&lt;/span&gt; for
x86_64 at
&lt;a href="http://www.firetooth.net/confluence/display/public/vSphere+Perl+SDK+and+CLI+RPM+Packages"&gt;http://www.firetooth.net/confluence/display/public/vSphere+Perl+&lt;span class="caps"&gt;SDK&lt;/span&gt;+and+&lt;span class="caps"&gt;CLI&lt;/span&gt;+&lt;span class="caps"&gt;RPM&lt;/span&gt;+Packages&lt;/a&gt;.
Many thanks to &lt;a href="http://www.linkedin.com/in/vwhitteron"&gt;Vaughan
Whitteron&lt;/a&gt; of &lt;span class="caps"&gt;NSW&lt;/span&gt; in Australia
for posting this! It built and installed without any problems on my
Fedora 16 desktop, and a CentOS 6.2 development&amp;nbsp;box.&lt;/p&gt;</summary><category term="perl"></category><category term="rpm"></category><category term="vcli"></category><category term="vmware"></category><category term="vsphere"></category></entry><entry><title>F5 BigIp - Manually Changing Session Persistence Cookies on the Client Side</title><link href="http://blog.jasonantman.com/2012/02/f5-bigip-manually-changing-session-persistence-cookies-on-the-client-side/" rel="alternate"></link><updated>2012-02-03T13:32:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-03:2012/02/f5-bigip-manually-changing-session-persistence-cookies-on-the-client-side/</id><summary type="html">&lt;p&gt;Yesterday I was asked to help out a bit debugging issues with a site
that sits behind a &lt;a href="http://www.f5.com/products/big-ip/"&gt;F5 &lt;span class="caps"&gt;BIG&lt;/span&gt;-&lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/a&gt; load
balancer (&lt;span class="caps"&gt;LB&lt;/span&gt;). It&amp;#8217;s a pretty simple site, load balanced between two web
servers. The developers were complaining about intermittent page load
issues, so I immediately considered a problem with one of the two
servers (&lt;em&gt;ass&lt;/em&gt;uming that the devs were clearing cookies and cache
between attempts). The &lt;span class="caps"&gt;LB&lt;/span&gt; is using &lt;span class="caps"&gt;HTTP&lt;/span&gt; Cookies for client session
persistence, but no matter how many times I cleared my cookies, I kept
being sent to the same back-end server. I know I could have added an
iRule to the &lt;span class="caps"&gt;LB&lt;/span&gt;, but it seems like bad practice to change a production
configuration for debugging something like&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;If your site uses a BigIp with cookies for persistence, it&amp;#8217;s no problem
to edit the cookies manually to force yourself to another back-end
server. Simply look through the cookies for a given site using something
like the &lt;a href="https://addons.mozilla.org/en-US/firefox/addon/web-developer/"&gt;Web Developer addon for
Firefox&lt;/a&gt;;
the BigIp cookie is named like &amp;#8220;BigIpServer&amp;lt;poolname&gt;&amp;#8221;. The encoding
information is specified by F5 in their knowledge base &lt;a href="http://support.f5.com/kb/en-us/solutions/public/6000/900/sol6917.html"&gt;sol6917:
Overview of &lt;span class="caps"&gt;BIG&lt;/span&gt;-&lt;span class="caps"&gt;IP&lt;/span&gt; persistence cookie
encoding&lt;/a&gt;.
I also managed to find a Perl one-liner from Tyler Krpata, Manger of
Security Engineering at Constant Contact, &lt;a href="http://www.tylerkrpata.com/2009/06/decode-f5-bigip-cookie-in-one-line-of.html"&gt;in a post on his
blog&lt;/a&gt;.
I built on that work to develop the following perl script, which can
both encode and decode BigIP cookie &lt;span class="caps"&gt;IP&lt;/span&gt;/port values. The latest version lives
on my &lt;a href="https://github.com/jantman/misc-scripts/blob/master/bigipcookie.pl"&gt;GitHub misc-scripts repository&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!/usr/bin/perl&lt;/span&gt;

&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Perl script to de/encode F5 BigIp persistence cookies.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# The latest version of this script can always be obtained from:&lt;/span&gt;
&lt;span class="c1"&gt;#    via &lt;span class="caps"&gt;HTTP&lt;/span&gt; ot &lt;span class="caps"&gt;SVN&lt;/span&gt;&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Update information and description can be found at:&lt;/span&gt;
&lt;span class="c1"&gt;#   &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Copyright 2012 Jason Antman  .&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#########################################################################################&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;LICENSE&lt;/span&gt;: AGPLv3 &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#    This program is free software: you can redistribute it and/or modify&lt;/span&gt;
&lt;span class="c1"&gt;#    it under the terms of the &lt;span class="caps"&gt;GNU&lt;/span&gt; Affero General Public License as published by&lt;/span&gt;
&lt;span class="c1"&gt;#    the Free Software Foundation, either version 3 of the License, or&lt;/span&gt;
&lt;span class="c1"&gt;#    (at your option) any later version.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#    This program is distributed in the hope that it will be useful,&lt;/span&gt;
&lt;span class="c1"&gt;#    but &lt;span class="caps"&gt;WITHOUT&lt;/span&gt; &lt;span class="caps"&gt;ANY&lt;/span&gt; &lt;span class="caps"&gt;WARRANTY&lt;/span&gt;; without even the implied warranty of&lt;/span&gt;
&lt;span class="c1"&gt;#    &lt;span class="caps"&gt;MERCHANTABILITY&lt;/span&gt; or &lt;span class="caps"&gt;FITNESS&lt;/span&gt; &lt;span class="caps"&gt;FOR&lt;/span&gt; A &lt;span class="caps"&gt;PARTICULAR&lt;/span&gt; &lt;span class="caps"&gt;PURPOSE&lt;/span&gt;.  See the&lt;/span&gt;
&lt;span class="c1"&gt;#    &lt;span class="caps"&gt;GNU&lt;/span&gt; Affero General Public License for more details.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#    You should have received a copy of the &lt;span class="caps"&gt;GNU&lt;/span&gt; Affero General Public License&lt;/span&gt;
&lt;span class="c1"&gt;#    along with this program.  If not, see .&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# If you make any modifications/fixes/feature additions, it would be greatly appreciated&lt;/span&gt;
&lt;span class="c1"&gt;# if you send them back to me at the above email address.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#########################################################################################&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;CREDITS&lt;/span&gt;:&lt;/span&gt;
&lt;span class="c1"&gt;# - F5 itself for the formula: &lt;/span&gt;
&lt;span class="c1"&gt;# - Tyler Krpata &lt;/span&gt;
&lt;span class="c1"&gt;#     for the Perl one-liner that this logic is based on.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# $HeadURL: http://svn.jasonantman.com/misc-scripts/bigipcookie.pl $&lt;/span&gt;
&lt;span class="c1"&gt;# $LastChangedRevision: 27 $&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Changelog:&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# 2012-02-02 Jason Antman :&lt;/span&gt;
&lt;span class="c1"&gt;#   - initial version&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;strict&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;warnings&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="nv"&gt;$#&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: bigipcookie.pl \n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt; &lt;span class="sr"&gt;m/^(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3}):(\d+)$/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$ipEnc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$3&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$portEnc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;hex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;join&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reverse&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;sprintf&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%04x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt;&lt;span class="sr"&gt; /../g&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$ipEnc.$portEnc.0000\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;elsif&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt; &lt;span class="sr"&gt;m/^(\d+)\.(\d+)\.0000$/&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="c1"&gt;# decode a cookie value&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$ipEnc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$portEnc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;join&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;map&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;hex&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nb"&gt;reverse&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;sprintf&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%08x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;split&lt;/span&gt; &lt;span class="sr"&gt;/\./&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$ipEnc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt;&lt;span class="sr"&gt; /../g&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$portDec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;hex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;join&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;reverse&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nb"&gt;sprintf&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;%04x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$portEnc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt;&lt;span class="sr"&gt; /../g&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$ip:$portDec\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: bigipcookie.pl \n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;An example of the&amp;nbsp;usage:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;jantman@palantir:pts/8:~/bin/misc-scripts &amp;gt; ./bigipcookie.pl 192.168.23.50:80&lt;/span&gt;
&lt;span class="go"&gt;840411328.20480.0000&lt;/span&gt;
&lt;span class="go"&gt;jantman@palantir:pts/8:~/bin/misc-scripts &amp;gt; ./bigipcookie.pl 840411328.20480.0000&lt;/span&gt;
&lt;span class="go"&gt;192.168.23.50:80&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;On a side note for those of your who are security-conscious: yes, of
course, this means that if you&amp;#8217;re using BigIp with cookie persistence,
it is disclosing the internal &lt;span class="caps"&gt;IP&lt;/span&gt; and port of your server to your end&amp;nbsp;users.&lt;/p&gt;</summary><category term="bigip"></category><category term="cookies"></category><category term="debugging"></category><category term="f5"></category><category term="load balancer"></category><category term="perl"></category><category term="persistence"></category><category term="web app"></category></entry><entry><title>GNU Screen and Multiple Regions</title><link href="http://blog.jasonantman.com/2012/02/gnu-screen-and-multiple-regions/" rel="alternate"></link><updated>2012-02-03T09:13:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-03:2012/02/gnu-screen-and-multiple-regions/</id><summary type="html">&lt;p&gt;Since I always seem to forget this wonderful feature of &lt;a href="http://www.gnu.org/software/screen/"&gt;&lt;span class="caps"&gt;GNU&lt;/span&gt;
screen&lt;/a&gt; (probably one of the pieces
of software I use the most every&amp;nbsp;day)&amp;#8230;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To split the current region horizontally into two equal regions:
    &lt;code&gt;C-a S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To switch between those regions: &lt;code&gt;C-a Tab&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To close all regions but the current one: &lt;code&gt;C-a Q&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is absolutely invaluable for watching logs on multiple machines at&amp;nbsp;once.&lt;/p&gt;</summary><category term="console"></category><category term="screen"></category><category term="sysadmin"></category></entry><entry><title>Using Templates to Track Outdated Content in a Documentation MediaWiki</title><link href="http://blog.jasonantman.com/2012/02/using-templates-to-track-outdated-content-in-a-documentation-mediawiki/" rel="alternate"></link><updated>2012-02-02T11:02:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-02-02:2012/02/using-templates-to-track-outdated-content-in-a-documentation-mediawiki/</id><summary type="html">&lt;p&gt;Both my last and current jobs use &lt;a href="http://www.mediawiki.org/"&gt;MediaWiki&lt;/a&gt;
for internal documentation. As always happens, some of this
documentation will inevitably get out-of-date, or totally deprecated. As
is also the case, many times when we&amp;#8217;re looking for docs in the middle
of an incident, we don&amp;#8217;t have the time to go back and fix what&amp;#8217;s wrong.
So, I devised the following template/category system to help keep track
of these problem&amp;nbsp;pages.&lt;/p&gt;
&lt;p&gt;First, create some templates that you will apply to the problem pages. I
use three - one for totally deprecated pages, one for pages that need
updating, and one for pages that just need cleanup. For the cleanup
template, in the MediaWiki search box, enter &amp;#8220;Template:Cleanup&amp;#8221; and
click &amp;#8220;go&amp;#8221;. You should be told that the page doesn&amp;#8217;t exist, and given a
link to create the page. Create it, and enter the following&amp;nbsp;content:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;[[Image:Cleanup.png]]

&amp;#39;&amp;#39;&amp;#39;This page needs to be cleaned up or reorganized.&amp;#39;&amp;#39;&amp;#39;

[[Category:Pages Needing Cleanup]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we create a category page for it, &amp;#8220;Category:Pages Needing Cleanup&amp;#8221;,
with the&amp;nbsp;content:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;__HIDDENCAT__

This category is for pages that are mostly correct and just need minor corrections or reorganization.

&amp;#39;&amp;#39;&amp;#39;To add pages to this category&amp;#39;&amp;#39;&amp;#39;, include the following at the &amp;#39;&amp;#39;&amp;#39;TOP&amp;#39;&amp;#39;&amp;#39; of the page:

{{cleanup}}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and save the&amp;nbsp;page.&lt;/p&gt;
&lt;p&gt;Now there&amp;#8217;s a few other changes we need to make. First, upload the
Cleanup.png graphic, which I got from wikimedia.org
&lt;a href="http://upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/40px-Edit-clear.svg.png"&gt;here&lt;/a&gt;
and uploaded as&amp;nbsp;Cleanup.png.&lt;/p&gt;
&lt;p&gt;If you refresh the Template:Cleanup page, you should now see the image.
On a side note, &amp;#8220;__HIDDENCAT__&amp;#8221; on the category page prevents that
category from showing up in the category list at the bottom of the pages
we add to it, but this only works in MediaWiki 1.13 and&amp;nbsp;up.&lt;/p&gt;
&lt;p&gt;The last step is to add the &lt;a href="http://www.mediawiki.org/wiki/Template:Mbox"&gt;MediaWiki mbox
template&lt;/a&gt; and its
dependencies. While I did this once before, I didn&amp;#8217;t really remember the
steps, but I found a post on &lt;a href="http://glynor.com/2010/05/the-trouble-with-ambox-and-mbox/"&gt;Glynor&amp;#8217;s
blog&lt;/a&gt; that
details them rather&amp;nbsp;nicely:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Enable the &lt;a href="http://www.mediawiki.org/wiki/Extension:ParserFunctions"&gt;ParserFunctions
    extension&lt;/a&gt;.
    There are download and install instructions on the extension page,
    but you&amp;#8217;ll want to enable string functions. To do this, include the
    extension in LocalSettings.php&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;require_once( &amp;quot;$&lt;span class="caps"&gt;IP&lt;/span&gt;/extensions/ParserFunctions/ParserFunctions.php&amp;quot; );&lt;/span&gt;
&lt;span class="x"&gt;$wgPFEnableStringFunctions = true;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a new page in your wiki called &amp;#8220;Mediawiki:Common.css&amp;#8221;, and
    paste in the content from &lt;a href="http://www.mediawiki.org/wiki/MediaWiki:Common.css"&gt;MediaWiki.org
    MediaWiki:Common.css&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Go to &lt;a href="http://en.wikipedia.org/w/index.php?title=Special:Export"&gt;Wikipedia&amp;#8217;s
    Special:Export&lt;/a&gt;
    page, and enter &amp;#8220;Template:Ambox&amp;#8221; in the box, check off &amp;#8220;Include
    templates&amp;#8221;, and export the template (and all dependencies) to a
    local &lt;span class="caps"&gt;XML&lt;/span&gt;&amp;nbsp;file.&lt;/li&gt;
&lt;li&gt;Go to the &amp;#8220;Special:Import&amp;#8221; page of your wiki, and upload the &lt;span class="caps"&gt;XML&lt;/span&gt;
    file you just grabbed from Wikipedia. This will import the Ambox and
    mbox templates, as well as their&amp;nbsp;dependencies.&lt;/li&gt;
&lt;li&gt;Now, if you go back and refresh the Template:Cleanup page you
    created, you should see the icon and a nice message&amp;nbsp;box:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="cleanup message box" src="/GFX/mw_cleanup.png" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, add the template and category pages for update and&amp;nbsp;deprecated:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Template:Update&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;[[Image:Warning.png]]

&amp;#39;&amp;#39;&amp;#39;This page is in need of updating. Some information on it may be out of date, and should not be relied on.&amp;#39;&amp;#39;&amp;#39;

[[Category:Pages Needing Updates]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;Category:Pages Needing Updates&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;__HIDDENCAT__

This category keeps track of pages that need changes or updates.

&amp;#39;&amp;#39;&amp;#39;To add pages to this category&amp;#39;&amp;#39;&amp;#39;, include the following at the &amp;#39;&amp;#39;&amp;#39;TOP&amp;#39;&amp;#39;&amp;#39; of the page:

{{update}}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;Template:Deprecated&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;[[Image:Critical.png]]

&amp;#39;&amp;#39;&amp;#39;The information on this page is badly out-of-date.&amp;#39;&amp;#39;&amp;#39; It describes a system that is no longer in production or has drastically changed, and &amp;#39;&amp;#39;&amp;#39;needs to be updated or rewritten&amp;#39;&amp;#39;&amp;#39;.

[[Category:Deprecated Content]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;Category:Deprecated Content&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt; __HIDDENCAT__

This category keeps track of pages that are &amp;#39;&amp;#39;&amp;#39;seriously old&amp;#39;&amp;#39;&amp;#39; or otherwise describe systems/hosts/etc. that have seriously changed from what is described in the page.

&amp;#39;&amp;#39;&amp;#39;To add pages to this category&amp;#39;&amp;#39;&amp;#39;, include the following at the &amp;#39;&amp;#39;&amp;#39;TOP&amp;#39;&amp;#39;&amp;#39; of the page:

{{deprecated}}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the download the two images -
&lt;a href="http://upload.wikimedia.org/wikipedia/commons/9/98/Ambox_deletion.png"&gt;http://upload.wikimedia.org/wikipedia/commons/9/98/Ambox_deletion.png&lt;/a&gt;
gets uploaded as Critical.png and
&lt;a href="http://upload.wikimedia.org/wikipedia/en/f/f4/Ambox_content.png"&gt;http://upload.wikimedia.org/wikipedia/en/f/f4/Ambox_content.png&lt;/a&gt;
gets uploaded as&amp;nbsp;Warning.png.&lt;/p&gt;
&lt;p&gt;That&amp;#8217;s it. To use this, just add &lt;code&gt;{{cleanup}}&lt;/code&gt;, &lt;code&gt;{{deprecated}}&lt;/code&gt; or
&lt;code&gt;{{update}}&lt;/code&gt; to the top of a wiki article (adding the &lt;span class="caps"&gt;HTML&lt;/span&gt; comment
before it is also recommended), and it will add the page to the
appropriate category and show a nice message box at the top of the&amp;nbsp;page:  &lt;/p&gt;
&lt;p&gt;Cleanup:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="cleanup message box" src="/GFX/mw_cleanup.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Update:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="update message box" src="/GFX/mw_update.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Deprecated:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="deprecated message box" src="/GFX/mw_deprecated.png" /&gt;&lt;/p&gt;
&lt;p&gt;I also add a link to the top of the main wiki&amp;nbsp;page:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Things that need to be done: [[:Category:Pages Needing Updates|Pages Needing Updates]], [[:Category:Deprecated Content|Pages with Largely Deprecated Content]], [[:Category:Pages Needing Cleanup|Pages Needing Cleanup]], [[Special:WantedPages|Links to Nonexistent Pages]]
&lt;/pre&gt;&lt;/div&gt;</summary><category term="documentation"></category><category term="mediawiki"></category><category term="sysadmin"></category></entry><entry><title>Synaptics touchpad driver synclient in Fedora 16 / Xorg with UDEV</title><link href="http://blog.jasonantman.com/2012/01/synaptics-touchpad-driver-synclient-in-fedora-16-xorg-with-udev/" rel="alternate"></link><updated>2012-01-27T17:51:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-27:2012/01/synaptics-touchpad-driver-synclient-in-fedora-16-xorg-with-udev/</id><summary type="html">&lt;p&gt;I just installed &lt;a href="http://fedoraproject.org"&gt;Fedora 16&lt;/a&gt; on an older &lt;span class="caps"&gt;IBM&lt;/span&gt;
&lt;a href="http://www.thinkwiki.org/wiki/Category:T42"&gt;ThinkPad T42&lt;/a&gt; laptop.
Unfortunately, the two mouse buttons below the
&lt;a href="http://www.thinkwiki.org/wiki/UltraNav"&gt;UltraNav&lt;/a&gt; touchpad just won&amp;#8217;t
work at all. Before opening up the case and fiddling around, I decided
to try a software solution. Even after fairly exhaustive research, I
couldn&amp;#8217;t find anyone with a similar&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;I did, however, find out that the synaptics touchpad driver has a
&lt;code&gt;synclient&lt;/code&gt; tool that can output the hardware events read directly from
the input device. I tried running &lt;code&gt;synclient -m 100&lt;/code&gt; (to monitor
hardware events every 100ms), but the only output that I got was
&lt;code&gt;Can't access shared memory area. SHMConfig disabled?&lt;/code&gt;. This was all a
bit confusing to me, since Fedora 16 doesn&amp;#8217;t even use an &lt;code&gt;xorg.conf&lt;/code&gt;
file. I was even more confused by a fair amount of information saying
that SHMConfig is no longer used in synaptics&amp;nbsp;1.2+.&lt;/p&gt;
&lt;p&gt;Long story short, the solution lies in
&lt;code&gt;/usr/share/X11/xorg.conf.d/50-synaptics.conf&lt;/code&gt;, which holds the
synaptics config snippets for xorg. All you need to do is add the
SHMConfig line before the end of the&amp;nbsp;section:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Section &amp;quot;InputClass&amp;quot;
    Identifier &amp;quot;touchpad catchall&amp;quot;
    Driver &amp;quot;synaptics&amp;quot;
    ...
    Option &amp;quot;SHMConfig&amp;quot; &amp;quot;on&amp;quot;
EndSection
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and then restart your X server. Now, running &lt;code&gt;synclient -m&lt;/code&gt; should work&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;I have to thank Red Hat&amp;#8217;s &lt;a href="http://fedoraproject.org/wiki/User:Kevin"&gt;Kevin
Fenzi&lt;/a&gt; (nirik on &lt;a href="http://webchat.freenode.net/?randomnick=1&amp;amp;channels=fedora&amp;amp;uio=d4"&gt;#fedora on
irc.freenode.org&lt;/a&gt;)
for putting another set of eyeballs on the problem, and throwing out
some ideas that finally led me to the&amp;nbsp;solution.&lt;/p&gt;</summary><category term="synaptics"></category><category term="synclient"></category><category term="thinkpad"></category><category term="touchpad"></category><category term="xorg"></category></entry><entry><title>PHP Script to Query Linode DNS Manager API</title><link href="http://blog.jasonantman.com/2012/01/php-script-to-query-linode-dns-manager-api/" rel="alternate"></link><updated>2012-01-20T22:49:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-20:2012/01/php-script-to-query-linode-dns-manager-api/</id><summary type="html">&lt;p&gt;I&amp;#8217;m in the process of moving all of my public-facing services, currently
hosted on a single
&lt;a href="http://www.linode.com/?r=5c8ad2931b410b55455aadbcf0a8d86d6f698a91"&gt;Linode&lt;/a&gt;,
to a new virtual machine (still with Linode, of course, just a new
CentOS 6 &lt;span class="caps"&gt;VM&lt;/span&gt;). Of course, I&amp;#8217;ve got a &lt;em&gt;lot&lt;/em&gt; (about 60) of &lt;span class="caps"&gt;DNS&lt;/span&gt; records,
spread across 8 domains, that point at the old machine. For name-based
vhosts in Apache, my usual procedure is to migrate everything over to
the new host and then change &lt;span class="caps"&gt;DNS&lt;/span&gt;, and once the change propagates (I&amp;#8217;m
using Linode&amp;#8217;s &lt;span class="caps"&gt;DNS&lt;/span&gt; hosting, so it makes things a &lt;span class="caps"&gt;LOT&lt;/span&gt; easier but I don&amp;#8217;t
have &lt;code&gt;rndc reload&lt;/code&gt; anymore) I test in a browser and, assuming all is
well, disable the vhost on the old server. To do all this, I need an
easy way to get a list of all the &lt;span class="caps"&gt;DNS&lt;/span&gt; records that still point to the
old&amp;nbsp;machine.&lt;/p&gt;
&lt;p&gt;Luckily, to augment their web-based control panel (Linode Manager),
Linode has a pretty full-featured &lt;a href="http://www.linode.com/api/"&gt;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; with
bindings for Python, Perl, &lt;span class="caps"&gt;PHP&lt;/span&gt;, Ruby, Java and others. While I like
Python and I&amp;#8217;m starting to learn Perl (by trying to shift most of my
non-time-sensitive scripting to it) for my new job, &lt;span class="caps"&gt;PHP&lt;/span&gt; is still my
strongest language (and the majority of my existing administrative
scripting is written in it, especially handy when it comes time to add a
web front-end to things). So I wrote the following script to query
Linode&amp;#8217;s &lt;a href="http://www.linode.com/api/dns"&gt;&lt;span class="caps"&gt;DNS&lt;/span&gt; Manager &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; using &lt;a href="https://github.com/krmdrms/linode/"&gt;Kerem
Durmus&amp;#8217; Linode &lt;span class="caps"&gt;API&lt;/span&gt; &lt;span class="caps"&gt;PHP&lt;/span&gt; wrapper&lt;/a&gt;
(installation instructions and info at that Github link). The script
simply writes all Linode &lt;span class="caps"&gt;DNS&lt;/span&gt; records for all zones to a &lt;span class="caps"&gt;CSV&lt;/span&gt; file (this
could take a while if you have a lot of&amp;nbsp;records&amp;#8230;).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * &lt;span class="caps"&gt;INSTALLATION&lt;/span&gt; (as per krmdrms &lt;span class="caps"&gt;README&lt;/span&gt;):&lt;/span&gt;
&lt;span class="x"&gt;   *  pear install Net_URL2-0.3.1&lt;/span&gt;
&lt;span class="x"&gt;   *  pear install HTTP_Request2-0.5.2&lt;/span&gt;
&lt;span class="x"&gt;   *  pear channel-discover pear.keremdurmus.com&lt;/span&gt;
&lt;span class="x"&gt;   *  pear install krmdrms/Services_Linode&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * Also requires php-openssl / php5-openssl&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * &lt;span class="caps"&gt;USAGE&lt;/span&gt;: php linodeDnsToCsv.php&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * Copyright 2011 Jason Antman  , all rights reserved.&lt;/span&gt;
&lt;span class="x"&gt;   * This script is free for use by anyone anywhere, provided that you comply with the following terms:&lt;/span&gt;
&lt;span class="x"&gt;   * 1) Keep this notice and copyright statement intact.&lt;/span&gt;
&lt;span class="x"&gt;   * 2) Send any substantial changes, improvements or bog fixes back to me at the above address.&lt;/span&gt;
&lt;span class="x"&gt;   * 3) If you include this in a product or redistribute it, you notify me, and include my name in the credits or changelog.&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * The following &lt;span class="caps"&gt;URL&lt;/span&gt; always points to the newest version of this script. If you obtained it from another source, you should&lt;/span&gt;
&lt;span class="x"&gt;   * check here:&lt;/span&gt;
&lt;span class="x"&gt;   * $HeadURL: http://svn.jasonantman.com/misc-scripts/linodeDnsToCsv.php $&lt;/span&gt;
&lt;span class="x"&gt;   * $LastChangedRevision: 25 $&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   * &lt;span class="caps"&gt;CHANGELOG&lt;/span&gt;:&lt;/span&gt;
&lt;span class="x"&gt;   * 2011-12-17 Jason Antman :&lt;/span&gt;
&lt;span class="x"&gt;   *    merged into my svn repo&lt;/span&gt;
&lt;span class="x"&gt;   * 2011-09-12 Jason Antman :&lt;/span&gt;
&lt;span class="x"&gt;   *    initial version of script&lt;/span&gt;
&lt;span class="x"&gt;   *&lt;/span&gt;
&lt;span class="x"&gt;   */&lt;/span&gt;

&lt;span class="x"&gt;require_once(&amp;quot;/var/www/linode_apikey.php&amp;quot;); // &lt;span class="caps"&gt;PHP&lt;/span&gt; file containing:   define(&amp;quot;API_KEY_LINODE&amp;quot;, &amp;quot;myApiKeyHere&amp;quot;);&lt;/span&gt;
&lt;span class="x"&gt;require_once(&amp;#39;Services/Linode.php&amp;#39;);&lt;/span&gt;

&lt;span class="x"&gt;// get list of all domains&lt;/span&gt;
&lt;span class="x"&gt;$domains = array(); // &lt;span class="caps"&gt;DOMAINID&lt;/span&gt; =&amp;gt; domain.tld&lt;/span&gt;
&lt;span class="x"&gt;try {&lt;/span&gt;
&lt;span class="x"&gt;  $linode = new Services_Linode(API_KEY_LINODE);&lt;/span&gt;
&lt;span class="x"&gt;  $result = $linode-&amp;gt;domain_list();&lt;/span&gt;

&lt;span class="x"&gt;  foreach($result[&amp;#39;&lt;span class="caps"&gt;DATA&lt;/span&gt;&amp;#39;] as $domain)&lt;/span&gt;
&lt;span class="x"&gt;    {&lt;/span&gt;
&lt;span class="x"&gt;      $domains[$domain[&amp;#39;&lt;span class="caps"&gt;DOMAINID&lt;/span&gt;&amp;#39;]] = $domain[&amp;quot;&lt;span class="caps"&gt;DOMAIN&lt;/span&gt;&amp;quot;];&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;
&lt;span class="x"&gt;catch (Services_Linode_Exception $e)&lt;/span&gt;
&lt;span class="x"&gt;{&lt;/span&gt;
&lt;span class="x"&gt;  echo $e-&amp;gt;getMessage();&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;

&lt;span class="x"&gt;$records = array(); // array of resource records&lt;/span&gt;
&lt;span class="x"&gt;$linode-&amp;gt;batching = true;&lt;/span&gt;
&lt;span class="x"&gt;foreach($domains as $id =&amp;gt; $name)&lt;/span&gt;
&lt;span class="x"&gt;{&lt;/span&gt;
&lt;span class="x"&gt;  $linode-&amp;gt;domain_resource_list(array(&amp;#39;DomainID&amp;#39; =&amp;gt; $id));&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;

&lt;span class="x"&gt;try {&lt;/span&gt;
&lt;span class="x"&gt;  $result = $linode-&amp;gt;batchFlush();&lt;/span&gt;

&lt;span class="x"&gt;  foreach($result as $batchPart)&lt;/span&gt;
&lt;span class="x"&gt;    {&lt;/span&gt;
&lt;span class="x"&gt;      foreach($batchPart[&amp;#39;&lt;span class="caps"&gt;DATA&lt;/span&gt;&amp;#39;] as $rrec)&lt;/span&gt;
&lt;span class="x"&gt;    {&lt;/span&gt;
&lt;span class="x"&gt;      if(! isset($records[$rrec[&amp;#39;&lt;span class="caps"&gt;DOMAINID&lt;/span&gt;&amp;#39;]])){ $records[$rrec[&amp;#39;&lt;span class="caps"&gt;DOMAINID&lt;/span&gt;&amp;#39;]] = array();}&lt;/span&gt;
&lt;span class="x"&gt;      $records[$rrec[&amp;#39;&lt;span class="caps"&gt;DOMAINID&lt;/span&gt;&amp;#39;]][$rrec[&amp;#39;&lt;span class="caps"&gt;RESOURCEID&lt;/span&gt;&amp;#39;]] = array(&amp;#39;name&amp;#39; =&amp;gt; $rrec[&amp;#39;&lt;span class="caps"&gt;NAME&lt;/span&gt;&amp;#39;], &amp;#39;type&amp;#39; =&amp;gt; $rrec[&amp;#39;&lt;span class="caps"&gt;TYPE&lt;/span&gt;&amp;#39;], &amp;#39;target&amp;#39; =&amp;gt; $rrec[&amp;#39;&lt;span class="caps"&gt;TARGET&lt;/span&gt;&amp;#39;]);&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;
&lt;span class="x"&gt;catch (Services_Linode_Exception $e)&lt;/span&gt;
&lt;span class="x"&gt;{&lt;/span&gt;
&lt;span class="x"&gt;  echo $e-&amp;gt;getMessage();&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;

&lt;span class="x"&gt;echo &amp;#39;&amp;quot;recid&amp;quot;,&amp;quot;domain&amp;quot;,&amp;quot;name&amp;quot;,&amp;quot;type&amp;quot;,&amp;quot;target&amp;quot;&amp;#39;.&amp;quot;\n&amp;quot;;&lt;/span&gt;
&lt;span class="x"&gt;foreach($domains as $id =&amp;gt; $name)&lt;/span&gt;
&lt;span class="x"&gt;{&lt;/span&gt;
&lt;span class="x"&gt;  foreach($records[$id] as $recid =&amp;gt; $arr)&lt;/span&gt;
&lt;span class="x"&gt;    {&lt;/span&gt;
&lt;span class="x"&gt;      echo &amp;#39;&amp;quot;&amp;#39;.$recid.&amp;#39;&amp;quot;,&amp;quot;&amp;#39;.$name.&amp;#39;&amp;quot;,&amp;quot;&amp;#39;.$arr[&amp;#39;name&amp;#39;].&amp;#39;&amp;quot;,&amp;quot;&amp;#39;.$arr[&amp;#39;type&amp;#39;].&amp;#39;&amp;quot;,&amp;quot;&amp;#39;.$arr[&amp;#39;target&amp;#39;].&amp;quot;\&amp;quot;\n&amp;quot;;&lt;/span&gt;
&lt;span class="x"&gt;    }&lt;/span&gt;
&lt;span class="x"&gt;}&lt;/span&gt;


&lt;span class="x"&gt;?&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That will print out a list containing the Linode &lt;span class="caps"&gt;DNS&lt;/span&gt; record id (recid),
domain, record name, type and&amp;nbsp;target:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&amp;quot;recid&amp;quot;,&amp;quot;domain&amp;quot;,&amp;quot;name&amp;quot;,&amp;quot;type&amp;quot;,&amp;quot;target&amp;quot;
&amp;quot;137423&amp;quot;,&amp;quot;jasonantman.com&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;TXT&amp;quot;,&amp;quot;v=spf1 mx:jasonantman.com -all&amp;quot;
&amp;quot;3597859&amp;quot;,&amp;quot;jasonantman.com&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;MX&amp;quot;,&amp;quot;linode1.jasonantman.com&amp;quot;
&amp;quot;3488952&amp;quot;,&amp;quot;jasonantman.com&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;mx&amp;quot;,&amp;quot;linode2.jasonantman.com&amp;quot;
&amp;quot;3472952&amp;quot;,&amp;quot;jasonantman.com&amp;quot;,&amp;quot;blog&amp;quot;,&amp;quot;CNAME&amp;quot;,&amp;quot;linode1.jasonantman.com&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you want to, say, search for only records that include host
&amp;#8220;example&amp;#8221;, you could use grep and awk&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;php linodeDnsToCsv.php | grep linode1 | grep -v &lt;span class="s1"&gt;&amp;#39;&amp;quot;linode1&amp;quot;,&amp;quot;a&amp;quot;&amp;#39;&lt;/span&gt; | awk -F , &lt;span class="s1"&gt;&amp;#39;{printf &amp;quot;%-27s %-20s %-7s %s\n&amp;quot;, $2, $3, $4, $5}&amp;#39;&lt;/span&gt; | sed &lt;span class="s1"&gt;&amp;#39;s/&amp;quot;//g&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I hope this helps someone else out, and saves them a few minutes of&amp;nbsp;coding&amp;#8230;&lt;/p&gt;</summary><category term="api"></category><category term="dns"></category><category term="linode"></category><category term="PHP"></category><category term="sysadmin"></category></entry><entry><title>Secure rsnapshot backups over the WAN via SSH</title><link href="http://blog.jasonantman.com/2012/01/secure-rsnapshot-backups-over-the-wan-via-ssh/" rel="alternate"></link><updated>2012-01-15T17:26:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-15:2012/01/secure-rsnapshot-backups-over-the-wan-via-ssh/</id><summary type="html">&lt;p&gt;Since I moved all of my &lt;span class="caps"&gt;WAN&lt;/span&gt;-facing stuff (mail, web, this blog, svn
etc.) to a virtual server with &lt;a href="http://www.linode.com"&gt;Linode&lt;/a&gt;, and just
have a desktop at home, it&amp;#8217;s no longer practical to use
&lt;a href="http://www.bacula.org/"&gt;Bacula&lt;/a&gt; for backups. Linode manages daily and
weekly backups through their backup service, but they&amp;#8217;ll only restore a
full filesystem at a time. I wanted something that would keep daily and
weekly incremental backups long enough that I could find a file changed
(or accidentally deleted) a few days or weeks ago. Since I&amp;#8217;d be backing
up to my desktop at home (which is on a residential dynamic &lt;span class="caps"&gt;IP&lt;/span&gt;
connection), the logical solution was something using
&lt;a href="http://rsync.samba.org/"&gt;rsync&lt;/a&gt;. Even better than that is the
&lt;a href="http://rsnapshot.org/"&gt;rsnapshot&lt;/a&gt; tool, which builds upon rsync and
hard links to manage incremental backups with as little disk usage as
possible (though I&amp;#8217;d certainly recommend excluding log&amp;nbsp;files).&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m pretty strict about security. Since my home connection has a dynamic
&lt;span class="caps"&gt;IP&lt;/span&gt;, things are a bit more complicated - I can&amp;#8217;t push from the server, I
can&amp;#8217;t &lt;span class="caps"&gt;ACL&lt;/span&gt; or firewall the server to just my home &lt;span class="caps"&gt;IP&lt;/span&gt;, and an IPsec &lt;span class="caps"&gt;VPN&lt;/span&gt;
would be difficult to accomplish (not to mention add a lot of overhead
to big file transfers). So, I opted for a solution that uses &lt;span class="caps"&gt;SSH&lt;/span&gt;
key-based authentication, forced comands, and a C&amp;nbsp;wrapper.&lt;/p&gt;
&lt;p&gt;The configuration of rsync and rsnapshot is mostly out of the scope of
this post. There are plenty of good resources for that, so I&amp;#8217;ll just
cover the things that won&amp;#8217;t be found in most tutorials. Also, I&amp;#8217;ll be
referring to the remote machine to be backed up as the &amp;#8220;remote host&amp;#8221; and
the local machine which triggers the backup and stores the data as the
&amp;#8220;local&amp;nbsp;host&amp;#8221;.&lt;/p&gt;
&lt;h2 id="local-host-setup-part-i"&gt;Local Host Setup - Part&amp;nbsp;I&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Choose and create a directory to store your backups in. I have a &lt;span class="caps"&gt;1TB&lt;/span&gt;
    external disk mounted at &lt;code&gt;/mnt/backup/&lt;/code&gt;, so I chose
    &lt;code&gt;/mnt/backup/rsnapshot/&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Generate two sets of password-less &lt;span class="caps"&gt;SSH&lt;/span&gt; keys using the &lt;code&gt;ssh-keygen&lt;/code&gt;
    program. One will be used to run the rsync command on the remote
    host, the other will be used to trigger your pre- and post-backup
    scripts. Name them accordingly (i.e.
    &amp;#8220;remoteHostname_remoteBackupUsername_cmd&amp;#8221; and
    &amp;#8220;remoteHostname_remoteBackupUsername_rsync&amp;#8221;). Now, get (scp) the
    public key for each pair to the remote&amp;nbsp;host.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="remote-host-setup"&gt;Remote Host&amp;nbsp;Setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Ensure that rsync is installed on the&amp;nbsp;host.&lt;/li&gt;
&lt;li&gt;Create a user to run the backups. I called this user &amp;#8220;rsyncuser&amp;#8221;.
    Create a home directory, and a group for the user. Do not set a
    password (you don&amp;#8217;t want password&amp;nbsp;logins).&lt;/li&gt;
&lt;li&gt;Copy the public key files you created above to the user&amp;#8217;s &lt;code&gt;~/.ssh/&lt;/code&gt;
    directory.&lt;/li&gt;
&lt;li&gt;Cat the &amp;#8220;remoteHostname_remoteBackupUsername_cmd&amp;#8221; public key into
    the user&amp;#8217;s &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Now comes the first fun part. Let&amp;#8217;s assume that your pre- and
    post-backup scripts are &lt;code&gt;/root/bin/rsnapshot-pre.sh&lt;/code&gt; and
    &lt;code&gt;/root/bin/rsnapshot-post.sh&lt;/code&gt;, respectively. As root, grab a copy of
    cmd-wrapper.c (from
    &lt;a href="https://github.com/jantman/misc-scripts/blob/master/cmd-wrapper.c"&gt;GitHub&lt;/a&gt;
    or at the bottom of this post). Modify for your use - the only thing
    likely to change is line 38, which ensures it will only run for a
    member of &lt;span class="caps"&gt;GID&lt;/span&gt; 502. Change this to rsyncuser&amp;#8217;s &lt;span class="caps"&gt;GID&lt;/span&gt;. Compile the
    wrapper with &lt;code&gt;gcc -o cmd-wrapper cmd-wrapper.c&lt;/code&gt;. Copy it to
    rsyncuser&amp;#8217;s home directory (/home/rsyncuser), &lt;code&gt;chown root:rsyncuser&lt;/code&gt;
    and &lt;code&gt;chmod 4750&lt;/code&gt;. Yes, this sets the &lt;span class="caps"&gt;SUID&lt;/span&gt; bit. The program will now
    be owned by root, and runnable &lt;em&gt;as root&lt;/em&gt; by rsyncuser (or, more
    specifically, any member of the rsyncuser&amp;nbsp;group).&lt;/li&gt;
&lt;li&gt;Open rsyncuser&amp;#8217;s &lt;code&gt;.ssh/authorized_keys&lt;/code&gt; file in a text editor. At
    the beginning of the &amp;#8220;remoteHostname_remoteBackupUsername_cmd&amp;#8221; key
    line, prepend &lt;code&gt;command="/home/rsyncuser/cmd-wrapper"&lt;/code&gt;. This sets up
    &lt;span class="caps"&gt;SSH&lt;/span&gt; forced command (there&amp;#8217;s a good overview in &lt;a href="http://oreilly.com/catalog/sshtdg/chapter/ch08.html"&gt;O&amp;#8217;Reilly&amp;#8217;s &lt;span class="caps"&gt;SSH&lt;/span&gt;: The
    Definitive
    Guide&lt;/a&gt;) so that
    when this key is used to login, it will directly execute
    &lt;code&gt;/home/rsyncuser/cmd-wrapper&lt;/code&gt; and then exit, without allowing access
    to anything&amp;nbsp;else.&lt;/li&gt;
&lt;li&gt;Add rsyncuser to &lt;code&gt;AllowUsers&lt;/code&gt; in &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt; (you &lt;em&gt;do&lt;/em&gt;
    limit user access via &lt;span class="caps"&gt;SSH&lt;/span&gt;, right?) and then reload&amp;nbsp;sshd.&lt;/li&gt;
&lt;li&gt;Now, if you &lt;span class="caps"&gt;SSH&lt;/span&gt; to rsyncuser@remoteHost from the local host, using
    the &amp;#8220;_cmd&amp;#8221; ssh key and a command of &amp;#8220;pre&amp;#8221; (i.e.
    &lt;code&gt;ssh -i /path/to/remoteHostname_remoteBackupUsername_cmd rsyncuser@remoteHost pre&lt;/code&gt;),
    it should execute &lt;code&gt;/root/bin/rsnapshot-pre.sh&lt;/code&gt; ad root, and you
    should see the output&amp;nbsp;locally.&lt;/li&gt;
&lt;li&gt;Repeat the above step for the post-backup script (replacing &amp;#8220;pre&amp;#8221;
    above with &amp;#8220;post&amp;#8221;). You should now have your pre- and post-backup
    scripts working, and triggered remotely. &lt;em&gt;(Note: these steps, and
    some of the other setup here, is a bit more complex so that it will
    work better with rsnapshot backups of multiple remote&amp;nbsp;hosts.)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Cat the &amp;#8220;remoteHostname_remoteBackupUsername_rsync&amp;#8221; public key
    into the backup user&amp;#8217;s &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;As root, grab a copy of rsync-wrapper.c (from
    &lt;a href="https://github.com/jantman/misc-scripts/blob/master/rsync-wrapper.c"&gt;GitHub&lt;/a&gt;
    or at the bottom of this post). Modify for your use - the only thing
    likely to change is line 38, which ensures it will only run for a
    member of &lt;span class="caps"&gt;GID&lt;/span&gt; 502 (change this to rsyncuser&amp;#8217;s &lt;span class="caps"&gt;GID&lt;/span&gt;), and perhaps the
    path of or arguments passed to rsync (the wrapper will call
    &lt;code&gt;/usr/bin/rsync --server --sender -vlogDtprRe.iLsf --numeric-ids . /&lt;/code&gt;).
    Compile the wrapper with &lt;code&gt;gcc -o rsync-wrapper rsync-wrapper.c&lt;/code&gt;.
    Copy it to rsyncuser&amp;#8217;s home directory (/home/rsyncuser),
    &lt;code&gt;chown root:rsyncuser&lt;/code&gt; and &lt;code&gt;chmod 4750&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Open rsyncuser&amp;#8217;s &lt;code&gt;.ssh/authorized_keys&lt;/code&gt; file in a text editor. At
    the beginning of the &amp;#8220;remoteHostname_remoteBackupUsername_rsync&amp;#8221;
    key line, prepend &lt;code&gt;command="/home/rsyncuser/rsync-wrapper"&lt;/code&gt;. This
    will run rsync with the arguments specified in rsync-wrapper.c every
    time this key is used to&amp;nbsp;login.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="local-host-setup-part-ii"&gt;Local Host Setup - Part&amp;nbsp;&lt;span class="caps"&gt;II&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;I use totally separate configs for each host that I backup, to keep
things clean and to let me enable, disable, or tweak one remote backup
without affecting the&amp;nbsp;others.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create host-specific pre- and post-backup scripts. I put them in
    &lt;code&gt;/etc/rsnapshot.d/&lt;/code&gt;.
    &lt;code&gt;/etc/rsnapshot.d/pre-remoteHostName.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="c"&gt;# do anything else needed on the local system before a backup&lt;/span&gt;
ssh -i /path/to/remoteHostname_remoteBackupUsername_cmd rsyncuser@remoteHost pre
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;/etc/rsnapshot.d/post-remoteHostName.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="c"&gt;# do anything else needed on the local system after a backup&lt;/span&gt;
ssh -i /path/to/remoteHostname_remoteBackupUsername_cmd rsyncuser@remoteHost post
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setup a set of rsync include and exclude files (see &lt;code&gt;man rsync(1)&lt;/code&gt;,
    &lt;code&gt;--include-from=&lt;/code&gt; and &lt;code&gt;--exclude-from=&lt;/code&gt;). I put mine at
    &lt;code&gt;/etc/rsnapshot.d/rsync-include-remoteHostName.txt&lt;/code&gt; and
    &lt;code&gt;/etc/rsnapshot.d/rsync-exclude-remoteHostName.txt&lt;/code&gt;, respectively.
    (Examples included at the bottom of this&amp;nbsp;post).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configure rsnapshot. I use a separate config file for each remote
    host. Copy the default &lt;code&gt;/etc/rsnapshot.conf&lt;/code&gt; to
    &lt;code&gt;/etc/rsnapshot-remoteHostName.conf&lt;/code&gt;. The important items are
    &lt;code&gt;rsync_short_args&lt;/code&gt;, &lt;code&gt;rsync_long_args&lt;/code&gt;, &lt;code&gt;ssh_args&lt;/code&gt;, &lt;code&gt;cmd_preexec&lt;/code&gt;,
    &lt;code&gt;cmd_postexec&lt;/code&gt; and &lt;code&gt;backup&lt;/code&gt;. Here&amp;#8217;s an example of my config file,
    with comments and blank lines&amp;nbsp;removed:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;config_version  1.2
snapshot_root   /mnt/backup/rsnapshot/
cmd_cp          /bin/cp
cmd_rm          /bin/rm
cmd_rsync       /usr/bin/rsync
cmd_ssh         /usr/bin/ssh
cmd_logger      /bin/logger
cmd_du          /usr/bin/du
cmd_rsnapshot_diff      /usr/bin/rsnapshot-diff
interval        daily   14 # save 14 daily backups
interval        weekly  6 # save 6 weekly backups
verbose         2
loglevel        3
logfile /var/log/rsnapshot-remoteHostName.log
lockfile        /var/run/rsnapshot-remoteHostName.pid
rsync_short_args        -a
rsync_long_args --delete --numeric-ids --relative --delete-excluded
ssh_args        -i /path/to/remoteHostname_remoteBackupUsername_rsync
exclude_file    /etc/rsnapshot.d/rsync-exclude-remoteHostName.txt
include_file    /etc/rsnapshot.d/rsync-include-remoteHostName.txt
link_dest       1
use_lazy_deletes        1
cmd_preexec     /etc/rsnapshot.d/pre-remoteHostName.sh
cmd_postexec    /etc/rsnapshot.d/post-remoteHostName.sh
backup  rsyncuser@remoteHostName:/      remoteHostName/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;backup&lt;/code&gt; line is what tells rsync what to back up (&lt;code&gt;/&lt;/code&gt; on
remoteHostName, logging in as rsyncuser), and where to back up to&amp;nbsp;(snapshot_root/remoteHostName/).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create two scripts that will actually trigger the backups, which
    I&amp;#8217;ll call &lt;code&gt;/root/bin/rsnapshot-daily.sh&lt;/code&gt; and &lt;code&gt;/root/bin/rsnapshot-weekly.sh&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/root/bin/rsnapshot-daily.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

/usr/bin/rsnapshot -c /etc/rsnapshot-remoteHostName.conf daily
&lt;span class="c"&gt;# add other hosts here; note, they&amp;#39;ll run in series&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;/root/bin/rsnapshot-weekly.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

/usr/bin/rsnapshot -c /etc/rsnapshot-remoteHostName.conf weekly
&lt;span class="c"&gt;# add other hosts here; note, they&amp;#39;ll run in series&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add two entries to root&amp;#8217;s croontab to run the rsnapshot backups.
    Adjust the following days and times to your&amp;nbsp;liking:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;0 1 * * Mon /root/bin/rsnapshot-weekly.sh # run the weekly backups every Monday at 01:00
30 2 * * * /root/bin/rsnapshot-daily.sh # run the daily backups every day at 02:30, which *should* be after the weekly finished on Monday morning
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check, after the next scheduled runs, that everything appears to
    have run correctly. If you want, you can manually trigger the daily
    script and watch what happens. If you do this more than once, you
    should delete the directories it creates, or else rotation will be
    messed up. If you have issues with rsync, aside from the usual
    troubleshooting, check that rsync-wrapper.c is calling rsync with
    the same arguments that rsnapshot is sending. It may be useful to
    use my
    &lt;a href="https://github.com/jantman/misc-scripts/blob/master/print-cmd.sh"&gt;print-cmd.sh&lt;/a&gt;
    script in place of the &amp;#8220;rsync-wrapper&amp;#8221; forced command. This script
    will simply log the command rsnapshot calls via&amp;nbsp;&lt;span class="caps"&gt;SSH&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Assuming all of this worked, you should now have a fairly secure
&lt;span class="caps"&gt;SSH&lt;/span&gt;-based remotely-triggered backup system. In a follow-up post I
provide my &lt;a href="/2012/02/nagios-check-plugin-for-rsnapshot-backups/"&gt;Nagios Check Plugin for Rsnapshot
Backups&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The referenced scripts, config files, etc. are&amp;nbsp;below:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cmd-wrapper.c&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;

&lt;span class="cm"&gt;/********************************************&lt;/span&gt;
&lt;span class="cm"&gt; * Wrapper - Secure Yourself                &lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; * 2007 - Mike Golvach - eggi@comcast.net   &lt;/span&gt;
&lt;span class="cm"&gt; * Modified 2012 by Jason Antman  &lt;/span&gt;
&lt;span class="cm"&gt; *  - configured for use as pre- and post-backup script wrapper&lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; * &lt;span class="caps"&gt;USAGE&lt;/span&gt;: cmd-wrapper [pre|post]&lt;/span&gt;
&lt;span class="cm"&gt; *&lt;/span&gt;
&lt;span class="cm"&gt; * $HeadURL: http://svn.jasonantman.com/misc-scripts/cmd-wrapper.c $&lt;/span&gt;
&lt;span class="cm"&gt; * $LastChangedRevision: 26 $&lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; ********************************************/&lt;/span&gt;

&lt;span class="cm"&gt;/* Creative Commons Attribution-Noncommercial-Share Alike 3.0 United States License */&lt;/span&gt;

&lt;span class="cm"&gt;/* Define global variables */&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;gid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="cm"&gt;/* main(int argc, char **argv) - main process loop */&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;envp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;origcmd&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="n"&gt;origcmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;SSH_ORIGINAL_COMMAND&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="cm"&gt;/* printf (&amp;quot;Original Command:%s\n&amp;quot;, origcmd); */&lt;/span&gt;

  &lt;span class="cm"&gt;/* Set euid and egid to actual user */&lt;/span&gt;

  &lt;span class="n"&gt;gid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getgid&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="n"&gt;setegid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getgid&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
  &lt;span class="n"&gt;seteuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getuid&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;

  &lt;span class="cm"&gt;/* Confirm user is in &lt;span class="caps"&gt;GROUP&lt;/span&gt;(502) group */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;gid&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;502&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;User Not Authorized! Exiting...&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* Check argc count only at this point */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Usage: cmd-wrapper [pre|post]&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* Set uid, gid, euid and egid to root */&lt;/span&gt;

  &lt;span class="n"&gt;setegid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;seteuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;setgid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;setuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="cm"&gt;/* Check argv for proper arguments and run&lt;/span&gt;
&lt;span class="cm"&gt;   * the corresponding script, if invoked.&lt;/span&gt;
&lt;span class="cm"&gt;   */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;strncmp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;origcmd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;pre&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;execl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/root/bin/rsnapshot-pre.sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;rsnapshot-pre.sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;&lt;span class="caps"&gt;NULL&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;perror&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Execl:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;strncmp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;origcmd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;post&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;execl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/root/bin/rsnapshot-post.sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;rsnapshot-post.sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;&lt;span class="caps"&gt;NULL&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;perror&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Execl:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: Invalid command: %s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;origcmd&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Usage: &lt;span class="caps"&gt;COMMAND&lt;/span&gt; [pre|post]&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;rsync-wrapper.c&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;
&lt;span class="cp"&gt;#include &lt;/span&gt;

&lt;span class="cm"&gt;/********************************************&lt;/span&gt;
&lt;span class="cm"&gt; * Wrapper - Secure Yourself                &lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; * 2007 - Mike Golvach - eggi@comcast.net   &lt;/span&gt;
&lt;span class="cm"&gt; * Modified 2012 by Jason Antman  &lt;/span&gt;
&lt;span class="cm"&gt; *  - configured for use as rsync wrapper&lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; * $HeadURL: http://svn.jasonantman.com/misc-scripts/rsync-wrapper.c $&lt;/span&gt;
&lt;span class="cm"&gt; * $LastChangedRevision: 26 $&lt;/span&gt;
&lt;span class="cm"&gt; *                                          &lt;/span&gt;
&lt;span class="cm"&gt; ********************************************/&lt;/span&gt;

&lt;span class="cm"&gt;/* Creative Commons Attribution-Noncommercial-Share Alike 3.0 United States License */&lt;/span&gt;

&lt;span class="cm"&gt;/* Define global variables */&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;gid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="cm"&gt;/* main(int argc, char **argv) - main process loop */&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="cm"&gt;/* Set euid and egid to actual user */&lt;/span&gt;

  &lt;span class="n"&gt;gid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getgid&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="n"&gt;setegid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getgid&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
  &lt;span class="n"&gt;seteuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;getuid&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;

  &lt;span class="cm"&gt;/* Confirm user is in &lt;span class="caps"&gt;GROUP&lt;/span&gt;(502) group */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;gid&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;502&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;User Not Authorized! Exiting...&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* Check argc count only at this point */&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Usage: rsync-wrapper&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="cm"&gt;/* Set uid, gid, euid and egid to root */&lt;/span&gt;

  &lt;span class="n"&gt;setegid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;seteuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;setgid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;setuid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="cm"&gt;/* Check argv for proper arguments and run&lt;/span&gt;
&lt;span class="cm"&gt;   * the corresponding script, if invoked.&lt;/span&gt;
&lt;span class="cm"&gt;   */&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;execl&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/usr/bin/rsync&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;rsync&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;--server&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;--sender&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;-vlogDtprRe.iLsf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;--numeric-ids&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;&lt;span class="caps"&gt;NULL&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;perror&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Execl:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;/etc/rsnapshot.d/rsync-include-remoteHostName.txt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# Include
+ /dev/console
+ /dev/initctl
+ /dev/null
+ /dev/zero
+ /usr/local/*
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;/etc/rsnapshot.d/rsync-exclude-remoteHostName.txt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;# Exclude
- /cgroup/*
- /dev/*
- /lib/*
- lost+found/
- /proc/*
- /sys/
- /tmp/
- /var/log/*
&lt;/pre&gt;&lt;/div&gt;</summary><category term="backups"></category><category term="linode"></category><category term="rsnapshot"></category><category term="rsync"></category><category term="security"></category><category term="ssh"></category><category term="wrapper"></category></entry><entry><title>WP-Syntax Plugin GeSHi Path Fix</title><link href="http://blog.jasonantman.com/2012/01/wp-syntax-plugin-geshi-path-fix/" rel="alternate"></link><updated>2012-01-12T19:09:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-01-12:2012/01/wp-syntax-plugin-geshi-path-fix/</id><summary type="html">&lt;p&gt;The &lt;a href="http://wordpress.org/extend/plugins/wp-syntax/"&gt;Wp-Syntax&lt;/a&gt; plugin
for &lt;a href="http://wordpress.org"&gt;WordPress&lt;/a&gt; provides syntax highlighting for
WordPress blogs via the &lt;a href="http://qbnz.com/highlighter"&gt;GeSHi&lt;/a&gt; &lt;span class="caps"&gt;PHP&lt;/span&gt; syntax
highlighter. Unfortunately, the plugin includes a builtin version of
GeSHi (currently 1.0.8.9) in &lt;code&gt;geshi/&lt;/code&gt;. As a result, not only are users
of the plugin not instructed to use the latest version of GeSHi, but it
won&amp;#8217;t use a host-wide GeSHi installation that&amp;#8217;s already in the &lt;span class="caps"&gt;PHP&lt;/span&gt;
include path (i.e. &lt;code&gt;/usr/share/php/&lt;/code&gt;), like the the many &lt;a href="http://pkgs.org/search/?keyword=php-geshi&amp;amp;search_on=name&amp;amp;distro=0&amp;amp;arch=32-bit"&gt;php-geshi
packages&lt;/a&gt;
offered by repositories including
&lt;a href="http://fedoraproject.org/wiki/EPEL"&gt;&lt;span class="caps"&gt;EPEL&lt;/span&gt;&lt;/a&gt; (for Fedora, CentOS and&amp;nbsp;&lt;span class="caps"&gt;RHEL&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;The fix is quite simple. Just open &lt;code&gt;wp-syntax.php&lt;/code&gt; in the &lt;code&gt;wp-syntax/&lt;/code&gt;
plugin directory in your favorite text editor and change the GeSHi
include line (for &lt;span class="caps"&gt;WP&lt;/span&gt;-Syntax 0.9.12, this is line 53)&amp;nbsp;from:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;include_once(&amp;quot;geshi/geshi.php&amp;quot;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;include_once(&amp;quot;geshi.php&amp;quot;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you already have GeSHi installed in the &lt;span class="caps"&gt;PHP&lt;/span&gt; include path, just remove
the &lt;code&gt;geshi&lt;/code&gt; directory in your &lt;code&gt;wp-syntax/&lt;/code&gt; plugin directory, flush the
WordPress caches (if any), and load a page which uses GeSHi - it should
now use the host-wide version. If you want to still use a local version
for wp-syntax, you can move things around to where they &lt;em&gt;should&lt;/em&gt; be in
the &lt;code&gt;wp-syntax/&lt;/code&gt; plugin&amp;nbsp;directory:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;mv geshi/geshi.php . &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; mv geshi/geshi/* geshi/ &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; rmdir geshi/geshi
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note - if you&amp;#8217;re in a shared hosting environment, or are otherwise not
able to upgrade the php-geshi package on your server yourself, you might
not want to do&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;I also &lt;a href="http://wordpress.org/support/topic/wp-syntax-move-geshi-include-path-to-allow-use-with-host-wide-geshi?replies=1#post-2556903"&gt;posted about this in the WordPress support
forums&lt;/a&gt;.
Hopefully the &lt;span class="caps"&gt;WP&lt;/span&gt;-Syntax devs will include this change in the next&amp;nbsp;version&amp;#8230;&lt;/p&gt;</summary><category term="GeSHi"></category><category term="PHP"></category><category term="syntax highlighting"></category><category term="wordpress"></category></entry><entry><title>Vyatta - Showing ISC dhcpd fixed-address leases</title><link href="http://blog.jasonantman.com/2011/12/vyatta-showing-isc-dhcpd-fixed-address-leases/" rel="alternate"></link><updated>2011-12-24T14:42:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-12-24:2011/12/vyatta-showing-isc-dhcpd-fixed-address-leases/</id><summary type="html">&lt;p&gt;&lt;span class="caps"&gt;ISC&lt;/span&gt; &lt;a href="http://www.isc.org/software/dhcp"&gt;dhcpd&lt;/a&gt; has the ability to always
give a specific &lt;span class="caps"&gt;MAC&lt;/span&gt; address the same &lt;span class="caps"&gt;IP&lt;/span&gt; address &amp;#8220;lease&amp;#8221; using the
fixed-address configuration option. This is configured in
&lt;a href="http://www.vyatta.org"&gt;Vyatta&lt;/a&gt; using the &lt;code&gt;static-mapping&lt;/code&gt; configuration
statement. Unfortunately, since dhcpd doesn&amp;#8217;t store fixed-address leases
in the &lt;code&gt;dhcpd.leases&lt;/code&gt; file, the Vyatta &lt;code&gt;show dhcp leases&lt;/code&gt; command
doesn&amp;#8217;t show anything about them - which makes it difficult to debug
anything dhcp-related if all of the hosts on your network are setup for
fixed addresses. I found a mention of this on the &lt;a href="http://www.vyatta.org/forum/viewtopic.php?p=121558"&gt;vyatta
forum&lt;/a&gt;, and also an
&lt;a href="https://bugzilla.vyatta.com/show_bug.cgi?id=1990"&gt;open bug (1990)&lt;/a&gt; to
fix it, but no proposed resolution. Since I came across this problem and
happen to know a bit about &lt;span class="caps"&gt;ISC&lt;/span&gt; dhcpd, I developed both a workaround for
users (including a perl script) and a possible solution for the Vyatta
developers to&amp;nbsp;implement.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Workaround for&amp;nbsp;Users:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s no way to get dhcpd to store fixed-address hosts in the
dhcpd.leases file (though it&amp;#8217;s been discussed on the dhcpd-users mailing
list a few times). There is, however, a way to get dhcpd to log every
time it sends an &lt;span class="caps"&gt;ACK&lt;/span&gt; to a client. The following Vyatta configuration
commands will get dhcpd to log all transactions to syslog, will have
&lt;a href="http://rsyslog.com/"&gt;rsyslog&lt;/a&gt; put that in &lt;code&gt;/var/log/user/dhcpd&lt;/code&gt;. Since
this log can fill up very quickly on a busy server, the latter two
commands will tell &lt;a href="https://fedorahosted.org/logrotate/"&gt;logrotate&lt;/a&gt; to
rotate the log file when it reaches 3000k in size, and keep 5 copies
(feel free to adjust to your&amp;nbsp;needs):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;set &lt;/span&gt;service dhcp-server global-parameters &lt;span class="s2"&gt;&amp;quot;log-facility local2;&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;set &lt;/span&gt;system syslog file dhcpd facility local2 level debug
&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;set &lt;/span&gt;system syslog file dhcpd archive files 5
&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;set &lt;/span&gt;system syslog file dhcpd archive size 3000
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once this is done, you can &lt;code&gt;tail -f /var/log/user/dhcpd&lt;/code&gt; to watch &lt;span class="caps"&gt;DHCP&lt;/span&gt;
discover/request/offer/ack in realtime, or grep through the log file for
a specific &lt;span class="caps"&gt;IP&lt;/span&gt; or &lt;span class="caps"&gt;MAC&lt;/span&gt;. If you want an easier method, I&amp;#8217;ve written a perl
script (latest version will always live in &lt;a href="https://github.com/jantman/misc-scripts/blob/master/show_dhcp_fixed_ACKs.pl"&gt;my GitHub misc-scripts
repo&lt;/a&gt;)
to grep through &lt;code&gt;/var/log/user/dhcpd&lt;/code&gt; and show the most recent &lt;span class="caps"&gt;DHCPACK&lt;/span&gt;
for each &lt;span class="caps"&gt;IP&lt;/span&gt; address, sorted by &lt;span class="caps"&gt;IP&lt;/span&gt;. Here&amp;#8217;s the code of the simple script,
which is more than half comments. To use it, after performing the above
steps, all you need to do is login to your Vyatta box,
&lt;code&gt;wget https://raw.github.com/jantman/misc-scripts/master/show_dhcp_fixed_ACKs.pl&lt;/code&gt;
and then &lt;code&gt;perl show_dhcp_fixed_ACKs.pl&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!/usr/bin/perl&lt;/span&gt;

&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# show_dhcp_fixed_ACKs.pl - script to show the most recent &lt;span class="caps"&gt;DHCP&lt;/span&gt; ACKs per &lt;span class="caps"&gt;IP&lt;/span&gt; address for &lt;span class="caps"&gt;ISC&lt;/span&gt; DHCPd,&lt;/span&gt;
&lt;span class="c1"&gt;#   from a log file. Originally written for Vyatta routers that just show the dynamic leases.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# To use this, you need to have dhcpd logging to syslog, and your syslog server putting the log file at&lt;/span&gt;
&lt;span class="c1"&gt;# /var/log/user/dhcpd (or a file path specified by the $logfile variable below.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# To accomplish this on Vyatta 6.3, run:&lt;/span&gt;
&lt;span class="c1"&gt;# set service dhcp-server global-parameters &amp;quot;log-facility local2;&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# set system syslog file dhcpd facility local2 level debug&lt;/span&gt;
&lt;span class="c1"&gt;# set system syslog file dhcpd archive files 5&lt;/span&gt;
&lt;span class="c1"&gt;# set system syslog file dhcpd archive size 3000&lt;/span&gt;
&lt;span class="c1"&gt;# commit&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Copyright 2011 Jason Antman  All Rights Reserved.&lt;/span&gt;
&lt;span class="c1"&gt;# This script is free for use by anyone anywhere, provided that you comply with the following terms:&lt;/span&gt;
&lt;span class="c1"&gt;# 1) Keep this notice and copyright statement intact.&lt;/span&gt;
&lt;span class="c1"&gt;# 2) Send any substantial changes, improvements or bog fixes back to me at the above address.&lt;/span&gt;
&lt;span class="c1"&gt;# 3) If you include this in a product or redistribute it, you notify me, and include my name in the credits or changelog.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# The following &lt;span class="caps"&gt;URL&lt;/span&gt; always points to the newest version of this script. If you obtained it from another source, you should&lt;/span&gt;
&lt;span class="c1"&gt;# check here:&lt;/span&gt;
&lt;span class="c1"&gt;# $HeadURL$&lt;/span&gt;
&lt;span class="c1"&gt;# $LastChangedRevision$&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;CHANGELOG&lt;/span&gt;:&lt;/span&gt;
&lt;span class="c1"&gt;# 2011-12-24 jason@jasonantman.com:&lt;/span&gt;
&lt;span class="c1"&gt;#    initial version of script&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;strict&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;use&lt;/span&gt; &lt;span class="n"&gt;warnings&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$logfile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/var/log/user/dhcpd&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;%data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;();&lt;/span&gt;

&lt;span class="nb"&gt;open&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;DF&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$logfile&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;die&lt;/span&gt; &lt;span class="vg"&gt;$!&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="nv"&gt;$line&lt;/span&gt; &lt;span class="o"&gt;!~&lt;/span&gt; &lt;span class="sr"&gt;m/dhcpd: &lt;span class="caps"&gt;DHCPACK&lt;/span&gt;/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="k"&gt;next&lt;/span&gt;&lt;span class="p"&gt;;}&lt;/span&gt;
    &lt;span class="nv"&gt;$line&lt;/span&gt; &lt;span class="o"&gt;=~&lt;/span&gt; &lt;span class="sr"&gt;m/([A-Za-z]+ [0-9]+ [0-9]{1,2}:[0-9]{2}:[0-9]{2}) [^\/x]+ dhcpd: &lt;span class="caps"&gt;DHCPACK&lt;/span&gt; on (\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}) to ((?:[0-9a-f]{2}[:-]){5}[0-9a-f]{2}) via (.+)/&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="c1"&gt;#print &amp;quot;$1==$2==$3==$4==\n&amp;quot; ;&lt;/span&gt;
    &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mac&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;if&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$4&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ip&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;    
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%-18s %-20s %-18s %-10s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;IP&lt;/span&gt; Address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Hardware Address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Interface&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%-18s %-20s %-18s %-10s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;----------&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;----------------&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;----&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;---------&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;# begin sort by &lt;span class="caps"&gt;IP&lt;/span&gt; address&lt;/span&gt;
&lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;@keys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
  &lt;span class="nb"&gt;map&lt;/span&gt;  &lt;span class="nb"&gt;substr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class="nb"&gt;sort&lt;/span&gt;
  &lt;span class="nb"&gt;map&lt;/span&gt;  &lt;span class="nb"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;C4&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class="sr"&gt;/(\d+)\.(\d+)\.(\d+)\.(\d+)/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="nv"&gt;$_&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;keys&lt;/span&gt; &lt;span class="nv"&gt;%data&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="c1"&gt;# end sort by &lt;span class="caps"&gt;IP&lt;/span&gt; address&lt;/span&gt;

&lt;span class="k"&gt;foreach&lt;/span&gt; &lt;span class="k"&gt;my&lt;/span&gt; &lt;span class="nv"&gt;$key&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;@keys&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%-18s %-20s %-18s %-10s\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$key&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ip&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$key&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mac&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$key&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nv"&gt;$data&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;$key&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;if&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;A solution for&amp;nbsp;Vyatta:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I suggested this to Vyatta in a reply to &lt;a href="https://bugzilla.vyatta.com/show_bug.cgi?id=1990"&gt;bug
1990&lt;/a&gt;. Since they
already use &lt;a href="http://rsyslog.com/"&gt;rsyslog&lt;/a&gt; which has very powerful
processing capabilities, it would be easy to have rsyslog parse the
&lt;span class="caps"&gt;DHCPACK&lt;/span&gt; messages in real time and update some data store (flat files or
a simple database) with the information. While how to store this would
be up to the Vyatta guys, I have some rsyslog configuration to parse
&lt;span class="caps"&gt;DHCPACK&lt;/span&gt; messages and update a MySQL database (with two tables; one for
most recent &lt;span class="caps"&gt;ACK&lt;/span&gt; per &lt;span class="caps"&gt;IP&lt;/span&gt; address and one for most recent &lt;span class="caps"&gt;ACK&lt;/span&gt; per &lt;span class="caps"&gt;MAC&lt;/span&gt;
address) that might be of some&amp;nbsp;use:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;$template DHCPACKonIP, &amp;quot;INSERT INTO dhcplog_ip   
       SET   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       msg_type=&amp;#39;DHCPACK&amp;#39;,   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,6,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;   
       ON DUPLICATE KEY UPDATE   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       gateway=&amp;#39;%msg:R,ERE,6,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;  
&amp;quot;,SQL

$template DHCPACKonMAC, &amp;quot;INSERT INTO dhcplog_mac   
       SET   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       msg_type=&amp;#39;DHCPACK&amp;#39;,   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,6,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;   
       ON DUPLICATE KEY UPDATE   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,6,BLANK:DHCPACK on ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) to (([0-9a-f]{2}:){5}[0-9a-f]{2})( \(([^)]+)\))? via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;  
&amp;quot;,SQL

$template DHCPACKtoIP, &amp;quot;INSERT INTO dhcplog_ip   
       SET   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       msg_type=&amp;#39;DHCPACK&amp;#39;,   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,4,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;   
       ON DUPLICATE KEY UPDATE   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       gateway=&amp;#39;%msg:R,ERE,4,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;  
&amp;quot;,SQL

$template DHCPACKtoMAC, &amp;quot;INSERT INTO dhcplog_mac   
       SET   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       msg_type=&amp;#39;DHCPACK&amp;#39;,   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       mac_addr=&amp;#39;%msg:R,ERE,2,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,4,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;   
       ON DUPLICATE KEY UPDATE   
       server_ip=inet_aton(&amp;#39;%fromhost-ip%&amp;#39;),   
       date=&amp;#39;%timereported:::date-mysql%&amp;#39;,   
       client_ip=inet_aton(&amp;#39;%msg:R,ERE,1,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;),   
       gateway=&amp;#39;%msg:R,ERE,4,BLANK:DHCPACK to ([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}) \((([0-9a-f]{2}:){5}[0-9a-f]{2})\) via (([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})|eth0)--end%&amp;#39;,   
       fullmsg=&amp;#39;%msg%&amp;#39;  
&amp;quot;,SQL

:msg, startswith, &amp;quot; DHCPACK on&amp;quot; :ommysql:hostname,database,dbuser,dbpass;DHCPACKonIP
&lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; :ommysql:hostname,database,dbuser,dbpass;DHCPACKonMAC
&lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; ~ ### &lt;span class="caps"&gt;DISCARD&lt;/span&gt;

if $msg startswith &amp;#39; &lt;span class="caps"&gt;DHCPACK&lt;/span&gt; to&amp;#39; and ( not ( $msg contains &amp;#39;no client hardware address&amp;#39; ) )   
then :ommysql:hostname,database,dbuser,dbpass;DHCPACKtoMAC
&lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; :ommysql:hostname,database,dbuser,dbpass;DHCPACKtoIP
&lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; ~ ### &lt;span class="caps"&gt;DISCARD&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="dhcpd"></category><category term="rsyslog"></category><category term="vyatta"></category></entry><entry><title>php-suhosin syslog issues</title><link href="http://blog.jasonantman.com/2011/10/php-suhosin-syslog-issues/" rel="alternate"></link><updated>2011-10-21T10:24:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-10-21:2011/10/php-suhosin-syslog-issues/</id><summary type="html">&lt;p&gt;I just installed php-&lt;a href="http://www.hardened-php.net/suhosin/"&gt;suhosin&lt;/a&gt;
0.9.29 from &lt;span class="caps"&gt;EPEL&lt;/span&gt; on a CentOS 5.6 box. I&amp;#8217;m running a whole bunch of
name-based vhosts in Apache, and have a bunch of web apps, so I opted to
run suhosin in simulation mode (don&amp;#8217;t actually block anything, but log
errors) and have it log via syslog to a single file. Unfortunately, when
I configured this, the syslog messages started showing up in the wrong
place, apparently with the wrong facility &lt;em&gt;and&lt;/em&gt; priority. After some
roundabout debugging (at first assuming syslogd to be the problem), I
determined that, for whatever really strange reason (perhaps an
incorrect syslog.h on the &lt;span class="caps"&gt;EPEL&lt;/span&gt; box that built the suhosin package?) the
LOG_* constants were incorrect. I looked up the correct integer values
in &lt;code&gt;/usr/include/sys/syslog.h&lt;/code&gt; and the following configuration
directives accomplished the task&amp;nbsp;correctly:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="na"&gt;suhosin.log.syslog.facility&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;128&lt;/span&gt;
&lt;span class="c1"&gt;; 128 = LOG_LOCAL0&lt;/span&gt;

&lt;span class="na"&gt;suhosin.log.syslog.priority&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;5&lt;/span&gt;
&lt;span class="c1"&gt;; 5 = LOG_NOTICE&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This one line puts suhosin into simulation mode, where it only logs
errors instead of enforcing on&amp;nbsp;them:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="na"&gt;suhosin.simulation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;On&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="centos"></category><category term="logging"></category><category term="PHP"></category><category term="security"></category><category term="suhosin"></category><category term="syslog"></category></entry><entry><title>Quick and Simple Timestamping of Debug Logs</title><link href="http://blog.jasonantman.com/2011/09/quick-and-simple-timestamping-of-debug-logs/" rel="alternate"></link><updated>2011-09-08T07:06:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-09-08:2011/09/quick-and-simple-timestamping-of-debug-logs/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been having some issues that may be
&lt;a href="http://puppetlabs.com/"&gt;Puppet&lt;/a&gt;-related. Unfortunately, Puppet (at
least the old 0.25.4 client that I&amp;#8217;m running) doesn&amp;#8217;t timestamp the
debug logs sent to stdout. I know it&amp;#8217;s hanging somewhere, but I need
concrete numbers to look at. Here&amp;#8217;s a wonderfully simple bash script
that timestamps everything sent to it on stdin, and echoes it back to&amp;nbsp;stdout:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;DATECMD&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;date +%H:%M:%S&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;while &lt;/span&gt;&lt;span class="nb"&gt;read &lt;/span&gt;line; &lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;$($&lt;span class="caps"&gt;DATECMD&lt;/span&gt;) $line&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Call it as simply as: &lt;code&gt;command | ~/bin/ts&lt;/code&gt;, or maybe like
&lt;code&gt;command 2&amp;gt;&amp;amp;1 | ~/bin/ts | tee foo.log&lt;/code&gt;. Dead simple, but very helpful
when the developers didn&amp;#8217;t think to timestamp debug log&amp;nbsp;output.&lt;/p&gt;</summary><category term="debugging"></category><category term="logs"></category><category term="puppet"></category><category term="sysadmin"></category><category term="timestamp"></category></entry></feed>