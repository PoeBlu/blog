Title: Computer Science?
Date: 2007-03-21 13:44
Author: admin
Category: Miscellaneous
Slug: computer-science

So, I'm a computer science major at Rutgers. What is computer science?
And *WHY* is it my major?

I was recently reading an excellent article online, by Neil McBride, a
principal lecturer in the School of Computing, De Montfort University,
UK. [The Death of
Computing](http://www.bcs.org/server.php?show=ConWebDoc.9662)
essentially speaks to the fact that the IT industry is different now
than it ever was in the past - IT is no longer a *programing*discipline.
Just look at job listings in IT, whether as upper-level managers or
summer interns. How many of them demand the degree of skills in, say,
Java, that are taught in CS classes? Most of them ask for Python, Ruby,
PHP, maybe some Java. But more importantly, the jobs aren't
programming-centric. As many have said, all of the software that's
needed is already out there. The modern emphasis in IT is on providing a
service - on SLAs, uptime, optimization, security, and incident
response. Not on developing new systems in low-level languages, but in
synthesizing many assets into a coherent, high-availability system with
as much transparency to the user as possible.

Just have a look at the Rutgers CS course catalog: Data structures,
Discreet structures, numerical methods, design and analysis of
algorithms, compilers, operating systems design, artificial
intelligence. Sure, that's nice. *Where is something that will prepare
me for a career?*

Not one course in an overview of Information Technology. Where's
networking? Where's systems management/administration? How about a
course in embedded systems design, or internet/intranet security?
There's not even an intro course to Unix.

Yes, these courses provide lots of information so I can know what my
computer is doing at every step of the way. But why do I need a semester
of algorithm design when there's a world of open-source software at my
fingertips? Why should I know operating system design, when 99% of it is
done by a relatively small group of people?

It seems to be just what Mr. McBride mentioned in his article - at least
here at Rutgers, they are trying to haul up the drawbridge, to educate a
small minority of elite programmers. Where are the skills that myself,
and people my age, need when looking for a job? Internet applications,
firewall/router design, embedded systems, languages like Python, Ruby,
Perl, and other scripting languages that allow me to quickly and
efficiently accomplish a task? Is it really true that a degree in CS is
actually just "a degree", a prerequisite for a job, and everything else
should be learned on our own?

My data structures class is a perfect example. One of our projects was
using Java and Linked Lists to implement a crude example of string
comparison in a security application. Why would I do that when I can
store the data in a MySQL database and write a simple script to perform
comparisons? There's not even an introductory systems course. Are we
really aiming to educate programmers who have never seen a tape drive,
who have never had an introduction to scripting languages, how to
perform a good system backup, or how to secure their workstations?
